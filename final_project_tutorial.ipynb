{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44afbef3",
   "metadata": {},
   "source": [
    "# Final Project Starting Guide\n",
    "\n",
    "Hello everyone, welcome to the final project! This notebook is provided to you to reiterate the rules and guidelines, and give you some starting points.\n",
    "\n",
    "### What we provide\n",
    "\n",
    "In this project, we will provide you with \n",
    "- This starting guide\n",
    "- A working API that you can access under ASU network (i.e., on campus or with VPN)\n",
    "- A starting development data that you can use to develop your agent. It contains 1,000 instances with {domain, input, expected_output}\n",
    "\n",
    "### Your goal\n",
    "\n",
    "In this project, you will implement an inference-time agent to solve reasoning requests, as those provided in the development data. The grading of this project will be effort-based and you will get full credit if you produce the minimum deliverables below, with subject to the rules and requirements below.\n",
    "\n",
    "#### Minimum Deliverables\n",
    "\n",
    "1. A working agent loop (in the form of a Github project) that the TA can run, and implements *at least three* inference-time algorithms or techniques.\n",
    "2. Outputs from your agent on the released test data (see important dates). \n",
    "3. A short one-page report on how your agent works, and pointer to important techniques (referece to code blocks).\n",
    "\n",
    "#### Rules and Requirements\n",
    "1. You must only use our provided API call to access LLMs; meaning that you cannot use any other LLMs in any other way within your agent loop. Some exceptions may be made if you call certain external tools (e.g., Google search) that use some LLMs internally. Please discuss any exceptions with us to avoid penalties up to 50% of the project grade.\n",
    "2. You must not hardcode a full delegation to an external tool (e.g., google_search(input_problem)). Such delegations must be automatically selected/decided by your agent. Hardcode delegations will lead to a zero.\n",
    "3. You cannot use Cursor or any AI coding aids to implement the final project. You can, however, ask LLMs (or other online resources) for conceptual clarification or code examples. Your final project should not contain any blocks of code (i.e., > 3 lines) that are written by AI. Violations will lead to a zero.\n",
    "4. Your agent should be able to run efficiently, with <20 LLM calls per question. Exceptions may be made when you have a complicated agent but please discuss with us. Up to 10% of the project grade may be deducted if we observe very inefficient LLM usages that do not clearly benefit the performance.\n",
    "5. Your agent must run without any requests to any paid services (paid is defined by if the TA has to pay to run it, regardless of whether you actuallly pay for it or not.) Violations will lead to a zero.\n",
    "6. You must submit a Github project link as your code submission. All changes must be tracked and any commits should be within 100 lines of +/- with good messages. Points will be deducted to up to 25% of the project grade if we observe \"magic commits\" or too few commits. \n",
    "\n",
    "\n",
    "### Suggestions\n",
    "1. Start early, please.\n",
    "2. You should consider how you can evaluate whether your output is good enough compared to the provided expected_outputs, and we will not release how we will actually evaluate your outputs; meaning that you have to try to predict how we will evaluate things.\n",
    "3. Start with a basic implementation, and iterate based on mistakes/feedbacks.\n",
    "4. Find more development data, or create your own cases to stree-test your agent. \n",
    "5. You are free to modify any provided code in this starting guide, or not using any of these code at all.\n",
    "\n",
    "### Important dates\n",
    "- **Release of final test data**: 11/25/2025\n",
    "- **Deadline for submitting all deliverables**: 12/05/2025\n",
    "\n",
    "### Extra Credit. \n",
    "The top 20 projects (ranked by performance metrics on the test data and at the TA's discretion of implementation quality) will be given extra credits. The actual credits will be between 1% to 7.5% depending on the ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af7858ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Minimal setup\n",
    "# If needed (uncomment in a notebook):pip install requests python-dotenv\n",
    "\n",
    "# to create an agent loop like Openai we need tool calling first \n",
    "\n",
    "import os, json, textwrap, re, time\n",
    "import requests\n",
    "\n",
    "API_KEY  = os.getenv(\"OPENAI_API_KEY\", \"cse476\")\n",
    "API_BASE = os.getenv(\"API_BASE\", \"http://10.4.58.53:41701/v1\")  \n",
    "MODEL    = os.getenv(\"MODEL_NAME\", \"bens_model\")              \n",
    "\n",
    "def call_model_chat_completions(prompt: str,\n",
    "                                system: str = \"You are a helpful assistant. Reply with only the final answer—no explanation.\",\n",
    "                                model: str = MODEL,\n",
    "                                maxtoken : int =128,\n",
    "                                temperature: float = 0.0,\n",
    "                                timeout: int = 60) -> dict:\n",
    "    \"\"\"\n",
    "    Calls an OpenAI-style /v1/chat/completions endpoint and returns:\n",
    "    { 'ok': bool, 'text': str or None, 'raw': dict or None, 'status': int, 'error': str or None, 'headers': dict }\n",
    "    \"\"\"\n",
    "    url = f\"{API_BASE}/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "        \"Content-Type\":  \"application/json\",\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system},\n",
    "            {\"role\": \"user\",   \"content\": prompt}\n",
    "        ],\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": maxtoken,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        resp = requests.post(url, headers=headers, json=payload, timeout=timeout)\n",
    "        status = resp.status_code\n",
    "        hdrs   = dict(resp.headers)\n",
    "        if status == 200:\n",
    "            data = resp.json()\n",
    "            text = data.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "            return {\"ok\": True, \"text\": text, \"raw\": data, \"status\": status, \"error\": None, \"headers\": hdrs}\n",
    "        else:\n",
    "            # try best-effort to surface error text\n",
    "            err_text = None\n",
    "            try:\n",
    "                err_text = resp.json()\n",
    "            except Exception:\n",
    "                err_text = resp.text\n",
    "            return {\"ok\": False, \"text\": None, \"raw\": None, \"status\": status, \"error\": str(err_text), \"headers\": hdrs}\n",
    "    except requests.RequestException as e:\n",
    "        return {\"ok\": False, \"text\": None, \"raw\": None, \"status\": -1, \"error\": str(e), \"headers\": {}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f1f624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_loop(question: str, tools: list, history: list = None, max_steps: int = 6):\n",
    "    if history is None:\n",
    "        history = []\n",
    "    \n",
    "    # System prompt that teaches model about tools and final answer format\n",
    "    tool_descriptions = \"\\n\".join([f\"- {t['name']}: {t.get('description', 'No description')}\" for t in tools])\n",
    "    system_prompt = f\"\"\"You are a helpful assistant with access to these tools:\n",
    "{tool_descriptions}\n",
    "\n",
    "When you want to use a tool, say: USE TOOL: tool_name(arguments)\n",
    "When you have the final answer, say: FINAL ANSWER: your answer here\n",
    "\n",
    "IMPORTANT: Always end with FINAL ANSWER: followed by just the answer, nothing else.\n",
    "\"\"\"\n",
    "    \n",
    "    for step in range(max_steps):\n",
    "        # Construct the prompt with history\n",
    "        if history:\n",
    "            history_text = \"Previous steps:\\n\" + \"\\n\".join(history)\n",
    "            prompt = f\"Question: {question}\\n\\n{history_text}\\n\\nWhat do you want to do next? Remember to say FINAL ANSWER: when done.\"\n",
    "        else:\n",
    "            prompt = f\"Question: {question}\\n\\nWhat do you want to do next?\"\n",
    "        \n",
    "        # Call the model\n",
    "        response = call_model_chat_completions(prompt, system=system_prompt, maxtoken=256)\n",
    "        if not response['ok']:\n",
    "            print(f\"Model call failed: {response['error']}\")\n",
    "            return None\n",
    "        \n",
    "        model_output = response['text'].strip()\n",
    "        print(f\"Step {step + 1}: {model_output}\")\n",
    "        \n",
    "        # Check for final answer (case insensitive)\n",
    "        lower_output = model_output.lower()\n",
    "        if \"final answer:\" in lower_output:\n",
    "            # Extract everything after \"final answer:\"\n",
    "            idx = lower_output.find(\"final answer:\")\n",
    "            final_answer = model_output[idx + len(\"final answer:\"):].strip()\n",
    "            print(f\">>> Final answer: {final_answer}\")\n",
    "            return final_answer\n",
    "        \n",
    "        # Check if the model wants to call a tool\n",
    "        tool_called = False\n",
    "        for tool in tools:\n",
    "            if tool['name'].lower() in lower_output:\n",
    "                tool_result = tool['function'](model_output)\n",
    "                \n",
    "                # If python_code_returner was called, return the code as final answer\n",
    "                if tool['name'] == \"python_code_returner\":\n",
    "                    print(f\"    Generated code:\\n{tool_result[:200]}...\")\n",
    "                    return tool_result\n",
    "                \n",
    "                history.append(f\"Step {step + 1}: Called {tool['name']}, got result: {tool_result}\")\n",
    "                print(f\"    Tool result: {tool_result}\")\n",
    "                tool_called = True\n",
    "                break\n",
    "        \n",
    "        if not tool_called:\n",
    "            # No tool called - add to history and continue reasoning\n",
    "            # Don't extract numbers prematurely - let the model finish reasoning\n",
    "            history.append(f\"Step {step + 1}: {model_output[:200]}\")\n",
    "            # Continue to next step to let model finish\n",
    "    \n",
    "    print(\"Max steps reached without final answer\")\n",
    "    # Return the last tool result if available\n",
    "    if history:\n",
    "        last = history[-1]\n",
    "        if \"result:\" in last:\n",
    "            return last.split(\"result:\")[-1].strip()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e376f863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing calculator: 1658\n",
      "Testing python_runner: 15\n",
      "\n",
      "Testing python_code_returner: def add_numbers(a, b):\n",
      "    return a + b\n",
      "\n",
      "Testing python_code_returner: def add_numbers(a, b):\n",
      "    return a + b\n"
     ]
    }
   ],
   "source": [
    "def calculator(text):\n",
    "    \"\"\"Extract and evaluate a math expression from the model output.\"\"\"\n",
    "    # Simple approach: look for \"calculator(\" and extract until \")\"\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    if \"calculator(\" in text_lower:\n",
    "        # Find start position after \"calculator(\"\n",
    "        start = text_lower.find(\"calculator(\") + len(\"calculator(\")\n",
    "        # Find the closing parenthesis\n",
    "        end = text.find(\")\", start)\n",
    "        if end != -1:\n",
    "            expr = text[start:end].strip()\n",
    "        else:\n",
    "            expr = \"\"\n",
    "    else:\n",
    "        # Fallback: just try to find numbers and operators\n",
    "        expr = \"\"\n",
    "        for char in text:\n",
    "            if char in \"0123456789+-*/.() \":\n",
    "                expr += char\n",
    "        expr = expr.strip()\n",
    "    \n",
    "    if not expr:\n",
    "        return \"Error: No expression found\"\n",
    "    \n",
    "    try:\n",
    "        # Replace ^ with ** for exponentiation\n",
    "        expr = expr.replace(\"^\", \"**\")\n",
    "        result = eval(expr)\n",
    "        return str(result)\n",
    "    except Exception as e:\n",
    "        return \"Error: \" + str(e)\n",
    "\n",
    "\n",
    "# Tool 2: Python script runner - executes Python code safely\n",
    "def python_runner(text):\n",
    "    \"\"\"Extract and run Python code from the model output.\"\"\"\n",
    "    code = \"\"\n",
    "    \n",
    "    # first : Look for ```python and ```\n",
    "    if \"```python\" in text.lower():\n",
    "        # Find where the code starts adfter ```python\n",
    "        start_marker = \"```python\"\n",
    "        start = text.lower().find(start_marker) + len(start_marker)\n",
    "        # Find where it ends \n",
    "        end = text.find(\"```\", start)\n",
    "        if end != -1:\n",
    "            code = text[start:end].strip()\n",
    "    \n",
    "    # Method 2: Look for \"python_runner:\" \n",
    "    elif \"python_runner:\" in text.lower():\n",
    "        start = text.lower().find(\"python_runner:\") + len(\"python_runner:\")\n",
    "        code = text[start:].strip()\n",
    "    \n",
    "    # Method 3: Look for single backticks `code`\n",
    "    elif \"`\" in text:\n",
    "        start = text.find(\"`\") + 1\n",
    "        end = text.find(\"`\", start)\n",
    "        if end != -1:\n",
    "            code = text[start:end].strip()\n",
    "    \n",
    "    if not code:\n",
    "        return \"Error: No code found\"\n",
    "    \n",
    "    # Run the extracted code safely\n",
    "    try:\n",
    "        local_vars = {}\n",
    "        safe_builtins = {\n",
    "            \"print\": print, \n",
    "            \"len\": len, \n",
    "            \"range\": range,\n",
    "            \"int\": int, \n",
    "            \"float\": float, \n",
    "            \"str\": str,\n",
    "            \"list\": list, \n",
    "            \"dict\": dict, \n",
    "            \"sum\": sum,\n",
    "            \"min\": min, \n",
    "            \"max\": max, \n",
    "            \"abs\": abs,\n",
    "            \"round\": round, \n",
    "            \"sorted\": sorted\n",
    "        }\n",
    "        exec(code, {\"__builtins__\": safe_builtins}, local_vars)\n",
    "        if \"result\" in local_vars:\n",
    "            return str(local_vars[\"result\"])\n",
    "        elif local_vars:\n",
    "            return str(local_vars)\n",
    "        else:\n",
    "            return \"Code ran successfully (no output)\"\n",
    "    except Exception as e:\n",
    "        return \"Error: \" + str(e)\n",
    "\n",
    "\n",
    "# Tool 3: Chain-of-Thought reasoning for difficult problems\n",
    "def chain_of_thought(text):\n",
    "    \"\"\"\n",
    "    Analyzes problem difficulty and applies step-by-step reasoning for hard problems.\n",
    "    For easy problems, returns a quick hint. For hard problems, calls the API for deep reasoning.\n",
    "    \"\"\"\n",
    "    problem = \"\"\n",
    "    if \"cot(\" in text.lower():\n",
    "        start = text.lower().find(\"cot(\") + len(\"cot(\")\n",
    "        end = text.find(\")\", start)\n",
    "        if end != -1:\n",
    "            problem = text[start:end].strip()\n",
    "    else:\n",
    "        \n",
    "        problem = text\n",
    "    \n",
    "    if not problem:\n",
    "        return \"Error: No problem found for CoT analysis\"\n",
    "    \n",
    "    # First, ask the model to fifnd difficulty (1-10 scale)\n",
    "    difficulty_prompt = f\"\"\"Rate the difficulty of this problem on a scale of 1-10.\n",
    "1-3 = Easy (basic arithmetic, simple facts)\n",
    "4-6 = Medium (multi-step reasoning, some complexity)\n",
    "7-10 = Hard (complex math, logic puzzles, multi-step proofs)\n",
    "\n",
    "Problem: {problem}\n",
    "\n",
    "Reply with ONLY a number from 1-10.\"\"\"\n",
    "    \n",
    "    difficulty_response = call_model_chat_completions(\n",
    "        difficulty_prompt,\n",
    "        system=\"You are a problem difficulty assessor. Reply with only a number 1-10.\",\n",
    "        temperature=0.0\n",
    "    )\n",
    "    \n",
    "    # Parse the difficulty score\n",
    "    difficulty = 5  # default to medium\n",
    "    if difficulty_response['ok']:\n",
    "        try:\n",
    "            # Extract first number from response\n",
    "            for char in difficulty_response['text']:\n",
    "                if char.isdigit():\n",
    "                    difficulty = int(char)\n",
    "                    break\n",
    "        except:\n",
    "            difficulty = 5\n",
    "    \n",
    "    # If easy (1-4), give a quick hint without deep reasoning\n",
    "    if difficulty <= 4:\n",
    "        return f\"[Easy problem, difficulty={difficulty}] Think simply and give the direct answer.\"\n",
    "    \n",
    "    # If medium to hard (5-10), use Chain-of-Thought reasoning\n",
    "    cot_prompt = f\"\"\"Solve this problem step by step. Think carefully through each step.\n",
    "\n",
    "Problem: {problem}\n",
    "\n",
    "Let's think step by step:\n",
    "1. First, identify what we're asked to find.\n",
    "2. Break down the problem into smaller parts.\n",
    "3. Solve each part carefully.\n",
    "4. Combine the results for the final answer.\n",
    "\n",
    "Show your reasoning, then give the final answer.\"\"\"\n",
    "    \n",
    "    cot_response = call_model_chat_completions(\n",
    "        cot_prompt,\n",
    "        system=\"You are a careful problem solver. Think step by step before answering.\",\n",
    "        temperature=0.0,\n",
    "        maxtoken=512  # More tokens for detailed reasoning\n",
    "    )\n",
    "    \n",
    "    if cot_response['ok']:\n",
    "        reasoning = cot_response['text'].strip()\n",
    "        return f\"[Hard problem, difficulty={difficulty}] Step-by-step reasoning:\\n{reasoning}\"\n",
    "    else:\n",
    "        return f\"Error in CoT reasoning: {cot_response['error']}\"\n",
    "\n",
    "\n",
    "# Tool 4: Python code returner - generates code as output (doesn't run it)\n",
    "def python_code_returner(text):\n",
    "    \"\"\"\n",
    "    Generate Python code as the answer (not execute it).\n",
    "    Use this when the question asks you to WRITE code, not run it.\n",
    "    \"\"\"\n",
    "    # Use the full text as context for code generation\n",
    "    problem = text\n",
    "    \n",
    "    prompt = f\"\"\"Write Python code to solve this problem.\n",
    "Return ONLY the function body code - no explanations, no markdown, no comments.\n",
    "Use standard library imports if needed.\n",
    "Match the expected function signature if one is provided in the problem.\n",
    "\n",
    "Problem: {problem}\n",
    "\n",
    "Output ONLY executable Python code:\"\"\"\n",
    "    \n",
    "    response = call_model_chat_completions(\n",
    "        prompt,\n",
    "        system=\"You are a code generator. Output ONLY Python code. No explanations. No markdown. Just raw executable code that solves the problem.\",\n",
    "        temperature=0.0,\n",
    "        maxtoken=768\n",
    "    )\n",
    "    \n",
    "    if response['ok']:\n",
    "        code = response['text'].strip()\n",
    "        # Remove markdown code blocks if the model added them\n",
    "        if code.startswith(\"```python\"):\n",
    "            code = code[9:]\n",
    "        if code.startswith(\"```\"):\n",
    "            code = code[3:]\n",
    "        if code.endswith(\"```\"):\n",
    "            code = code[:-3]\n",
    "        return code.strip()\n",
    "    return \"Error generating code\"\n",
    "\n",
    "\n",
    "# Define the tools list\n",
    "tools = [\n",
    "    {\n",
    "        \"name\": \"calculator\",\n",
    "        \"description\": \"Evaluates math expressions. Use: calculator(2 + 3 * 4)\",\n",
    "        \"function\": calculator\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"python_runner\", \n",
    "        \"description\": \"Runs Python code and returns the result. Use when you need to EXECUTE code: ```python your_code ```\",\n",
    "        \"function\": python_runner\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"cot\",\n",
    "        \"description\": \"Chain-of-Thought reasoning. Use for complex problems: cot(problem description)\",\n",
    "        \"function\": chain_of_thought\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"python_code_returner\",\n",
    "        \"description\": \"Generates Python code as the FINAL ANSWER. Use when asked to WRITE/IMPLEMENT a function or code. Use: python_code_returner(task description). Returns the code itself, not execution result.\",\n",
    "        \"function\": python_code_returner\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Testing calculator:\", calculator(\"calculator(412 * 4 + 10)\"))\n",
    "print(\"Testing python_runner:\", python_runner(\"```python\\nresult = sum([1,2,3,4,5])\\n```\"))\n",
    "print(\"\\nTesting python_code_returner:\", python_code_returner(\"python_code_returner(write a function that adds two numbers)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdce9f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: USE TOOL: calculator(123*23+23+5)\n",
      "FINAL ANSWER: 2919\n",
      ">>> Final answer: 2919\n",
      "2919\n"
     ]
    }
   ],
   "source": [
    "# testing loop\n",
    "print(agent_loop(\"calculate (123*23+23+5)\", tools=tools))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6362f9",
   "metadata": {},
   "source": [
    "## 1) Smoke test: direct inference\n",
    "\n",
    "We’ll do a single request with a strict instruction to answer briefly.  \n",
    "*If you see an auth error, set `OPENAI_API_KEY` and (if needed) `API_BASE`/`MODEL_NAME`.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8c02ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: True HTTP: 200\n",
      "MODEL SAYS: 45\n"
     ]
    }
   ],
   "source": [
    "# %% Direct call example\n",
    "demo_prompt = \"What is 17 + 28? Answer with just the number.\"\n",
    "result = call_model_chat_completions(demo_prompt)\n",
    "print(\"OK:\", result[\"ok\"], \"HTTP:\", result[\"status\"])\n",
    "print(\"MODEL SAYS:\", (result[\"text\"] or \"\").strip())\n",
    "\n",
    "# Optional: Inspect rate-limit headers if your provider exposes them\n",
    "for k in [\"x-ratelimit-remaining-requests\", \"x-ratelimit-limit-requests\", \"x-request-id\"]:\n",
    "    if k in result[\"headers\"]:\n",
    "        print(f\"{k}: {result['headers'][k]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae1c568",
   "metadata": {},
   "source": [
    "## 2) A tiny test set (3 questions)\n",
    "\n",
    "We’ll cover:\n",
    "1. **Math reasoning** — inequality solving,\n",
    "2. **Common sense** — buoyancy/ice & water,\n",
    "3. **Logic** — a classic race-position puzzle.\n",
    "\n",
    "We also tightly constrain the required answer forms to enable simple auto‑grading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0334e53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Define three tests: input + expected\n",
    "tests = [\n",
    "    {\n",
    "        \"id\": \"math_inequality\",\n",
    "        \"type\": \"numeric\",  # grader will prefer numeric extraction\n",
    "        \"prompt\": \"Solve for the smallest integer n such that 3n + 5 > 26. Answer with just the integer.\",\n",
    "        \"expected\": \"8\",    # Because 3n > 21 => n > 7, smallest integer is 8\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"commonsense_ice\",\n",
    "        \"type\": \"text\",\n",
    "        \"prompt\": (\n",
    "            \"You place an ice cube in a glass of water and mark the water level. \"\n",
    "            \"After the ice melts, does the water level rise, fall, or stay the same? \"\n",
    "            \"Answer with exactly one of: 'rise', 'fall', 'stay the same'.\"\n",
    "        ),\n",
    "        \"expected\": \"stay the same\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"logic_race\",\n",
    "        \"type\": \"text\",\n",
    "        \"prompt\": (\n",
    "            \"In a race, you pass the person in second place. What position are you now in? \"\n",
    "            \"Answer with a single word like 'first', 'second', 'third'.\"\n",
    "        ),\n",
    "        \"expected\": \"second\",\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ba77d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: USE TOOL: calculator(3*n + 5 > 26)\n",
      "FINAL ANSWER: 8\n",
      ">>> Final answer: 8\n",
      "8\n",
      "Step 1: The ice cube displaces water equal to its own weight when it is floating. When it melts, the volume of water it produces is the same as the volume of water it displaced while floating. Therefore, the water level remains the same.\n",
      "\n",
      "FINAL ANSWER: stay the same\n",
      ">>> Final answer: stay the same\n",
      "stay the same\n",
      "Step 1: The ice cube displaces water equal to its own weight when it is floating. When it melts, the volume of water it produces is the same as the volume of water it displaced while floating. Therefore, the water level remains the same.\n",
      "\n",
      "FINAL ANSWER: stay the same\n",
      ">>> Final answer: stay the same\n",
      "stay the same\n",
      "Step 1: In a race, if you pass the person in second place, you take their position, which is second. Therefore, you are now in second place.\n",
      "\n",
      "FINAL ANSWER: second\n",
      ">>> Final answer: second\n",
      "second\n",
      "Step 1: In a race, if you pass the person in second place, you take their position, which is second. Therefore, you are now in second place.\n",
      "\n",
      "FINAL ANSWER: second\n",
      ">>> Final answer: second\n",
      "second\n"
     ]
    }
   ],
   "source": [
    "for test in tests:\n",
    "    print(agent_loop(test, tools))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9840398",
   "metadata": {},
   "source": [
    "## 3) Minimal evaluator\n",
    "\n",
    "We provide some example code to decide whether the agent outputs match the expected outputs, just to give you an idea of how evaluations can be done. You are free to use this code, or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffddeb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing: math_inequality ---\n",
      "Step 1: USE TOOL: calculator(3*n + 5 > 26)\n",
      "    Tool result: Error: name 'n' is not defined\n",
      "Step 1: USE TOOL: calculator(3*n + 5 > 26)\n",
      "    Tool result: Error: name 'n' is not defined\n",
      "Step 2: USE TOOL: python_runner\n",
      "```python\n",
      "# Solve for the smallest integer n such that 3n + 5 > 26\n",
      "n = 1\n",
      "while 3 * n + 5 <= 26:\n",
      "    n += 1\n",
      "n\n",
      "```\n",
      "    Tool result: {'n': 8}\n",
      "Step 2: USE TOOL: python_runner\n",
      "```python\n",
      "# Solve for the smallest integer n such that 3n + 5 > 26\n",
      "n = 1\n",
      "while 3 * n + 5 <= 26:\n",
      "    n += 1\n",
      "n\n",
      "```\n",
      "    Tool result: {'n': 8}\n",
      "Step 3: The smallest integer $ n $ that satisfies the inequality $ 3n + 5 > 26 $ is $ n = 8 $.\n",
      "\n",
      "FINAL ANSWER: 8\n",
      ">>> Final answer: 8\n",
      "\n",
      "--- Testing: commonsense_ice ---\n",
      "Step 3: The smallest integer $ n $ that satisfies the inequality $ 3n + 5 > 26 $ is $ n = 8 $.\n",
      "\n",
      "FINAL ANSWER: 8\n",
      ">>> Final answer: 8\n",
      "\n",
      "--- Testing: commonsense_ice ---\n",
      "Step 1: The ice cube displaces water equal to its own weight when it is floating. When it melts, the volume of water it adds is equal to the volume of water it displaced. Therefore, the water level remains the same.\n",
      "\n",
      "FINAL ANSWER: stay the same\n",
      ">>> Final answer: stay the same\n",
      "\n",
      "--- Testing: logic_race ---\n",
      "Step 1: The ice cube displaces water equal to its own weight when it is floating. When it melts, the volume of water it adds is equal to the volume of water it displaced. Therefore, the water level remains the same.\n",
      "\n",
      "FINAL ANSWER: stay the same\n",
      ">>> Final answer: stay the same\n",
      "\n",
      "--- Testing: logic_race ---\n",
      "Step 1: If you pass the person in second place, you take their position, which means you are now in second place. \n",
      "\n",
      "FINAL ANSWER: second\n",
      ">>> Final answer: second\n",
      "\n",
      "==================================================\n",
      "RESULTS SUMMARY\n",
      "==================================================\n",
      "Score: 3/3 correct\n",
      "✅ math_inequality: expected='8', got='8'\n",
      "✅ commonsense_ice: expected='stay the same', got='stay the same'\n",
      "✅ logic_race: expected='second', got='second'\n",
      "Step 1: If you pass the person in second place, you take their position, which means you are now in second place. \n",
      "\n",
      "FINAL ANSWER: second\n",
      ">>> Final answer: second\n",
      "\n",
      "==================================================\n",
      "RESULTS SUMMARY\n",
      "==================================================\n",
      "Score: 3/3 correct\n",
      "✅ math_inequality: expected='8', got='8'\n",
      "✅ commonsense_ice: expected='stay the same', got='stay the same'\n",
      "✅ logic_race: expected='second', got='second'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def normalize_text(s: str) -> str:\n",
    "    s = (s or \"\").strip().lower()\n",
    "    # Remove surrounding punctuation and extra whitespace\n",
    "    s = re.sub(r\"[^\\w\\s\\-']\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "\n",
    "    # Map common synonyms used in these tests\n",
    "    synonyms = {\n",
    "        \"unchanged\": \"stay the same\",\n",
    "        \"no change\": \"stay the same\",\n",
    "        \"same\": \"stay the same\",\n",
    "        \"second place\": \"second\",\n",
    "        \"2nd\": \"second\",\n",
    "        \"first place\": \"first\",\n",
    "        \"third place\": \"third\",\n",
    "    }\n",
    "    return synonyms.get(s, s)\n",
    "\n",
    "def extract_number(s: str):\n",
    "    # Returns first number occurrence as string if found, else None\n",
    "    if not s:\n",
    "        return None\n",
    "    m = re.search(r\"[-+]?\\d+(\\.\\d+)?\", s)\n",
    "    return m.group(0) if m else None\n",
    "\n",
    "def grade(expected: str, got: str, kind: str) -> bool:\n",
    "    if kind == \"numeric\":\n",
    "        exp_num = extract_number(expected)\n",
    "        got_num = extract_number(got)\n",
    "        return (exp_num is not None) and (got_num == exp_num)\n",
    "    else:\n",
    "        return normalize_text(got) == normalize_text(expected)\n",
    "\n",
    "def evaluate_tests_with_agent(tests, tools, verbose=True):\n",
    "    rows = []\n",
    "    for t in tests:\n",
    "        print(f\"\\n--- Testing: {t['id']} ---\")\n",
    "        \n",
    "        # Use agent_loop instead of direct call\n",
    "        got = agent_loop(t[\"prompt\"], tools=tools, history=None)\n",
    "        got = (got or \"\").strip()\n",
    "        \n",
    "        is_correct = grade(t[\"expected\"], got, t[\"type\"])\n",
    "        rows.append({\n",
    "            \"id\": t[\"id\"],\n",
    "            \"expected\": t[\"expected\"],\n",
    "            \"got\": got,\n",
    "            \"correct\": is_correct,\n",
    "        })\n",
    "        \n",
    "        # Small delay between tests\n",
    "        time.sleep(0.2)\n",
    "\n",
    "    # Print a summary report\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"RESULTS SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    correct = sum(1 for x in rows if x[\"correct\"])\n",
    "    print(f\"Score: {correct}/{len(rows)} correct\")\n",
    "    for x in rows:\n",
    "        mark = \"✅\" if x[\"correct\"] else \"❌\"\n",
    "        print(f\"{mark} {x['id']}: expected={x['expected']!r}, got={x['got']!r}\")\n",
    "    return rows\n",
    "\n",
    "# Run evaluation with agent loop\n",
    "results = evaluate_tests_with_agent(tests, tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6559aa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_evaluate(question, prediction, expected_answer, model=MODEL):\n",
    "    \"\"\"\n",
    "    Use the model itself as a strict grader.\n",
    "    Returns True if the model says the prediction matches the expected answer; else False.\n",
    "    Falls back to a simple normalized string compare if the model's reply is malformed.\n",
    "    \"\"\"\n",
    "    import re\n",
    "\n",
    "    system = \"You are a strict grader. Reply with exactly True or False. No punctuation. No explanation.\"\n",
    "    prompt = f\"\"\"You are grading a question-answer pair.\n",
    "\n",
    "Return exactly True if the PREDICTION would be accepted as correct for the EXPECTED_ANSWER.\n",
    "Otherwise, return False.\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "PREDICTION:\n",
    "{prediction}\n",
    "\n",
    "EXPECTED_ANSWER:\n",
    "{expected_answer}\n",
    "\n",
    "Answer with exactly: True or False\n",
    "\"\"\"\n",
    "\n",
    "    r = call_model_chat_completions(\n",
    "        prompt,\n",
    "        system=system,\n",
    "        model=model,\n",
    "        temperature=0.0,\n",
    "    )\n",
    "\n",
    "    reply = (r.get(\"text\") or \"\").strip().lower()\n",
    "    if reply.startswith(\"true\"):\n",
    "        return True\n",
    "    if reply.startswith(\"false\"):\n",
    "        return False\n",
    "\n",
    "    # Fallback: simple normalization-based equality\n",
    "    norm = lambda s: re.sub(r\"\\s+\", \" \", (s or \"\").strip().lower())\n",
    "    return norm(prediction) == norm(expected_answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7bfad26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1000 questions\n",
      "\n",
      "==================================================\n",
      "[1/10] Domain: math\n",
      "Q: Write $\\frac{3}{20}$ as a decimal....\n",
      "Expected: 0.15...\n",
      "Step 1: To convert the fraction $\\frac{3}{20}$ to a decimal, we can perform the division of 3 by 20. Let's calculate this. \n",
      "\n",
      "USE TOOL: calculator(3 / 20)\n",
      "\n",
      "FINAL ANSWER: 0.15\n",
      ">>> Final answer: 0.15\n",
      "Got: 0.15...\n",
      "LLM Judge: ✅\n",
      "Step 1: To convert the fraction $\\frac{3}{20}$ to a decimal, we can perform the division of 3 by 20. Let's calculate this. \n",
      "\n",
      "USE TOOL: calculator(3 / 20)\n",
      "\n",
      "FINAL ANSWER: 0.15\n",
      ">>> Final answer: 0.15\n",
      "Got: 0.15...\n",
      "LLM Judge: ✅\n",
      "\n",
      "==================================================\n",
      "[2/10] Domain: coding\n",
      "Q: Process a Pandas DataFrame by removing a specific column and adding a 'IsEvenIndex' column. The 'IsE...\n",
      "Expected:     # Remove specified column using pandas\n",
      "    updated_df = pd.DataFrame(df).drop(col, axis=1)\n",
      "    \n",
      "...\n",
      "\n",
      "==================================================\n",
      "[2/10] Domain: coding\n",
      "Q: Process a Pandas DataFrame by removing a specific column and adding a 'IsEvenIndex' column. The 'IsE...\n",
      "Expected:     # Remove specified column using pandas\n",
      "    updated_df = pd.DataFrame(df).drop(col, axis=1)\n",
      "    \n",
      "...\n",
      "Step 1: USE TOOL: python_code_returner(\"Implement a function to process a Pandas DataFrame by removing a specific column and adding a 'IsEvenIndex' column indicating if the index of each row is even.\")\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "def task_func(df, col):\n",
      "    # Remove the specified column\n",
      "    df = df.drop(columns=[col], errors='ignore')\n",
      "    \n",
      "    # Add 'IsEvenIndex' column\n",
      "    df['IsEvenIndex'] = df.index % 2 == 0\n",
      "    \n",
      "    return df\n",
      "```\n",
      "Step 1: USE TOOL: python_code_returner(\"Implement a function to process a Pandas DataFrame by removing a specific column and adding a 'IsEvenIndex' column indicating if the index of each row is even.\")\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "def task_func(df, col):\n",
      "    # Remove the specified column\n",
      "    df = df.drop(columns=[col], errors='ignore')\n",
      "    \n",
      "    # Add 'IsEvenIndex' column\n",
      "    df['IsEvenIndex'] = df.index % 2 == 0\n",
      "    \n",
      "    return df\n",
      "```\n",
      "    Generated code:\n",
      "import pandas as pd\n",
      "\n",
      "def process_dataframe(df, column_to_remove):\n",
      "    df = df.drop(columns=[column_to_remove])\n",
      "    df['IsEvenIndex'] = df.index % 2 == 0\n",
      "    return df...\n",
      "Got: import pandas as pd\n",
      "\n",
      "def process_dataframe(df, column_to_remove):\n",
      "    df = df.drop(columns=[column_t...\n",
      "LLM Judge: ❌\n",
      "    Generated code:\n",
      "import pandas as pd\n",
      "\n",
      "def process_dataframe(df, column_to_remove):\n",
      "    df = df.drop(columns=[column_to_remove])\n",
      "    df['IsEvenIndex'] = df.index % 2 == 0\n",
      "    return df...\n",
      "Got: import pandas as pd\n",
      "\n",
      "def process_dataframe(df, column_to_remove):\n",
      "    df = df.drop(columns=[column_t...\n",
      "LLM Judge: ❌\n",
      "\n",
      "==================================================\n",
      "[3/10] Domain: math\n",
      "Q: A triangle has vertices $P_{}^{}=(-8,5)$ , $Q_{}^{}=(-15,-19)$ , and $R_{}^{}=(1,-7)$ . The equation...\n",
      "Expected: 89...\n",
      "\n",
      "==================================================\n",
      "[3/10] Domain: math\n",
      "Q: A triangle has vertices $P_{}^{}=(-8,5)$ , $Q_{}^{}=(-15,-19)$ , and $R_{}^{}=(1,-7)$ . The equation...\n",
      "Expected: 89...\n",
      "Step 1: To solve this problem, we need to find the equation of the angle bisector of $\\angle P$ in the triangle with vertices $P = (-8, 5)$, $Q = (-15, -19)$, and $R = (1, -7)$. The equation of the bisector is given in the form $ax + 2y + c = 0$, and we are asked to find $a + c$.\n",
      "\n",
      "### Step 1: Find the vectors from point $P$ to points $Q$ and $R$\n",
      "We will use the coordinates of the points to find the vectors\n",
      ">>> Extracted answer: -8\n",
      "Got: -8...\n",
      "LLM Judge: ❌\n",
      "Step 1: To solve this problem, we need to find the equation of the angle bisector of $\\angle P$ in the triangle with vertices $P = (-8, 5)$, $Q = (-15, -19)$, and $R = (1, -7)$. The equation of the bisector is given in the form $ax + 2y + c = 0$, and we are asked to find $a + c$.\n",
      "\n",
      "### Step 1: Find the vectors from point $P$ to points $Q$ and $R$\n",
      "We will use the coordinates of the points to find the vectors\n",
      ">>> Extracted answer: -8\n",
      "Got: -8...\n",
      "LLM Judge: ❌\n",
      "\n",
      "==================================================\n",
      "[4/10] Domain: common_sense\n",
      "Q: Would Topa Inca Yupanqui have encountered the western honey bee?...\n",
      "Expected: False...\n",
      "\n",
      "==================================================\n",
      "[4/10] Domain: common_sense\n",
      "Q: Would Topa Inca Yupanqui have encountered the western honey bee?...\n",
      "Expected: False...\n",
      "Step 1: To determine whether Topa Inca Yupanqui would have encountered the western honey bee, we need to consider the historical and geographical context of his life and the natural distribution of the western honey bee.\n",
      "\n",
      "Topa Inca Yupanqui was an Inca ruler who lived in the 16th century. The western honey bee (Apis mellifera) is native to Europe, Asia, and Africa, and it was not introduced to the Americas until much later, primarily through European colonization. The Inca Empire existed before significant European contact, which began in the late 15th century.\n",
      "\n",
      "Therefore, it is highly unlikely that Top\n",
      ">>> Extracted answer: .\n",
      "Got: ....\n",
      "LLM Judge: ✅\n",
      "Step 1: To determine whether Topa Inca Yupanqui would have encountered the western honey bee, we need to consider the historical and geographical context of his life and the natural distribution of the western honey bee.\n",
      "\n",
      "Topa Inca Yupanqui was an Inca ruler who lived in the 16th century. The western honey bee (Apis mellifera) is native to Europe, Asia, and Africa, and it was not introduced to the Americas until much later, primarily through European colonization. The Inca Empire existed before significant European contact, which began in the late 15th century.\n",
      "\n",
      "Therefore, it is highly unlikely that Top\n",
      ">>> Extracted answer: .\n",
      "Got: ....\n",
      "LLM Judge: ✅\n",
      "\n",
      "==================================================\n",
      "[5/10] Domain: future_prediction\n",
      "Q: You are an agent that can predict future events. The event to be predicted: \"请预测北京时间2025-08-11, QQ音乐...\n",
      "Expected: ['Jasmine']...\n",
      "\n",
      "==================================================\n",
      "[5/10] Domain: future_prediction\n",
      "Q: You are an agent that can predict future events. The event to be predicted: \"请预测北京时间2025-08-11, QQ音乐...\n",
      "Expected: ['Jasmine']...\n",
      "Step 1: I will use the cot tool to reason about this prediction problem. I will analyze the available data and make a prediction based on the best available information.\n",
      "\n",
      "USE TOOL: cot(\"Predict the number one song on the QQ Music Pop Index in Beijing Time on 2025-08-11\")\n",
      "    Tool result: [Easy problem, difficulty=1] Think simply and give the direct answer.\n",
      "Step 1: I will use the cot tool to reason about this prediction problem. I will analyze the available data and make a prediction based on the best available information.\n",
      "\n",
      "USE TOOL: cot(\"Predict the number one song on the QQ Music Pop Index in Beijing Time on 2025-08-11\")\n",
      "    Tool result: [Easy problem, difficulty=1] Think simply and give the direct answer.\n",
      "Step 2: 预测未来事件涉及不确定性，因此无法提供确切答案。然而，基于当前数据和趋势，可以推测在2025年8月11日，QQ音乐流行指数榜的第一名可能是近期热门歌曲，例如《As It Was》或《Flowers》等流行歌曲。这些歌曲在流媒体平台上表现强劲，可能在榜单上占据高位。\n",
      "\n",
      "\\boxed{《As It Was》}\n",
      ">>> Extracted answer: 2025\n",
      "Got: 2025...\n",
      "Step 2: 预测未来事件涉及不确定性，因此无法提供确切答案。然而，基于当前数据和趋势，可以推测在2025年8月11日，QQ音乐流行指数榜的第一名可能是近期热门歌曲，例如《As It Was》或《Flowers》等流行歌曲。这些歌曲在流媒体平台上表现强劲，可能在榜单上占据高位。\n",
      "\n",
      "\\boxed{《As It Was》}\n",
      ">>> Extracted answer: 2025\n",
      "Got: 2025...\n",
      "LLM Judge: ❌\n",
      "LLM Judge: ❌\n",
      "\n",
      "==================================================\n",
      "[6/10] Domain: future_prediction\n",
      "Q: You are an agent that can predict future events. The event to be predicted: \"请预测北京时间2025-07-30, 懂车帝全...\n",
      "Expected: ['奥迪A6L', '零跑B01', '宝马3系', '迈腾', '速腾']...\n",
      "\n",
      "==================================================\n",
      "[6/10] Domain: future_prediction\n",
      "Q: You are an agent that can predict future events. The event to be predicted: \"请预测北京时间2025-07-30, 懂车帝全...\n",
      "Expected: ['奥迪A6L', '零跑B01', '宝马3系', '迈腾', '速腾']...\n",
      "Step 1: I will use the best available data and analysis to make a prediction about the top 5轿车 models on the Dachengdi National Hot List in China at 2025-07-30. I will make this prediction based on current trends, historical data, and market dynamics.\n",
      "\n",
      "I will now make the prediction. \n",
      "\n",
      "\\boxed{比亚迪汉, 奔驰C级, 奥迪A6, 丰田凯美瑞, 上汽大众帕萨特}\n",
      ">>> Extracted answer: 5\n",
      "Got: 5...\n",
      "LLM Judge: ❌\n",
      "Step 1: I will use the best available data and analysis to make a prediction about the top 5轿车 models on the Dachengdi National Hot List in China at 2025-07-30. I will make this prediction based on current trends, historical data, and market dynamics.\n",
      "\n",
      "I will now make the prediction. \n",
      "\n",
      "\\boxed{比亚迪汉, 奔驰C级, 奥迪A6, 丰田凯美瑞, 上汽大众帕萨特}\n",
      ">>> Extracted answer: 5\n",
      "Got: 5...\n",
      "LLM Judge: ❌\n",
      "\n",
      "==================================================\n",
      "[7/10] Domain: future_prediction\n",
      "Q: You are an agent that can predict future events. The event to be predicted: \"请预测北京时间2025-08-11, 新榜·微...\n",
      "Expected: ['UNIQ-王一博', '丁禹兮', 'TOP登陆少年-朱志鑫']...\n",
      "\n",
      "==================================================\n",
      "[7/10] Domain: future_prediction\n",
      "Q: You are an agent that can predict future events. The event to be predicted: \"请预测北京时间2025-08-11, 新榜·微...\n",
      "Expected: ['UNIQ-王一博', '丁禹兮', 'TOP登陆少年-朱志鑫']...\n",
      "Step 1: 预测未来事件需要基于现有的数据和趋势进行分析。然而，对于“新榜·微博指数·个人认证·日榜”的前3名作者，由于该榜单是动态变化的，且受多种因素影响（如热点事件、用户行为、内容质量等），无法准确预测具体结果。\n",
      "\n",
      "基于当前数据和趋势，可以推测该榜单的前3名作者可能包括以下几位（仅为示例，实际结果可能不同）：\n",
      "\n",
      "1.  @李子柒\n",
      "2.  @罗翔说刑法\n",
      "3.  @张朝阳\n",
      "\n",
      "因此，预测结果为：\n",
      "\n",
      "\\boxed{李\n",
      ">>> Extracted answer: 3\n",
      "Got: 3...\n",
      "LLM Judge: ❌\n",
      "Step 1: 预测未来事件需要基于现有的数据和趋势进行分析。然而，对于“新榜·微博指数·个人认证·日榜”的前3名作者，由于该榜单是动态变化的，且受多种因素影响（如热点事件、用户行为、内容质量等），无法准确预测具体结果。\n",
      "\n",
      "基于当前数据和趋势，可以推测该榜单的前3名作者可能包括以下几位（仅为示例，实际结果可能不同）：\n",
      "\n",
      "1.  @李子柒\n",
      "2.  @罗翔说刑法\n",
      "3.  @张朝阳\n",
      "\n",
      "因此，预测结果为：\n",
      "\n",
      "\\boxed{李\n",
      ">>> Extracted answer: 3\n",
      "Got: 3...\n",
      "LLM Judge: ❌\n",
      "\n",
      "==================================================\n",
      "[8/10] Domain: coding\n",
      "Q: Extracts all URLs from the provided string, analyzes each URL to extract the domain, and uses the IP...\n",
      "Expected:     urls = re.findall(r'(https?://[^\\s,]+)', myString)\n",
      "    geo_data = {}\n",
      "\n",
      "    for url in urls:\n",
      "     ...\n",
      "\n",
      "==================================================\n",
      "[8/10] Domain: coding\n",
      "Q: Extracts all URLs from the provided string, analyzes each URL to extract the domain, and uses the IP...\n",
      "Expected:     urls = re.findall(r'(https?://[^\\s,]+)', myString)\n",
      "    geo_data = {}\n",
      "\n",
      "    for url in urls:\n",
      "     ...\n",
      "Step 1: I will write a self-contained function that extracts URLs from the input string, analyzes each URL to extract the domain, and uses the IP API to get geolocation data for each domain. The function will return a dictionary mapping domains to their geolocation data.\n",
      "\n",
      "Let me proceed with writing the code. \n",
      "\n",
      "USE TOOL: python_code_returner(\"Write a function that extracts URLs from a string, extracts domains, and uses the IP API to get geolocation data for each domain. The function should return a dictionary mapping domains to their geolocation data as returned by the IP API. If an API request fails, the corresponding value will be None.\")\n",
      "Step 1: I will write a self-contained function that extracts URLs from the input string, analyzes each URL to extract the domain, and uses the IP API to get geolocation data for each domain. The function will return a dictionary mapping domains to their geolocation data.\n",
      "\n",
      "Let me proceed with writing the code. \n",
      "\n",
      "USE TOOL: python_code_returner(\"Write a function that extracts URLs from a string, extracts domains, and uses the IP API to get geolocation data for each domain. The function should return a dictionary mapping domains to their geolocation data as returned by the IP API. If an API request fails, the corresponding value will be None.\")\n",
      "    Generated code:\n",
      "import re\n",
      "import requests\n",
      "\n",
      "def extract_domains_geolocation(text):\n",
      "    urls = re.findall(r'https?://(?:www\\.)?([^\"\\']+\\.[a-z]{2,})', text)\n",
      "    domains = list(set(urls))\n",
      "    result = {}\n",
      "    for domain i...\n",
      "Got: import re\n",
      "import requests\n",
      "\n",
      "def extract_domains_geolocation(text):\n",
      "    urls = re.findall(r'https?://(...\n",
      "LLM Judge: ❌\n",
      "    Generated code:\n",
      "import re\n",
      "import requests\n",
      "\n",
      "def extract_domains_geolocation(text):\n",
      "    urls = re.findall(r'https?://(?:www\\.)?([^\"\\']+\\.[a-z]{2,})', text)\n",
      "    domains = list(set(urls))\n",
      "    result = {}\n",
      "    for domain i...\n",
      "Got: import re\n",
      "import requests\n",
      "\n",
      "def extract_domains_geolocation(text):\n",
      "    urls = re.findall(r'https?://(...\n",
      "LLM Judge: ❌\n",
      "\n",
      "==================================================\n",
      "[9/10] Domain: common_sense\n",
      "Q: Do people who smoke Djarum's like cloves?...\n",
      "Expected: True...\n",
      "\n",
      "==================================================\n",
      "[9/10] Domain: common_sense\n",
      "Q: Do people who smoke Djarum's like cloves?...\n",
      "Expected: True...\n",
      "Step 1: The question is about personal preferences and opinions, which cannot be determined through factual data or calculations. It is subjective and depends on individual tastes. \n",
      "\n",
      "Since this is not a mathematical or computational question, I cannot use any of the provided tools to answer it. \n",
      "\n",
      "FINAL ANSWER: This question is subjective and depends on individual preferences. Some people who smoke Djarum's may like cloves, while others may not.\n",
      ">>> Final answer: This question is subjective and depends on individual preferences. Some people who smoke Djarum's may like cloves, while others may not.\n",
      "Got: This question is subjective and depends on individual preferences. Some people who smoke Djarum's ma...\n",
      "LLM Judge: ✅\n",
      "Step 1: The question is about personal preferences and opinions, which cannot be determined through factual data or calculations. It is subjective and depends on individual tastes. \n",
      "\n",
      "Since this is not a mathematical or computational question, I cannot use any of the provided tools to answer it. \n",
      "\n",
      "FINAL ANSWER: This question is subjective and depends on individual preferences. Some people who smoke Djarum's may like cloves, while others may not.\n",
      ">>> Final answer: This question is subjective and depends on individual preferences. Some people who smoke Djarum's may like cloves, while others may not.\n",
      "Got: This question is subjective and depends on individual preferences. Some people who smoke Djarum's ma...\n",
      "LLM Judge: ✅\n",
      "\n",
      "==================================================\n",
      "[10/10] Domain: coding\n",
      "Q: Find and run all .bat files in a given directory, returning their file names and exit codes.\n",
      "The fun...\n",
      "Expected: \n",
      "    results = []\n",
      "    file_paths = glob.glob(os.path.join(directory_path, '*.bat'))\n",
      "\n",
      "    for file_pa...\n",
      "\n",
      "==================================================\n",
      "[10/10] Domain: coding\n",
      "Q: Find and run all .bat files in a given directory, returning their file names and exit codes.\n",
      "The fun...\n",
      "Expected: \n",
      "    results = []\n",
      "    file_paths = glob.glob(os.path.join(directory_path, '*.bat'))\n",
      "\n",
      "    for file_pa...\n",
      "Step 1: I will write a function that:\n",
      "1. Uses `glob` to find all `.bat` files in the given directory.\n",
      "2. Uses `subprocess` to run each `.bat` file.\n",
      "3. Captures the exit code for each file.\n",
      "4. Returns a list of tuples containing the file name and its exit code.\n",
      "\n",
      "Let me implement this function. \n",
      "\n",
      "USE TOOL: python_code_returner(\"Implement the function to find and run all .bat files in a given directory, returning their file names and exit codes.\")\n",
      "Step 1: I will write a function that:\n",
      "1. Uses `glob` to find all `.bat` files in the given directory.\n",
      "2. Uses `subprocess` to run each `.bat` file.\n",
      "3. Captures the exit code for each file.\n",
      "4. Returns a list of tuples containing the file name and its exit code.\n",
      "\n",
      "Let me implement this function. \n",
      "\n",
      "USE TOOL: python_code_returner(\"Implement the function to find and run all .bat files in a given directory, returning their file names and exit codes.\")\n",
      "    Generated code:\n",
      "import os\n",
      "import subprocess\n",
      "\n",
      "def find_and_run_bat_files(directory):\n",
      "    bat_files = []\n",
      "    for filename in os.listdir(directory):\n",
      "        if filename.endswith('.bat'):\n",
      "            file_path = os.path....\n",
      "Got: import os\n",
      "import subprocess\n",
      "\n",
      "def find_and_run_bat_files(directory):\n",
      "    bat_files = []\n",
      "    for filen...\n",
      "LLM Judge: ❌\n",
      "    Generated code:\n",
      "import os\n",
      "import subprocess\n",
      "\n",
      "def find_and_run_bat_files(directory):\n",
      "    bat_files = []\n",
      "    for filename in os.listdir(directory):\n",
      "        if filename.endswith('.bat'):\n",
      "            file_path = os.path....\n",
      "Got: import os\n",
      "import subprocess\n",
      "\n",
      "def find_and_run_bat_files(directory):\n",
      "    bat_files = []\n",
      "    for filen...\n",
      "LLM Judge: ❌\n",
      "\n",
      "==================================================\n",
      "FINAL SCORE: 3/10 (30.0%)\n",
      "  coding: 0/3\n",
      "  common_sense: 2/2\n",
      "  future_prediction: 0/3\n",
      "  math: 1/2\n",
      "\n",
      "==================================================\n",
      "FINAL SCORE: 3/10 (30.0%)\n",
      "  coding: 0/3\n",
      "  common_sense: 2/2\n",
      "  future_prediction: 0/3\n",
      "  math: 1/2\n"
     ]
    }
   ],
   "source": [
    "# LLM-as-judge evaluation for agent loop on dev data\n",
    "import random\n",
    "\n",
    "with open(\"cse476_final_project_dev_data.json\", \"r\") as f:\n",
    "    dev_data = json.load(f)\n",
    "\n",
    "# Filter to non-coding for simpler testing (optional)\n",
    "# dev_data = [item for item in dev_data if item['domain'] != 'coding']\n",
    "\n",
    "print(f\"Loaded {len(dev_data)} questions\")\n",
    "\n",
    "random.seed(42)\n",
    "sample = random.sample(dev_data, 10)  # Test 10 questions\n",
    "\n",
    "def evaluate_with_llm_judge(sample, tools):\n",
    "    results = []\n",
    "    correct_count = 0\n",
    "    \n",
    "    for i, item in enumerate(sample):\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"[{i+1}/{len(sample)}] Domain: {item['domain']}\")\n",
    "        print(f\"Q: {item['input'][:100]}...\")\n",
    "        print(f\"Expected: {str(item['output'])[:100]}...\")\n",
    "        \n",
    "        # Get agent's answer\n",
    "        got = agent_loop(item['input'], tools=tools)\n",
    "        if got is None:\n",
    "            got = \"\"\n",
    "        elif not isinstance(got, str):\n",
    "            got = str(got)\n",
    "        got = got.strip()\n",
    "        \n",
    "        print(f\"Got: {got[:100]}...\")\n",
    "        \n",
    "        # Use LLM as judge\n",
    "        is_correct = self_evaluate(\n",
    "            question=item['input'],\n",
    "            prediction=got,\n",
    "            expected_answer=str(item['output']),\n",
    "            model=MODEL\n",
    "        )\n",
    "        \n",
    "        if is_correct:\n",
    "            correct_count += 1\n",
    "        \n",
    "        results.append({\n",
    "            \"domain\": item['domain'],\n",
    "            \"expected\": item['output'],\n",
    "            \"got\": got,\n",
    "            \"correct\": is_correct\n",
    "        })\n",
    "        \n",
    "        print(f\"LLM Judge: {'✅' if is_correct else '❌'}\")\n",
    "        time.sleep(0.3)\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"FINAL SCORE: {correct_count}/{len(sample)} ({100*correct_count/len(sample):.1f}%)\")\n",
    "    \n",
    "    # By domain\n",
    "    domains = set(r['domain'] for r in results)\n",
    "    for d in sorted(domains):\n",
    "        d_results = [r for r in results if r['domain'] == d]\n",
    "        d_correct = sum(1 for r in d_results if r['correct'])\n",
    "        print(f\"  {d}: {d_correct}/{len(d_results)}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run evaluation\n",
    "results = evaluate_with_llm_judge(sample, tools)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
