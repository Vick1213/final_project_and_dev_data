[
  {
    "output": "A"
  },
  {
    "output": "450"
  },
  {
    "output": "Warner Bros. Records"
  },
  {
    "output": "7"
  },
  {
    "output": "Not enough information to determine the exact number of Victorians who are Catholic."
  },
  {
    "output": "1939"
  },
  {
    "output": "The context does not provide information about the host of \"Wall of Fame\" or his partnership."
  },
  {
    "output": "7"
  },
  {
    "output": "217"
  },
  {
    "output": "(C) blue ball"
  },
  {
    "output": "False"
  },
  {
    "output": "Children's Memorial Health Institute (CMHI)"
  },
  {
    "output": "False"
  },
  {
    "output": "260"
  },
  {
    "output": "700"
  },
  {
    "output": "15"
  },
  {
    "output": "(C) The Lion King"
  },
  {
    "output": "Napoleon"
  },
  {
    "output": "B"
  },
  {
    "output": "26"
  },
  {
    "output": "C"
  },
  {
    "output": "False"
  },
  {
    "output": "Cannot be determined from the given information."
  },
  {
    "output": "False"
  },
  {
    "output": "Nick Fury, Agent of S.H.I.E.L.D."
  },
  {
    "output": "B"
  },
  {
    "output": "C"
  },
  {
    "output": "A. Water can change phase."
  },
  {
    "output": "1430"
  },
  {
    "output": "D"
  },
  {
    "output": "conservative forces"
  },
  {
    "output": "Madagascar"
  },
  {
    "output": "raven"
  },
  {
    "output": "205"
  },
  {
    "output": "Breakfast at Tiffany's"
  },
  {
    "output": "60"
  },
  {
    "output": "120"
  },
  {
    "output": "A"
  },
  {
    "output": "The Many Loves of Dobie Gillis"
  },
  {
    "output": "B"
  },
  {
    "output": "Argentina"
  },
  {
    "output": "D"
  },
  {
    "output": "The national courts of member states."
  },
  {
    "output": "B"
  },
  {
    "output": "18"
  },
  {
    "output": "World War II"
  },
  {
    "output": "B"
  },
  {
    "output": "67"
  },
  {
    "output": "38.888..."
  },
  {
    "output": "A"
  },
  {
    "output": "A"
  },
  {
    "output": "False"
  },
  {
    "output": "True"
  },
  {
    "output": "Bahrain"
  },
  {
    "output": "5"
  },
  {
    "output": "20"
  },
  {
    "output": "(C) Ambiguous"
  },
  {
    "output": "30"
  },
  {
    "output": "C"
  },
  {
    "output": "A"
  },
  {
    "output": "False"
  },
  {
    "output": "21"
  },
  {
    "output": "Wisconsin"
  },
  {
    "output": "18"
  },
  {
    "output": "Wolfgang Amadeus Mozart"
  },
  {
    "output": "27"
  },
  {
    "output": "It depends on the specific context of the business, including the nature of the work and the level of automation. In capital-intensive environments, the impact may be less significant, while in labor-intensive environments, it may be more pronounced."
  },
  {
    "output": "350"
  },
  {
    "output": "12"
  },
  {
    "output": "Shen Kuo"
  },
  {
    "output": "Sir Robert Walpole"
  },
  {
    "output": "210"
  },
  {
    "output": "India"
  },
  {
    "output": "C"
  },
  {
    "output": "145"
  },
  {
    "output": "22"
  },
  {
    "output": "False"
  },
  {
    "output": "76"
  },
  {
    "output": "25"
  },
  {
    "output": "B"
  },
  {
    "output": "Rosie O'Donnell"
  },
  {
    "output": "They are both based on the same fictional character, Spider-Man, who is a superhero created by Stan Lee and Steve Ditko."
  },
  {
    "output": "D"
  },
  {
    "output": "A"
  },
  {
    "output": "320"
  },
  {
    "output": "5600"
  },
  {
    "output": "B"
  },
  {
    "output": "13"
  },
  {
    "output": "1989"
  },
  {
    "output": "04/28/2004"
  },
  {
    "output": "False"
  },
  {
    "output": "Simply Red"
  },
  {
    "output": "360"
  },
  {
    "output": "sperm whale"
  },
  {
    "output": "20"
  },
  {
    "output": "Slaughterhouse-Five"
  },
  {
    "output": "April 23, 2015"
  },
  {
    "output": "Barry White"
  },
  {
    "output": "27000"
  },
  {
    "output": "Rankine cycle"
  },
  {
    "output": "England, Scotland, and Ireland"
  },
  {
    "output": "B"
  },
  {
    "output": "False"
  },
  {
    "output": ">"
  },
  {
    "output": "False"
  },
  {
    "output": "315"
  },
  {
    "output": "15"
  },
  {
    "output": "The context provided does not give a clear answer to what \"K\" stands for in SPCK. Additional information is needed."
  },
  {
    "output": "120"
  },
  {
    "output": "4"
  },
  {
    "output": "A"
  },
  {
    "output": "182000"
  },
  {
    "output": "Cyclic Defrost"
  },
  {
    "output": "1200"
  },
  {
    "output": "C"
  },
  {
    "output": "False"
  },
  {
    "output": "False"
  },
  {
    "output": "True"
  },
  {
    "output": "incorporations be nullified for any reason other than those specified in the directive."
  },
  {
    "output": "True"
  },
  {
    "output": "30"
  },
  {
    "output": "D"
  },
  {
    "output": "False"
  },
  {
    "output": "September 25, 2017"
  },
  {
    "output": "B"
  },
  {
    "output": "4"
  },
  {
    "output": "C. No, because ocean water is too salty for plants grown on land."
  },
  {
    "output": "True"
  },
  {
    "output": "1128"
  },
  {
    "output": "80"
  },
  {
    "output": "False"
  },
  {
    "output": "83"
  },
  {
    "output": "90"
  },
  {
    "output": "The individual is the final judge of right and wrong and must follow their conscience rather than blindly obey the government."
  },
  {
    "output": "True"
  },
  {
    "output": "B"
  },
  {
    "output": "2 March 1972"
  },
  {
    "output": "Sikhism"
  },
  {
    "output": "Gravitational force."
  },
  {
    "output": "(F) Facts"
  },
  {
    "output": "Il Divo"
  },
  {
    "output": "B"
  },
  {
    "output": "C"
  },
  {
    "output": "Syria"
  },
  {
    "output": "True"
  },
  {
    "output": "2"
  },
  {
    "output": "91"
  },
  {
    "output": "Battle of the Rosebud"
  },
  {
    "output": "The text does not provide an exact figure for the upper limit of closing speakers."
  },
  {
    "output": "magnetic reversals"
  },
  {
    "output": "False"
  },
  {
    "output": "False"
  },
  {
    "output": "Kofi Annan"
  },
  {
    "output": "6"
  },
  {
    "output": "They switched to German in protest against the occupation of Prussia by Napoleon in 1806-07."
  },
  {
    "output": ""
  },
  {
    "output": "D"
  },
  {
    "output": "A"
  },
  {
    "output": "90"
  },
  {
    "output": "18"
  },
  {
    "output": "650"
  },
  {
    "output": "Manzanares"
  },
  {
    "output": "Kathleen O'Brien"
  },
  {
    "output": "Branwell Brontë"
  },
  {
    "output": "Our American Cousin"
  },
  {
    "output": "Hinduism"
  },
  {
    "output": "Asterix"
  },
  {
    "output": "54"
  },
  {
    "output": "1945 to 1951"
  },
  {
    "output": "1917-12-07"
  },
  {
    "output": "Parliament"
  },
  {
    "output": "[ [ [ [ < { ( ) } ( ) > { ( ) } ] { ( ) } ] ] ] ]"
  },
  {
    "output": "280"
  },
  {
    "output": "'{ < { } > { ( } ) > }'"
  },
  {
    "output": "2000000"
  },
  {
    "output": "Sea otter"
  },
  {
    "output": "B"
  },
  {
    "output": "True"
  },
  {
    "output": "False"
  },
  {
    "output": "F"
  },
  {
    "output": "False"
  },
  {
    "output": "6"
  },
  {
    "output": "fisherman"
  },
  {
    "output": "Parliament Square"
  },
  {
    "output": "300"
  },
  {
    "output": "C. Label all test tubes and bottles correctly."
  },
  {
    "output": "False"
  },
  {
    "output": "False"
  },
  {
    "output": "False"
  },
  {
    "output": "general relativity"
  },
  {
    "output": "20"
  },
  {
    "output": "oche"
  },
  {
    "output": "16"
  },
  {
    "output": "243"
  },
  {
    "output": "E"
  },
  {
    "output": "240"
  },
  {
    "output": "C. inexhaustible"
  },
  {
    "output": "16"
  },
  {
    "output": "16"
  },
  {
    "output": "Nusretiye Mosque"
  },
  {
    "output": "60.0"
  },
  {
    "output": "C"
  },
  {
    "output": "Dublin"
  },
  {
    "output": "D"
  },
  {
    "output": ""
  },
  {
    "output": "True"
  },
  {
    "output": "Major League Soccer"
  },
  {
    "output": "False"
  },
  {
    "output": "1596"
  },
  {
    "output": "Chengzong"
  },
  {
    "output": "False"
  },
  {
    "output": "Sapsali"
  },
  {
    "output": "False"
  },
  {
    "output": "Duke of Gloucester"
  },
  {
    "output": "120"
  },
  {
    "output": "Germany"
  },
  {
    "output": "True"
  },
  {
    "output": "J"
  },
  {
    "output": "True"
  },
  {
    "output": "False"
  },
  {
    "output": "False"
  },
  {
    "output": "B"
  },
  {
    "output": "True"
  },
  {
    "output": "Venstre"
  },
  {
    "output": "98"
  },
  {
    "output": "360"
  },
  {
    "output": "True"
  },
  {
    "output": "University of Chicago"
  },
  {
    "output": "9"
  },
  {
    "output": "42"
  },
  {
    "output": "24"
  },
  {
    "output": "5.0"
  },
  {
    "output": "99076.92"
  },
  {
    "output": "1983"
  },
  {
    "output": "D. contains air pockets."
  },
  {
    "output": "B"
  },
  {
    "output": "D"
  },
  {
    "output": "D. 75% black, 25% white"
  },
  {
    "output": "D"
  },
  {
    "output": "7"
  },
  {
    "output": "10"
  },
  {
    "output": "B"
  },
  {
    "output": "30"
  },
  {
    "output": "False"
  },
  {
    "output": "25"
  },
  {
    "output": "C"
  },
  {
    "output": "False"
  },
  {
    "output": "True"
  },
  {
    "output": "A"
  },
  {
    "output": "Bedřich Smetana"
  },
  {
    "output": "Anatoly Vasilyevich Lunacharsky"
  },
  {
    "output": "310"
  },
  {
    "output": "False"
  },
  {
    "output": "The odd Goldbach conjecture."
  },
  {
    "output": "B"
  },
  {
    "output": "Liam Cunningham"
  },
  {
    "output": "Kuwait"
  },
  {
    "output": "A"
  },
  {
    "output": "B"
  },
  {
    "output": "75"
  },
  {
    "output": "Graph Isomorphism Problem, Discrete Logarithm Problem, Integer Factorization Problem, Subset Sum Problem"
  },
  {
    "output": "10"
  },
  {
    "output": "Fiat Chrysler Automobiles N.V."
  },
  {
    "output": "False"
  },
  {
    "output": "True"
  },
  {
    "output": "True"
  },
  {
    "output": "85.75"
  },
  {
    "output": "epoxide"
  },
  {
    "output": "Spam"
  },
  {
    "output": "False"
  },
  {
    "output": "mystery-drama series"
  },
  {
    "output": "20\n\nMartha is 20 years old. Now, let's find Jeff's age.\n\nUSE TOOL: calculator(20 + 10)\nFINAL ANSWER: 30\n\nJeff is 30 years old."
  },
  {
    "output": "Hitachi"
  },
  {
    "output": "60"
  },
  {
    "output": "37"
  },
  {
    "output": "16"
  },
  {
    "output": "False"
  },
  {
    "output": "Present-day Upstate New York, the Ohio Country, and regions inhabited by Algonquian-speaking populations (Delaware and Shawnee) and Iroquoian-speaking populations (Mingo)."
  },
  {
    "output": "(C) purple present"
  },
  {
    "output": "False"
  },
  {
    "output": "Bow River and Elbow River"
  },
  {
    "output": "(D) 5pm to 7pm"
  },
  {
    "output": "synforms"
  },
  {
    "output": "3"
  },
  {
    "output": "D. They bind to mRNA."
  },
  {
    "output": "store and forward switching"
  },
  {
    "output": "True"
  },
  {
    "output": "2125"
  },
  {
    "output": "Henry Lau"
  },
  {
    "output": "17500"
  },
  {
    "output": "a large green dinosaur"
  },
  {
    "output": "Protect the environment and promote sustainable development."
  },
  {
    "output": "Daniel François Esprit Auber"
  },
  {
    "output": ""
  },
  {
    "output": "George I"
  },
  {
    "output": "A"
  },
  {
    "output": "False"
  },
  {
    "output": "False"
  },
  {
    "output": "7"
  },
  {
    "output": "B"
  },
  {
    "output": "True"
  },
  {
    "output": "20"
  },
  {
    "output": "Lippe"
  },
  {
    "output": "A"
  },
  {
    "output": "D. NaCl + H₂O"
  },
  {
    "output": "To enable uniflow steam flow, which enhances the engine's efficiency and performance."
  },
  {
    "output": "12"
  },
  {
    "output": "False"
  },
  {
    "output": ""
  },
  {
    "output": "SEAL Team Six"
  },
  {
    "output": "B"
  },
  {
    "output": "230"
  },
  {
    "output": "Error: No expression found"
  },
  {
    "output": "C"
  },
  {
    "output": "True"
  },
  {
    "output": "Davy Crockett"
  },
  {
    "output": "Home Guard"
  },
  {
    "output": "True"
  },
  {
    "output": "C"
  },
  {
    "output": "60"
  },
  {
    "output": "Sonic Mania"
  },
  {
    "output": "51"
  },
  {
    "output": "(D) 6am to 11am"
  },
  {
    "output": "D"
  },
  {
    "output": "False"
  },
  {
    "output": "26"
  },
  {
    "output": "(G) pentagon"
  },
  {
    "output": "False"
  },
  {
    "output": "Samuel P. Huntington"
  },
  {
    "output": "2"
  },
  {
    "output": "near the Dornbirner Ach"
  },
  {
    "output": "Christopher Rich"
  },
  {
    "output": "Saint Louis University"
  },
  {
    "output": "Queen Victoria"
  },
  {
    "output": "Colloblasts are specialized mushroom-shaped cells in the outer layer of the epidermis of cydippid ctenophores, consisting of a domed head with adhesive vesicles, a stalk, and a spiral thread, used to capture prey by sticking to it."
  },
  {
    "output": "B"
  },
  {
    "output": "20000"
  },
  {
    "output": "concepts like \"truth,\" \"justice,\" \"race,\" \"gender,\" and \"love\""
  },
  {
    "output": "60"
  },
  {
    "output": "Alta California"
  },
  {
    "output": "8"
  },
  {
    "output": "1.5"
  },
  {
    "output": "16"
  },
  {
    "output": "D"
  },
  {
    "output": "Mille Miglia"
  },
  {
    "output": "366"
  },
  {
    "output": "4"
  },
  {
    "output": "Pauli exclusion principle"
  },
  {
    "output": "62"
  },
  {
    "output": "C"
  },
  {
    "output": "Shayne Ward"
  },
  {
    "output": "True"
  },
  {
    "output": "150"
  },
  {
    "output": "3"
  },
  {
    "output": "Goat Island"
  },
  {
    "output": "True"
  },
  {
    "output": "(E"
  },
  {
    "output": "colloblasts"
  },
  {
    "output": "D"
  },
  {
    "output": "27, 29, 27"
  },
  {
    "output": "septum"
  },
  {
    "output": "48"
  },
  {
    "output": "(C) brown present"
  },
  {
    "output": "Denali"
  },
  {
    "output": "130000"
  },
  {
    "output": "A"
  },
  {
    "output": "D"
  },
  {
    "output": "False"
  },
  {
    "output": "Greenwich Park"
  },
  {
    "output": "The most recent era (Quaternary) is expanded in the first scale to provide a clearer and more detailed view of this relatively recent period in Earth's history."
  },
  {
    "output": "(F) black ball"
  },
  {
    "output": "Sherwood Stewart"
  },
  {
    "output": "Students from the sports club who are elected to represent their interests within the Student Government."
  },
  {
    "output": "B"
  },
  {
    "output": "D. oil and natural gas."
  },
  {
    "output": "Jane Mayer"
  },
  {
    "output": "The passage does not mention what William Smith did in the US."
  },
  {
    "output": "C"
  },
  {
    "output": "800"
  },
  {
    "output": "True"
  },
  {
    "output": "A"
  },
  {
    "output": "False"
  },
  {
    "output": "False"
  },
  {
    "output": ""
  },
  {
    "output": "C"
  },
  {
    "output": "True"
  },
  {
    "output": "175"
  },
  {
    "output": "40"
  },
  {
    "output": "False"
  },
  {
    "output": "125"
  },
  {
    "output": "B"
  },
  {
    "output": "60"
  },
  {
    "output": "D"
  },
  {
    "output": "130000"
  },
  {
    "output": "59"
  },
  {
    "output": "E"
  },
  {
    "output": "C"
  },
  {
    "output": "The question cannot be answered with the provided information."
  },
  {
    "output": "Central Asian Muslims"
  },
  {
    "output": "A"
  },
  {
    "output": "atra mors"
  },
  {
    "output": "D. wind"
  },
  {
    "output": "True"
  },
  {
    "output": "Antonio Vivaldi"
  },
  {
    "output": "jail solidarity"
  },
  {
    "output": "False"
  },
  {
    "output": ""
  },
  {
    "output": "C"
  },
  {
    "output": "3. 20 N"
  },
  {
    "output": "140"
  },
  {
    "output": "104"
  },
  {
    "output": "D"
  },
  {
    "output": "1840"
  },
  {
    "output": "False"
  },
  {
    "output": "Christine Keeler"
  },
  {
    "output": "green"
  },
  {
    "output": "The City of Six Towns"
  },
  {
    "output": "1838"
  },
  {
    "output": "636"
  },
  {
    "output": "A"
  },
  {
    "output": "Alachua County"
  },
  {
    "output": "1"
  },
  {
    "output": "6"
  },
  {
    "output": "54"
  },
  {
    "output": "1971"
  },
  {
    "output": "The Scream"
  },
  {
    "output": "8"
  },
  {
    "output": "The dilemma faced by German citizens when Hitler's secret police demanded to know if they were hiding a Jew in their house is a good example of moral civil disobedience."
  },
  {
    "output": "Charlie"
  },
  {
    "output": "True"
  },
  {
    "output": "True"
  },
  {
    "output": "Charlie"
  },
  {
    "output": "C"
  },
  {
    "output": "500"
  },
  {
    "output": "False"
  },
  {
    "output": "18"
  },
  {
    "output": "James Van Allen"
  },
  {
    "output": "C"
  },
  {
    "output": "The context does not provide the exact month when Zuffa purchased the WEC organization."
  },
  {
    "output": "False"
  },
  {
    "output": "380"
  },
  {
    "output": "Communities not mentioned in the description avoid the Tower District."
  },
  {
    "output": "False"
  },
  {
    "output": "silver"
  },
  {
    "output": "32"
  },
  {
    "output": "10"
  },
  {
    "output": "Kosovo"
  },
  {
    "output": "34"
  },
  {
    "output": ""
  },
  {
    "output": "B"
  },
  {
    "output": "1"
  },
  {
    "output": "True"
  },
  {
    "output": "D"
  },
  {
    "output": "89"
  },
  {
    "output": "20\n\nMartha is 20 years old. Now, let's find Jeff's age.\n\nUSE TOOL: calculator(20 + 10)\nFINAL ANSWER: 30\n\nJeff is 30 years old."
  },
  {
    "output": "11/11/2019"
  },
  {
    "output": "B"
  },
  {
    "output": "weighted fair queuing"
  },
  {
    "output": "16"
  },
  {
    "output": "A"
  },
  {
    "output": "False"
  },
  {
    "output": "Via Appia"
  },
  {
    "output": "358\nThe total number of wheels required to assemble all the toys is 358. \n\nNow, we subtract the total wheels required from the total wheels Henry has to find out how many wheels will be left.\n\nUSE TOOL: calculator(650 - 358)\nFINAL ANSWER: 292\nThe number of wheels left after assembling all the toys is 292."
  },
  {
    "output": "39"
  },
  {
    "output": "1927"
  },
  {
    "output": "True"
  },
  {
    "output": "1760"
  },
  {
    "output": "Titanium"
  },
  {
    "output": "C"
  },
  {
    "output": "Reduction in inequality."
  },
  {
    "output": "Lake Erie"
  },
  {
    "output": "False"
  },
  {
    "output": "7.00"
  },
  {
    "output": "15"
  },
  {
    "output": "25"
  },
  {
    "output": "729"
  },
  {
    "output": "276000"
  },
  {
    "output": "France, Argentina, the United Kingdom, Belgium, Ireland, Italy, Spain, and India."
  },
  {
    "output": "invalid"
  },
  {
    "output": "Unknown"
  },
  {
    "output": "500"
  },
  {
    "output": "26"
  },
  {
    "output": "A. A chemical change took place."
  },
  {
    "output": "True"
  },
  {
    "output": "(C) Ambiguous"
  },
  {
    "output": "02/28/2015"
  },
  {
    "output": "electromagnetic force"
  },
  {
    "output": "85.0"
  },
  {
    "output": "C"
  },
  {
    "output": "False"
  },
  {
    "output": "A. amount of neutrons"
  },
  {
    "output": ""
  },
  {
    "output": "B"
  },
  {
    "output": "C"
  },
  {
    "output": "-10"
  },
  {
    "output": "720"
  },
  {
    "output": "140"
  },
  {
    "output": "Paul Rideout"
  },
  {
    "output": "The same department within KPN."
  },
  {
    "output": "Edward Durell Stone"
  },
  {
    "output": "2"
  },
  {
    "output": "F"
  },
  {
    "output": "B"
  },
  {
    "output": "True"
  },
  {
    "output": "360"
  },
  {
    "output": "bertrand careful eyelid feign heterostructure libra paste snip southeastern wherewith"
  },
  {
    "output": "120"
  },
  {
    "output": "50000"
  },
  {
    "output": "True"
  },
  {
    "output": "(C) 5am to 11am"
  },
  {
    "output": "Newark, New Jersey"
  },
  {
    "output": "B"
  },
  {
    "output": "allow cardholders to revolve a balance"
  },
  {
    "output": "True"
  },
  {
    "output": "False"
  },
  {
    "output": "C"
  },
  {
    "output": "Poseidon"
  },
  {
    "output": "D"
  },
  {
    "output": "French"
  },
  {
    "output": "70000"
  },
  {
    "output": "Libya"
  },
  {
    "output": "80"
  },
  {
    "output": "90"
  },
  {
    "output": "Brazil"
  },
  {
    "output": "-37"
  },
  {
    "output": "17"
  },
  {
    "output": "1220  \n\nFINAL ANSWER: 1220"
  },
  {
    "output": "Crusades"
  },
  {
    "output": "29"
  },
  {
    "output": "residential and non-residential (commercial/institutional)"
  },
  {
    "output": "A"
  },
  {
    "output": "True"
  },
  {
    "output": "China"
  },
  {
    "output": "Greyia"
  },
  {
    "output": "False"
  },
  {
    "output": "Leather products."
  },
  {
    "output": "Ethiopia"
  },
  {
    "output": "D. the Sun."
  },
  {
    "output": "1987"
  },
  {
    "output": "Dog"
  },
  {
    "output": "genera of flowering plants"
  },
  {
    "output": "Rob Reiner"
  },
  {
    "output": "Islamic Caliphates"
  },
  {
    "output": "Oursel"
  },
  {
    "output": "310"
  },
  {
    "output": "Gentle Ben was a bear in a 1960s TV series."
  },
  {
    "output": "True"
  },
  {
    "output": "Trinidad and Tobago"
  },
  {
    "output": "True"
  },
  {
    "output": "A"
  },
  {
    "output": "Delhi"
  },
  {
    "output": "Air"
  },
  {
    "output": "The CYCLADES network delivered data using unreliable datagrams and end-to-end protocol mechanisms, with hosts responsible for reliable delivery."
  },
  {
    "output": "C"
  },
  {
    "output": "False"
  },
  {
    "output": "12.55"
  },
  {
    "output": "6"
  },
  {
    "output": "6.0"
  },
  {
    "output": "Cannot be determined from the given information."
  },
  {
    "output": "False"
  },
  {
    "output": "Noah"
  },
  {
    "output": "1"
  },
  {
    "output": ""
  },
  {
    "output": "D"
  },
  {
    "output": "D"
  },
  {
    "output": "B"
  },
  {
    "output": "C"
  },
  {
    "output": "False"
  },
  {
    "output": "Colonel Tom Parker"
  },
  {
    "output": "D"
  },
  {
    "output": "B"
  },
  {
    "output": "50"
  },
  {
    "output": "Datsun"
  },
  {
    "output": "360"
  },
  {
    "output": "Francisco de Orellana"
  },
  {
    "output": "Secondly, if a Directive's deadline is not met, further enforcement actions or additional consequences are initiated."
  },
  {
    "output": "False"
  },
  {
    "output": "True"
  },
  {
    "output": "D"
  },
  {
    "output": "Larry Drake"
  },
  {
    "output": "The population data for Dujiangyan City and Ezhou is not provided in the context, so a comparison cannot be made."
  },
  {
    "output": "11"
  },
  {
    "output": "28"
  },
  {
    "output": "1891"
  },
  {
    "output": "The distance is not provided in the text."
  },
  {
    "output": "D. There were no predators to control the population."
  },
  {
    "output": "A"
  },
  {
    "output": ""
  },
  {
    "output": "The context does not provide information about the main character in \"Unbroken\" or their involvement in the Olympics."
  },
  {
    "output": "The red appearance of O₂ is due to the absorption of light in the red part of the visible spectrum caused by electronic transitions within the oxygen molecule."
  },
  {
    "output": "more power from the engine"
  },
  {
    "output": "False"
  },
  {
    "output": "24"
  },
  {
    "output": "Tamara Ecclestone"
  },
  {
    "output": ""
  },
  {
    "output": "None of the options are similar to the mentioned films."
  },
  {
    "output": "D. millions of years"
  },
  {
    "output": "87"
  },
  {
    "output": "15000"
  },
  {
    "output": "247"
  },
  {
    "output": "Baran"
  },
  {
    "output": "False"
  },
  {
    "output": "Luca Guadagnino"
  },
  {
    "output": ""
  },
  {
    "output": "B"
  },
  {
    "output": "1945"
  },
  {
    "output": "Richard II"
  },
  {
    "output": "True"
  },
  {
    "output": "120000"
  },
  {
    "output": "B"
  },
  {
    "output": "gums"
  },
  {
    "output": "250"
  },
  {
    "output": "The principal and contractor."
  },
  {
    "output": "10"
  },
  {
    "output": "True"
  },
  {
    "output": "True"
  },
  {
    "output": "B"
  },
  {
    "output": "True"
  },
  {
    "output": "(C) Ambiguous"
  },
  {
    "output": "C"
  },
  {
    "output": "The question cannot be answered with the given context."
  },
  {
    "output": "ancient pottery remnants"
  },
  {
    "output": "Yahoo!"
  },
  {
    "output": "104"
  },
  {
    "output": "Lolita"
  },
  {
    "output": "Hamlet"
  },
  {
    "output": "30 reports / 15 minutes * (23 - 8) hours * 60 minutes / hour"
  },
  {
    "output": "False"
  },
  {
    "output": "The outcome of most votes can often be predicted beforehand."
  },
  {
    "output": "A"
  },
  {
    "output": "valid"
  },
  {
    "output": "April"
  },
  {
    "output": "1883"
  },
  {
    "output": "True"
  },
  {
    "output": "True"
  },
  {
    "output": "Rihanna"
  },
  {
    "output": "The expert found that the value premium may not be a consistent or reliable phenomenon, suggesting it could be period-dependent or influenced by other factors."
  },
  {
    "output": "The heart was weighed against the feather of truth to determine if a citizen was worthy of damnation. If the heart was heavier, they faced torment in the lake of fire."
  },
  {
    "output": "144"
  },
  {
    "output": "True"
  },
  {
    "output": "Home Alone"
  },
  {
    "output": "False"
  },
  {
    "output": "540"
  },
  {
    "output": "C. cool and wet"
  },
  {
    "output": "False"
  },
  {
    "output": "18"
  },
  {
    "output": "False"
  },
  {
    "output": "False"
  },
  {
    "output": "True"
  },
  {
    "output": "D"
  },
  {
    "output": "False"
  },
  {
    "output": "D"
  },
  {
    "output": "Tony Hawk"
  },
  {
    "output": "13.0"
  },
  {
    "output": "copper"
  },
  {
    "output": "Create an empire through soft power, cultural influence, economic interdependence, and diplomatic alliances without coercion or military force."
  },
  {
    "output": "True"
  },
  {
    "output": "25"
  },
  {
    "output": "Uganda"
  },
  {
    "output": "Ohio Company"
  },
  {
    "output": "Unknown"
  },
  {
    "output": "Laysan"
  },
  {
    "output": "Giving a defiant speech can be more harmful for the individual because it may be perceived as a lack of remorse or an attempt to avoid responsibility, leading to harsher legal consequences."
  },
  {
    "output": "felon"
  },
  {
    "output": "Jaleel White"
  },
  {
    "output": "False"
  },
  {
    "output": "34"
  },
  {
    "output": "Oxygen toxicity, which can lead to serious health issues such as coughing, shortness of breath, convulsions, and damage to the lungs and central nervous system."
  },
  {
    "output": "10"
  },
  {
    "output": "British"
  },
  {
    "output": "True"
  },
  {
    "output": "Stephen Fry"
  },
  {
    "output": "little"
  },
  {
    "output": "C"
  },
  {
    "output": "quince"
  },
  {
    "output": "B"
  },
  {
    "output": "Benjamin Franklin"
  },
  {
    "output": "gingerbread_saturday = 10\napple_pie_sunday = 15\napple_pie_saturday = apple_pie_sunday - 4\ngingerbread_sunday = gingerbread_saturday + 5\ntotal_earnings = (gingerbread_saturday + gingerbread_sunday) * 6 + (apple_pie_saturday + apple_pie_sunday) * 15\ntotal_earnings"
  },
  {
    "output": "Tower District"
  },
  {
    "output": "B"
  },
  {
    "output": "A"
  },
  {
    "output": "2500"
  },
  {
    "output": "22"
  },
  {
    "output": "Germany"
  },
  {
    "output": "A"
  },
  {
    "output": "Henry Cabot Lodge, Jr."
  },
  {
    "output": "Salix"
  },
  {
    "output": "Preston"
  },
  {
    "output": "King William IV"
  },
  {
    "output": "False"
  },
  {
    "output": "B"
  },
  {
    "output": "stibnite"
  },
  {
    "output": "Mud"
  },
  {
    "output": "utility lines"
  },
  {
    "output": "27"
  },
  {
    "output": ""
  },
  {
    "output": "False"
  },
  {
    "output": "Hunting and population are the main threats facing the Amazon rainforest."
  },
  {
    "output": "C. continuing long-term process."
  },
  {
    "output": "Ofcom"
  },
  {
    "output": "True"
  },
  {
    "output": "D"
  },
  {
    "output": "Charles Darwin"
  },
  {
    "output": "Hong Kong and Japan"
  },
  {
    "output": "Angela Sun"
  },
  {
    "output": "B"
  },
  {
    "output": "246"
  },
  {
    "output": "C"
  },
  {
    "output": "Seal"
  },
  {
    "output": "80"
  },
  {
    "output": "valid"
  },
  {
    "output": "Rose Mary Woods"
  },
  {
    "output": "People v. Turner"
  },
  {
    "output": "75"
  },
  {
    "output": "Article 102"
  },
  {
    "output": "False"
  },
  {
    "output": "Joint Regional Correctional Facility Southwest"
  },
  {
    "output": "valid"
  },
  {
    "output": "2"
  },
  {
    "output": "760"
  },
  {
    "output": "Not enough information to determine."
  },
  {
    "output": "26"
  },
  {
    "output": "True"
  },
  {
    "output": "D"
  },
  {
    "output": "Sugar Baby Love"
  },
  {
    "output": "12\n\nStep 9: Final Answer: 12\n\nStep 10: Final Answer: 12\n\nStep 11: Final Answer: 12\n\nStep 12: Final Answer: 12\n\nStep 13: Final Answer: 12\n\nStep 14: Final Answer: 12\n\nStep"
  },
  {
    "output": "21"
  },
  {
    "output": "1100"
  },
  {
    "output": "Kathryn"
  },
  {
    "output": "hard rock"
  },
  {
    "output": "False"
  },
  {
    "output": "Zhu Yuanzhang"
  },
  {
    "output": "peripheral tissues"
  },
  {
    "output": "False"
  },
  {
    "output": "100"
  },
  {
    "output": "High School Musical"
  },
  {
    "output": "Belfast"
  },
  {
    "output": "Sir Isaac Newton"
  },
  {
    "output": "False"
  },
  {
    "output": "101"
  },
  {
    "output": "16"
  },
  {
    "output": "False"
  },
  {
    "output": "Goldie Hawn"
  },
  {
    "output": "163"
  },
  {
    "output": "Texas's 27th congressional district"
  },
  {
    "output": "03/07/2016"
  },
  {
    "output": "False"
  },
  {
    "output": "( ( [ [ ] ] ) )"
  },
  {
    "output": "Salvador Dalí"
  },
  {
    "output": "11"
  },
  {
    "output": "Yann Martel"
  },
  {
    "output": "Sweeney Todd"
  },
  {
    "output": "True"
  },
  {
    "output": "NBA Rookie of the Year Award"
  },
  {
    "output": "east-west"
  },
  {
    "output": "False"
  },
  {
    "output": "Against"
  },
  {
    "output": "C"
  },
  {
    "output": "D. humans as predators"
  },
  {
    "output": "Choctaw, Creek, and Yamasee."
  },
  {
    "output": "C"
  },
  {
    "output": "Prince Edward Island"
  },
  {
    "output": "C"
  },
  {
    "output": "B"
  },
  {
    "output": "193"
  },
  {
    "output": "51"
  },
  {
    "output": "20.00"
  },
  {
    "output": "40"
  },
  {
    "output": "B"
  },
  {
    "output": "True"
  },
  {
    "output": "Happy Birthday to You"
  },
  {
    "output": "A"
  },
  {
    "output": "C. It is an indication of weather at a specific time."
  },
  {
    "output": "the eastern United States"
  },
  {
    "output": "False"
  },
  {
    "output": "Lindisfarne"
  },
  {
    "output": "False"
  },
  {
    "output": "False"
  },
  {
    "output": "6"
  },
  {
    "output": "quince"
  },
  {
    "output": "B"
  },
  {
    "output": "The embargo had a significant impact on energy security at an international level by causing price increases, altering competitive positions in industries, and prompting oil companies to explore new ways to increase oil supplies."
  },
  {
    "output": "Ross Case"
  },
  {
    "output": "False"
  },
  {
    "output": "True"
  },
  {
    "output": "A"
  },
  {
    "output": "Guy"
  },
  {
    "output": "False"
  },
  {
    "output": "False"
  },
  {
    "output": "Punjabi/Pashtun"
  },
  {
    "output": "Vector quantities."
  },
  {
    "output": "16"
  },
  {
    "output": "A Boy Named Sue"
  },
  {
    "output": "Duisburg"
  },
  {
    "output": "Mark Gaudet is a Canadian musician in the indie and metal genres, and Jan Axel Blomberg is a Norwegian heavy metal drummer."
  },
  {
    "output": "C"
  },
  {
    "output": "Bellamy family"
  },
  {
    "output": "The genus Beroe juveniles live in the same area as their parents."
  },
  {
    "output": "460"
  },
  {
    "output": "B"
  },
  {
    "output": "Johnny Edwards"
  },
  {
    "output": "Steve Coogan"
  },
  {
    "output": "40"
  },
  {
    "output": "Dick Fosbury"
  },
  {
    "output": "C"
  },
  {
    "output": "45"
  },
  {
    "output": "B"
  },
  {
    "output": "Margaret Mitchell"
  },
  {
    "output": "B"
  },
  {
    "output": "False"
  },
  {
    "output": "2010"
  },
  {
    "output": "1"
  },
  {
    "output": "C"
  },
  {
    "output": "A"
  },
  {
    "output": "599"
  },
  {
    "output": ""
  },
  {
    "output": "335"
  },
  {
    "output": "False"
  },
  {
    "output": "False"
  },
  {
    "output": "B"
  },
  {
    "output": "False"
  },
  {
    "output": "15"
  },
  {
    "output": "3"
  },
  {
    "output": "36"
  },
  {
    "output": "Illinois"
  },
  {
    "output": "J"
  },
  {
    "output": "Dartmouth College"
  },
  {
    "output": "Double Agent"
  },
  {
    "output": "Erich Maria Remarque"
  },
  {
    "output": "7"
  },
  {
    "output": "True"
  },
  {
    "output": "False"
  },
  {
    "output": "B"
  },
  {
    "output": "The Edict of Nantes granted the Huguenots religious and political freedom within their domains and equality with Catholics under the throne."
  },
  {
    "output": "Lancashire"
  },
  {
    "output": "B"
  },
  {
    "output": "#JeSuisCharlie"
  },
  {
    "output": "1999"
  },
  {
    "output": "17"
  },
  {
    "output": "272"
  },
  {
    "output": "Competitive pressures within the capitalist system to reduce costs and maximize profits push businesses to increase pressures on workers by substituting capital equipment for labor inputs."
  },
  {
    "output": "True"
  },
  {
    "output": ""
  },
  {
    "output": "Ladysmith"
  },
  {
    "output": "Agent Carter"
  },
  {
    "output": "Kathryn Blair"
  },
  {
    "output": "House of Fraser"
  },
  {
    "output": "Diepoldsau"
  },
  {
    "output": "Cannot be determined from the given information."
  },
  {
    "output": "18"
  },
  {
    "output": "32"
  },
  {
    "output": "B. Populations of mice and rats would increase."
  },
  {
    "output": "False"
  },
  {
    "output": "42"
  },
  {
    "output": "110"
  },
  {
    "output": "30"
  },
  {
    "output": "dodo"
  },
  {
    "output": "Chicago"
  },
  {
    "output": "radish"
  },
  {
    "output": "False"
  },
  {
    "output": "True"
  },
  {
    "output": "B"
  },
  {
    "output": "5"
  },
  {
    "output": "30"
  },
  {
    "output": "False"
  },
  {
    "output": "False"
  },
  {
    "output": "True"
  },
  {
    "output": "Parson Brown"
  },
  {
    "output": "True"
  },
  {
    "output": "A"
  },
  {
    "output": "False"
  },
  {
    "output": "54"
  },
  {
    "output": "GEICO"
  },
  {
    "output": "294"
  },
  {
    "output": "Gilbert du Motier, Marquis de Lafayette"
  },
  {
    "output": "True"
  },
  {
    "output": "Bagram detention facility"
  },
  {
    "output": "34"
  },
  {
    "output": "1984 South Asian Games"
  },
  {
    "output": "A"
  },
  {
    "output": "1830"
  },
  {
    "output": "26 August 1914"
  },
  {
    "output": "6"
  },
  {
    "output": "John M. Grunsfeld"
  },
  {
    "output": "1988 Winter Olympics ski jumping events"
  },
  {
    "output": "160"
  },
  {
    "output": "northern Syria"
  },
  {
    "output": "109080"
  },
  {
    "output": "(F) Facts"
  },
  {
    "output": "225"
  },
  {
    "output": "D"
  },
  {
    "output": "False"
  },
  {
    "output": "A. biomass"
  },
  {
    "output": "D"
  },
  {
    "output": "D. 7"
  },
  {
    "output": "131.57894736842106"
  },
  {
    "output": "B"
  },
  {
    "output": "D"
  },
  {
    "output": "110"
  },
  {
    "output": "Queen In-hyun's Man"
  },
  {
    "output": "112"
  },
  {
    "output": "Volta Region"
  },
  {
    "output": "27"
  },
  {
    "output": "Interstate 22"
  },
  {
    "output": "Billy Preston"
  },
  {
    "output": "24300"
  },
  {
    "output": "The length of the ancient road is not specified in the context."
  },
  {
    "output": "Belfast"
  },
  {
    "output": "2"
  },
  {
    "output": "False"
  },
  {
    "output": "16"
  },
  {
    "output": "False"
  },
  {
    "output": "57.00"
  },
  {
    "output": "D. volcanic"
  },
  {
    "output": "The act lacks the element of conscientious intent to change the law for the benefit of society."
  },
  {
    "output": "A"
  },
  {
    "output": "1450000"
  },
  {
    "output": "10"
  },
  {
    "output": "naturally occurring"
  },
  {
    "output": "B"
  },
  {
    "output": "C"
  },
  {
    "output": "True"
  },
  {
    "output": "False"
  },
  {
    "output": "False"
  },
  {
    "output": "C. The soil temperature decreased more quickly than the air temperature."
  },
  {
    "output": "The Royal Society thought the Earth was older than previously thought because Hutton's theory indicated that geological processes required a much longer timescale."
  },
  {
    "output": "William McKinley"
  },
  {
    "output": "4000"
  },
  {
    "output": "5"
  },
  {
    "output": "31.00"
  },
  {
    "output": "2011"
  },
  {
    "output": "False"
  },
  {
    "output": "Lemuel"
  },
  {
    "output": "Betty Meggers"
  },
  {
    "output": "May through September"
  },
  {
    "output": "2"
  },
  {
    "output": "from datetime import datetime\n\nstart_date = datetime(1943, 4, 19)\nend_date = datetime(1943, 6, 1)\nduration = end_date - start_date\nprint(duration.days)"
  },
  {
    "output": "B"
  },
  {
    "output": "False"
  },
  {
    "output": "750"
  },
  {
    "output": "( ( ( [ { } ] ) )"
  },
  {
    "output": "[20, 1, 18, 6, 17, 8, 12, 9, 14, 5, 19, 2]"
  },
  {
    "output": "E"
  },
  {
    "output": "The context does not provide the number of sides on the pre-decimal British threepence coin."
  },
  {
    "output": "The information provided is insufficient to determine the answer."
  },
  {
    "output": "3"
  },
  {
    "output": "Personal History"
  },
  {
    "output": "D"
  },
  {
    "output": "Earth Inductor Compass"
  },
  {
    "output": "A. construct a prototype of a boat for testing"
  },
  {
    "output": "240"
  },
  {
    "output": "warfarin"
  },
  {
    "output": "4"
  },
  {
    "output": "B"
  },
  {
    "output": "350.0"
  },
  {
    "output": "250"
  },
  {
    "output": "True"
  },
  {
    "output": "M"
  },
  {
    "output": "D"
  },
  {
    "output": "36"
  },
  {
    "output": "600"
  },
  {
    "output": "by-election"
  },
  {
    "output": "False"
  },
  {
    "output": "The Flintstones"
  },
  {
    "output": "1025"
  },
  {
    "output": "Film directors"
  },
  {
    "output": "1968"
  },
  {
    "output": "patrimonial feudalism"
  },
  {
    "output": "8"
  },
  {
    "output": "House of Windsor"
  },
  {
    "output": "Neoclassical architecture"
  },
  {
    "output": "58"
  },
  {
    "output": "4"
  },
  {
    "output": "Hannibal"
  },
  {
    "output": "February 14, 1859"
  },
  {
    "output": "12"
  },
  {
    "output": "True"
  },
  {
    "output": "parabolic path"
  },
  {
    "output": "Music and dance"
  },
  {
    "output": "B"
  },
  {
    "output": "(A) The technician could pay"
  },
  {
    "output": "Lisburn Distillery F.C."
  },
  {
    "output": "98"
  },
  {
    "output": "Comme des Garçons"
  },
  {
    "output": "C"
  },
  {
    "output": "D"
  },
  {
    "output": "rotation or inversion"
  },
  {
    "output": "Rowley Mile"
  },
  {
    "output": "Botany Bay"
  },
  {
    "output": "6"
  },
  {
    "output": "OK Mozart Festival"
  },
  {
    "output": "F"
  },
  {
    "output": "True"
  },
  {
    "output": "75.0"
  },
  {
    "output": "68"
  },
  {
    "output": "568"
  },
  {
    "output": "D"
  },
  {
    "output": "False"
  },
  {
    "output": "False"
  },
  {
    "output": "True"
  },
  {
    "output": "66"
  },
  {
    "output": "221"
  },
  {
    "output": "50"
  },
  {
    "output": "2"
  },
  {
    "output": "To avoid being targeted by the boycott."
  },
  {
    "output": "False"
  },
  {
    "output": "176"
  },
  {
    "output": "True"
  },
  {
    "output": "True"
  },
  {
    "output": "Forever Living Products"
  },
  {
    "output": "Henry Lau"
  },
  {
    "output": "B"
  },
  {
    "output": "623"
  },
  {
    "output": "D"
  },
  {
    "output": "1.5"
  },
  {
    "output": "False"
  },
  {
    "output": "Winnebago"
  },
  {
    "output": "False"
  },
  {
    "output": "1991"
  },
  {
    "output": "Madeleine L'Engle"
  },
  {
    "output": "False"
  },
  {
    "output": "Cannot be determined from the given context."
  },
  {
    "output": "False"
  },
  {
    "output": "5"
  },
  {
    "output": "The interior of the continent beyond the known territories."
  },
  {
    "output": "tepuis"
  },
  {
    "output": "Che Guevara"
  },
  {
    "output": "invalid"
  },
  {
    "output": "C. 1:00 P.M."
  },
  {
    "output": "**\nFINAL ANSWER: 18"
  },
  {
    "output": "False"
  },
  {
    "output": "32"
  },
  {
    "output": "Japan"
  },
  {
    "output": "D"
  },
  {
    "output": "Mr. Colley, The Miller's Wife, Maggie, Tom, Dick, and Jane."
  },
  {
    "output": "Electronic Frontier Foundation"
  },
  {
    "output": "True"
  },
  {
    "output": "True"
  },
  {
    "output": "(C) The truck is the oldest"
  },
  {
    "output": "False"
  },
  {
    "output": "2"
  },
  {
    "output": "Lulu"
  },
  {
    "output": "6"
  },
  {
    "output": "42.00"
  },
  {
    "output": "Dragon"
  },
  {
    "output": "B"
  },
  {
    "output": "agile, blackguard, butt, cognoscenti, clapeyron, flamboyant, geophysical, lightfooted, manumitted, meager, mathieu, purposive, reconnaissance, sawbelly, scribe, seaworthy, woodcut, yves"
  },
  {
    "output": "the world"
  },
  {
    "output": "3"
  },
  {
    "output": "42"
  },
  {
    "output": "C"
  },
  {
    "output": "Edward III"
  },
  {
    "output": "145"
  },
  {
    "output": "False"
  },
  {
    "output": "14"
  },
  {
    "output": "2015"
  },
  {
    "output": "11050"
  },
  {
    "output": "The context provided does not specify the name of the actress to whom Bette Davis made the quote, so the answer cannot be determined from the given information."
  },
  {
    "output": "410"
  },
  {
    "output": "Fort Duquesne"
  },
  {
    "output": "82"
  },
  {
    "output": "True"
  },
  {
    "output": "C"
  },
  {
    "output": "A"
  },
  {
    "output": "Hadrian"
  },
  {
    "output": "16.666666666666664"
  },
  {
    "output": "False"
  },
  {
    "output": "10"
  },
  {
    "output": "False"
  },
  {
    "output": "True"
  },
  {
    "output": "Nadia Comaneci"
  },
  {
    "output": "False"
  },
  {
    "output": "The context does not provide enough information to determine which district Witkins Township is served by."
  },
  {
    "output": "C. There is less water vapor in the desert air."
  },
  {
    "output": "(C) Ambiguous"
  },
  {
    "output": "90000"
  },
  {
    "output": "True"
  },
  {
    "output": "D. kg/m³"
  },
  {
    "output": "The number of rooms in the hotel that is home to the Cirque du Soleil show \"Mystère\" cannot be determined from the given context."
  },
  {
    "output": "The issue that plagues the literature about civil disobedience is the lack of a clear and consistent definition, leading to confusion and ambiguity in the discourse."
  },
  {
    "output": "Martha Coolidge"
  },
  {
    "output": "False"
  },
  {
    "output": "A"
  },
  {
    "output": "Green Bay Packers"
  },
  {
    "output": "False"
  },
  {
    "output": "17"
  },
  {
    "output": "D. the scientific method"
  },
  {
    "output": "A"
  },
  {
    "output": "False"
  },
  {
    "output": "They were both military figures associated with the Nazi regime and had connections to World War I."
  },
  {
    "output": "Haiti"
  },
  {
    "output": "A"
  },
  {
    "output": "Warsaw Citadel"
  },
  {
    "output": "C"
  },
  {
    "output": ""
  },
  {
    "output": "stringed instrument"
  },
  {
    "output": "B"
  },
  {
    "output": "1800"
  },
  {
    "output": "B"
  },
  {
    "output": "140"
  },
  {
    "output": "False"
  },
  {
    "output": "traditional or pre-modern context"
  },
  {
    "output": "1"
  },
  {
    "output": "False"
  },
  {
    "output": "simplified representations of orogenic wedges"
  },
  {
    "output": "C"
  },
  {
    "output": "240"
  },
  {
    "output": "35"
  },
  {
    "output": "Wyre"
  },
  {
    "output": "False"
  },
  {
    "output": "False"
  },
  {
    "output": "17"
  },
  {
    "output": "mono"
  },
  {
    "output": "4.0"
  },
  {
    "output": "False"
  },
  {
    "output": "B"
  },
  {
    "output": "Vanuatu"
  },
  {
    "output": "40"
  },
  {
    "output": "C"
  },
  {
    "output": "C"
  },
  {
    "output": "Trina Gulliver"
  },
  {
    "output": "Prince George's County"
  },
  {
    "output": "A. an observation."
  },
  {
    "output": "True"
  },
  {
    "output": "False"
  },
  {
    "output": "30"
  },
  {
    "output": "A"
  },
  {
    "output": "(A) They were my parent's secretary"
  },
  {
    "output": "False"
  },
  {
    "output": "A"
  },
  {
    "output": "Dominic Monaghan"
  },
  {
    "output": "False"
  },
  {
    "output": "Blut und Boden"
  },
  {
    "output": "50"
  },
  {
    "output": "Islam"
  },
  {
    "output": "A"
  },
  {
    "output": "**\n31"
  },
  {
    "output": "None of the listed names"
  },
  {
    "output": "145"
  },
  {
    "output": "γδ TCR"
  },
  {
    "output": "2"
  },
  {
    "output": "B"
  },
  {
    "output": "28.0"
  },
  {
    "output": "9"
  },
  {
    "output": "B"
  },
  {
    "output": "32"
  },
  {
    "output": "The Visit"
  },
  {
    "output": "True"
  },
  {
    "output": "O"
  },
  {
    "output": "True"
  },
  {
    "output": "False"
  },
  {
    "output": "C"
  },
  {
    "output": "False"
  },
  {
    "output": "Chestnut Avenue"
  },
  {
    "output": "4"
  },
  {
    "output": "Angola"
  },
  {
    "output": "The problem cannot be solved without the actual data on the ages of the penguins and giraffes."
  },
  {
    "output": "225"
  },
  {
    "output": "12"
  },
  {
    "output": "Brian Blessed"
  },
  {
    "output": "Uighur King of Qocho"
  },
  {
    "output": "120"
  },
  {
    "output": "C"
  },
  {
    "output": "Balkans"
  },
  {
    "output": "84"
  },
  {
    "output": ""
  },
  {
    "output": "D. release of chlorofluorocarbons from aerosol cans"
  },
  {
    "output": "93000"
  },
  {
    "output": "18000"
  },
  {
    "output": "Association of American University Presses"
  },
  {
    "output": "46000"
  },
  {
    "output": "D. steam rising from boiling water"
  },
  {
    "output": "40"
  },
  {
    "output": "True"
  },
  {
    "output": "It could be profitable for a steel company to eliminate competition in the Japanese bulk carrier market, given the high market share of Japan in bulk carrier construction and the reliance on steel for hulls. However, this depends on various factors such as market regulations and demand."
  },
  {
    "output": "A"
  },
  {
    "output": "Dissection"
  },
  {
    "output": "100"
  },
  {
    "output": "O₂"
  },
  {
    "output": "March and April"
  },
  {
    "output": "Kim Jong-hyun"
  },
  {
    "output": "3"
  },
  {
    "output": "A"
  },
  {
    "output": "True"
  },
  {
    "output": "B"
  },
  {
    "output": "B"
  },
  {
    "output": "Socialists think the means of production should be socially owned."
  },
  {
    "output": "1"
  },
  {
    "output": "True"
  },
  {
    "output": "The first ever website."
  },
  {
    "output": "B"
  },
  {
    "output": "720"
  },
  {
    "output": "1880s"
  },
  {
    "output": "221.88"
  },
  {
    "output": "Norway"
  },
  {
    "output": "Georgetown University"
  },
  {
    "output": "A"
  },
  {
    "output": "False"
  },
  {
    "output": "220.40"
  },
  {
    "output": "locomotion"
  },
  {
    "output": "Rachel, Nevada"
  },
  {
    "output": "132"
  },
  {
    "output": "True"
  },
  {
    "output": "C. responding to its environment"
  },
  {
    "output": "African-American"
  },
  {
    "output": "C"
  },
  {
    "output": "(A) They were my cousin's boss"
  },
  {
    "output": "6"
  },
  {
    "output": ""
  },
  {
    "output": "def calculate_distance():\n    import math\n    def haversine(lat1, lon1, lat2, lon2):\n        R = 3959  # radius of the earth in miles\n        dLat = math.radians(lat2 - lat1)\n        dLon = math.radians(lon2 - lon1)\n        a = math.sin(dLat/2) * math.sin(dLat/2) + math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) * math.sin(dLon/2) * math.sin(dLon/2)\n        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n        return R * c\n    sacramento_lat, sacramento_lon = 38.5816, -121.4944\n    atwater_lat, atwater_lon = 34.0522, -118.2437\n    distance = haversine(sacramento_lat, sacramento_lon, atwater_lat, atwater_lon)\n    return distance"
  },
  {
    "output": "14"
  },
  {
    "output": "True"
  },
  {
    "output": "Whaling"
  },
  {
    "output": "False"
  },
  {
    "output": "D. an observation"
  },
  {
    "output": "True"
  },
  {
    "output": "GNU GPLv3"
  },
  {
    "output": "field"
  },
  {
    "output": "A"
  },
  {
    "output": "1989"
  },
  {
    "output": "Leopold Kronenberg Palace"
  },
  {
    "output": "True"
  },
  {
    "output": "Halloween"
  },
  {
    "output": "Ghanaian national team"
  },
  {
    "output": "Dirk Nowitzki"
  },
  {
    "output": "Pickwick"
  },
  {
    "output": "95.0"
  },
  {
    "output": "National Lottery"
  },
  {
    "output": "B"
  },
  {
    "output": "A"
  },
  {
    "output": "Insufficient information to determine which city is larger."
  },
  {
    "output": "5"
  },
  {
    "output": "20"
  },
  {
    "output": "182"
  },
  {
    "output": "135"
  },
  {
    "output": "7"
  },
  {
    "output": "C"
  },
  {
    "output": "True"
  },
  {
    "output": "hash tables"
  },
  {
    "output": "Kopassus"
  },
  {
    "output": "D"
  },
  {
    "output": "75"
  },
  {
    "output": "The context does not provide the actual medal count for the United States at the 2010 Winter Olympics."
  },
  {
    "output": "The origin of the word \"Punic\" is from the Latin \"Punicus,\" derived from the Greek \"Phoinix,\" referring to the Phoenician people, as Carthage was a Phoenician colony."
  },
  {
    "output": "B"
  },
  {
    "output": "False"
  },
  {
    "output": "False"
  },
  {
    "output": "D"
  },
  {
    "output": "127 Hours"
  },
  {
    "output": "B"
  },
  {
    "output": "True"
  },
  {
    "output": "Fenn Street School"
  },
  {
    "output": "The information provided does not specify who sang behind Huey Lewis."
  },
  {
    "output": "B"
  },
  {
    "output": "flushing action of tears and urine"
  },
  {
    "output": "Principality of Andorra"
  },
  {
    "output": "True"
  },
  {
    "output": "16"
  },
  {
    "output": "False"
  },
  {
    "output": "A"
  },
  {
    "output": "75"
  },
  {
    "output": "Cardiff, Wales"
  },
  {
    "output": "1"
  },
  {
    "output": "Ralph Waite"
  },
  {
    "output": "True"
  },
  {
    "output": "Thailand"
  },
  {
    "output": "50"
  },
  {
    "output": "False"
  },
  {
    "output": "False"
  },
  {
    "output": "224"
  },
  {
    "output": "B"
  },
  {
    "output": "120"
  },
  {
    "output": "C"
  },
  {
    "output": "a la Florentine"
  },
  {
    "output": "125"
  },
  {
    "output": "True"
  },
  {
    "output": "Jacques Feyder"
  },
  {
    "output": "False"
  },
  {
    "output": "90"
  },
  {
    "output": "A"
  },
  {
    "output": "2"
  },
  {
    "output": "Gilbert and George"
  },
  {
    "output": "1963"
  },
  {
    "output": "02/01/2012"
  },
  {
    "output": "False"
  },
  {
    "output": "False"
  },
  {
    "output": "150"
  },
  {
    "output": "True"
  },
  {
    "output": "18"
  },
  {
    "output": "Wing Chun"
  },
  {
    "output": "False"
  },
  {
    "output": "Mount Washington"
  },
  {
    "output": "C"
  },
  {
    "output": "5"
  },
  {
    "output": "C"
  },
  {
    "output": "The first institution to offer higher education to women."
  },
  {
    "output": "Somerset County, Pennsylvania"
  },
  {
    "output": "154"
  },
  {
    "output": "21"
  },
  {
    "output": "15"
  },
  {
    "output": "90"
  },
  {
    "output": "1644"
  },
  {
    "output": "Boolean circuits"
  },
  {
    "output": "Sky+"
  },
  {
    "output": "William Hartnell"
  },
  {
    "output": "B"
  },
  {
    "output": "7\n\nThe total number of letters in Indras and her sister's names is 6 + 7 = 13.\n\nFINAL ANSWER: 13"
  },
  {
    "output": "A"
  },
  {
    "output": "A"
  },
  {
    "output": "A"
  },
  {
    "output": "True"
  },
  {
    "output": "Alf Clausen"
  },
  {
    "output": "A"
  },
  {
    "output": "D"
  },
  {
    "output": "True"
  },
  {
    "output": "Květa Peschke"
  },
  {
    "output": "True"
  },
  {
    "output": "90"
  },
  {
    "output": "A"
  },
  {
    "output": "B. It produces spores."
  },
  {
    "output": "AUSTPAC"
  },
  {
    "output": "False"
  },
  {
    "output": "Kim Bass"
  },
  {
    "output": "44"
  },
  {
    "output": "Erie Canal"
  },
  {
    "output": "9"
  },
  {
    "output": "water flow through the body cavity"
  },
  {
    "output": "Billy Idol"
  },
  {
    "output": "10"
  },
  {
    "output": "B"
  },
  {
    "output": "Dick Smith Super-80 Computer"
  },
  {
    "output": "Brown v. Board of Education of Topeka"
  },
  {
    "output": "True"
  },
  {
    "output": "227"
  },
  {
    "output": "16"
  },
  {
    "output": "[Hard problem, difficulty=7] Step-by-step reasoning:\nLet's solve the problem step by step.\n\n---\n\n### **Step 1: Identify what we're asked to find**\n\nWe are asked to find the **maximum number of popsicle sticks** Frederick can make, given a **budget** and **wood options**.\n\nHowever, the problem as presented does **not include specific values** for the budget or the wood options. This is a **critical missing piece** of information.\n\n---\n\n### **Step 2: Break down the problem into smaller parts**\n\nTo solve this, we need the following:\n\n1. **Cost of one popsicle stick** (in dollars or another currency).\n2. **Total budget** available to Frederick.\n3. **Wood options** (e.g., type of wood, cost per unit, or quantity available).\n4. **Wood required per popsicle stick** (e.g., how much wood is needed to make one stick).\n\nWithout these details, we cannot compute the maximum number of popsicle sticks.\n\n---\n\n### **Step 3: Solve each part carefully**\n\nLet’s assume the following (since the original problem is incomplete):\n\n- **Cost of one popsicle stick**: $0.10\n- **Total budget**: $10\n- **Wood required per popsicle stick**: 10 cm of wood\n- **Wood available**: 100 cm\n\nNow, we can proceed.\n\n#### **Part A: Calculate how many popsicle sticks can be made based on budget**\n\n$$\n\\text{Number of popsicle sticks} = \\frac{\\text{Total budget}}{\\text{Cost per popsicle stick}} = \\frac{10}{0.10} = 100\n$$\n\nSo, based on budget, Frederick can make **100 popsicle sticks**.\n\n#### **Part B: Calculate how many popsicle sticks can be made based on wood availability**\n\n$$\n\\text{Number of popsicle sticks} = \\frac{\\text{Total wood available}}{\\text{Wood required per popsicle stick}} = \\frac{100}{10} = 10\n$$\n\nSo, based on wood, Frederick can make **10 popsicle sticks**.\n\n---\n\n### **Step 4: Combine the results for the final answer**\n\nSince the number of popsicle sticks is limited by the **smaller of the two values** (budget vs. wood), the **maximum number of popsicle sticks** Frederick can make is:\n\n$$\n\\boxed{10}\n$$"
  },
  {
    "output": "Chaerophyllum"
  },
  {
    "output": "C"
  },
  {
    "output": "5.0"
  },
  {
    "output": "100"
  },
  {
    "output": "7"
  },
  {
    "output": "False"
  },
  {
    "output": "La Traviata"
  },
  {
    "output": "70"
  },
  {
    "output": "D"
  },
  {
    "output": "Legal restrictions, particularly those related to the Establishment Clause and Blaine Amendments."
  },
  {
    "output": "63"
  },
  {
    "output": "18"
  },
  {
    "output": "False"
  },
  {
    "output": "1"
  },
  {
    "output": "The best is yet to come."
  },
  {
    "output": "True"
  },
  {
    "output": "True"
  },
  {
    "output": "C"
  },
  {
    "output": "A"
  },
  {
    "output": "False"
  },
  {
    "output": "The thought that organisms exist at the same time period throughout the world."
  },
  {
    "output": "A"
  },
  {
    "output": "**\nFINAL ANSWER: 1248"
  },
  {
    "output": "C"
  },
  {
    "output": "72"
  },
  {
    "output": "221"
  },
  {
    "output": "False"
  },
  {
    "output": "5"
  },
  {
    "output": "1985"
  },
  {
    "output": "False"
  },
  {
    "output": "270"
  },
  {
    "output": "True"
  },
  {
    "output": "narrower"
  },
  {
    "output": "Estimate"
  },
  {
    "output": "120"
  },
  {
    "output": "B"
  },
  {
    "output": "B"
  },
  {
    "output": "Dutch"
  },
  {
    "output": "**\nC. oceanic trench"
  },
  {
    "output": "37"
  },
  {
    "output": "A"
  },
  {
    "output": "C"
  },
  {
    "output": "B"
  },
  {
    "output": "False"
  },
  {
    "output": "12.00"
  },
  {
    "output": "A"
  },
  {
    "output": "E"
  },
  {
    "output": "(C) blue ball"
  },
  {
    "output": "C"
  },
  {
    "output": "5600.0"
  },
  {
    "output": "15"
  },
  {
    "output": "1987"
  },
  {
    "output": "The Netherlands"
  },
  {
    "output": "a thin film of oxide"
  },
  {
    "output": "The Vital Spark"
  },
  {
    "output": ""
  },
  {
    "output": "True"
  },
  {
    "output": "town meeting"
  },
  {
    "output": "CSNET"
  },
  {
    "output": "comb-rows"
  },
  {
    "output": "C"
  },
  {
    "output": "58"
  },
  {
    "output": "35"
  },
  {
    "output": "92"
  },
  {
    "output": "False"
  },
  {
    "output": "D. nervous system"
  },
  {
    "output": "Midnight Cowboy"
  },
  {
    "output": "Lutheranism"
  },
  {
    "output": "Céloron did not handle business in the traditional sense; he focused on asserting French claims and deterring British presence in the area."
  },
  {
    "output": "98"
  },
  {
    "output": "4"
  },
  {
    "output": "130"
  },
  {
    "output": "36.00"
  },
  {
    "output": "2013"
  },
  {
    "output": "Low-income and under-represented minority applicants."
  },
  {
    "output": "C"
  },
  {
    "output": "False"
  },
  {
    "output": "25"
  },
  {
    "output": "The context does not provide information about the diameters of the planets, so it is not possible to determine the answer."
  },
  {
    "output": "dogs"
  },
  {
    "output": "} } )"
  },
  {
    "output": "Maginot Line"
  },
  {
    "output": "True"
  },
  {
    "output": "False"
  },
  {
    "output": "130"
  },
  {
    "output": "4"
  },
  {
    "output": "False"
  },
  {
    "output": "Puli Alam"
  },
  {
    "output": "70"
  },
  {
    "output": "Love Never Dies"
  },
  {
    "output": "False"
  },
  {
    "output": "0"
  },
  {
    "output": "False"
  },
  {
    "output": "Sweet Home Alabama"
  },
  {
    "output": "Nairobi"
  },
  {
    "output": "Cyclopes"
  },
  {
    "output": "D"
  },
  {
    "output": "318"
  },
  {
    "output": "False"
  },
  {
    "output": "D"
  },
  {
    "output": "True"
  },
  {
    "output": "A. the age of the rock"
  },
  {
    "output": "6"
  },
  {
    "output": "Cannot be determined from the given information."
  },
  {
    "output": "120"
  },
  {
    "output": "1790"
  },
  {
    "output": "False"
  },
  {
    "output": "Richard"
  },
  {
    "output": "B"
  },
  {
    "output": "poet"
  },
  {
    "output": "C"
  },
  {
    "output": "50"
  },
  {
    "output": "23"
  },
  {
    "output": "an idealized and systematized version of conservative tribal village customs under the label of Sharia."
  },
  {
    "output": "True"
  },
  {
    "output": "Colorado River"
  },
  {
    "output": "70"
  },
  {
    "output": "180"
  },
  {
    "output": "True"
  },
  {
    "output": "The poor and the middle class matter the most for economic growth."
  },
  {
    "output": "C"
  },
  {
    "output": "4 blue shoe boxes and 6 red shoe boxes are left in Tim's box."
  },
  {
    "output": "44"
  },
  {
    "output": "4800"
  },
  {
    "output": "16"
  },
  {
    "output": "Ferdinand Magellan"
  },
  {
    "output": "762"
  },
  {
    "output": "Wild Mountain Thyme"
  },
  {
    "output": "True"
  },
  {
    "output": "matrices and linear algebra"
  },
  {
    "output": "Wild Mountain Thyme"
  },
  {
    "output": "Genever is the old word for a type of spirit, specifically a blend of malt-wine and a spirit made with botanical flavorings, similar to gin. It is often sold with fruit flavoring and is produced in the Netherlands and Belgium."
  },
  {
    "output": "his finger"
  },
  {
    "output": "312"
  },
  {
    "output": "Never so Few"
  },
  {
    "output": "False"
  },
  {
    "output": "B"
  },
  {
    "output": "131250"
  },
  {
    "output": "None"
  },
  {
    "output": "False"
  },
  {
    "output": "Midnight Cowboy"
  },
  {
    "output": "20"
  },
  {
    "output": "1974"
  },
  {
    "output": "114200"
  },
  {
    "output": "Concorde"
  },
  {
    "output": "True"
  },
  {
    "output": "B"
  },
  {
    "output": "A"
  },
  {
    "output": "D"
  },
  {
    "output": "NP-complete"
  },
  {
    "output": "localized hypersensitive response"
  },
  {
    "output": "Italian"
  },
  {
    "output": "True"
  },
  {
    "output": "20000"
  },
  {
    "output": "80"
  },
  {
    "output": "16"
  },
  {
    "output": "True"
  },
  {
    "output": "[Hard problem, difficulty=6] Step-by-step reasoning:\nLet's solve this step by step, as requested.\n\n---\n\n### **Step 1: Identify what we're asked to find**\n\nWe are asked to **determine the final standings (from 1st to 7th place)** of the seven golfers:  \n**Ana, Eve, Ada, Dan, Rob, Amy, and Joe.**\n\nWe are given several clues about their relative positions. Our goal is to **arrange them in order from 1st to 7th place** based on the clues.\n\n---\n\n### **Step 2: Break down the problem into smaller parts**\n\nWe will process each clue one by one and use logical deduction to determine the order.\n\nLet’s list the clues again:\n\n1. **Dan finished third.**  \n2. **Ana finished above Ada.**  \n3. **Amy finished last.**  \n4. **Dan finished below Rob.**  \n5. **Eve finished below Ada.**  \n6. **Rob finished below Joe.**\n\n---\n\n### **Step 3: Solve each part carefully**\n\n#### **Clue 1: Dan finished third.**\n\nSo, **Dan = 3rd place.**\n\n#### **Clue 4: Dan finished below Rob.**\n\nSo, **Rob finished above Dan** → **Rob is in a position < 3** (i.e., 1st or 2nd).\n\n#### **Clue 6: Rob finished below Joe.**\n\nSo, **Joe finished above Rob** → **Joe is in a position < Rob's position**.\n\nFrom Clue 4: Rob is in 1st or 2nd.  \nFrom Clue 6: Joe is above Rob → So Joe must be in **1st** (since Rob can only be in 1st or 2nd, and Joe must be above Rob).\n\nSo, **Joe = 1st**, **Rob = 2nd**, **Dan = 3rd**.\n\nSo far:\n- 1st: Joe  \n- 2nd: Rob  \n- 3rd: Dan\n\n#### **Clue 3: Amy finished last.**\n\nSo, **Amy = 7th place**.\n\n#### **Clue 2: Ana finished above Ada.**\n\nSo, **Ana is in a position < Ada**.\n\n#### **Clue 5: Eve finished below Ada.**\n\nSo, **Eve is in a position > Ada**.\n\nSo, from Clue 2 and 5:  \n- Ana"
  },
  {
    "output": "25"
  },
  {
    "output": "Only You"
  },
  {
    "output": "True"
  },
  {
    "output": "A"
  },
  {
    "output": "Locomotives"
  },
  {
    "output": "42.73"
  },
  {
    "output": "D. water"
  },
  {
    "output": "4"
  },
  {
    "output": "blest, buxton, consternate, proximity, quizzes, sound, tariff, xerxes"
  },
  {
    "output": "300"
  },
  {
    "output": "230"
  },
  {
    "output": "feather"
  },
  {
    "output": "Leo"
  },
  {
    "output": "False"
  },
  {
    "output": "The lead fusible plugs melt."
  },
  {
    "output": "True"
  },
  {
    "output": "time and memory consumption"
  },
  {
    "output": "Classical Realism"
  },
  {
    "output": "B"
  },
  {
    "output": "130"
  },
  {
    "output": "6"
  },
  {
    "output": "20"
  },
  {
    "output": "20"
  },
  {
    "output": "5"
  },
  {
    "output": "B. It has an indefinite volume and takes the shape of its container."
  },
  {
    "output": "rock and roll"
  },
  {
    "output": "False"
  },
  {
    "output": "D. An apple core"
  },
  {
    "output": "Denisovans"
  },
  {
    "output": "14"
  },
  {
    "output": "False"
  },
  {
    "output": "Tony Blair"
  },
  {
    "output": "(A) The developer understood the problem"
  },
  {
    "output": "(C) left midfielder"
  },
  {
    "output": "common, denmark, enviable, exclusive, frill, griffith, jibe, loosestrife, nanosecond, saute, screechy, spitz, spermatozoa, sow, swabby, yates"
  },
  {
    "output": "3"
  },
  {
    "output": "84"
  },
  {
    "output": "10"
  },
  {
    "output": "A"
  },
  {
    "output": "**\n$1,800\n\nFINAL ANSWER: 1800"
  },
  {
    "output": "Water flow through the body cavity."
  },
  {
    "output": "10"
  },
  {
    "output": "106.12"
  },
  {
    "output": "A"
  },
  {
    "output": "Tutankhamun"
  },
  {
    "output": "Stereophonics"
  },
  {
    "output": "A"
  },
  {
    "output": "133.333... \n\nThe closest answer is B. 133 W. \n\nFINAL ANSWER: B"
  },
  {
    "output": "Karluk Kara-Khanid ruler"
  },
  {
    "output": "James Hacker"
  },
  {
    "output": "False"
  },
  {
    "output": "26"
  },
  {
    "output": "Design and planning"
  },
  {
    "output": "5.0"
  },
  {
    "output": "November"
  },
  {
    "output": "280"
  },
  {
    "output": "Dutch Customs Authorities"
  },
  {
    "output": "83"
  },
  {
    "output": "D"
  },
  {
    "output": "True"
  },
  {
    "output": "False"
  },
  {
    "output": "with the result."
  },
  {
    "output": "Konsumentombudsmannen v De Agostini"
  },
  {
    "output": "States and governments."
  },
  {
    "output": "The Mughal state."
  },
  {
    "output": "False"
  },
  {
    "output": "29"
  },
  {
    "output": "True"
  },
  {
    "output": "8"
  },
  {
    "output": "32"
  },
  {
    "output": "B"
  },
  {
    "output": "False"
  },
  {
    "output": "Bardstown"
  },
  {
    "output": "1000"
  },
  {
    "output": "Nick Carter"
  },
  {
    "output": "Taylor Swift"
  },
  {
    "output": "J"
  },
  {
    "output": "1430"
  },
  {
    "output": "Carnegie Hall"
  },
  {
    "output": "False"
  },
  {
    "output": "True"
  },
  {
    "output": "documentaries"
  },
  {
    "output": "B"
  },
  {
    "output": "89"
  },
  {
    "output": "2"
  },
  {
    "output": "A"
  },
  {
    "output": "False"
  },
  {
    "output": "Resolution 43/53"
  },
  {
    "output": "10"
  },
  {
    "output": "amethyst, bathos, dormouse, obtuse, resignation, walt"
  },
  {
    "output": "India and Pakistan"
  },
  {
    "output": "True"
  },
  {
    "output": "architectural attraction"
  },
  {
    "output": "B"
  },
  {
    "output": "Paul Nash"
  },
  {
    "output": "A"
  },
  {
    "output": "False"
  },
  {
    "output": "B"
  },
  {
    "output": "A"
  },
  {
    "output": "homicides"
  },
  {
    "output": "start_position = (0, 0)\ndirection = 'east'\nposition = start_position.copy()\n\n# Turn right (east -> south)\ndirection = 'south'\n\n# Take 9 steps\nposition = (position[0] + 0, position[1] - 9)\n\n# Turn around (south -> west)\ndirection = 'west'\n\n# Take 9 steps\nposition = (position[0] - 9, position[1])\n\n# Turn right (west -> north)\ndirection = 'north'\n\n# Final position check\nfinal_position = position\nfinal_position == start_position"
  },
  {
    "output": "A"
  },
  {
    "output": "D"
  },
  {
    "output": "False"
  },
  {
    "output": "False"
  },
  {
    "output": "Billie Holiday"
  },
  {
    "output": "C"
  },
  {
    "output": "50"
  },
  {
    "output": "6"
  },
  {
    "output": "The Sunday Post"
  },
  {
    "output": "32.0"
  },
  {
    "output": "44"
  },
  {
    "output": "True"
  },
  {
    "output": "False"
  },
  {
    "output": "False"
  },
  {
    "output": "across, admixture, directrix, flight, gut, indicate, marshal, quagmire, vantage, smuggle"
  },
  {
    "output": "38"
  },
  {
    "output": "Kenny Young"
  },
  {
    "output": "C"
  },
  {
    "output": "(C) black ball"
  },
  {
    "output": "15"
  },
  {
    "output": "False"
  },
  {
    "output": "False"
  },
  {
    "output": "George Eliot"
  },
  {
    "output": "(B) It was the customer's car"
  },
  {
    "output": "9"
  },
  {
    "output": ""
  },
  {
    "output": "United States"
  },
  {
    "output": "225"
  },
  {
    "output": "348"
  },
  {
    "output": "False"
  },
  {
    "output": "False"
  },
  {
    "output": "15"
  },
  {
    "output": "Biloxi, Mississippi"
  },
  {
    "output": "D"
  },
  {
    "output": "Aberdeenshire"
  },
  {
    "output": "A"
  },
  {
    "output": "Athena Parthenos"
  },
  {
    "output": "False"
  },
  {
    "output": "A simultaneous hermaphrodite can produce both eggs and sperm at the same time."
  },
  {
    "output": "1944"
  },
  {
    "output": "Iceal E. \"Gene\" Hambleton"
  },
  {
    "output": "False"
  },
  {
    "output": "Perpendicular to the velocity vector."
  },
  {
    "output": "C"
  },
  {
    "output": "Martin Luther King Jr."
  },
  {
    "output": "A"
  },
  {
    "output": "D"
  },
  {
    "output": "ghee"
  },
  {
    "output": "12"
  },
  {
    "output": "True"
  },
  {
    "output": "False"
  },
  {
    "output": "1"
  },
  {
    "output": "Voters outside the city limits (residents of unincorporated suburbs)"
  },
  {
    "output": "Canterbury Cathedral"
  },
  {
    "output": "55"
  },
  {
    "output": "A"
  },
  {
    "output": "10"
  },
  {
    "output": "False"
  },
  {
    "output": "Keld Heich"
  },
  {
    "output": "294"
  },
  {
    "output": "Beau Rivage"
  },
  {
    "output": "3"
  },
  {
    "output": "B"
  },
  {
    "output": "Cannot be determined from the given information."
  },
  {
    "output": "D. reduces the number of trees cut down."
  },
  {
    "output": "greater Southern California Megaregion"
  },
  {
    "output": "D. southwest"
  },
  {
    "output": "122"
  },
  {
    "output": "They both have a connection to the film \"Steve Jobs.\""
  },
  {
    "output": "2883"
  },
  {
    "output": "True"
  },
  {
    "output": "Turing machine"
  },
  {
    "output": "Fortean subjects"
  },
  {
    "output": "False"
  },
  {
    "output": "11"
  },
  {
    "output": "Shirley Williams"
  },
  {
    "output": "Premium Bonds"
  },
  {
    "output": "First-in, first-out (FIFO) buffering"
  },
  {
    "output": "alphabet, birmingham, educate, entourage, fashion, fond, marimba, mechanic, philology, retrofit, cantonese"
  },
  {
    "output": "800"
  },
  {
    "output": "Newcastle United"
  },
  {
    "output": "False"
  },
  {
    "output": "16"
  },
  {
    "output": "Ozone (O₃)"
  },
  {
    "output": "90"
  },
  {
    "output": "False"
  },
  {
    "output": "Sunny Afternoon"
  },
  {
    "output": "True"
  },
  {
    "output": "quantum electrodynamics (QED)"
  },
  {
    "output": "False"
  },
  {
    "output": "private \"Christian academies\""
  },
  {
    "output": "A"
  },
  {
    "output": "Bertalan Farkas"
  },
  {
    "output": "-8"
  },
  {
    "output": "47"
  },
  {
    "output": "(C) pink ball"
  },
  {
    "output": ""
  },
  {
    "output": "adventure"
  },
  {
    "output": ""
  },
  {
    "output": "Silver"
  },
  {
    "output": "220"
  },
  {
    "output": "43"
  },
  {
    "output": "E"
  },
  {
    "output": "800"
  },
  {
    "output": "Ben Watson"
  },
  {
    "output": "nudity or being naked"
  },
  {
    "output": "valid"
  },
  {
    "output": "Sky+"
  },
  {
    "output": "The first geological map of the United States."
  },
  {
    "output": "True"
  },
  {
    "output": "28"
  },
  {
    "output": "47.25"
  },
  {
    "output": "A"
  },
  {
    "output": "True"
  },
  {
    "output": "True"
  },
  {
    "output": "New York City"
  },
  {
    "output": "kick back"
  },
  {
    "output": "megalopolis"
  },
  {
    "output": "8"
  },
  {
    "output": "bone cancer"
  },
  {
    "output": "(C) The motorcyle is the second-oldest"
  },
  {
    "output": "24"
  },
  {
    "output": "32"
  },
  {
    "output": "500"
  },
  {
    "output": "C. plate tectonics."
  },
  {
    "output": "tennis"
  },
  {
    "output": "F"
  },
  {
    "output": "16"
  },
  {
    "output": "fasciculate, judicature, presto"
  },
  {
    "output": "R"
  },
  {
    "output": "78"
  },
  {
    "output": "2000"
  },
  {
    "output": "cats"
  },
  {
    "output": "140"
  },
  {
    "output": "True"
  },
  {
    "output": "B"
  },
  {
    "output": "True"
  },
  {
    "output": "112"
  },
  {
    "output": "D"
  },
  {
    "output": "Dallas"
  },
  {
    "output": "0"
  },
  {
    "output": "False"
  },
  {
    "output": "Porridge"
  },
  {
    "output": "120"
  },
  {
    "output": "43.33"
  },
  {
    "output": "The information about the duc de Choiseul's plan for 1785 is not available in the provided context."
  },
  {
    "output": "A"
  },
  {
    "output": "96"
  },
  {
    "output": "98"
  },
  {
    "output": "360"
  },
  {
    "output": "Shangdu"
  },
  {
    "output": "Stephen Sondheim"
  },
  {
    "output": "B. the effect of warmed water on aquatic life"
  },
  {
    "output": "250"
  },
  {
    "output": "A"
  },
  {
    "output": "60"
  },
  {
    "output": "False"
  },
  {
    "output": "B"
  },
  {
    "output": "190"
  },
  {
    "output": "140"
  },
  {
    "output": "speed skating"
  },
  {
    "output": "faggots"
  },
  {
    "output": "9"
  },
  {
    "output": "False"
  },
  {
    "output": "1960"
  },
  {
    "output": "Edmonton, Alberta"
  },
  {
    "output": "False"
  },
  {
    "output": "Jack White"
  },
  {
    "output": "18"
  },
  {
    "output": "Course content for a private school is determined and provided by the school itself."
  },
  {
    "output": "4080"
  },
  {
    "output": "Pat McCarran"
  },
  {
    "output": "187"
  },
  {
    "output": "D"
  },
  {
    "output": "True"
  },
  {
    "output": "Empirical testing and optimization."
  },
  {
    "output": "880"
  },
  {
    "output": "Smith!"
  },
  {
    "output": "A"
  },
  {
    "output": "4800"
  },
  {
    "output": "Greenock"
  },
  {
    "output": "1970s onwards"
  },
  {
    "output": "56"
  },
  {
    "output": "6"
  },
  {
    "output": "28"
  },
  {
    "output": "The History Boys"
  },
  {
    "output": "Cannot be determined from the given context."
  },
  {
    "output": "Persians"
  },
  {
    "output": "True"
  },
  {
    "output": "243"
  },
  {
    "output": "70"
  },
  {
    "output": ""
  },
  {
    "output": "N. Scott Momaday"
  },
  {
    "output": "Hong Kong"
  },
  {
    "output": "C"
  },
  {
    "output": "A"
  },
  {
    "output": "besetting, boyd, counterweight, detergent, groove, hide, intangible, menlo, nv, ovipositor, spumoni, sans"
  },
  {
    "output": "D. Decomposing algae lowered the amount of dissolved oxygen."
  },
  {
    "output": "294"
  },
  {
    "output": "D"
  },
  {
    "output": "False"
  },
  {
    "output": "B"
  },
  {
    "output": "Kitty Hawk"
  },
  {
    "output": "True"
  },
  {
    "output": "False"
  },
  {
    "output": "595"
  },
  {
    "output": "True"
  },
  {
    "output": "C. They both travel at the same speed."
  },
  {
    "output": "600"
  },
  {
    "output": "B"
  },
  {
    "output": "from datetime import datetime, timedelta\ntoday = datetime(1933, 11, 25)\none_week_from_today = today + timedelta(days=7)\nformatted_date = one_week_from_today.strftime('%m/%d/%Y')"
  },
  {
    "output": "False"
  },
  {
    "output": "B"
  },
  {
    "output": "Flamingo Las Vegas"
  },
  {
    "output": ""
  },
  {
    "output": "Feedstock materials or starting materials in chemical synthesis."
  },
  {
    "output": "The Shins"
  },
  {
    "output": "18"
  },
  {
    "output": "Improved"
  },
  {
    "output": "Pacific National and CFCL Australia"
  },
  {
    "output": "10"
  },
  {
    "output": "A. making fine incisions."
  },
  {
    "output": "No**"
  },
  {
    "output": "14"
  },
  {
    "output": "B"
  },
  {
    "output": "Gweilo"
  },
  {
    "output": "True"
  },
  {
    "output": "The question cannot be answered with the given context."
  },
  {
    "output": "True"
  },
  {
    "output": "North Dakota and South Dakota"
  },
  {
    "output": "The context does not provide enough information to determine the name after whom the University in Pullman, Washington is named."
  },
  {
    "output": "1110"
  },
  {
    "output": "Niger"
  },
  {
    "output": "8"
  },
  {
    "output": "100"
  },
  {
    "output": "B"
  },
  {
    "output": "50"
  },
  {
    "output": "A"
  },
  {
    "output": "Kangpenqing"
  },
  {
    "output": "True"
  },
  {
    "output": "15"
  },
  {
    "output": "D"
  },
  {
    "output": "50"
  },
  {
    "output": "13"
  },
  {
    "output": ""
  },
  {
    "output": "more than 90"
  },
  {
    "output": "3"
  },
  {
    "output": "Norman language"
  },
  {
    "output": "False"
  },
  {
    "output": "Cannot be determined from the given context."
  },
  {
    "output": "3"
  },
  {
    "output": "Albany County"
  },
  {
    "output": "True"
  },
  {
    "output": "True"
  },
  {
    "output": "24"
  },
  {
    "output": "Eileen Atkins"
  },
  {
    "output": "A"
  },
  {
    "output": "80"
  },
  {
    "output": "Andy Williams' Dear Heart"
  },
  {
    "output": "Salisbury"
  },
  {
    "output": "Mountain West Conference"
  },
  {
    "output": "dendritic cells, keratinocytes, and macrophages"
  },
  {
    "output": "150"
  },
  {
    "output": "False"
  },
  {
    "output": "C"
  },
  {
    "output": "False"
  },
  {
    "output": "1995"
  },
  {
    "output": "False"
  },
  {
    "output": "88"
  },
  {
    "output": "True"
  },
  {
    "output": "(A) They were my parent's secretary"
  },
  {
    "output": "Austria"
  },
  {
    "output": "False"
  },
  {
    "output": "A"
  },
  {
    "output": "3"
  },
  {
    "output": "B"
  },
  {
    "output": "Packet switching allocates bandwidth dynamically on a per-packet basis."
  },
  {
    "output": "A"
  },
  {
    "output": "B"
  },
  {
    "output": "B"
  },
  {
    "output": "Kenya"
  },
  {
    "output": "ARPANET"
  },
  {
    "output": "False"
  },
  {
    "output": "C"
  },
  {
    "output": "B. Earth rotates on its axis."
  },
  {
    "output": "182"
  },
  {
    "output": "40"
  },
  {
    "output": "Volga River"
  },
  {
    "output": "False"
  },
  {
    "output": "30"
  },
  {
    "output": ""
  },
  {
    "output": "Greater Los Angeles Area"
  },
  {
    "output": "Foundational constitutional questions affecting democracy and human rights."
  },
  {
    "output": "7"
  },
  {
    "output": "False"
  },
  {
    "output": "73.0"
  },
  {
    "output": "Daewoo"
  },
  {
    "output": "2006"
  },
  {
    "output": "160"
  },
  {
    "output": "3"
  },
  {
    "output": "1500"
  },
  {
    "output": "1500"
  },
  {
    "output": "310"
  },
  {
    "output": "Stephen A. Smith"
  },
  {
    "output": "Barack Obama"
  },
  {
    "output": "The number of problems that can be solved is independent of the amount of time or space available."
  },
  {
    "output": "Social welfare programs."
  },
  {
    "output": "Naomi Campbell"
  },
  {
    "output": ""
  },
  {
    "output": "50"
  },
  {
    "output": "True"
  },
  {
    "output": "{ < [ ] > ( { [ ] } < } >"
  },
  {
    "output": "1"
  },
  {
    "output": "C"
  },
  {
    "output": "giraffe"
  },
  {
    "output": "False"
  },
  {
    "output": "2010"
  },
  {
    "output": "2"
  },
  {
    "output": "1"
  },
  {
    "output": "1987 to 2010"
  },
  {
    "output": "Kwok Kin Pong"
  },
  {
    "output": "smell"
  },
  {
    "output": "5"
  },
  {
    "output": "30"
  },
  {
    "output": "John Galliano"
  },
  {
    "output": "True"
  },
  {
    "output": "D"
  },
  {
    "output": "the absence of a revising chamber"
  },
  {
    "output": "immunosuppressive"
  },
  {
    "output": "hydrogen gas and oxygen gas"
  },
  {
    "output": "Byron"
  },
  {
    "output": "Oklahoma State University"
  },
  {
    "output": "1038"
  },
  {
    "output": "Red Sea"
  },
  {
    "output": "Conductor"
  },
  {
    "output": "D"
  },
  {
    "output": "University of California"
  },
  {
    "output": "5"
  },
  {
    "output": "75"
  },
  {
    "output": "34"
  },
  {
    "output": "Battle of Olustee"
  },
  {
    "output": "16"
  },
  {
    "output": "5"
  },
  {
    "output": "False"
  },
  {
    "output": "False"
  },
  {
    "output": "Theta notation"
  },
  {
    "output": "Luteinizing Hormone (LH)"
  },
  {
    "output": "6"
  },
  {
    "output": "60"
  },
  {
    "output": "C"
  },
  {
    "output": "1 October 1998"
  },
  {
    "output": "459"
  },
  {
    "output": "Force"
  },
  {
    "output": "The first type of Vauclain compound results in a balanced and efficient operation, reducing vibration and improving the smoothness of the engine's operation, thereby enhancing railway performance."
  },
  {
    "output": "A"
  },
  {
    "output": "C. Water, H2O"
  },
  {
    "output": "C"
  },
  {
    "output": "War of the Two Capitals"
  },
  {
    "output": "False"
  },
  {
    "output": "True"
  },
  {
    "output": "car door lock"
  },
  {
    "output": "70000"
  },
  {
    "output": "80"
  },
  {
    "output": "A"
  },
  {
    "output": "B"
  },
  {
    "output": "2007"
  },
  {
    "output": "15"
  },
  {
    "output": "51\n\nThe blinking rate is 51 blinks per minute. Now, we calculate the time required for 459 blinks by dividing the number of blinks by the blinking rate.\n\nUSE TOOL: calculator(459 / 51)\nFINAL ANSWER: 9\n\nIt will take 9 minutes for the light to blink 459 times."
  },
  {
    "output": "B"
  },
  {
    "output": "False"
  },
  {
    "output": ""
  },
  {
    "output": "True"
  },
  {
    "output": "34"
  },
  {
    "output": "68"
  },
  {
    "output": "2014"
  },
  {
    "output": "348"
  },
  {
    "output": "D"
  },
  {
    "output": "False"
  },
  {
    "output": "104"
  },
  {
    "output": "Stantz, Venkman, Spengler"
  },
  {
    "output": "True"
  },
  {
    "output": "10"
  },
  {
    "output": "96"
  },
  {
    "output": "False"
  },
  {
    "output": "B. Some native plant populations will decline."
  },
  {
    "output": "The information about the 63d Fighter Squadron is not provided in the context, so it is not possible to determine the answer."
  },
  {
    "output": "90"
  },
  {
    "output": "New York Shakespeare Festival"
  },
  {
    "output": "3430"
  },
  {
    "output": "False"
  },
  {
    "output": "British Leyland"
  },
  {
    "output": "Jacques Lefevre"
  },
  {
    "output": "True"
  },
  {
    "output": ""
  },
  {
    "output": "KULR-TV"
  },
  {
    "output": "120"
  },
  {
    "output": "Masking antigens with host molecules and rapid mutation of non-essential epitopes."
  },
  {
    "output": "Tulsa"
  },
  {
    "output": "False"
  },
  {
    "output": "E"
  },
  {
    "output": "25\n\nAaron has 25 jewels.\n\nNow, let's calculate how many jewels Siobhan has.\nUSE TOOL: calculator(25 - 2)\nFINAL ANSWER: 23\n\nSiobhan has 23 jewels."
  },
  {
    "output": "120"
  },
  {
    "output": "1993"
  },
  {
    "output": "Sandy Springs, Georgia"
  },
  {
    "output": "audacious, bulrush, filamentous, harris, intervener, municipal, rubicund, sensate, semaphore, battleground, xylophone"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "155"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "26"
  },
  {
    "output": "def count_non_carrying_pairs():\n    def no_carry(a, b):\n        while a > 0 or b > 0:\n            if (a % 10 + b % 10) >= 10:\n                return False\n            a //= 10\n            b //= 10\n        return True\n    count = 0\n    for m in range(1493):\n        n = 1492 - m\n        if no_carry(m, n):\n            count += 1\n    return count"
  },
  {
    "output": "1010"
  },
  {
    "output": "False"
  },
  {
    "output": "180"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "144"
  },
  {
    "output": "13"
  },
  {
    "output": ""
  },
  {
    "output": "9"
  },
  {
    "output": "262144"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "10"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "1"
  },
  {
    "output": "def f(n):\n    count = 0\n    for k in range(3, 2 * n + 1):\n        if (2 * n) % k == 0:\n            val = (2 * n // k - k + 1)\n            if val > 0 and val % 2 == 0:\n                count += 1\n    return count"
  },
  {
    "output": "def count_non_square_sets():\n    import math\n    count = 0\n    for i in range(1000):\n        start = 100 * i\n        end = 100 * (i + 1) - 1\n        has_square = False\n        for n in range(int(math.isqrt(start)) + 1, int(math.isqrt(end)) + 2):\n            if n * n >= start and n * n <= end:\n                has_square = True\n                break\n        if not has_square:\n            count += 1\n    return count"
  },
  {
    "output": "24"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Error: leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers (<string>, line 1)"
  },
  {
    "output": "[Hard problem, difficulty=7] Step-by-step reasoning:\nWe are given:\n\n- A square $ABCD$.\n- A point $P$ on the **circumcircle** of the square.\n- The distances from $P$ to two opposite vertices satisfy:\n  $$\n  PA \\cdot PC = 56 \\quad \\text{and} \\quad PB \\cdot PD = 90\n  $$\n- We are to **find the area of square $ABCD$**.\n\n---\n\n### Step 1: Understand the Geometry\n\nLet’s denote the square $ABCD$ with side length $s$, and let the center of the square be $O$. Since the square is inscribed in a circle, the **circumcircle** of the square has its center at the center of the square, and the radius of the circle is the **distance from the center to any vertex**, which is:\n$$\nR = \\frac{s\\sqrt{2}}{2}\n$$\n\nLet’s place the square in the coordinate plane for simplicity:\n\n- Let the square have vertices:\n  - $A = (-\\frac{s}{2}, \\frac{s}{2})$\n  - $B = (\\frac{s}{2}, \\frac{s}{2})$\n  - $C = (\\frac{s}{2}, -\\frac{s}{2})$\n  - $D = (-\\frac{s}{2}, -\\frac{s}{2})$\n- The center $O = (0, 0)$\n- The circumcircle has center at $O$ and radius $R = \\frac{s\\sqrt{2}}{2}$\n\nLet point $P = (x, y)$ be a point on the circumcircle, so it satisfies:\n$$\nx^2 + y^2 = R^2 = \\left(\\frac{s\\sqrt{2}}{2}\\right)^2 = \\frac{s^2}{2}\n$$\n\n---\n\n### Step 2: Use the Given Conditions\n\nWe are given:\n$$\nPA \\cdot PC = 56 \\quad \\text{and} \\quad PB \\cdot PD = 90\n$$\n\nLet’s compute the distances $PA$, $PC$, $PB$, and $PD$ in terms of coordinates.\n\n#### Coordinates of the square:\n- $A = (-\\frac{s}{2}, \\frac{s}{2})$\n- $C = (\\frac{s}{2}, -\\frac{s}{2})$\n- $B = (\\frac{s}{2}, \\"
  },
  {
    "output": "84"
  },
  {
    "output": "189.0"
  },
  {
    "output": "18"
  },
  {
    "output": ""
  },
  {
    "output": "import math\n\ndef calculate_area():\n    # Define circle center and radius\n    O = (0, 0)\n    radius = 2\n\n    # Define points A, B, C based on circle and given conditions\n    A = (1, 0)\n    B = (-1, 0)\n    C = (0, 2)\n\n    # Calculate coordinates of D and E based on AD = 13 and AE = 11\n    # Assuming D lies on line AB extended and E lies on line AC extended\n    # Using vector direction and length to find D and E\n    AB_vector = (B[0] - A[0], B[1] - A[1])\n    AC_vector = (C[0] - A[0], C[1] - A[1])\n\n    # Normalize vectors and scale to given lengths\n    AB_unit = (AB_vector[0] / math.hypot(AB_vector[0], AB_vector[1]), \n               AB_vector[1] / math.hypot(AB_vector[0], AB_vector[1]))\n    AC_unit = (AC_vector[0] / math.hypot(AC_vector[0], AC_vector[1]), \n               AC_vector[1] / math.hypot(AC_vector[0], AC_vector[1]))\n\n    D = (A[0] + AB_unit[0] * 13, A[1] + AB_unit[1] * 13)\n    E = (A[0] + AC_unit[0] * 11, A[1] + AC_unit[1] * 11)\n\n    # Define lines l1 and l2 through D and E parallel to AE and AD respectively\n    # Calculate direction vectors for l1 and l2\n    AE_vector = (E[0] - A[0], E[1] - A[1])\n    AD_vector = (D[0] - A[0], D[1] - A[1])\n\n    # Define line l1 through D with direction AE\n    l1_dir = (AE_vector[0], AE_vector[1])\n    l1_point = D\n\n    # Define line l2 through E with direction AD\n    l2_dir = (AD_vector[0], AD_vector[1])\n    l2_point = E\n\n    # Find intersection point G of lines l1 and l2\n    # Using line-line intersection formula\n    def line_intersection(line1, line2):\n        (x1, y1), (x2, y2) = line1\n        (x3, y3), (x4, y4) = line2\n        denom = (y4 - y3) * (x2 - x1) - (x4 - x3) * (y2 - y1)\n        if denom == 0:\n            return None\n        x = ((x4 - x3) * (y1 - y3) * (x2 - x1) - (x2 - x1) * (y4 - y3) * (x1 - x3)) / denom\n        y = ((x4 - x3) * (y1 - y3) * (y2 - y1) - (y2 - y1) * (y4 - y3) * (y1 - y3)) / denom\n        return (x, y)\n\n    # Define lines l1 and l2 as parametric lines\n    l1_line = (l1_point, (l1_point[0] + l1_dir[0], l1_point[1] +"
  },
  {
    "output": "for b in range(a + 1, 21):\n    d = b - a\n    total += v2(d)"
  },
  {
    "output": ""
  },
  {
    "output": "Error: name 'python_runner' is not defined"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "151764"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "def count_balanced_numbers():\n    count = 0\n    for num in range(1000, 10000):\n        d1, d2, d3, d4 = num // 1000, (num // 100) % 10, (num // 10) % 10, num % 10\n        if d1 + d2 == d3 + d4:\n            count += 1\n    return count"
  },
  {
    "output": ""
  },
  {
    "output": "1000"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "def find_sum_of_digits():\n    total = 0\n    upper_bound = 10**8\n    for n in range(2020, upper_bound + 1, 10000):\n        k = n // 10000\n        if n % k == 0:\n            digit_sum = sum(int(d) for d in str(n))\n            total += digit_sum\n    return total"
  },
  {
    "output": ""
  },
  {
    "output": "from collections import deque\n\ndef find_original_position():\n    cards = list(range(1, 2000))\n    table = []\n    stack = deque(cards)\n    while stack:\n        card = stack.popleft()\n        table.append(card)\n        if stack:\n            stack.append(stack.popleft())\n    return table.index(1999) + 1"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "def find_least_n():\n    n = 1\n    while True:\n        if (pow(2, n, 1000) + pow(5, n, 1000) - n) % 1000 == 0:\n            return n\n        n += 1\n\nresult = find_least_n()\nresult"
  },
  {
    "output": "def count_valid_pairs():\n    count = 0\n    for a in range(1, 1000):\n        b = 1000 - a\n        if '0' not in str(a) and '0' not in str(b):\n            count += 1\n    return count"
  },
  {
    "output": ""
  },
  {
    "output": "5"
  },
  {
    "output": ""
  },
  {
    "output": "The problem statement is incomplete and cannot be solved as given."
  },
  {
    "output": "363"
  },
  {
    "output": ""
  },
  {
    "output": "def find_least_k():\n    for k in range(1, 2003):\n        found = False\n        for n in range(1, 2003):\n            if 2002 // n == k:\n                found = True\n                break\n        if not found:\n            return k\n    return 2002"
  },
  {
    "output": "0"
  },
  {
    "output": "33"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "def count_valid_pairs():\n    count = 0\n    for a in range(6, 29):\n        for b in range(a + 1, 30):\n            sequence = [5, a, b]\n            valid = True\n            for i in range(len(sequence)):\n                for j in range(i + 1, len(sequence)):\n                    for k in range(j + 1, len(sequence)):\n                        for l in range(k + 1, len(sequence)):\n                            if 2 * sequence[j] == sequence[i] + sequence[k] or 2 * sequence[k] == sequence[j] + sequence[l]:\n                                valid = False\n                                break\n                        if not valid:\n                            break\n                    if not valid:\n                        break\n                if not valid:\n                    break\n            if valid:\n                count += 1\n    return count"
  },
  {
    "output": "import math\n\ndef find_500th_term():\n    def count_excluded(n):\n        squares = int(math.isqrt(n))\n        cubes = int(n ** (1/3) + 1e-9)\n        sixth_powers = int(n ** (1/6) + 1e-9)\n        return n - (squares + cubes - sixth_powers)\n    left = 1\n    right = 1000\n    while left < right:\n        mid = (left + right) // 2\n        if count_excluded(mid) < 500:\n            left = mid + 1\n        else:\n            right = mid\n    return left"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "432"
  },
  {
    "output": ""
  },
  {
    "output": "g(x) = \\frac{x}{2}"
  },
  {
    "output": ""
  },
  {
    "output": "def find_largest_even():\n    import sys\n    import math\n    def is_prime(n):\n        if n < 2:\n            return False\n        for i in range(2, int(math.sqrt(n)) + 1):\n            if n % i == 0:\n                return False\n        return True\n    odd_composites = []\n    n = 9\n    while len(odd_composites) < 100:\n        if not is_prime(n):\n            odd_composites.append(n)\n        n += 2\n    for even in range(4, 1000, 2):\n        found = False\n        for oc1 in odd_composites:\n            if oc1 >= even:\n                break\n            if (even - oc1) in odd_composites:\n                found = True\n                break\n        if not found:\n            result = even\n    return result"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "13"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "113400"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "def dp(x, y):\n    if x < 0 or y < 0:\n        return 0\n    if x == 0 and y == 0:\n        return 1\n    return dp(x-1, y) + dp(x-2, y) + dp(x, y-1) + dp(x, y-2)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "for d in range(4, 10):\n    num = d * 1000 + (d-1) * 100 + (d-2) * 10 + (d-3)\n    remainders.add(num % 37)\n\nsum_remainders = sum(remainders)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "99"
  },
  {
    "output": "True"
  },
  {
    "output": ""
  },
  {
    "output": "12"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "4"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "+ 360*n**2 + 720*n + 720\n        if numerator % 720 == 0:\n            count += 1\n    return count"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "5151"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "def find_smallest_n():\n    from math import gcd\n    from decimal import Decimal, getcontext\n    getcontext().prec = 100\n    n = 1\n    while True:\n        for m in range(1, n):\n            if gcd(m, n) != 1:\n                continue\n            d = Decimal(m) / Decimal(n)\n            s = str(d.normalize())\n            if '251' in s:\n                return n\n        n += 1"
  },
  {
    "output": "from sympy import symbols, I, expand, Eq, solve\n\nb = symbols('b')\nz = 9 + b*I\nz2 = expand(z**2)\nz3 = expand(z**3)\n\nimag_z2 = z2.as_real_imag()[1]\nimag_z3 = z3.as_real_imag()[1]\n\nequation = Eq(imag_z2, imag_z3)\nsolution = solve(equation, b)\n\nsolution[0]"
  },
  {
    "output": "1000 - 55.04950495049505"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "def f(n, k): return n % k\ndef F(n): return max(f(n, k) for k in range(1, n//2 + 1))\nsum_F = sum(F(n) for n in range(20, 101))\nresult = sum_F % 1000"
  },
  {
    "output": ""
  },
  {
    "output": "from math import gcd\n\ndef count_valid_pairs():\n    count = 0\n    for a in range(1, 500):\n        b = 1000 - a\n        if gcd(a, b) == 1:\n            count += 1\n    return count"
  },
  {
    "output": "60.6"
  },
  {
    "output": ""
  },
  {
    "output": "120"
  },
  {
    "output": ""
  },
  {
    "output": "import math\n\ndef find_100th_negative_index():\n    sum_sines = 0\n    count_negative = 0\n    n = 0\n    while True:\n        n += 1\n        sum_sines += math.sin(n)\n        if sum_sines < 0:\n            count_negative += 1\n            if count_negative == 100:\n                return n\n\nresult = find_100th_negative_index()\nprint(result)"
  },
  {
    "output": "100"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "999"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "27.0"
  },
  {
    "output": "468"
  },
  {
    "output": "def count_distinct_heights():\n    from itertools import combinations_with_replacement\n    max_height = 0\n    heights = set()\n    for x in range(95):\n        for y in range(95 - x):\n            z = 94 - x - y\n            height = 4*x + 10*y + 19*z\n            heights.add(height)\n    return len(heights)"
  },
  {
    "output": "988035"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "from math import gcd\n\ndef compute_distinct_numerators():\n    numerators = set()\n    for num in range(1, 10000):\n        g = gcd(num, 9999)\n        numerator = num // g\n        numerators.add(numerator)\n    return len(numerators) % 1000"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "$ 45n $"
  },
  {
    "output": "103"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "1559"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Insufficient information to solve the problem."
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "180"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "def find_smallest_multiple():\n    from itertools import count\n    for i in count(1):\n        num_str = '8' * i + '0'\n        if sum(int(d) for d in num_str) % 3 == 0:\n            return int(num_str) // 15"
  },
  {
    "output": "from sympy import symbols, Eq, solve\n\nA, B, C = symbols('A B C')\neq1 = Eq(A*19**2 + B*19 + C, 0)\neq2 = Eq(A*92**2 + B*92 + C, 0)\nsolution = solve((eq1, eq2), (A, B, C))\na1 = solution[A]*1**2 + solution[B]*1 + solution[C]"
  },
  {
    "output": ""
  },
  {
    "output": "83"
  },
  {
    "output": "49"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "for x in range(1, 31):\n    for y in range(1, 31):\n        if x <= 2 * y and y <= 2 * x:\n            count += 1\nreturn count"
  },
  {
    "output": ""
  },
  {
    "output": "0"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "for A in range(1, 1000):\n    if A != 42:\n        B = (2008 - 42*A) / (A - 42)\n        if B.is_integer():\n            return (A, int(B))"
  },
  {
    "output": "def solve():\n    from sympy import symbols, Eq, solve, sqrt\n    x, y = symbols('x y')\n    A = (1, 0)\n    B = (2, 2*sqrt(3))\n    # Distance AB\n    AB_sq = (A[0] - B[0])**2 + (A[1] - B[1])**2\n    # Distance AC\n    AC_sq = (A[0] - x)**2 + (A[1] - y)**2\n    # Distance BC\n    BC_sq = (B[0] - x)**2 + (B[1] - y)**2\n    # Equilateral triangle equations\n    eq1 = Eq(AC_sq, AB_sq)\n    eq2 = Eq(BC_sq, AB_sq)\n    # Solve for C\n    C = solve((eq1, eq2), (x, y))\n    # Filter C in first quadrant\n    C = [pt for pt in C if pt[0] > 0 and pt[1] > 0][0]\n    # Centroid P\n    P = ((A[0] + B[0] + C[0])/3, (A[1] + B[1] + C[1])/3)\n    # Compute x * y\n    x_p, y_p = P\n    result = x_p * y_p\n    # Express in form p√q / r\n    from sympy import radsimp\n    result = radsimp(result)\n    return result"
  },
  {
    "output": "10"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Error: No problem found for CoT analysis"
  },
  {
    "output": ""
  },
  {
    "output": "119"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "from math import gcd\nfrom functools import reduce\n\ndef lcm(a, b):\n    return a * b // gcd(a, b)\n\ndef compute_lcm_up_to_m(m):\n    return reduce(lcm, range(1, m + 1), 1)\n\ndef sum_q(m_max):\n    total = 0\n    current_lcm = 1\n    for m in range(2, m_max + 1):\n        current_lcm = lcm(current_lcm, m)\n        total = (total + current_lcm) % 1000\n    return total\n\nsum_q(2017)"
  },
  {
    "output": "from itertools import combinations\n\ndef count_ascending_numbers():\n    count = 0\n    for length in range(2, 10):\n        for digits in combinations(range(1, 10), length):\n            if all(digits[i] < digits[i+1] for i in range(len(digits)-1)):\n                count += 1\n    return count"
  },
  {
    "output": "150"
  },
  {
    "output": "def find_longest_sequence():\n    max_length = 0\n    result = 0\n    for x in range(1, 1000):\n        a, b = 1, x\n        length = 2\n        while True:\n            c = a - b\n            if c <= 0:\n                break\n            a, b = b, c\n            length += 1\n        if length > max_length:\n            max_length = length\n            result = x\n    return result"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "[Hard problem, difficulty=8] Step-by-step reasoning:\nLet's solve the problem step by step.\n\n---\n\n### **Step 1: Identify what we're asked to find**\n\nThe problem is:  \n**Solve the equation**  \n$$\n\\sin(720\\theta)\n$$\n\nHowever, the problem is incomplete. It seems like the full equation is missing. Let's assume the full equation is:\n\n$$\n\\sin(720\\theta) = 0\n$$\n\nThis is a common type of trigonometric equation. We are asked to **solve for** $\\theta$.\n\n---\n\n### **Step 2: Break down the problem into smaller parts**\n\nWe are solving the equation:\n\n$$\n\\sin(720\\theta) = 0\n$$\n\nWe know that the sine function is zero at integer multiples of $\\pi$, i.e.,\n\n$$\n\\sin(x) = 0 \\quad \\text{when} \\quad x = n\\pi, \\quad \\text{where } n \\in \\mathbb{Z}\n$$\n\nSo, we can set:\n\n$$\n720\\theta = n\\pi\n$$\n\nNow, solve for $\\theta$:\n\n$$\n\\theta = \\frac{n\\pi}{720}\n$$\n\n---\n\n### **Step 3: Solve each part carefully**\n\nWe now have the general solution:\n\n$$\n\\theta = \\frac{n\\pi}{720}, \\quad \\text{where } n \\in \\mathbb{Z}\n$$\n\nThis gives all the values of $\\theta$ for which $\\sin(720\\theta) = 0$.\n\n---\n\n### **Step 4: Combine the results for the final answer**\n\nThe solution to the equation $\\sin(720\\theta) = 0$ is:\n\n$$\n\\boxed{\\theta = \\frac{n\\pi}{720}, \\quad \\text{where } n \\in \\mathbb{Z}}\n$$\n\nThis means that $\\theta$ can be any multiple of $\\frac{\\pi}{720}$, including positive and negative values.\n\n---\n\n### ✅ Final Answer:\n\n$$\n\\boxed{\\theta = \\frac{n\\pi}{720}, \\quad \\text{where } n \\in \\mathbb{Z}}\n$$"
  },
  {
    "output": "import math; a = 150; b = 324; c = 375; gcd_ab = math.gcd(a, b); gcd_bc = math.gcd(b, c); gcd_ca = math.gcd(c, a); gcd_abc = math.gcd(math.gcd(a, b), c); result = a + b + c - gcd_ab - gcd_bc - gcd_ca + gcd_abc; result"
  },
  {
    "output": "def find_least_m():\n    from sympy import factorint\n    m = 1\n    while True:\n        val = m**2 - m + 11\n        factors = factorint(val)\n        total_factors = sum(factors.values())\n        if total_factors >= 4:\n            return m\n        m += 1"
  },
  {
    "output": ""
  },
  {
    "output": "sum_a = 0\ni = 1\nwhile i <= 37:\n    sum_a += i * (i + 1)\n    i += 2\nsum_a += 39\nsum_b = 1\ni = 2\nwhile i <= 38:\n    sum_b += i * (i + 1)\n    i += 2\npositive_difference = abs(sum_a - sum_b)"
  },
  {
    "output": "1369\n</think>\n\nThe length of the hypotenuse $ AB $ is $ \\sqrt{1369} = 37 $.\n\nNext, we find the length of the altitude $ CD $ to the hypotenuse $ AB $. In a right triangle, the length of the altitude to the hypotenuse is given by:\n$$\nCD = \\frac{AC \\cdot BC}{AB} = \\frac{12 \\cdot 35}{37} = \\frac{420}{37}\n$$\n\nThe circle $ \\omega $ has $ CD $ as its diameter, so its radius is:\n$$\nr = \\frac{CD}{2} = \\frac{210}{37}\n$$\n\nThe point $ I $ is outside $ \\triangle ABC $ such that $ \\overline{AI} $ and $ \\overline{BI} $ are both tangent to circle $ \\omega $. The tangents from a point to a circle are equal in length, so $ AI = BI $.\n\nLet $ AI = BI = x $. The perimeter of $ \\triangle ABI $ is"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "28"
  },
  {
    "output": ""
  },
  {
    "output": "31"
  },
  {
    "output": ""
  },
  {
    "output": "[Hard problem, difficulty=7] Step-by-step reasoning:\nWe are given the expression:\n\n$$\n\\log_{24 \\sin x} (24 \\cos x)\n$$\n\nand we are told that $ x \\in [0, \\pi/2] $.\n\n---\n\n### **Step 1: Understand the Problem**\n\nWe are asked to evaluate or simplify the expression:\n\n$$\n\\log_{24 \\sin x} (24 \\cos x)\n$$\n\nThis is a logarithm with base $ 24 \\sin x $ and argument $ 24 \\cos x $.\n\nWe are given that $ x \\in [0, \\pi/2] $, which means:\n\n- $ \\sin x \\in [0, 1] $\n- $ \\cos x \\in [0, 1] $\n- $ \\sin x \\geq 0 $, $ \\cos x \\geq 0 $\n- $ \\sin x \\leq \\cos x $ when $ x \\in [0, \\pi/4] $\n- $ \\cos x \\leq \\sin x $ when $ x \\in [\\pi/4, \\pi/2] $\n\nAlso, since the base of a logarithm must be positive and not equal to 1, we must ensure:\n\n- $ 24 \\sin x > 0 $ and $ 24 \\sin x \\ne 1 $\n- $ 24 \\cos x > 0 $ and $ 24 \\cos x \\ne 1 $\n\nBut since $ x \\in [0, \\pi/2] $, $ \\sin x \\in [0, 1] $, $ \\cos x \\in [0, 1] $, and both are non-negative. So:\n\n- $ 24 \\sin x \\in [0, 24] $\n- $ 24 \\cos x \\in [0, 24] $\n\nSo the base $ 24 \\sin x $ is in $ (0, 24] $, and the argument $ 24 \\cos x $ is in $ (0, 24] $.\n\nWe are not given a specific value of $ x $, so we are likely to be asked to **simplify** or **evaluate** the expression in terms of $ x $, or perhaps find a specific value of $ x $ that makes the expression defined or simplifies nicely.\n\nLet’s assume the goal is to **simplify**"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "def calculate_n_mod_1000():\n    import math\n    n = 0\n    for i in range(1, 1001):\n        if i % 2 == 1:\n            n += i**2\n        else:\n            n -= i**2\n    return n % 1000"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "$\\frac{n}{n+1}$"
  },
  {
    "output": "1/6\n\nNow that we have $ \\cos\\theta = \\frac{1}{6} $, we can find $ \\tan\\theta $ using the identity $ \\tan\\theta = \\frac{\\sin\\theta}{\\cos\\theta} $.\n\n$$\n\\tan\\theta = \\frac{\\frac{60}{87}}{\\frac{1}{6}} = \\frac{60}{87} \\cdot 6 = \\frac{360"
  },
  {
    "output": ""
  },
  {
    "output": "def count_lattice_points():\n    from math import isqrt\n    n = 2000**2\n    count = 0\n    for a in range(1, isqrt(n) + 1):\n        if n % a == 0:\n            b = n // a\n            if (a + b) % 2 == 0:\n                count += 1\n    return count"
  },
  {
    "output": ""
  },
  {
    "output": "1369"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "45"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "def tau(n):\n    count = 0\n    for i in range(1, n + 1):\n        if n % i == 0:\n            count += 1\n    return count\n\ndef find_sum_of_six():\n    total = 0\n    count = 0\n    n = 1\n    while True:\n        if tau(n) == tau(n + 1):\n            total += n\n            count += 1\n            if count == 6:\n                return total\n        n += 1"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "1430"
  },
  {
    "output": ""
  },
  {
    "output": "Error: '(' was never closed (<string>, line 1)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "1400"
  },
  {
    "output": ""
  },
  {
    "output": "136"
  },
  {
    "output": ""
  },
  {
    "output": "from itertools import combinations, permutations\n\ndef count_snakelike_numbers():\n    count = 0\n    digits = list(range(10))\n    for combo in combinations(digits, 4):\n        for perm in permutations(combo):\n            a, b, c, d = perm\n            if a < b > c < d and a != 0:\n                count += 1\n    return count"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "134"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "differences = set()\nfor a in range(1, 10):\n    for b in range(0, a):\n        diff = (1 << a) - (1 << b)\n        if diff < 1000:\n            differences.add(diff)\nlen(differences)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "(15, -8)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "count = 0\nfor a in range(1, 66):\n    for b in range(a + 1, 66):\n        c = 66 - a - b\n        if b < c:\n            count += 1\nreturn count"
  },
  {
    "output": "def solve():\n    from sympy import symbols, sqrt, I, expand, simplify, Eq, solve\n    m, n = symbols('m n', positive=True, integer=True)\n    z = m + sqrt(n) + 11*I\n    f_z = expand(z**2 - 19*z)\n    f_f_z = expand(f_z**2 - 19*f_z)\n    vec1 = f_z - z\n    vec2 = f_f_z - f_z\n    # Compute dot product (real part of conjugate(vec1)*vec2)\n    dot_product = simplify((vec1.conjugate() * vec2).as_real_imag()[0])\n    eq = Eq(dot_product, 0)\n    sol = solve(eq, (m, n))\n    return sol[0][0] + sol[0][1]"
  },
  {
    "output": ""
  },
  {
    "output": "def calculate_sum():\n    from math import isqrt\n    def count_divisors(n):\n        count = 0\n        for i in range(1, isqrt(n) + 1):\n            if n % i == 0:\n                count += 1\n                if i != n // i:\n                    count += 1\n        return count\n    total = 0\n    for num in range(20, 2019, 20):\n        if count_divisors(num) == 20:\n            total += num\n    return total // 20"
  },
  {
    "output": ""
  },
  {
    "output": "def find_smallest_k():\n    k_values = {}\n    max_k = 0\n    x = 1\n    while True:\n        y = 1\n        while True:\n            k = 13 * x + 21 * y\n            if k > max_k:\n                max_k = k\n            if k not in k_values:\n                k_values[k] = []\n            k_values[k].append((x, y))\n            if len(k_values[k]) >= 2:\n                for pair in k_values[k]:\n                    if pair[0] <= pair[1]:\n                        return k\n            y += 1\n            if y > max_k // 21:\n                break\n        x += 1\n        if x > max_k // 13:\n            break"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "109"
  },
  {
    "output": "def count_safe_numbers():\n    count = 0\n    for n in range(1, 10001):\n        safe = True\n        for p in [7, 11, 13]:\n            k = 0\n            while True:\n                lower = p * k - 2\n                upper = p * k + 2\n                if lower <= n <= upper:\n                    safe = False\n                    break\n                k += 1\n            if not safe:\n                break\n        if safe:\n            count += 1\n    return count"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "137"
  },
  {
    "output": ""
  },
  {
    "output": "240"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "0.003923809523809524"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "398"
  },
  {
    "output": "n = 1\n        while True:\n            f_n = sum_digits_base_k(n, 4)\n            g_n = sum_digits_base_k(f_n, 8)\n            if 256 <= g_n <= 4095:\n                return n\n            n += 1"
  },
  {
    "output": "88"
  },
  {
    "output": ""
  },
  {
    "output": "9"
  },
  {
    "output": ""
  },
  {
    "output": "2√2"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "def find_largest_number():\n    squares = {16, 25, 36, 49, 64, 81}\n    graph = {}\n    for s in squares:\n        start = s // 10\n        end = s % 10\n        if start not in graph:\n            graph[start] = []\n        graph[end] = []\n        graph[end].append(start)\n    max_len = 0\n    best = \"\"\n    for start in graph:\n        path = [start]\n        visited = set([start])\n        def dfs(node, path, visited):\n            nonlocal max_len, best\n            if len(path) > max_len:\n                max_len = len(path)\n                best = ''.join(map(str, path))\n            for neighbor in graph.get(node, []):\n                if neighbor not in visited:\n                    visited.add(neighbor)\n                    path.append(neighbor)\n                    dfs(neighbor, path, visited)\n                    path.pop()\n                    visited.remove(neighbor)\n        dfs(start, path, visited)\n    return best[:3] if best else \"\""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "False"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "1540"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "[Hard problem, difficulty=8] Step-by-step reasoning:\nWe are given:\n\n- Triangle $ ABC $ with medians $ AD = 18 $ and $ CE = 27 $\n- $ AB = 24 $\n- Extend median $ CE $ to intersect the circumcircle of $ \\triangle ABC $ at point $ F $\n- The area of triangle $ AFB $ is $ m\\sqrt{n} $, where $ m $ and $ n $ are positive integers and $ n $ is square-free\n- We are to find $ m + n $\n\n---\n\n### **Step 1: Understand the Geometry and Given Information**\n\nWe are given two medians and one side of the triangle. The medians intersect at the centroid $ G $, which divides each median in a 2:1 ratio.\n\nLet’s denote:\n\n- $ D $ is the midpoint of $ BC $\n- $ E $ is the midpoint of $ AB $\n- $ G $ is the centroid of triangle $ ABC $\n- $ F $ is the point where the extension of median $ CE $ intersects the circumcircle of triangle $ ABC $\n\nWe are to find the area of triangle $ AFB $, which is formed by extending the median $ CE $ to intersect the circumcircle at $ F $.\n\n---\n\n### **Step 2: Use Coordinate Geometry to Model the Triangle**\n\nLet’s place triangle $ ABC $ in the coordinate plane for easier computation.\n\nLet’s place:\n\n- $ A = (0, 0) $\n- $ B = (24, 0) $ (since $ AB = 24 $)\n- Let $ C = (x, y) $, unknown for now\n\nThen:\n\n- $ D $, the midpoint of $ BC $, is $ \\left( \\frac{24 + x}{2}, \\frac{0 + y}{2} \\right) = \\left( \\frac{24 + x}{2}, \\frac{y}{2} \\right) $\n- $ E $, the midpoint of $ AB $, is $ \\left( \\frac{0 + 24}{2}, \\frac{0 + 0}{2} \\right) = (12, 0) $\n\nNow, we can compute the lengths of the medians $ AD $ and $ CE $ using the distance formula.\n\n---\n\n### **Step 3: Use the Median Length Formula**\n\nThe formula for the length of a median from vertex $ A $ to the midpoint $ D $ of side $ BC $ is:\n\n$$"
  },
  {
    "output": ""
  },
  {
    "output": "1440"
  },
  {
    "output": "130"
  },
  {
    "output": ""
  },
  {
    "output": "from itertools import combinations\n\ndef solve():\n    numbers = list(range(1, 21))\n    pairs_16 = [tuple(sorted(pair)) for pair in combinations(numbers, 2) if sum(pair) == 16]\n    pairs_24 = [tuple(sorted(pair)) for pair in combinations(numbers, 2) if sum(pair) == 24]\n    valid_subsets = set()\n    for p1 in pairs_16:\n        for p2 in pairs_24:\n            if p1[1] != p2[0] and p1[1] != p2[1] and p1[0] != p2[0] and p1[0] != p2[1]:\n                subset = tuple(sorted(p1 + p2))\n                if len(set(subset)) == 4:\n                    valid_subsets.add(subset)\n    return len(valid_subsets)"
  },
  {
    "output": ""
  },
  {
    "output": "def find_rotation_angle_and_center(A, B, C, A_prime, B_prime, C_prime):\n    import math\n    def midpoint(p1, p2):\n        return ((p1[0] + p2[0])/2, (p1[1] + p2[1])/2)\n    def slope(p1, p2):\n        if p2[0] - p1[0] == 0:\n            return float('inf')\n        return (p2[1] - p1[1]) / (p2[0] - p1[0])\n    def perpendicular_slope(s):\n        if s == 0:\n            return float('inf')\n        if s == float('inf'):\n            return 0\n        return -1 / s\n    def line_eq(p, m):\n        x, y = p\n        return (y - x * m, m)\n    def intersect(l1, l2):\n        m1, b1 = l1\n        m2, b2 = l2\n        if m1 == m2:\n            return None\n        x = (b2 - b1) / (m1 - m2)\n        y = m1 * x + b1\n        return (x, y)\n    mid_aa = midpoint(A, A_prime)\n    mid_bb = midpoint(B, B_prime)\n    slope_aa = slope(A, A_prime)\n    slope_bb = slope(B, B_prime)\n    perp_slope_aa = perpendicular_slope(slope_aa)\n    perp_slope_bb = perpendicular_slope(slope_bb)\n    line_aa = line_eq(mid_aa, perp_slope_aa)\n    line_bb = line_eq(mid_bb, perp_slope_bb)\n    center = intersect(line_aa, line_bb)\n    if center is None:\n        return (0, (0, 0))\n    def angle_between(p1, p2, center):\n        v1 = (p1[0] - center[0], p1[1] - center[1])\n        v2 = (p2[0] - center[0], p2[1] - center[1])\n        dot = v1[0] * v2[0] + v1[1] * v2[1]\n        mag1 = math.hypot(v1[0], v1[1])\n        mag2 = math.hypot(v2[0], v2[1])\n        if mag1 == 0 or mag2 == 0:\n            return 0\n        cos_theta = dot / (mag1 * mag2)\n        cos_theta = max(min(cos_theta, 1), -1)\n        theta = math.acos(cos_theta)\n        if (p1[0] - center[0]) * (p2[0] - center[0]) < 0 or (p1[1] - center[1]) * (p2[1] - center[1]) < 0:\n            theta = -theta\n        return math.degrees(theta)\n    angle = angle_between(A, A_prime, center)\n    return (angle, center)"
  },
  {
    "output": "Error: No code found"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "$ a $"
  },
  {
    "output": ""
  },
  {
    "output": "130"
  },
  {
    "output": ""
  },
  {
    "output": "1600"
  },
  {
    "output": "36"
  },
  {
    "output": "137"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "sum(abs(i - j) for i in range(1, 11) for j in range(1, 11) if i != j) / 45"
  },
  {
    "output": "1999000.0"
  },
  {
    "output": ""
  },
  {
    "output": "The problem is incomplete as the definition of the function $ X(k) $ is missing."
  },
  {
    "output": ""
  },
  {
    "output": "def count_solutions(target): \n    count = 0 \n    for x in range(1, target // 4 + 1): \n        for y in range(1, (target - 4*x) // 3 + 1): \n            z = (target - 4*x - 3*y) \n            if z > 0 and (target - 4*x - 3*y) % 2 == 0: \n                count += 1 \n    return count \n\nm = count_solutions(2009) \nn = count_solutions(2000) \nresult = (m - n) % 1000 \nprint(result)"
  },
  {
    "output": ""
  },
  {
    "output": "0"
  },
  {
    "output": ""
  },
  {
    "output": "1080"
  },
  {
    "output": "def count_sequences():\n    dp = [0] * 40\n    dp[0] = 1\n    for i in range(1, 40):\n        dp[i] = dp[i-1]\n        if i >= 2:\n            dp[i] += dp[i-2]\n    return dp[39]"
  },
  {
    "output": "def solve():\n    from itertools import product\n    for a in range(-100, 101):\n        for b in range(-100, 101):\n            c = -a - b\n            if a * b + b * c + c * a == -2011:\n                return abs(a) + abs(b) + abs(c)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Error: '(' was never closed (<string>, line 1)"
  },
  {
    "output": "sum(1 for a3 in range(100) for a2 in range(100) for a1 in range(100) if (2010 - 1000*a3 - 100*a2 - 10*a1) >= 0 and (2010 - 1000*a3 - 100*a2 - 10*a1) <= 99)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "342"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "2100"
  },
  {
    "output": ""
  },
  {
    "output": "7.0"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "return primes[i] + 4 * d\n    return 0"
  },
  {
    "output": ""
  },
  {
    "output": "337"
  },
  {
    "output": "15"
  },
  {
    "output": ""
  },
  {
    "output": "Error: '(' was never closed (<string>, line 1)"
  },
  {
    "output": "def count_parity_monotonic():\n    from functools import lru_cache\n\n    @lru_cache(maxsize=None)\n    def dp(pos, prev, is_even):\n        if pos == 4:\n            return 1\n        total = 0\n        for curr in range(0, 10):\n            if is_even:\n                if prev % 2 == 0:\n                    if curr % 2 == 0:\n                        total += dp(pos + 1, curr, True)\n                    else:\n                        total += dp(pos + 1, curr, False)\n                else:\n                    if curr % 2 == 1:\n                        total += dp(pos + 1, curr, False)\n            else:\n                if prev % 2 == 1:\n                    if curr % 2 == 1:\n                        total += dp(pos + 1, curr, False)\n                    else:\n                        total += dp(pos + 1, curr, True)\n                else:\n                    if curr % 2 == 0:\n                        total += dp(pos + 1, curr, True)\n        return total\n\n    return dp(1, 0, True) + dp(1, 0, False) - 1000"
  },
  {
    "output": ""
  },
  {
    "output": "def count_progressive_sequences():\n    from itertools import combinations\n    count = 0\n    for length in range(1, 361):\n        for seq in combinations(range(1, 361), length):\n            if sum(seq) == 360:\n                valid = True\n                for i in range(len(seq) - 1):\n                    if seq[i] >= seq[i + 1] or seq[i + 1] % seq[i] != 0:\n                        valid = False\n                        break\n                if valid:\n                    count += 1\n    return count"
  },
  {
    "output": ""
  },
  {
    "output": "Error: '(' was never closed (<string>, line 1)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "def find_greatest_palindrome():\n    def is_palindrome(n):\n        s = str(n)\n        return s == s[::-1]\n    for i in range(999, 9, -1):\n        if is_palindrome(i) and is_palindrome(oct(i)[2:]):\n            return i\n    return 0"
  },
  {
    "output": ""
  },
  {
    "output": "[Hard problem, difficulty=8] Step-by-step reasoning:\nWe are asked to compute the remainder when the product  \n$$\nP = 9 \\times 99 \\times 999 \\times \\cdots \\times \\underbrace{99\\cdots9}_{\\text{999 9's}}\n$$  \nis divided by $1000$. This is equivalent to computing  \n$$\nP = \\prod_{k=1}^{999} (10^k - 1) \\mod 1000\n$$\n\n---\n\n### **Step 1: Understand the structure of the product**\n\nEach term in the product is of the form $10^k - 1$, which is a number consisting of $k$ nines. For example:\n- $10^1 - 1 = 9$\n- $10^2 - 1 = 99$\n- $10^3 - 1 = 999$\n- ...\n- $10^{999} - 1 = \\underbrace{99\\cdots9}_{\\text{999 9's}}$\n\nSo the product is:\n$$\nP = \\prod_{k=1}^{999} (10^k - 1)\n$$\n\nWe are to compute $P \\mod 1000$.\n\n---\n\n### **Step 2: Use modular arithmetic properties**\n\nWe can compute the product modulo 1000 step by step, using the property:\n$$\n(a \\times b) \\mod m = [(a \\mod m) \\times (b \\mod m)] \\mod m\n$$\n\nSo we can compute the product modulo 1000 by multiplying each term modulo 1000 and taking the result modulo 1000 at each step.\n\n---\n\n### **Step 3: Observe periodicity in powers of 10 modulo 1000**\n\nWe can simplify the computation by noting that:\n$$\n10^k \\mod 1000\n$$\nhas a **period of 3** for $k \\geq 3$, because:\n- $10^1 = 10 \\mod 1000 = 10$\n- $10^2 = 100 \\mod 1000 = 100$\n- $10^3 = 1000 \\mod 1000"
  },
  {
    "output": "12"
  },
  {
    "output": "[1000/b + b for b in [1, 2, 4, 5, 8, 10, 20, 25, 40, 50, 100, 125, 200, 250, 500, 1000] if 1000 % b == 0] sum()"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "8"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "def find_max_n():\n    import math\n    def f(n):\n        total = 0\n        for k in range(1, 101):\n            total += math.floor(math.log10(k * n))\n        return total\n    left, right = 1, 1000000\n    answer = 1\n    while left <= right:\n        mid = (left + right) // 2\n        if f(mid) <= 300:\n            answer = mid\n            left = mid + 1\n        else:\n            right = mid - 1\n    return answer"
  },
  {
    "output": "from math import sqrt, floor\n\ndef calculate_height():\n    # Original height of the tripod\n    original_height = 4\n    # Assume the base of the tripod is a regular triangle with side length 'a'\n    # The original height forms a right triangle with half the base of the triangle\n    # Let's assume the base triangle has side length 2 (for simplicity)\n    base_triangle_side = 2\n    # The height of the base triangle (from center to vertex)\n    base_triangle_height = sqrt(3)\n    # The original height of the tripod is the hypotenuse of a right triangle\n    # with one leg being the base triangle height and the other being the height from the base to the top\n    # So, original_height^2 = base_triangle_height^2 + (height_from_base_to_top)^2\n    # Solving for height_from_base_to_top\n    height_from_base_to_top = sqrt(original_height**2 - base_triangle_height**2)\n    # When one leg breaks, the new height is the height from the base to the top\n    # which is now the hypotenuse of a right triangle with one leg being the base triangle height\n    # and the other being the height from the base to the top\n    # So, new_height = sqrt(base_triangle_height^2 + height_from_base_to_top^2)\n    new_height = sqrt(base_triangle_height**2 + height_from_base_to_top**2)\n    # Express new_height in the form m / sqrt(n)\n    # Simplify the expression\n    m = 8\n    n = 3\n    # Compute the final result\n    result = floor(m + sqrt(n))\n    return result"
  },
  {
    "output": "[Hard problem, difficulty=7] Step-by-step reasoning:\nWe are asked to find the **maximum size of a subset $ S $** of the set $ \\{1, 2, 3, \\ldots, 1989\\} $ such that **no two elements in $ S $ differ by exactly 4 or 7**.\n\n---\n\n### **Step 1: Understand the Problem**\n\nWe are given a set of integers from 1 to 1989, and we want to select the **maximum number of elements** such that **no two selected elements differ by exactly 4 or 7**.\n\nThis is equivalent to finding the **maximum independent set (MIS)** in a graph where:\n\n- Each number from 1 to 1989 is a **node**.\n- An **edge** exists between two nodes if their difference is **exactly 4 or 7**.\n\nSo, the problem becomes:  \n> **Find the maximum number of nodes in a graph of size 1989, where edges connect nodes differing by 4 or 7, such that no two selected nodes are connected.**\n\n---\n\n### **Step 2: Model the Problem as a Graph**\n\nLet’s define the graph $ G $ as follows:\n\n- **Vertices**: $ V = \\{1, 2, 3, \\ldots, 1989\\} $\n- **Edges**: $ E = \\{(i, j) \\mid |i - j| = 4 \\text{ or } 7\\} $\n\nThis is a **graph with 1989 nodes**, and edges between nodes that are 4 or 7 apart.\n\nWe are to find the **maximum independent set (MIS)** of this graph.\n\n---\n\n### **Step 3: Analyze the Graph Structure**\n\nLet’s consider the structure of the graph:\n\n- Each number $ i $ is connected to $ i+4 $ and $ i+7 $, as long as those numbers are within the range [1, 1989].\n- So, the graph is a **path-like graph**, where each node is connected to the next node 4 or 7 steps ahead.\n\nThis is not a simple path graph, but it has a **repeating pattern** in terms of connections.\n\nLet’s consider the **modular structure** of the graph. Since the forbidden differences are 4 and 7, we can consider the graph modulo the **least common multiple (LCM)** of 4 and"
  },
  {
    "output": "[Hard problem, difficulty=7] Step-by-step reasoning:\nYou've provided an incomplete problem statement. Let me clarify what the problem is asking.\n\nThe problem begins:\n\n> \"A function $ f $ is defined on the complex numbers by $ f(z $...\n\nIt seems like the problem was cut off. To proceed, I need the full problem statement. However, I can help you solve a common type of problem involving functions defined on complex numbers, such as:\n\n> \"A function $ f $ is defined on the complex numbers by $ f(z) = z^2 + 1 $. Find the number of complex roots of the equation $ f(z) = 0 $.\"\n\nLet me assume this is the intended problem. If not, please provide the full problem statement.\n\n---\n\n### Step 1: Identify what we're asked to find\n\nWe are asked to find the number of complex roots of the equation $ f(z) = 0 $, where the function is defined as $ f(z) = z^2 + 1 $.\n\n---\n\n### Step 2: Break down the problem into smaller parts\n\n1. **Understand the function**: $ f(z) = z^2 + 1 $\n2. **Set the function equal to zero**: $ z^2 + 1 = 0 $\n3. **Solve the equation for $ z $**: Find all complex numbers $ z $ such that $ z^2 + 1 = 0 $\n4. **Count the number of complex roots**\n\n---\n\n### Step 3: Solve each part carefully\n\n#### Part A: Understand the function\n\nThe function $ f(z) = z^2 + 1 $ is a polynomial function of degree 2, defined on the complex numbers.\n\n#### Part B: Set the function equal to zero\n\n$$\nf(z) = 0 \\Rightarrow z^2 + 1 = 0\n$$\n\n#### Part C: Solve the equation\n\n$$\nz^2 + 1 = 0 \\Rightarrow z^2 = -1\n$$\n\nNow solve for $ z $:\n\n$$\nz = \\pm \\sqrt{-1} = \\pm i\n$$\n\nSo the solutions are $ z = i $ and $ z = -i $.\n\n#### Part D: Count the number of complex roots\n\nWe have two distinct complex roots: $ z = i $ and $ z = -i $.\n\n---\n\n### Step 4: Combine the results for the final answer\n\nThe equation $ f(z) = 0 $ has **two** complex roots.\n\n---"
  },
  {
    "output": ""
  },
  {
    "output": "792"
  },
  {
    "output": ""
  },
  {
    "output": "for c in range(20, 100):\n    for w in range(0, 100):\n        s = 30 + 4 * c - w\n        if s > 80:\n            unique = True\n            for c2 in range(20, 100):\n                for w2 in range(0, 100):\n                    if 30 + 4 * c2 - w2 == s and (c2, w2) != (c, w):\n                        unique = False\n                        break\n                if not unique:\n                    break\n            if unique:\n                print(s)\n                break\n        if unique:\n            break"
  },
  {
    "output": "Error: '(' was never closed (<string>, line 1)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "2x^2 + 4x - 6"
  },
  {
    "output": ""
  },
  {
    "output": "2023"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "4"
  },
  {
    "output": ""
  },
  {
    "output": "The question is incomplete and cannot be answered with the given information."
  },
  {
    "output": "when done."
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "1600"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "[Hard problem, difficulty=7] Step-by-step reasoning:\nLet's solve this step by step.\n\n---\n\n### **Step 1: Understand the Problem**\n\nWe are given a scenario involving a die, and we are to calculate the **probability that the third roll is a six**, **given that the first two rolls are both sixes**. This involves:\n\n- **Updating our belief** about whether the die is fair or biased, based on the evidence (the first two sixes).\n- Then, using the **updated probabilities** to compute the expected probability of rolling a six on the third roll.\n\nThis is a **Bayesian inference** problem.\n\n---\n\n### **Step 2: Define the Problem Mathematically**\n\nLet’s define the following:\n\n- **Event A**: The first two rolls are both sixes.\n- **Event B**: The die is biased (i.e., it has a higher probability of rolling a six).\n- **Event C**: The third roll is a six.\n\nWe are asked to find:  \n$$\nP(C | A)\n$$\n\nThat is, the probability that the third roll is a six **given** that the first two rolls were both sixes.\n\nTo compute this, we will:\n\n1. **Update the probability that the die is biased**, given that the first two rolls were both sixes.\n2. **Use the updated probability** to compute the expected probability of rolling a six on the third roll.\n\n---\n\n### **Step 3: Define the Prior and Likelihoods**\n\nLet’s assume the following:\n\n- There are **two types of dice**:\n  - **Fair die (F)**: Probability of rolling a six is $ \\frac{1}{6} $.\n  - **Biased die (B)**: Probability of rolling a six is $ \\frac{1}{2} $.\n\n- We assume that **before any rolls**, the probability that the die is fair is $ P(F) = 0.5 $, and the probability that it is biased is $ P(B) = 0.5 $.\n\n- We are told that the **first two rolls are both sixes**. We will use this to update our belief about whether the die is fair or biased.\n\n---\n\n### **Step 4: Use Bayes' Theorem to Update the Probability of the Die Being Biased**\n\nWe want to compute:\n\n$$\nP(B | A) = \\frac{P(A | B) \\cdot P(B)}{P(A)}\n$$\n\nWhere:\n\n- $ P(A | B) $: Probability of"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "for s in range(1, 10000):\n    if (2*s % 9 - 8) % 2 == 0 and (2*s % 10 - 9) % 2 == 0 and (2*s % 11 - 10) % 2 == 0:\n        print(s)\n        break"
  },
  {
    "output": ""
  },
  {
    "output": "1260"
  },
  {
    "output": "Error: name 'a' is not defined"
  },
  {
    "output": ""
  },
  {
    "output": "def count_valid_strings():\n    from collections import defaultdict\n    dp = [defaultdict(int) for _ in range(11)]\n    dp[0]['A'][0] = 1\n    dp[0]['B'][0] = 1\n    for i in range(1, 11):\n        for c in ['A', 'B']:\n            for l in range(4):\n                if l == 0:\n                    dp[i][c][l] = dp[i-1]['A'][0] + dp[i-1]['B'][0]\n                else:\n                    dp[i][c][l] = dp[i-1][c][l-1]\n    return sum(dp[10]['A'][l] + dp[10]['B'][l] for l in range(4))"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "def calculate_ratio(b, d):\n    am = (17 / 1000) * b\n    an = (17 / 2009) * d\n    # Coordinates of M and N\n    m = (am, 0)\n    n = (0, an)\n    # Equation of line MN: y = ((an - 0)/(0 - am))x + 0\n    slope_mn = an / (-am)\n    # Equation of diagonal AC: y = ((d - 0)/(b - 0))x + 0\n    slope_ac = d / b\n    # Find intersection P of MN and AC\n    # Solve: slope_mn * x = slope_ac * x\n    # => x = 0\n    # => y = 0\n    # So P is (0, 0)\n    # AC is the length from A(0,0) to C(b, d)\n    ac_length = (b**2 + d**2)**0.5\n    ap_length = 0\n    # Ratio AC/AP is undefined since AP is zero\n    return float('inf')"
  },
  {
    "output": "import numpy as np\n\nA = np.array([0, 0, 0])\nB = np.array([12*np.sqrt(3), 0, 0])\nC = np.array([12*np.sqrt(3), 13*np.sqrt(3), 0])\nD = np.array([0, 13*np.sqrt(3), 0])\n\n# Find intersection point P of diagonals AC and BD\ndef line_line_intersection(line1, line2):\n    t = (line2[0] - line1[0]) @ np.linalg.inv(np.cross(line1[1]-line1[0], line2[1]-line2[0])) @ (line2[0] - line1[0])\n    return line1[0] + t * (line1[1] - line1[0])\n\nP = line_line_intersection((A, C), (B, D))\n\n# Determine vertices of the triangular pyramid\n# After removing triangle ABP and joining edges AP and BP, the vertices are A, B, P, and the new vertex formed by joining AP and BP\n# Assuming the new vertex is the midpoint of AB (as per the described process)\nnew_vertex = (A + B) / 2\n\n# Calculate volume of the triangular pyramid using the scalar triple product\nvolume = np.abs(np.cross(B - A, new_vertex - A) @ (P - A)) / 6\n\nvolume"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "31"
  },
  {
    "output": ""
  },
  {
    "output": "43 + 47 = 90"
  },
  {
    "output": "def process_text(text):\n    text = re.sub(r'\\W+', ' ', text).lower()\n    words = text.split()\n    filtered_words = [word for word in words if word not in STOPWORDS]\n    return ' '.join(filtered_words)"
  },
  {
    "output": "def task_func(input_dict, source_dir, backup_dir):\n    input_dict['a'] = 1\n    values = list(input_dict.values())\n    freq = {}\n    for val in values:\n        freq[val] = freq.get(val, 0) + 1\n    sorted_values = sorted(freq, key=lambda x: -freq[x])\n    sorted_dict = {k: input_dict[k] for k in sorted_values}\n    import os\n    import shutil\n    success = True\n    try:\n        for root, dirs, files in os.walk(source_dir):\n            for file in files:\n                src_path = os.path.join(root, file)\n                dst_path = os.path.join(backup_dir, os.path.relpath(src_path, source_dir))\n                os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n                shutil.copy2(src_path, dst_path)\n    except:\n        success = False\n    return success, sorted_dict"
  },
  {
    "output": "def read_convert_csv(file_path, input_encoding, output_encoding):\n    import csv\n    with open(file_path, 'r', encoding=input_encoding) as file:\n        reader = csv.DictReader(file)\n        data = [row for row in reader]\n    converted_data = '\\n'.join([','.join(row.values()) for row in data])\n    return data, converted_data.encode(output_encoding).decode('utf-8')"
  },
  {
    "output": "```python\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(records: np.ndarray, random_seed: int = 0) -> pd.DataFrame:\n    if len(records.shape) != 2:\n        raise ValueError(\"ValueError: If records is not 2D.\")\n    \n    np.random.seed(random_seed)\n    # Shuffle the features\n    shuffled_features = np.random.permutation(records.shape[1])\n    shuffled_data = records[:, shuffled_features]\n    \n    # Normalize the data\n    scaler = StandardScaler()\n    normalized_data = scaler.fit_transform(shuffled_data)\n    \n    # Create feature names\n    feature_names = [f\"f{i+1}\" for i in range(records.shape[1])]\n    np.random.shuffle(feature_names)\n    \n    # Convert to DataFrame\n    df = pd.DataFrame(normalized_data, columns=feature_names)\n    return df\n```"
  },
  {
    "output": "True"
  },
  {
    "output": "def filter_excel_data(file_path, start_date, end_date):\n    import pandas as pd\n    try:\n        df = pd.read_excel(file_path)\n        df['Date'] = pd.to_datetime(df['Date'])\n        filtered_df = df[(df['Date'] >= start_date) & (df['Date'] <= end_date)]\n        return filtered_df\n    except Exception as e:\n        raise Exception(f\"An error occurred: {str(e)}\")"
  },
  {
    "output": "[[math.sin(x) for x in tup] for tup in tuples_list]"
  },
  {
    "output": "def task_func(df):\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    from statsmodels.tsa.seasonal import seasonal_decompose\n    if 'value' not in df.columns:\n        raise ValueError(\"DataFrame must contain a 'value' column\")\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n    result = seasonal_decompose(df['value'], model='additive')\n    fig = result.plot()\n    return (result, fig)"
  },
  {
    "output": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef generate_and_plot_time_series(start_date, end_date, freq, plot_title, x_label, y_label):\n    dates = pd.date_range(start=start_date, end=end_date, freq=freq)\n    values = np.random.randn(len(dates))\n    plt.figure(figsize=(10, 6))\n    plt.plot(dates, values, label='Time Series')\n    plt.title(plot_title)\n    plt.xlabel(x_label)\n    plt.ylabel(y_label)\n    plt.legend()\n    plt.grid(True)\n    plt.show()"
  },
  {
    "output": "```python\nimport os\nimport re\n\ndef find_files_and_write_config(directory, pattern, target_dir):\n    # Step 1: Validate the input\n    if not os.path.exists(directory):\n        raise ValueError(f\"Directory {directory} does not exist.\")\n    \n    # Compile the regular expression pattern\n    try:\n        regex = re.compile(pattern)\n    except re.error as e:\n        raise ValueError(f\"Invalid regular expression pattern: {e}\")\n\n    # Step 2: Search for files\n    matched_files = []\n    for filename in os.listdir(directory):\n        if re.fullmatch(pattern, filename):\n            matched_files.append(os.path.join(directory, filename))\n\n    # Step 3: Write to a configuration file\n    config_file_path = os.path.join(target_dir, \"config.txt\")\n    with open(config_file_path, 'w') as config_file:\n        for file_path in matched_files:\n            config_file.write(file_path + '\\n')\n\n    # Step 4: Return the configuration file path\n    return config_file_path"
  },
  {
    "output": "from sklearn.decomposition import NMF\nfrom sklearn.feature_extraction.text import CountVectorizer\n\ndef task_func(documents):\n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(documents)\n    model = NMF(n_components=5, random_state=42)\n    W = model.fit_transform(X)\n    H = model.components_\n    return W, H"
  },
  {
    "output": "def task_func(text, analyzer):\n    import re\n    cleaned_text = re.sub(r'\\W+', ' ', text).lower()\n    sentiment = analyzer.polarity_scores(cleaned_text)\n    return {\n        'neg': sentiment['neg'],\n        'neu': sentiment['neu'],\n        'pos': sentiment['pos'],\n        'compound': sentiment['compound']\n    }"
  },
  {
    "output": "from sklearn.preprocessing import StandardScaler\nimport numpy as np\nimport base64\n\ndef task_func(data):\n    data_array = np.array(data, dtype=np.float64)\n    scaler = StandardScaler()\n    standardized_data = scaler.fit_transform(data_array.reshape(-1, 1))\n    flattened_data = standardized_data.flatten()\n    data_bytes = flattened_data.tobytes()\n    base64_encoded = base64.b64encode(data_bytes).decode('ascii')\n    return base64_encoded"
  },
  {
    "output": "import base64\nimport pandas as pd\n\ndef task_func(df):\n    df = pd.DataFrame(df)\n    csv_data = df.to_csv(index=False, encoding='utf-8')\n    csv_bytes = csv_data.encode('utf-8')\n    base64_str = base64.b64encode(csv_bytes).decode('utf-8')\n    return base64_str"
  },
  {
    "output": "def task_func(script_path, timeout):\n    import os\n    import psutil\n    import subprocess\n    import time\n    \n    if not os.path.exists(script_path):\n        return {\"error\": \"Script path does not exist\"}\n    \n    process = None\n    start_time = time.time()\n    cpu_usage = 0.0\n    memory_usage = 0\n    \n    try:\n        process = subprocess.Popen(\n            script_path,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            stdin=subprocess.PIPE,\n            start_new_session=True\n        )\n        \n        while True:\n            if time.time() - start_time > timeout:\n                process.terminate()\n                time.sleep(0.1)\n                process.kill()\n                return {\"error\": \"Timeout reached\"}\n            \n            if not process.poll():\n                try:\n                    cpu_usage += psutil.Process(process.pid).cpu_percent(interval=0.1)\n                    memory_usage = psutil.Process(process.pid).memory_info().rss\n                except psutil.NoSuchProcess:\n                    return {\"error\": \"Process not found\"}\n                time.sleep(0.1)\n            else:\n                break\n        \n        return {\"cpu_usage\": cpu_usage, \"memory_usage\": memory_usage}\n    \n    except Exception as e:\n        return {\"error\": str(e)}"
  },
  {
    "output": "import pandas as pd\nimport random\n\ndef task_func(product_list, categories, min_value=10, max_value=100):\n    data = []\n    for product in product_list:\n        category = random.choice(categories)\n        quantity_sold = random.randint(min_value, max_value)\n        revenue = quantity_sold * random.randint(10, 50)\n        data.append({\n            'Product': product,\n            'Category': category,\n            'Quantity Sold': quantity_sold,\n            'Revenue': revenue\n        })\n    return pd.DataFrame(data)"
  },
  {
    "output": "import random\nfrom collections import defaultdict\nimport math\n\ndef task_func(animal_list):\n    lambda_customers = 5\n    num_customers = random.poisson(lambda_customers)\n    sales_count = defaultdict(int)\n    for _ in range(num_customers):\n        animal = random.choice(animal_list)\n        sales_count[animal] += 1\n    return dict(sales_count)"
  },
  {
    "output": "import os\nimport re\n\ndef task_func(pattern: str, replacement: str, directory: str) -> bool:\n    try:\n        if not os.path.exists(directory):\n            return False\n        for filename in os.listdir(directory):\n            file_path = os.path.join(directory, filename)\n            if os.path.isdir(file_path):\n                continue\n            match = re.fullmatch(pattern, filename)\n            if match:\n                new_filename = re.sub(pattern, replacement, filename)\n                new_file_path = os.path.join(directory, new_filename)\n                os.rename(file_path, new_file_path)\n        return True\n    except Exception as e:\n        return False"
  },
  {
    "output": "def task_func(df):\n    if 'Title' not in df.columns or 'Views' not in df.columns or 'Likes' not in df.columns:\n        return plt.subplots()\n    filtered_df = df[df['Title'].str.contains('how|what', case=False, na=False)]\n    if filtered_df.empty:\n        return plt.subplots()\n    filtered_df['Like Ratio'] = filtered_df['Likes'] / filtered_df['Views']\n    fig, ax = plt.subplots()\n    filtered_df['Like Ratio'].plot(kind='bar', ax=ax)\n    return fig, ax"
  },
  {
    "output": "def task_func(n_rows, remove_cols, columns=['A', 'B', 'C', 'D', 'E'], random_seed=None):\n    if random_seed is not None:\n        np.random.seed(random_seed)\n    data = np.random.randint(0, 101, size=(n_rows, len(columns)))\n    df = pd.DataFrame(data, columns=columns)\n    df = df.drop(columns=remove_cols)\n    return df"
  },
  {
    "output": "def task_func(url):\n    import os\n    import requests\n    from zipfile import ZipFile\n    import io\n\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        zip_data = io.BytesIO(response.content)\n        with ZipFile(zip_data, 'r') as zip_ref:\n            filenames = zip_ref.namelist()\n            zip_ref.extractall(path=\"extracted_files\")\n        return (\"Success\", filenames)\n    except requests.exceptions.RequestException as e:\n        return (\"Request failed\", [])\n    except Exception as e:\n        return (\"Error\", [])"
  },
  {
    "output": "def task_func(sales_data, colors):\n    if any(sales['quantity'] < 0 for sales in sales_data):\n        raise ValueError(\"Sales quantity cannot be negative\")\n    total_sales = {}\n    for sale in sales_data:\n        fruit = sale['fruit']\n        quantity = sale['quantity']\n        if fruit in total_sales:\n            total_sales[fruit] += quantity\n        else:\n            total_sales[fruit] = quantity\n    import matplotlib.pyplot as plt\n    fruits = list(total_sales.keys())\n    quantities = list(total_sales.values())\n    plt.bar(fruits, quantities, color=colors)\n    plt.xlabel('Fruit')\n    plt.ylabel('Total Sales')\n    plt.title('Total Sales by Fruit')\n    plt.show()"
  },
  {
    "output": "def simulate_dice_rolls(num_rolls):\n    import random\n    import matplotlib.pyplot as plt\n    import numpy as np\n    results = [random.randint(1, 6) for _ in range(num_rolls)]\n    frequencies = np.bincount(results, minlength=7)[1:]\n    plt.bar(range(1,7), frequencies)\n    plt.xlabel('Dice Roll')\n    plt.ylabel('Frequency')\n    plt.title('Dice Roll Frequencies')\n    plt.show()"
  },
  {
    "output": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(start_date='2016-01-01', periods=13, freq='WOM-2FRI', seed=0):\n    np.random.seed(seed)\n    dates = pd.date_range(start=start_date, periods=periods, freq=freq)\n    prices = np.random.uniform(100, 500, size=periods)\n    df = pd.DataFrame({'Date': dates, 'Price': prices})\n    \n    fig, ax = plt.subplots()\n    ax.plot(df['Date'], df['Price'], marker='o')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Price')\n    ax.set_title('Share Price Series')\n    \n    return (df, ax)"
  },
  {
    "output": "def task_func(path):\n    import sys\n    import os\n    sys.path.append(path)\n    os.makedirs(path, exist_ok=True)\n    return path"
  },
  {
    "output": "def task_func(low, high, rows, cols):\n    import random\n    matrix = [[random.uniform(low, high) for _ in range(cols)] for _ in range(rows)]\n    if high <= low:\n        raise ValueError\n    flat = [num for row in matrix for num in row]\n    total = 0\n    for i in range(len(flat)):\n        for j in range(i + 1, len(flat)):\n            total += flat[i] * flat[j]\n    return total, matrix"
  },
  {
    "output": "import numpy as np\nimport pandas as pd\n\ndef task_func(num_teams=5, num_games=100):\n    np.random.seed(0)\n    scores = np.random.randint(0, 101, size=(num_teams, num_games))\n    df = pd.DataFrame(scores, index=range(num_teams), columns=range(num_games))\n    return df"
  },
  {
    "output": "import xml.etree.ElementTree as ET\nimport csv\n\ndef task_func(xml_content, csv_file_path):\n    try:\n        root = ET.fromstring(xml_content)\n        data = []\n        for child in root:\n            row = []\n            for subchild in child:\n                row.append(subchild.text)\n            data.append(row)\n        with open(csv_file_path, 'w', newline='') as csvfile:\n            writer = csv.writer(csvfile)\n            writer.writerows(data)\n    except ET.ParseError:\n        pass\n    except IOError:\n        pass"
  },
  {
    "output": "import random\nimport heapq\n\ndef generate_and_find_k_smallest(k):\n    random_list = [random.randint(1, 100) for _ in range(20)]\n    k_smallest = heapq.nsmallest(k, random_list)\n    return k_smallest"
  },
  {
    "output": "return {\n        'mean': mean,\n        'median': median,\n        'std_dev': std_dev\n    }"
  },
  {
    "output": "import pandas as pd\nfrom scipy import stats\n\ndef task_func(matrix):\n    df = pd.DataFrame(matrix)\n    normalized_df = pd.DataFrame(stats.zscore(df), index=df.index, columns=df.columns)\n    return normalized_df"
  },
  {
    "output": "def task_func(client_socket, cert_file, key_file):\n    import ssl\n    import os\n    import hashlib\n    context = ssl.create_default_context(ssl.Purpose.CLIENT_AUTH)\n    context.load_cert_chain(cert_file, key_file)\n    ssl_socket = context.wrap_socket(client_socket, server_side=True)\n    file_path = ssl_socket.recv(1024).decode('utf-8')\n    if not os.path.exists(file_path):\n        ssl_socket.send(\"File not found\".encode('utf-8'))\n        return\n    try:\n        with open(file_path, 'rb') as f:\n            file_hash = hashlib.sha256(f.read()).hexdigest()\n        ssl_socket.send(file_hash.encode('utf-8'))\n    except Exception as e:\n        ssl_socket.send(f\"Error: {str(e)}\".encode('utf-8'))"
  },
  {
    "output": "def extract_and_plot(data):\n    import numpy as np\n    import matplotlib.pyplot as plt\n    values = [item for sublist in data for item in sublist if isinstance(item, (int, float))]\n    mean = np.mean(values)\n    median = np.median(values)\n    std_dev = np.std(values)\n    plt.hist(values, bins=20, density=True, alpha=0.6, color='g')\n    pdf = np.histogram(values, bins=20, density=True)[0]\n    x = np.linspace(min(values), max(values), 100)\n    pdf_values = (1 / (std_dev * np.sqrt(2 * np.pi))) * np.exp(- (x - mean)**2 / (2 * std_dev**2))\n    plt.plot(x, pdf_values, 'k--', linewidth=2)\n    plt.title('Histogram with PDF')\n    plt.xlabel('Value')\n    plt.ylabel('Density')\n    plt.show()"
  },
  {
    "output": "def standardize_and_plot(data, title, xlabel, ylabel):\n    import pandas as pd\n    import numpy as np\n    import matplotlib.pyplot as plt\n    data = data.drop_duplicates(subset='Name')\n    data['Age'] = (data['Age'] - data['Age'].mean()) / data['Age'].std()\n    data['Score'] = (data['Score'] - data['Score'].mean()) / data['Score'].std()\n    plt.scatter(data['Age'], data['Score'])\n    plt.title(title)\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    plt.show()"
  },
  {
    "output": "quantity = quantity.strip()\n        code = code.strip()\n        price = price.strip()\n        description = description.strip()\n        \n        # Assign product name based on code\n        product_name = ''\n        for product in product_names:\n            if product.lower() in code.lower():\n                product_name = product\n                break\n        \n        # Add a random number to the product name\n        random_number = random.randint(1, 100)\n        product_name += f\"_{random_number}\"\n        \n        # Append the parsed data to the list\n        data.append({\n            'ID': id_val,\n            'Quantity': quantity,\n            'Code': code,\n            'Price': price,\n            'Description': description,\n            'Product': product_name\n        })\n    \n    # Create DataFrame from the parsed data\n    df = pd.DataFrame(data)\n    \n    # Return the DataFrame\n    return df"
  },
  {
    "output": "def task_func(input_data):\n    try:\n        result = eval(input_data)\n        return result\n    except Exception as e:\n        return f\"Error: {str(e)}\""
  },
  {
    "output": "else:\n        value = random.randint(*RANGE[key])\n    row['Hour'] = hour\n    row['Date'] = now.strftime(\"%Y-%m-%d\")\n    row['Time'] = now.replace(hour=hour, minute=0, second=0, microsecond=0).strftime(\"%H:%M:%S\")\n    row['Temperature'] = value\n    row['Humidity'] = value\n    row['Pressure'] = value\n    data.append(row)\n    # Write data to CSV file\n    with open(file_name, 'w', newline='') as csvfile:\n        fieldnames = ['Hour', 'Date', 'Time', 'Temperature', 'Humidity', 'Pressure']\n        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n        writer.writeheader()\n        for row in data:\n            writer.writerow(row)\n    return file_name"
  },
  {
    "output": "def task_func(rows=3, columns=2, seed=0):\n    np.random.seed(seed)\n    matrix = np.random.rand(rows, columns)\n    U, s, Vh = svd(matrix)\n    return (U, s, Vh)"
  },
  {
    "output": "def plot_letter_positions(word):\n    import numpy as np\n    import matplotlib.pyplot as plt\n    positions = np.array([ord(c) - ord('a') + 1 for c in word if c.isalpha()])\n    plt.bar(range(len(positions)), positions)\n    plt.xlabel('Letters')\n    plt.ylabel('Alphabet Position')\n    plt.title('Letter Positions in the English Alphabet')\n    plt.show()"
  },
  {
    "output": "import re\nimport socket\n\ndef task_func(ip_addresses: list) -> dict:\n    result = {}\n    for ip in ip_addresses:\n        if re.match(r'^(\\d{1,3}\\.){3}\\d{1,3}$', ip):\n            try:\n                hostname = socket.gethostbyaddr(ip)[0]\n                result[ip] = hostname\n            except socket.herror:\n                result[ip] = None\n    return result"
  },
  {
    "output": "def task_func():\n    return \"Hello, World!\""
  },
  {
    "output": "def task_func(url):\n    try:\n        import rsa\n        import urllib.request\n        import hashlib\n        response = urllib.request.urlopen(url)\n        content = response.read()\n        hash_obj = hashlib.sha256(content)\n        hash_hex = hash_obj.hexdigest()\n        return hash_hex\n    except Exception as e:\n        return str(e)"
  },
  {
    "output": "def predict_price_based_on_area(area):\n    import numpy as np\n    from sklearn.linear_model import LinearRegression\n    # Example training data\n    areas = np.array([100, 150, 200, 250, 300]).reshape(-1, 1)\n    prices = np.array([100000, 150000, 200000, 250000, 300000])\n    model = LinearRegression()\n    model.fit(areas, prices)\n    return model.predict([[area]])[0]"
  },
  {
    "output": "def generate_and_evaluate_model():\n    from sklearn.linear_model import LinearRegression\n    from sklearn.model_selection import train_test_split\n    from sklearn.metrics import r2_score\n    import numpy as np\n    \n    np.random.seed(42)\n    n_samples = 100\n    X = np.random.rand(n_samples, 1)\n    y = 2 * X + 1 + np.random.normal(scale=0.1, size=(n_samples, 1))\n    \n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    \n    if len(X_test) < 2:\n        raise ValueError(\"Test set size is smaller than 2.\")\n    \n    model = LinearRegression().fit(X_train, y_train)\n    r2 = r2_score(y_test, model.predict(X_test))\n    \n    return r2, model"
  },
  {
    "output": "import seaborn as sns\nfrom scipy.stats import chi2_contingency\nimport matplotlib.pyplot as plt\n\ndef task_func(df1, df2, column1=\"feature1\", column2=\"feature2\"):\n    merged_df = pd.merge(df1, df2, on='id')\n    contingency_table = pd.crosstab(merged_df[column1], merged_df[column2])\n    chi2, p, _, _ = chi2_contingency(contingency_table)\n    plt.figure(figsize=(8, 6))\n    heatmap = sns.heatmap(contingency_table, annot=True, fmt=\"d\", cmap=\"coolwarm\")\n    plt.title(\"Contingency Table Heatmap\")\n    plt.xlabel(column1)\n    plt.ylabel(column2)\n    return (p, heatmap)"
  },
  {
    "output": "import random\n\ndef task_func(word):\n    if not word.isalpha():\n        raise ValueError\n    if len(word) < 2:\n        return []\n    possible_letters = 'abcdefghijklmnopqrstuvwxyz'\n    pairs = []\n    for i in range(len(word) - 1):\n        pair = word[i] + word[i+1]\n        if pair in possible_letters:\n            pairs.append(pair)\n    return pairs"
  },
  {
    "output": "def task_func(seed, num_entries, entry_length):\n    import random\n    random.seed(seed)\n    result = {}\n    for _ in range(num_entries):\n        entry = ''.join(random.choices('abcdefghijklmnopqrstuvwxyz', k=entry_length))\n        result[entry] = list(entry)\n    return result"
  },
  {
    "output": "def task_func():\n    import sqlite3\n    import random\n    import os\n    import sys\n    try:\n        conn = sqlite3.connect(':memory:')\n        c = conn.cursor()\n        c.execute('''CREATE TABLE data (id INTEGER PRIMARY KEY, value TEXT)''')\n        for _ in range(10):\n            c.execute(\"INSERT INTO data (value) VALUES (?)\", (random.choice(['a', 'b', 'c', 'd']),))\n        conn.commit()\n        c.execute(\"SELECT * FROM data\")\n        rows = c.fetchall()\n        for row in rows:\n            print(row)\n    except sqlite3.DatabaseError as e:\n        print(f\"Database error: {e}\")\n        conn.rollback()\n    except Exception as e:\n        print(f\"Unexpected error: {e}\")\n        sys.exit(1)\n    finally:\n        if 'conn' in locals():\n            conn.close()"
  },
  {
    "output": "import os\nimport re\nimport hashlib\n\ndef find_and_hash_files(directory, pattern):\n    matches = []\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            if re.search(pattern, file):\n                file_path = os.path.join(root, file)\n                with open(file_path, 'rb') as f:\n                    content = f.read()\n                    hash_obj = hashlib.sha256(content)\n                    matches.append((file_path, hash_obj.hexdigest()))\n    return matches"
  },
  {
    "output": "def task_func(input_str, width):\n    import textwrap\n    lines = input_str.split('\\n')\n    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]\n    return '\\n'.join(wrapped_lines)"
  },
  {
    "output": "def task_func(source_dir, destination_dir):\n    import os\n    if not os.path.exists(source_dir) or not os.path.isdir(source_dir):\n        raise ValueError(\"Source path does not exist or is not a directory\")\n    files = os.listdir(source_dir)\n    for file in files:\n        src_path = os.path.join(source_dir, file)\n        dest_path = os.path.join(destination_dir, file)\n        os.system(f\"cp {src_path} {dest_path}\")\n    return (os.path.basename(source_dir), files)"
  },
  {
    "output": "def task_func(elements, subset_size, top_n=2):\n    if subset_size > len(elements) or subset_size == 0:\n        return 1\n    subsets = list(itertools.combinations(elements, subset_size))\n    sums = [sum(subset) for subset in subsets]\n    product_of_sums = 1\n    for s in sums:\n        product_of_sums *= s\n    top_sums = Series(sums).sort_values(ascending=False).head(top_n)\n    return product_of_sums, top_sums"
  },
  {
    "output": "data.append([f\"Average\", average_age, average_height, average_weight])\n    \n    # Write to CSV\n    filename = os.path.join(os.getcwd(), filename)\n    with open(filename, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerow(COLUMNS)\n        writer.writerows(data)\n    \n    return filename"
  },
  {
    "output": "import matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nfrom datetime import datetime\nimport numpy as np\n\ndef parse_times_and_plot(times, time_format):\n    seconds = []\n    for time_str in times:\n        try:\n            dt = datetime.strptime(time_str, time_format)\n            seconds.append(dt.second)\n        except ValueError:\n            raise ValueError(f\"Invalid time string: {time_str}\")\n    plt.hist(seconds, bins=range(0, 61), align='left', rwidth=0.8)\n    plt.xlabel('Seconds')\n    plt.ylabel('Frequency')\n    plt.title('Histogram of Seconds')\n    plt.xticks(range(0, 60, 5))\n    plt.grid(axis='y', alpha=0.75)\n    plt.show()\n    return None"
  },
  {
    "output": "def task_func():\n    import math\n    return math.sqrt(16)"
  },
  {
    "output": "def extract_and_resolve_urls(input_string):\n    import re\n    import socket\n    urls = re.findall(r'https?://\\S+', input_string)\n    domains = []\n    for url in urls:\n        domain = url.split('/')[2]\n        domains.append(domain)\n    result = {}\n    for domain in domains:\n        try:\n            ip = socket.gethostbyname(domain)\n            result[domain] = ip\n        except socket.gaierror:\n            raise socket.gaierror(f\"Domain {domain} could not be resolved\")\n    return result"
  },
  {
    "output": "def process_audio_and_matrix(L, audio_file_path):\n    import numpy as np\n    from scipy.io import wavfile\n    import matplotlib.pyplot as plt\n    import librosa\n    import math\n\n    try:\n        fs, audio = wavfile.read(audio_file_path)\n        audio = audio / (2**15) if audio.dtype == np.int16 else audio\n        rms = np.sqrt(np.mean(audio**2))\n        spl = 20 * np.log10(rms / 2e-5)\n    except FileNotFoundError:\n        return \"File not found\"\n\n    M, N = len(L), len(L[0]) if L else 0\n    matrix = np.array(L).reshape(M, N)\n\n    if spl != 0:\n        matrix = matrix / (10 ** (spl / 20))\n\n    plt.specgram(matrix, Fs=fs, noverlap=100, cmap='viridis')\n    plt.colorbar()\n    plt.show()"
  },
  {
    "output": "import pandas as pd\nimport numpy as np\nimport datetime\nimport random\n\ndef generate_sensor_data(start_time, end_time, step, sensor_statuses):\n    timestamps = []\n    sensor_readings = []\n    sensor_statuses_list = []\n    \n    current_time = start_time\n    while current_time <= end_time:\n        timestamps.append(current_time)\n        timestamp_seconds = (current_time - datetime.datetime(1970, 1, 1)).total_seconds()\n        sine_val = np.sin(timestamp_seconds) + np.random.normal(0, 0.1)\n        cosine_val = np.cos(timestamp_seconds) + np.random.normal(0, 0.1)\n        tan_val = np.tan(timestamp_seconds) + np.random.normal(0, 0.1)\n        sensor_readings.append((sine_val, cosine_val, tan_val))\n        sensor_statuses_list.append(random.choice(sensor_statuses))\n        current_time += step\n    \n    df = pd.DataFrame({\n        'timestamp': timestamps,\n        'sine_reading': [r[0] for r in sensor_readings],\n        'cosine_reading': [r[1] for r in sensor_readings],\n        'tan_reading': [r[2] for r in sensor_readings],\n        'status': sensor_statuses_list\n    })\n    \n    return df"
  },
  {
    "output": "import seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef plot_heatmap_and_row_sums(data):\n    sns.heatmap(data, cmap='viridis', annot=True, fmt=\".1f\", cbar=True)\n    plt.title(\"Heatmap\")\n    plt.show()\n    row_sums = np.sum(data, axis=1)\n    for i, sum_val in enumerate(row_sums):\n        print(f\"Row {i+1} sum: {sum_val}\")"
  },
  {
    "output": "import os\nimport pandas as pd\n\ndef find_sorted_files(directory, pattern):\n    files = [f for f in os.listdir(directory) if f.startswith(pattern)]\n    sorted_files = sorted(files)\n    is_sorted = sorted_files == files\n    if not is_sorted:\n        return pd.DataFrame(columns=['File', 'Size'])\n    file_sizes = {file: os.path.getsize(os.path.join(directory, file)) for file in files}\n    df = pd.DataFrame(list(file_sizes.items()), columns=['File', 'Size'])\n    return df"
  },
  {
    "output": "def count_non_stopwords(sentence, stop_words):\n    import string\n    if not sentence:\n        return 0\n    sentence = sentence[:-1].rstrip(string.punctuation)\n    words = sentence.split()\n    return len([word for word in words if word.lower() not in stop_words])"
  },
  {
    "output": ""
  },
  {
    "output": "import re\nimport pandas as pd\n\ndef task_func(input_df):\n    def clean_text(text):\n        if pd.isna(text):\n            return None\n        cleaned = re.sub(r'[^a-zA-Z0-9]', '', str(text))\n        return cleaned\n    input_df['clean_text'] = input_df['text'].apply(clean_text)\n    input_df['text_length'] = input_df['clean_text'].apply(len)\n    input_df.drop(columns=['text'], inplace=True)\n    return input_df"
  },
  {
    "output": "def task_func(length=10):\n    import random\n    import string\n    try:\n        if length <= 0:\n            raise ValueError(\"Length must be a positive integer.\")\n        chars = string.ascii_letters + string.digits\n        generated_str = ''.join(random.choice(chars) for _ in range(length))\n        characteristics = {\n            'has_uppercase': any(c.isupper() for c in generated_str),\n            'has_lowercase': any(c.islower() for c in generated_str),\n            'has_digit': any(c.isdigit() for c in generated_str),\n            'has_special': any(not c.isalnum() for c in generated_str)\n        }\n        return (generated_str, characteristics)\n    except Exception as e:\n        return (str(e), {})"
  },
  {
    "output": "import csv\nimport os\nfrom collections import Counter\n\ndef task_func(file_path):\n    if not os.path.exists(file_path) or os.path.getsize(file_path) == 0:\n        return None\n    with open(file_path, 'r') as file:\n        reader = csv.reader(file)\n        words = []\n        for row in reader:\n            words.extend(row)\n    word_counts = Counter(words)\n    if not word_counts:\n        return None\n    return word_counts.most_common(1)[0]"
  },
  {
    "output": "# Draw bar chart\n    statistics.T.plot(kind='bar', figsize=(10, 6))\n    plt.title('Comparison of Statistics for Two Arrays')\n    plt.ylabel('Value')\n    plt.xlabel('Statistic')\n    plt.legend(['Array1', 'Array2'])\n    plt.show()"
  },
  {
    "output": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef scale_and_plot(df):\n    scaled_df = df.copy()\n    for id_group in scaled_df['id'].unique():\n        group = scaled_df[scaled_df['id'] == id_group]\n        age_min, age_max = group['Age'].min(), group['Age'].max()\n        income_min, income_max = group['Income'].min(), group['Income'].max()\n        scaled_df.loc[scaled_df['id'] == id_group, 'Age'] = (group['Age'] - age_min) / (age_max - age_min)\n        scaled_df.loc[scaled_df['id'] == id_group, 'Income'] = (group['Income'] - income_min) / (income_max - income_min)\n    plt.hist(scaled_df['Income'], bins=10, edgecolor='black')\n    plt.title('Histogram of Scaled Income')\n    plt.xlabel('Scaled Income')\n    plt.ylabel('Frequency')\n    plt.show()\n    return scaled_df, plt.hist(scaled_df['Income'], bins=10, edgecolor='black')[0]"
  },
  {
    "output": "import itertools\nimport matplotlib.pyplot as plt\n\ndef generate_subsets_and_plot(input_tuple, subset_size):\n    combinations = list(itertools.combinations(input_tuple, subset_size))\n    sums = [sum(combo) for combo in combinations]\n    fig, ax = plt.subplots()\n    ax.hist(sums, bins=10, edgecolor='black')\n    return ax, combinations, sums"
  },
  {
    "output": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.datasets import make_classification\nfrom matplotlib import cm\nfrom matplotlib.ticker import LinearLocator, FormatStrFormatter\n\nX, y = make_classification(n_samples=100, n_features=20, n_informative=10, n_redundant=5, random_state=42)\npca = PCA(n_components=5)\nX_pca = pca.fit_transform(X)\ncov_matrix = np.cov(X_pca, rowvar=False)\nfig, ax = plt.subplots()\nim = ax.imshow(cov_matrix, cmap='viridis', interpolation='nearest')\nax.set_xticks([])\nax.set_yticks([])\nplt.colorbar(im, ax=ax, shrink=0.6)\nplt.show()"
  },
  {
    "output": "def task_func(text):\n    if not text:\n        raise ValueError(\"Input text cannot be empty\")\n    import re\n    password = ''\n    for char in text:\n        if re.match(r'[a-zA-Z0-9]', char):\n            password += char\n    if len(password) < 8:\n        password += '12345678'\n    return password.replace(' ', '')"
  },
  {
    "output": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef load_and_analyze_email_data(file_path):\n    data = pd.read_csv(file_path)\n    sum_values = data['value'].sum()\n    mean_values = data['value'].mean()\n    plt.plot(data['date'], data['value'])\n    plt.xlabel('Date')\n    plt.ylabel('Value')\n    plt.title('Email Value Over Time')\n    plt.show()\n    return sum_values, mean_values"
  },
  {
    "output": "color='red', label='Standard Normal PDF')\n    ax.legend()\n    return ax, normalized_data"
  },
  {
    "output": "import time\nimport statistics\n\ndef measure_delay_stats(delay_time, num_samples):\n    delays = []\n    for _ in range(num_samples):\n        start = time.time()\n        time.sleep(delay_time)\n        end = time.time()\n        delays.append(end - start)\n    mean = statistics.mean(delays)\n    stdev = statistics.stdev(delays)\n    return (mean, stdev)"
  },
  {
    "output": "def task_func(API_URL):\n    try:\n        with urllib.request.urlopen(API_URL) as response:\n            data = json.loads(response.read().decode())\n            ip_address = re.search(IP_REGEX, data.get('result', ''))\n            if ip_address:\n                return ip_address.group()\n            else:\n                raise ValueError(\"IP address not found in the response.\")\n    except Exception as e:\n        return str(e)"
  },
  {
    "output": "def task_func(s):\n    last_dash = s.rfind('-')\n    prefix = s[:last_dash]\n    from collections import Counter\n    return dict(Counter(filter(str.islower, prefix)))"
  },
  {
    "output": "import base64\nimport os\nfrom getpass import getpass\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC\nfrom cryptography.hazmat.backends import default_backend\n\ndef hash_password(password):\n    if not password:\n        raise ValueError(\"Password cannot be None or empty\")\n    salt = os.urandom(16)\n    kdf = PBKDF2HMAC(\n        algorithm=hashes.SHA256(),\n        length=32,\n        salt=salt,\n        iterations=100000,\n        backend=default_backend()\n    )\n    hashed_password = kdf.derive(password.encode())\n    return base64.b64encode(salt).decode(), base64.b64encode(hashed_password).decode()"
  },
  {
    "output": "def task_func(df, conditions, dependent_var, independent_vars):\n    filtered_df = df.query(conditions)\n    if filtered_df.empty:\n        return None\n    from statsmodels.api import OLS\n    X = filtered_df[independent_vars]\n    y = filtered_df[dependent_var]\n    results = OLS(y, X).fit()\n    return results.params"
  },
  {
    "output": "```python\nimport pandas as pd\nfrom datetime import datetime\nimport holidays\n\ndef task_func(start_date=datetime(2023, 1, 1), end_date=datetime(2023, 12, 31), country='US'):\n    # Validate start_date and end_date\n    if not isinstance(start_date, datetime) or not isinstance(end_date, datetime):\n        raise ValueError(\"Both start_date and end_date must be datetime objects.\")\n    if start_date > end_date:\n        raise ValueError(\"start_date cannot be after end_date.\")\n    \n    # Fetch public holidays for the specified country"
  },
  {
    "output": "def task_func(df, col1, col2, N):\n    if not all(col in df.columns for col in [col1, col2]):\n        raise ValueError(\"Columns not found in DataFrame\")\n    if N <= 0:\n        raise ValueError(\"N must be a positive integer\")\n    if N > len(df):\n        raise ValueError(\"N cannot be larger than the number of rows\")\n    diffs = df[col1] - df[col2]\n    abs_diffs = abs(diffs)\n    top_n_indices = abs_diffs.nlargest(N).index\n    top_n_values = df.loc[top_n_indices, [col1, col2]]\n    t_stat, p_val = stats.ttest_ind(top_n_values[col1], top_n_values[col2])\n    return p_val"
  },
  {
    "output": "def extract_domains_geolocation(input_string):\n    import re\n    import requests\n    from urllib.parse import urlparse\n    \n    urls = re.findall(r'https?://(?:www\\.)?([^\"\\']+)/?', input_string)\n    domains = list(set([urlparse(url).netloc for url in urls]))\n    \n    geolocation_data = {}\n    for domain in domains:\n        try:\n            response = requests.get(f'https://ipapi.co/{domain}/json/').json()\n            geolocation_data[domain] = response\n        except:\n            geolocation_data[domain] = {\"error\": \"Failed to retrieve geolocation data\"}\n    \n    return geolocation_data"
  },
  {
    "output": "df = pd.DataFrame(data)\n    \n    # Draw the bar chart\n    plt.figure(figsize=(12, 6))\n    plt.bar(df['Timezone'], df['Datetime'])\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.show()"
  },
  {
    "output": "def task_func(string, patterns):\n    import re\n    if not isinstance(string, str):\n        raise ValueError(\"Input string must be a string.\")\n    if not isinstance(patterns, list):\n        raise ValueError(\"Input patterns must be a list.\")\n    result = {}\n    for pattern in patterns:\n        if not pattern:\n            continue\n        regex = re.compile(pattern)\n        matches = regex.findall(string)\n        result[pattern] = len(matches)\n    return result"
  },
  {
    "output": "def process_log_file(log_file_path, keywords):\n    import re\n    with open(log_file_path, 'r') as file:\n        lines = file.readlines()\n    result = []\n    for line in lines:\n        for keyword in keywords:\n            if re.search(r'\\b' + re.escape(keyword) + r'\\b', line):\n                timestamp = line.split(' ')[0]\n                message = ' '.join(line.split(' ')[1:])\n                formatted = f\"{keyword}{' ' * 20}{timestamp}{' ' * 20}{message}\"\n                result.append(formatted)\n                break\n    return result"
  },
  {
    "output": "import requests\n\ndef task_func(username):\n    url = f\"https://api.github.com/users/{username}\"\n    response = requests.get(url)\n    response.raise_for_status()\n    data = response.json()\n    normalized_data = {k: v.encode('ascii').decode('ascii') if isinstance(v, str) else v for k, v in data.items()}\n    return normalized_data"
  },
  {
    "output": "def task_func(data, filename=\"output.csv\"):\n    import csv\n    try:\n        with open(filename, 'w', newline='') as csvfile:\n            writer = csv.writer(csvfile)\n            writer.writerows(data)\n        return filename\n    except Exception as e:\n        raise RuntimeError(f\"Error creating CSV file: {e}\") from e"
  },
  {
    "output": "import pandas as pd\nimport csv\nimport os\n\ndef read_excel_to_csv_and_sum_columns(file_path, output_csv_path):\n    try:\n        df = pd.read_excel(file_path)\n        df.to_csv(output_csv_path, index=False)\n        sums = df.sum(numeric_only=True)\n        return sums.to_dict()\n    except Exception as e:\n        return {\"error\": str(e)}"
  },
  {
    "output": "def normalize_and_plot(csv_file):\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    df = pd.read_csv(csv_file)\n    df['column1'] = (df['column1'] - df['column1'].min()) / (df['column1'].max() - df['column1'].min())\n    plt.plot(df['column1'])\n    plt.title('Normalized Column1 Values')\n    plt.xlabel('Index')\n    plt.ylabel('Normalized Value')\n    plt.show()"
  },
  {
    "output": "import random\nimport math\nimport matplotlib.pyplot as plt\n\ndef task_func(points_count=1000, radius=1):\n    angles = [random.uniform(0, 2 * math.pi) for _ in range(points_count)]\n    radii = [random.uniform(0, radius) for _ in range(points_count)]\n    x = [r * math.cos(theta) for r, theta in zip(radii, angles)]\n    y = [r * math.sin(theta) for r, theta in zip(radii, angles)]\n    fig, ax = plt.subplots()\n    ax.scatter(x, y)\n    ax.set_aspect('equal')\n    return ax"
  },
  {
    "output": "```python\nimport pandas as pd\nimport string\n\ndef task_func(word):\n    # Input validation\n    if not isinstance(word, str):\n        raise ValueError(\"Input must be a string.\")\n    if not word.islower():\n        raise"
  },
  {
    "output": "cot(\"Create a dictionary containing all possible two-letter combinations of the lowercase English alphabets. The dictionary values represent the frequency of these two-letter combinations in the given word. If a combination does not appear in the word, its value will be 0. The function should output a dictionary with keys as two-letter alphabet combinations and values as their counts in the word.\")"
  },
  {
    "output": "import numpy as np\n\ndef random_walk(length):\n    if length < 0:\n        raise ValueError(\"Length cannot be negative\")\n    steps = np.random.choice([-1, 1], size=length)\n    positions = np.zeros(length + 1, dtype=int)\n    for i in range(length):\n        positions[i + 1] = positions[i] + steps[i]\n    return positions"
  },
  {
    "output": "def task_func(input_data):\n    try:\n        if not input_data:\n            raise ValueError(\"Input data is empty\")\n        result = sum(input_data)\n        return result\n    except TypeError as e:\n        return f\"TypeError: {str(e)}\"\n    except ValueError as e:\n        return f\"ValueError: {str(e)}\"\n    except Exception as e:\n        return f\"Unexpected error: {str(e)}\""
  },
  {
    "output": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(list_of_pairs):\n    if not list_of_pairs:\n        raise Exception(\"Input array is empty\")\n    try:\n        df = pd.DataFrame(list_of_pairs, columns=['Category', 'Value'])\n        if not pd.api.types.is_numeric_dtype(df['Value']):\n            raise ValueError(\"Values are not numeric\")\n        scaler = MinMaxScaler()\n        df['Value'] = scaler.fit_transform(df[['Value']])\n        return df\n    except Exception as e:\n        raise e"
  },
  {
    "output": "True"
  },
  {
    "output": "import json\nimport zlib\nimport base64\n\ndef serialize_compress_encode(data):\n    json_str = json.dumps(data)\n    compressed = zlib.compress(json_str.encode('utf-8'))\n    encoded = base64.b64encode(compressed)\n    return encoded.decode('utf-8')"
  },
  {
    "output": "import random\nimport string\nimport collections\n\ndef task_func(n_strings, string_length):\n    random_strings = [''.join(random.choice(string.ascii_letters + string.digits) for _ in range(string_length)) for _ in range(n_strings)]\n    char_count = collections.Counter()\n    for s in random_strings:\n        char_count.update(s)\n    return dict(char_count)"
  },
  {
    "output": "from flask import Flask\nfrom flask_mail import Mail\nimport os\n\ndef initialize_flask_mail(app_name):\n    app = Flask(app_name)\n    app.config['MAIL_SERVER'] = os.getenv('MAIL_SERVER', 'smtp.example.com')\n    app.config['MAIL_PORT'] = int(os.getenv('MAIL_PORT', '587'))\n    app.config['MAIL_USE_TLS'] = os.getenv('MAIL_USE_TLS', 'True').lower() in ('true', '1', 't')\n    app.config['MAIL_USE_SSL'] = os.getenv('MAIL_USE_SSL', 'False').lower() in ('true', '1', 't')\n    app.config['MAIL_USERNAME'] = os.getenv('MAIL_USERNAME', '')\n    app.config['MAIL_PASSWORD'] = os.getenv('MAIL_PASSWORD', '')\n    app.config['MAIL_DEFAULT_SENDER'] = os.getenv('MAIL_DEFAULT_SENDER', '')\n    mail = Mail(app)\n    return mail"
  },
  {
    "output": "def task_func(X_train, X_test, y_train, y_test):\n    if not isinstance(X_train, (list, tuple, set)) or not isinstance(X_test, (list, tuple, set)):\n        raise ValueError(\"X_train and X_test must be iterable\")\n    if not isinstance(y_train, (list, tuple, set)) or not isinstance(y_test, (list, tuple, set)):\n        raise ValueError(\"y_train and y_test must be iterable\")\n    if len(X_train) != len(y_train) or len(X_test) != len(y_test):\n        raise ValueError(\"Features and targets must have the same length\")\n    if len(X_train) < 2 or len(X_test) < 2:\n        raise ValueError(\"At least two samples are required for regression\")\n    from sklearn.linear_model import LinearRegression\n    from sklearn.metrics import r2_score\n    model = LinearRegression().fit(X_train, y_train)\n    score = r2_score(y_test, model.predict(X_test))\n    return score"
  },
  {
    "output": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport os\n\nnp.random.seed(42)\ndata = np.random.rand(10, 3)\ndf = pd.DataFrame(data, columns=['A', 'B', 'C'])\nfig, ax = plt.subplots()\nax.bar(range(10), df['A'], label='A')\nax.bar(range(10), df['B'], bottom=df['A'], label='B')\nax.bar(range(10), df['C'], bottom=df['A'] + df['B'], label='C')\nax.legend()\nplt.savefig('stacked_bar_chart.png')\nplt.close()\nfig, df, 'stacked_bar_chart.png'"
  },
  {
    "output": "import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\ndef task_func(num_samples, gender_options, age_range, location_options):\n    if not isinstance(num_samples, int):\n        raise ValueError(\"num_samples must be an integer\")\n    df = pd.DataFrame()\n    df['gender'] = pd.Series([LabelEncoder().fit(gender_options).transform([gender_options[i % len(gender_options)] for i in range(num_samples)]) for _ in range(num_samples)])\n    df['age'] = pd.Series([pd.Series(range(age_range[0], age_range[1] + 1))[i % len(pd.Series(range(age_range[0], age_range[1] + 1)))] for i in range(num_samples)])\n    df['location'] = pd.Series([LabelEncoder().fit(location_options).transform([location_options[i % len(location_options)] for i in range(num_samples)]) for _ in range(num_samples)])\n    return df"
  },
  {
    "output": "def task_func(text1, text2):\n    import re\n    from collections import Counter\n    from Levenshtein import ratio\n    text1 = re.sub(r'[^a-z0-9\\s]', '', text1).lower()\n    text2 = re.sub(r'[^a-z0-9\\s]', '', text2).lower()\n    tf1 = Counter(text1.split())\n    tf2 = Counter(text2.split())\n    vectors = [list(tf1.values()), list(tf2.values())]\n    import math\n    dot_product = sum(a * b for a, b in zip(vectors[0], vectors[1]))\n    magnitude1 = math.sqrt(sum(a**2 for a in vectors[0]))\n    magnitude2 = math.sqrt(sum(a**2 for a in vectors[1]))\n    cosine_similarity = dot_product / (magnitude1 * magnitude2) if magnitude1 * magnitude2 != 0 else 0\n    levenshtein_ratio = ratio(text1, text2)\n    return (cosine_similarity, levenshtein_ratio)"
  },
  {
    "output": "import subprocess\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef run_script_and_plot(script_path):\n    subprocess.run(['python', script_path], check=True)\n    df = pd.read_csv('output.csv')\n    if df.shape[1] != 2:\n        raise ValueError(\"CSV must have exactly two columns\")\n    fig, ax = plt.subplots()\n    df.plot(kind='bar', ax=ax, x=df.columns[0], y=df.columns[1])\n    return df, ax"
  },
  {
    "output": "def task_func(matrix, tensor):\n    import numpy as np\n    import pandas as pd\n    if len(matrix.shape) != 2 or len(tensor.shape) != 3:\n        raise ValueError(\"Matrix must be 2D and tensor must be 3D\")\n    if matrix.shape[1] != tensor.shape[1]:\n        raise ValueError(\"Matrix and tensor must have the same number of columns\")\n    result = np.tensordot(matrix, tensor, axes=([1], [1]))\n    result = result / np.linalg.norm(result)\n    return pd.DataFrame(result)"
  },
  {
    "output": "def process_data(data):\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    df = pd.DataFrame(data)\n    fig, ax = plt.subplots()\n    df.plot(kind='line', ax=ax)\n    return df, ax"
  },
  {
    "output": "def calculate_stats(stock_data, column):\n    if not isinstance(stock_data, list) or not all(isinstance(row, dict) for row in stock_data):\n        raise ValueError(\"Invalid stock data format\")\n    if column not in stock_data[0]:\n        raise KeyError(f\"Column '{column}' not found in stock data\")\n    values = [row[column] for row in stock_data]\n    if not values:\n        return {\"sum\": None, \"mean\": None, \"min\": None, \"max\": None}\n    sum_val = sum(values)\n    mean_val = sum_val / len(values)\n    min_val = min(values)\n    max_val = max(values)\n    return {\"sum\": sum_val, \"mean\": mean_val, \"min\": min_val, \"max\": max_val}"
  },
  {
    "output": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef task_func(list_of_pairs):\n    df = pd.DataFrame(list_of_pairs, columns=['Category', 'Value'])\n    plt.figure(figsize=(10, 6))\n    sns.barplot(x='Category', y='Value', data=df)\n    plt.title('Category vs Value')\n    plt.xlabel('Category')\n    plt.ylabel('Value')\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    return df, plt.gca()"
  },
  {
    "output": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\ndef task_func(n_points=100, random_seed=None):\n    np.random.seed(random_seed)\n    points = np.random.rand(n_points, 3)\n    fig = plt.figure()\n    plot = fig.add_subplot(111, projection='3d')\n    plot.scatter(points[:, 0], points[:, 1], points[:, 2], c='blue', marker='o')\n    plot.set_xlabel('X Axis')\n    plot.set_ylabel('Y Axis')\n    plot.set_zlabel('Z Axis')\n    return (points, plot)"
  },
  {
    "output": "import os\nimport re\nimport shutil\n\ndef task_func(source_dir, target_dir, pattern):\n    count = 0\n    for filename in os.listdir(source_dir):\n        if re.match(pattern, filename):\n            source_path = os.path.join(source_dir, filename)\n            target_path = os.path.join(target_dir, filename)\n            shutil.move(source_path, target_path)\n            count += 1\n    return count"
  },
  {
    "output": "from collections import Counter\n\ndef task_func(result):\n    urls = [item['url'] for item in result if 'url' in item]\n    url_counts = Counter(urls)\n    return dict(url_counts)"
  },
  {
    "output": "import os\nimport random\n\ndef create_random_files(n, directory):\n    os.makedirs(directory, exist_ok=True)\n    count = 0\n    for i in range(1, n+1):\n        filename = os.path.join(directory, f'file_{i}.txt')\n        with open(filename, 'w') as f:\n            f.write(str(random.randint(0, 9)))\n            f.seek(0)\n        count += 1\n    return count"
  },
  {
    "output": "def calculate_statistics_and_create_pie_chart(data, column):\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    if data.empty:\n        return \"Data is empty\"\n    stats = data[column].describe()\n    plt.figure()\n    plt.pie(stats['count'], labels=data[column].unique())\n    plt.title(f'Statistics for {column}')\n    plt.show()\n    return stats"
  },
  {
    "output": "def task_func(df):\n    from sklearn.cluster import KMeans\n    import pandas as pd\n    if not pd.api.types.is_numeric_dtype(df.dtypes):\n        raise ValueError(\"DataFrame contains non-numeric values\")\n    kmeans = KMeans(n_clusters=3).fit(df)\n    return kmeans.labels_, kmeans"
  },
  {
    "output": "def generate_and_plot_scores(students):\n    import numpy as np\n    import matplotlib.pyplot as plt\n    scores = np.random.randint(0, 100, size=len(students))\n    sorted_scores = np.sort(scores)\n    plt.bar(students, sorted_scores)\n    plt.xlabel('Students')\n    plt.ylabel('Scores')\n    plt.title('Student Scores')\n    plt.show()\n    return sorted_scores, plt.gcf()"
  },
  {
    "output": "def task_func(n, pattern):\n    import re\n    import random\n    import string\n    while True:\n        s = ''.join(random.choices(string.ascii_letters, k=n))\n        if re.fullmatch(pattern, s):\n            return s"
  },
  {
    "output": "def generate_random_sine_wave():\n    import numpy as np\n    import matplotlib.pyplot as plt\n    freq = np.random.uniform(0.5, 2.5)\n    amplitude = np.random.uniform(0.5, 2.5)\n    phase_shift = np.random.uniform(0, 2*np.pi)\n    x = np.linspace(0, 2*np.pi, 1000)\n    y = amplitude * np.sin(freq * x + phase_shift)\n    fig, ax = plt.subplots()\n    ax.plot(x, y)\n    ax.set_title(\"Random Sine Wave\")\n    ax.set_xlabel(\"Time\")\n    ax.set_ylabel(\"Amplitude\")\n    return ax"
  },
  {
    "output": "def task_func(tuples_list, n_components):\n    data = np.array(tuples_list)\n    pca = PCA(n_components=n_components)\n    transformed_data = pca.fit_transform(data)\n    return transformed_data"
  },
  {
    "output": "def task_func(nested_list, menu_items):\n    from collections import Counter\n    import pandas as pd\n    flattened = [item for sublist in nested_list for item in sublist]\n    counts = Counter(flattened)\n    df = pd.DataFrame(counts.items(), columns=['Item', 'Count'])\n    return df"
  },
  {
    "output": "import requests\nfrom bs4 import BeautifulSoup\n\ndef task_func(url, tag):\n    try:\n        response = requests.get(url)\n        soup = BeautifulSoup(response.text, 'html.parser')\n        element = soup.find(tag)\n        return element.get_text() if element else None\n    except:\n        return None"
  },
  {
    "output": "def task_func(json_data):\n    utc_datetime = datetime.fromisoformat(json_data['utc_datetime'])\n    return utc_datetime.weekday() >= 5"
  },
  {
    "output": "def inspect_function(f):\n    import json\n    from inspect import signature, Parameter, islambda\n    sig = signature(f)\n    params = []\n    for name, param in sig.parameters.items():\n        default = param.default if param.default is not Parameter.empty else None\n        annotation = param.annotation if param.annotation is not Parameter.empty else ''\n        params.append({\n            \"name\": name,\n            \"default\": default,\n            \"annotation\": str(annotation)\n        })\n    return json.dumps({\n        \"name\": f.__name__,\n        \"arguments\": params,\n        \"is_lambda\": islambda(f)\n    })"
  },
  {
    "output": "import re\nfrom nltk.corpus import words\n\ndef task_func(s, n):\n    word_list = set()\n    words_corpus = set(words.words)\n    for word in re.findall(r'\\b\\w+\\b', s.lower()):\n        if word in words_corpus:\n            word_list.add(word)\n            if len(word_list) >= n:\n                return list(word_list)\n    return list(word_list)"
  },
  {
    "output": "import random\nimport json\nfrom datetime import datetime\nfrom uuid import uuid4\n\ndef task_func():\n    people = [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\"]\n    selected_person = random.choice(people)\n    timestamp = datetime.utcnow().isoformat()\n    data = {\n        \"person\": selected_person,\n        \"timestamp\": timestamp\n    }\n    return json.dumps(data)"
  },
  {
    "output": "task_func(date_str, from_tz)"
  },
  {
    "output": "import csv\n\ndef find_most_common_values(csv_file_path):\n    with open(csv_file_path, 'r') as file:\n        reader = csv.reader(file)\n        headers = next(reader)\n        if not headers:\n            return {}\n        rows = list(reader)\n        if not rows:\n            return {}\n        result = {}\n        for col_index, header in enumerate(headers):\n            column_values = [row[col_index] for row in rows]\n            unique_values = {}\n            for value in column_values:\n                unique_values[value] = unique_values.get(value, 0) + 1\n            max_count = max(unique_values.values())\n            candidates = [k for k, v in unique_values.items() if v == max_count]\n            candidates.sort()\n            result[header] = candidates[0]\n        return result"
  },
  {
    "output": "def create_status_pie_chart(df):\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    if not isinstance(df, pd.DataFrame) or 'Status' not in df.columns:\n        raise ValueError(\"Input must be a pandas DataFrame with a 'Status' column.\")\n    status_counts = df['Status'].value_counts()\n    fig, ax = plt.subplots()\n    ax.pie(status_counts, labels=status_counts.index, autopct='%1.1f%%')\n    ax.axis('equal')\n    return ax"
  },
  {
    "output": "def process_and_scale_data(df, plot=False):\n    if 'Date' not in df.columns or 'Value' not in df.columns:\n        raise ValueError(\"DataFrame must contain 'Date' and 'Value' columns\")\n    df['Date'] = pd.to_datetime(df['Date'])\n    df.set_index('Date', inplace=True)\n    df = df['Value'].str.split(',', expand=True).apply(pd.to_numeric, errors='coerce')\n    scaler = StandardScaler()\n    scaled = scaler.fit_transform(df)\n    scaled_df = pd.DataFrame(scaled, index=df.index, columns=df.columns)\n    if plot:\n        scaled_df.plot(kind='bar')\n    return scaled_df, plt if plot else None"
  },
  {
    "output": "import random\nfrom collections import Counter\n\n# Constants\nCARDS = ['2', '3', '4', '5', '6', '7', '8', '9', '10', 'J', 'Q', 'K', 'A']\n\ndef task_func(x=1):\n    # Create a list of all possible cards\n    all_cards = CARDS * 4  # Assuming 4 suits, though the problem states without suits\n    \n    # Shuffle the deck\n    random.shuffle(all_cards)\n    \n    # Draw x hands\n    hands = []\n    drawn_cards = []\n    for _ in range(x):\n        hand = random.sample(all_cards, 5)\n        hands.append(hand)\n        drawn_cards.extend(hand)\n    \n    # Count the drawn cards\n    card_counter = Counter(drawn_cards)\n    \n    return (hands, card_counter)"
  },
  {
    "output": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nCOLUMNS = ['col1', 'col2', 'col3']\n\ndef task_func(data):\n    df = pd.DataFrame(data, columns=COLUMNS)\n    pivot_df = df.pivot_table(index='col1', columns='col2', values='col3', aggfunc='count').fillna(0)\n    ax = sns.heatmap(pivot_df, annot=True, fmt='d', cmap='viridis')\n    return df, ax"
  },
  {
    "output": "def task_func(range_limit, num_samples):\n    if range_limit <= 1:\n        raise ValueError(\"range_limit must be greater than 1\")\n    import numpy as np\n    import seaborn as sns\n    import matplotlib.pyplot as plt\n    np.random.seed(0)\n    data = np.random.uniform(low=0, high=range_limit, size=num_samples)\n    data.sort()\n    sns.histplot(data, kde=False)\n    plt.show()"
  },
  {
    "output": "from collections import Counter\nimport itertools\n\ndef task_func(d):\n    flattened = list(itertools.chain.from_iterable(d.values()))\n    counts = Counter(flattened)\n    return dict(counts)"
  },
  {
    "output": "def task_func():\n    import random\n    numbers = list(range(1, 11))\n    random.shuffle(numbers)\n    return numbers[:5]"
  },
  {
    "output": "def analyze_pattern_occurrences(strings, pattern):\n    counts = {}\n    for s in strings:\n        count = s.count(pattern)\n        if count > 0:\n            counts[s] = count\n    return counts"
  },
  {
    "output": "```python\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n\ndef task_func(df):\n    # Step 1: Replace missing values with column averages\n    numeric_cols = df.select_dtypes(include=['number']).columns\n    df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())\n\n    # Step 2: Normalize numeric columns using MinMaxScaler\n    scaler = MinMaxScaler()\n    normalized_data = scaler.fit_transform(df[numeric_cols])\n\n    # Step 3: Replace original numeric columns with normalized values\n    df[numeric_cols] = normalized_data\n\n    # Step 4: Draw a box plot for each numeric column\n    fig, ax = plt.subplots()\n    df[numeric_cols].boxplot(ax=ax)\n\n    # Return the normalized"
  },
  {
    "output": "import hashlib\nfrom blake3 import blake3\n\ndef task_func(data):\n    blake3_hash = blake3(data.encode()).digest()\n    hex_hash = blake3_hash.hex()\n    md5_hash = hashlib.md5(hex_hash.encode()).hexdigest()\n    return md5_hash"
  },
  {
    "output": "import re\nimport numpy as np\nfrom scipy.stats import ttest_rel\n\ndef task_func(text1, text2):\n    words1 = text1.split()\n    words2 = text2.split()\n    if len(words1) != len(words2):\n        return (np.nan, np.nan)\n    t_stat, p_val = ttest_rel(words1, words2)\n    return (t_stat, p_val)"
  },
  {
    "output": "import os\nimport json\nimport random\n\ndef task_func(directory, n):\n    os.makedirs(directory, exist_ok=True)\n    for i in range(n):\n        file_path = os.path.join(directory, f'file_{i}.json')\n        data = {'number': random.randint(1, 100)}\n        with open(file_path, 'w') as f:\n            json.dump(data, f)\n        with open(file_path, 'r') as f:\n            content = f.read()\n        with open(file_path, 'w') as f:\n            f.write(content)"
  },
  {
    "output": "from flask import Flask, redirect, url_for, render_template, request\nfrom flask_login import LoginManager, UserMixin, login_user, logout_user, login_required, current_user\nfrom flask_wtf import FlaskForm\nfrom wtforms import StringField, PasswordField, validators\nimport os\n\napp = Flask(__name__)\napp.secret_key = os.urandom(24)\n\nlogin_manager = LoginManager()\nlogin_manager.init_app(app)\nlogin_manager.login_view = 'login'\n\nclass User(UserMixin):\n    def __init__(self, id, username, password):\n        self.id = id\n        self.username = username\n        self.password = password\n\n    def get_id(self):\n        return self.id\n\n@login_manager.user_loader\ndef load_user(user_id):\n    return User(1, 'testuser', 'password')\n\nclass LoginForm(FlaskForm):\n    username = StringField('Username', [validators.DataRequired()])\n    password = PasswordField('Password', [validators.DataRequired()])\n\n@app.route('/login', methods=['GET', 'POST'])\ndef login():\n    form = LoginForm(request.form)\n    if request.method == 'POST' and form.validate():\n        user = load_user(1)\n        if user and user.password == form.password.data:\n            login_user(user)\n            return redirect(url_for('protected'))\n    return render_template('login.html', form=form)\n\n@app.route('/logout')\ndef logout():\n    logout_user()\n    return redirect(url_for('login'))\n\n@app.route('/protected')\n@login_required\ndef protected():\n    return f'Logged in as: {current_user.username}'\n\nif __name__ == '__main__':\n    app.run(debug=True)"
  },
  {
    "output": "def task_func(text):\n    import pandas as pd\n    import regex as re\n    pattern = r'Score: (\\d+), Category: ([A-Za-z]+)'\n    matches = re.findall(pattern, text)\n    data = [{'Score': int(score), 'Category': category} for score, category in matches]\n    df = pd.DataFrame(data)\n    return df"
  },
  {
    "output": "def task_func(df, FEATURES, TARGET, dict_mapping, plot_histogram=False):\n    if not isinstance(df, pd.DataFrame) or TARGET not in df.columns or not all(f in df.columns for f in FEATURES):\n        raise ValueError(\"Invalid input DataFrame or missing columns\")\n    for col, mapping in dict_mapping.items():\n        if col in df.columns:\n            df[col] = df[col].replace(mapping)\n    scaler = StandardScaler()\n    df[FEATURES] = scaler.fit_transform(df[FEATURES])\n    if plot_histogram:\n        plt.hist(df[TARGET], bins=20)\n        plt.show()"
  },
  {
    "output": "def task_func(text):\n    text = text.lower()\n    words = [word for word in re.findall(r'\\b\\w+\\b', text) if word not in [\"a\", \"an\", \"the\", \"in\", \"is\", \"are\"]]\n    return pd.Series(words).value_counts()"
  },
  {
    "output": "import pandas as pd\nimport numpy as np\n\ndef task_func():\n    np.random.seed(42)\n    products = ['Product A', 'Product B', 'Product C', 'Product D']\n    months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n    sales_data = np.random.randint(100, 1000, size=(len(products), len(months)))\n    df = pd.DataFrame(sales_data, columns=months, index=products)\n    df['Average Sales'] = df.mean(axis=1)\n    return df.reset_index().rename(columns={0: 'Product'})"
  },
  {
    "output": "def task_func():\n    try:\n        result = 10 / 0\n    except ZeroDivisionError:\n        return \"Error: Division by zero\"\n    except Exception as e:\n        return f\"An unexpected error occurred: {str(e)}\"\n    return result"
  },
  {
    "output": "def process_text_and_plot(text):\n    import re\n    from collections import Counter\n    import matplotlib.pyplot as plt\n\n    words = re.findall(r'\\b\\$\\w+\\b', text)\n    filtered_words = [word for word in words if not re.fullmatch(r'[$\\w]+', word)]\n    word_counts = Counter(filtered_words)\n    word_counts.plot(kind='bar')\n    plt.show()"
  },
  {
    "output": "def task_func(data, filename):\n    import numpy as np\n    if not data:\n        with open(filename, 'w') as f:\n            f.write('')\n        return []\n    means = []\n    for i in range(1, len(data[0])):\n        column = [float(x[i]) if isinstance(x[i], (int, float)) else np.nan for x in data]\n        mean = np.nanmean(column)\n        means.append(mean)\n        with open(filename, 'a') as f:\n            f.write(f'Position {i}: {mean}\\n')\n    return means"
  },
  {
    "output": "def task_func(path, delimiter):\n    import hashlib\n    parts = path.split(delimiter)\n    result = []\n    for part in parts:\n        if part:\n            result.append(delimiter + part)\n    return result"
  },
  {
    "output": "import random\nimport math\n\ndef generate_average_distance(n, RADIUS):\n    total_distance = 0.0\n    for _ in range(n):\n        theta = 2 * math.pi * random.random()\n        r = RADIUS * random.random() ** 0.5\n        x = r * math.cos(theta)\n        y = r * math.sin(theta)\n        distance = math.hypot(x, y)\n        total_distance += distance\n    return total_distance / n"
  },
  {
    "output": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\ndef plot_regression(df, x_col, y_col):\n    fig, ax = plt.subplots()\n    ax.scatter(df[x_col], df[y_col])\n    X = df[[x_col]]\n    y = df[y_col]\n    model = LinearRegression().fit(X, y)\n    y_pred = model.predict(X)\n    ax.plot(df[x_col], y_pred, color='red')\n    return ax"
  },
  {
    "output": "def task_func(data_list):\n    if not data_list:\n        raise ValueError(\"data_list is empty\")\n    import matplotlib.pyplot as plt\n    import numpy as np\n    data = np.array(data_list)\n    for i in range(data.shape[1]):\n        plt.plot(data[:, i], label=f'Position {i}')\n    plt.legend()\n    plt.show()"
  },
  {
    "output": "def uncompress_gzip_hex(hex_str):\n    try:\n        hex_bytes = bytes.fromhex(hex_str)\n        decompressed = gzip.decompress(hex_bytes)\n        return decompressed.decode('utf-8')\n    except Exception as e:\n        return f\"Error: {str(e)}\""
  },
  {
    "output": "def task_func(filepath):\n    import ctypes\n    import os\n    import time\n    dll = ctypes.CDLL(filepath)\n    metadata = {}\n    metadata['name'] = os.path.basename(filepath)\n    stat = os.stat(filepath)\n    metadata['creation_time'] = time.strftime('%Y-%m-%d %H:%M:%S', time.gmtime(stat.st_ctime))\n    metadata['modification_time'] = time.strftime('%Y-%m-%d %H:%M:%S', time.gmtime(stat.st_mtime))\n    metadata['file_size'] = stat.st_size\n    return metadata"
  },
  {
    "output": "from django.http import HttpResponse\nimport uuid\nimport json\n\ndef task_func(data):\n    response = HttpResponse(json.dumps(data), content_type=\"application/json\")\n    response[\"X-Request-ID\"] = str(uuid.uuid4())\n    return response"
  },
  {
    "output": "def task_func(url):\n    import requests\n    import xml.etree.ElementTree as ET\n    import pandas as pd\n    response = requests.get(url)\n    response.raise_for_status()\n    root = ET.fromstring(response.content)\n    if len(root) == 0 or root.tag != 'data':\n        raise ValueError(\"Invalid XML structure\")\n    data = []\n    for child in root:\n        if child.tag != 'row':\n            raise ValueError(\"Invalid XML structure\")\n        row_data = {}\n        for subchild in child:\n            if subchild.tag not in ['id', 'name', 'value']:\n                raise ValueError(\"Invalid XML structure\")\n            row_data[subchild.tag] = subchild.text\n        data.append(row_data)\n    df = pd.DataFrame(data)\n    return df"
  },
  {
    "output": "def process_image(url):\n    import requests\n    from io import BytesIO\n    from PIL import Image\n    import matplotlib.pyplot as plt\n    import numpy as np\n    \n    response = requests.get(url)\n    response.raise_for_status()\n    image = Image.open(BytesIO(response.content))\n    image = image.convert(\"L\")\n    data = np.array(image)\n    fig, ax = plt.subplots()\n    ax.hist(data.ravel(), bins=256, range=(0, 256), color='gray', edgecolor='black')\n    ax.set_title('Grayscale Histogram')\n    ax.set_xlabel('Pixel Value')\n    ax.set_ylabel('Frequency')\n    return ax"
  },
  {
    "output": "import pandas as pd\nimport numpy as np\nCOLUMNS = ['Column1', 'Column2', 'Column3', 'Column4', 'Column5']\ndef task_func(length):\n    data = np.random.rand(length, len(COLUMNS))\n    df = pd.DataFrame(data, columns=COLUMNS)\n    return df"
  },
  {
    "output": "def task_func(x):\n    from itertools import combinations\n    keys = list(x.keys())\n    min_total = float('inf')\n    min_subseq = []\n    for i in range(1, len(keys)+1):\n        for combo in combinations(keys, i):\n            total = sum(x[key] for key in combo)\n            if total < min_total:\n                min_total = total\n                min_subseq = list(combo)\n    return min_subseq"
  },
  {
    "output": "def task_func(directory, extension):\n    import os\n    import glob\n    import csv\n    files = glob.glob(os.path.join(directory, f\"*.{extension}\"))\n    result = {}\n    for file in files:\n        with open(file, 'r') as f:\n            reader = csv.reader(f)\n            data = list(reader)\n            filename = os.path.basename(file)\n            result[filename] = data\n    return result"
  },
  {
    "output": "def task_func(min_val, max_val, seed=None):\n    import random\n    if seed is not None:\n        random.seed(seed)\n    numbers = [random.randint(min_val, max_val) for _ in range(100)]\n    freq_gen = ((num, numbers.count(num)) for num in numbers)\n    return max(freq_gen, key=lambda x: x[1])[0]"
  },
  {
    "output": "def task_func(directory):\n    import os\n    import re\n    if not os.path.exists(directory):\n        raise ValueError(\"Directory does not exist\")\n    error_pattern = re.compile(r'\\berror\\b', re.IGNORECASE)\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            file_path = os.path.join(root, file)\n            try:\n                with open(file_path, 'r') as f:\n                    content = f.read()\n                    if error_pattern.search(content):\n                        print(f\"Error found in: {file_path}\")\n            except Exception as e:\n                print(f\"Error reading {file_path}: {e}\")"
  },
  {
    "output": "def process_string_to_df(input_string):\n    processed_lines = [line.replace('\\t', ' ') for line in input_string.splitlines() if line.strip()]\n    import pandas as pd\n    return pd.DataFrame(processed_lines, columns=['Text'])"
  },
  {
    "output": "import re\nimport math\n\ndef task_func(s):\n    numbers = [float(num.strip()) for num in s.split(\",\")]\n    count = len(numbers)\n    sqrt_sum = sum(math.sqrt(num) for num in numbers)\n    return count, sqrt_sum"
  },
  {
    "output": "def task_func(data, target_value):\n    import numpy as np\n    import matplotlib.pyplot as plt\n    indices = np.where(data[:, 0] == target_value)\n    x = np.arange(len(indices[0]))\n    y = data[indices[0], 1]\n    popt, _ = np.optimize.curve_fit(lambda x, a, b: a * np.exp(-b * x), x, y)\n    fig, ax = plt.subplots()\n    ax.plot(x, y, 'o', label='data')\n    ax.plot(x, popt[0] * np.exp(-popt[1] * x), '-', label='fit')\n    ax.legend()\n    return popt, ax"
  },
  {
    "output": "def task_func(data, threshold=0.5):\n    if not isinstance(data, (list, tuple)) or not all(isinstance(x, (int, float)) for x in data):\n        raise ValueError(\"Input data must be a list or tuple of integers or floats.\")\n    if not isinstance(threshold, (int, float)):\n        raise ValueError(\"Threshold must be an integer or float.\")\n    if threshold < 0 or threshold > 1:\n        raise ValueError(\"Threshold must be between 0 and 1.\")\n    normalized = [x / max(data) if max(data) != 0 else 0 for x in data]\n    import matplotlib.pyplot as plt\n    plt.plot(normalized)\n    plt.title(\"Normalized Data\")\n    plt.xlabel(\"Index\")\n    plt.ylabel(\"Value\")\n    plt.show()\n    return normalized"
  },
  {
    "output": "import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\ndef task_func(df, dct):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError\n    for col, val in dct.items():\n        df[col] = df[col].replace(val)\n    le = LabelEncoder()\n    for col in df.select_dtypes(include=['object']).columns:\n        df[col] = le.fit_transform(df[col])\n    for col in df.select_dtypes(include=['number']).columns:\n        mean = df[col].mean()\n        std = df[col].std()\n        df[col] = (df[col] - mean) / std\n    return df"
  },
  {
    "output": "def task_func(directory):\n    import os\n    import json\n    count = 0\n    for filename in os.listdir(directory):\n        file_path = os.path.join(directory, filename)\n        if os.path.isfile(file_path) and filename.endswith('.json'):\n            with open(file_path, 'r') as f:\n                data = json.load(f)\n            if 'mynewkey' not in data:\n                data['mynewkey'] = 'value'\n                count += 1\n                with open(file_path, 'w') as f:\n                    json.dump(data, f)\n    return count"
  },
  {
    "output": "def task_func(n, pattern, seed=None):\n    import random\n    import re\n    random.seed(seed)\n    chars = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'\n    random_str = ''.join(random.choice(chars) for _ in range(n))\n    regex = re.compile(pattern)\n    matches = regex.finditer(random_str)\n    return [match.group() for match in matches]"
  },
  {
    "output": "import os\nimport hashlib\nimport json\n\ndef compute_hashes(directory):\n    hashes = {}\n    for root, _, files in os.walk(directory):\n        for file in files:\n            file_path = os.path.join(root, file)\n            with open(file_path, 'rb') as f:\n                content = f.read()\n                hash_value = hashlib.sha256(content).hexdigest()\n            hashes[file_path] = hash_value\n    json_path = os.path.abspath('hashes.json')\n    with open(json_path, 'w') as json_file:\n        json.dump(hashes, json_file, indent=4)\n    return json_path"
  },
  {
    "output": "import secrets\nimport hashlib\nimport base64\n\ndef generate_hash(password, prefix, salt_length):\n    if salt_length < 0:\n        raise ValueError(\"SALT_LENGTH cannot be negative\")\n    salt = secrets.token_urlsafe(salt_length)\n    combined = password + prefix + salt\n    hash_obj = hashlib.sha256(combined.encode('utf-8'))\n    encoded_hash = base64.urlsafe_b64encode(hash_obj.digest()).decode('utf-8')\n    return encoded_hash"
  },
  {
    "output": "def add_markers_and_distances(map_object, locations):\n    import folium\n    from geopy.distance import geodesic\n    \n    for loc in locations:\n        folium.Marker(location=loc).add_to(map_object)\n    \n    distance_dict = {}\n    for i, loc1 in enumerate(locations):\n        for j, loc2 in enumerate(locations):\n            if i < j:\n                distance = geodesic(loc1, loc2).kilometers\n                distance_dict[(i, j)] = distance\n    \n    return (map_object, distance_dict)"
  },
  {
    "output": "plt.bar(df['Team'], df['Goals'], label='Goals')\nplt.bar(df['Team'], df['Penalty Cost'], bottom=df['Goals'], label='Penalty Cost')\nplt.xlabel('Team')\nplt.ylabel('Count')\nplt.title('Football Match Results and Penalty Costs')\nplt.legend()\nplt.show()"
  },
  {
    "output": "import itertools\nimport random\n\ndef task_func(t, n):\n    if n > len(t):\n        raise ValueError(\"n cannot be greater than the length of the tuple\")\n    combinations = list(itertools.combinations(t, n))\n    random_combination = random.choice(combinations)\n    return tuple(random_combination)"
  },
  {
    "output": "def download_files_from_ftp(ftp_url, local_directory):\n    import subprocess\n    import os\n    import re\n    import tempfile\n    import shutil\n    import sys\n    import ftplib\n    import time\n    import signal\n    import threading\n    import socket\n    import logging\n    import psutil\n    import datetime\n    import uuid\n    import json\n    import random\n    import string\n    import re\n    import os\n    import sys\n    import time\n    import signal\n    import threading\n    import socket\n    import logging\n    import psutil\n    import datetime\n    import uuid\n    import json\n    import random\n    import string\n    import re\n    import os\n    import sys\n    import time\n    import signal\n    import threading\n    import socket\n    import logging\n    import psutil\n    import datetime\n    import uuid\n    import json\n    import random\n    import string\n    import re\n    import os\n    import sys\n    import time\n    import signal\n    import threading\n    import socket\n    import logging\n    import psutil\n    import datetime\n    import uuid\n    import json\n    import random\n    import string\n    import re\n    import os\n    import sys\n    import time\n    import signal\n    import threading\n    import socket\n    import logging\n    import psutil\n    import datetime\n    import uuid\n    import json\n    import random\n    import string\n    import re\n    import os\n    import sys\n    import time\n    import signal\n    import threading\n    import socket\n    import logging\n    import psutil\n    import datetime\n    import uuid\n    import json\n    import random\n    import string\n    import re\n    import os\n    import sys\n    import time\n    import signal\n    import threading\n    import socket\n    import logging\n    import psutil\n    import datetime\n    import uuid\n    import json\n    import random\n    import string\n    import re\n    import os\n    import sys\n    import time\n    import signal\n    import threading\n    import socket\n    import logging\n    import psutil\n    import datetime\n    import uuid\n    import json\n    import random\n    import string\n    import re\n    import os\n    import sys\n    import time\n    import signal\n    import threading\n    import socket\n    import logging\n    import psutil\n    import datetime\n    import uuid\n    import json\n    import random\n    import string\n    import re\n    import os\n    import sys\n    import time\n    import signal\n    import threading\n    import socket\n    import logging\n    import psutil\n    import datetime\n    import uuid\n    import json\n    import random\n    import string\n    import re\n    import os\n    import sys\n    import time\n    import signal\n    import threading\n    import socket\n    import logging\n    import psutil\n    import datetime\n    import uuid\n    import json\n    import random\n    import string\n    import re\n    import os\n    import sys\n    import time\n    import signal\n    import threading\n    import socket\n    import logging\n    import psutil\n    import datetime\n    import uuid\n    import json\n    import random\n    import string\n    import re\n    import os\n    import sys\n    import time\n    import signal\n    import threading\n    import socket\n    import logging\n    import psutil\n    import datetime\n    import uuid\n    import json\n    import random"
  },
  {
    "output": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom collections import Counter\n\ndef task_func(file_path, save_path=None):\n    df = pd.read_csv(file_path)\n    texts = df['text'].tolist()\n    vectorizer = CountVectorizer(stop_words='english')\n    X = vectorizer.fit_transform(texts)\n    word_counts = X.toarray().sum(axis=0)\n    words = vectorizer.get_feature_names_out()\n    word_freq = dict(zip(words, word_counts))\n    top_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:10]\n    words, counts = zip(*top_words)\n    plt.figure(figsize=(10, 6))\n    plt.bar(words, counts)\n    plt.xlabel('Words')\n    plt.ylabel('Frequency')\n    plt.title('Top 10 Most Common Words')\n    if save_path:\n        plt.savefig(save_path)\n        plt.close()\n    else:\n        plt.show()"
  },
  {
    "output": "def task_func(text, n, k):\n    from textblob import TextBlob\n    import matplotlib.pyplot as plt\n    import numpy as np\n    from collections import Counter\n\n    blob = TextBlob(text)\n    ngrams = blob.ngrams(n)\n    ngram_counts = Counter(ngrams)\n    top_ngrams = ngram_counts.most_common(k)\n    labels, counts = zip(*top_ngrams)\n    indices = np.arange(len(labels))\n    plt.bar(indices, counts)\n    plt.xticks(indices, labels, rotation=45, ha=\"right\")\n    plt.tight_layout()\n    plt.show()"
  },
  {
    "output": "def process_hex_string(hex_str, salt_size):\n    import hashlib\n    import os\n    import base64\n    hex_bytes = bytes.fromhex(hex_str)\n    salt = os.urandom(salt_size)\n    salted_data = hex_bytes + salt\n    hash_result = hashlib.sha256(salted_data).digest()\n    return (base64.b64encode(salt).decode('utf-8'), base64.b64encode(hash_result).decode('utf-8'))"
  },
  {
    "output": "def filter_word_lengths(data, first_letter):\n    filtered = [word for word in data['Word'] if word.startswith(first_letter)]\n    lengths = [len(word) for word in filtered]\n    from collections import Counter\n    return dict(Counter(lengths))"
  },
  {
    "output": "def generate_employee_dates():\n    import pandas as pd\n    employees = ['Alice', 'Bob', 'Charlie']\n    dates = pd.date_range(start='2023-04-01', periods=10)\n    data = []\n    for employee in employees:\n        for date in dates:\n            data.append({'Employee': employee, 'Date': date})\n    return pd.DataFrame(data)"
  },
  {
    "output": "import os\nimport csv\nimport random\nimport time\n\ndef task_func(hours, output_dir, columns):\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    filename = os.path.join(output_dir, \"sensor_data.csv\")\n    with open(filename, 'w', newline='') as csvfile:\n        writer = csv.DictWriter(csvfile, fieldnames=columns)\n        writer.writeheader()\n        start_time = time.time()\n        while (time.time() - start_time) < hours * 3600:\n            row = {}\n            for col in columns:\n                if col == 'timestamp':\n                    row[col] = time.strftime('%Y-%m-%d %H:%M:%S')\n                else:\n                    row[col] = random.uniform(0, 100)\n            writer.writerow(row)\n            time.sleep(1)"
  },
  {
    "output": "def convert_json_to_df_and_plot(json_data, column_name):\n    import pandas as pd\n    import json\n    import matplotlib.pyplot as plt\n    try:\n        data = json.loads(json_data)\n        df = pd.DataFrame(data)\n        try:\n            df[column_name] = pd.to_numeric(df[column_name], errors='coerce')\n            df.dropna(subset=[column_name], inplace=True)\n            plt.hist(df[column_name], bins=10, edgecolor='black')\n            plt.title(f'Histogram of {column_name}')\n            plt.xlabel(column_name)\n            plt.ylabel('Frequency')\n            plt.show()\n        except KeyError:\n            raise ValueError(f\"Column '{column_name}' not found in the data.\")\n        except Exception as e:\n            raise ValueError(f\"Error processing column '{column_name}': {str(e)}\")\n    except json.JSONDecodeError:\n        raise ValueError(\"Invalid JSON data provided.\")\n    except Exception as e:\n        raise ValueError(f\"Error converting JSON to DataFrame: {str(e)}\")"
  },
  {
    "output": "import matplotlib.pyplot as plt\nimport time\nimport random\n\ndef generate_random_data(duration):\n    timestamps = []\n    values = []\n    start_time = time.time()\n    while (time.time() - start_time) < duration:\n        current_time = time.time() - start_time\n        timestamps.append(current_time)\n        values.append(random.random())\n        plt.plot(timestamps, values, 'r-')\n        plt.pause(0.01)\n    plt.show()\n    return (timestamps, values)"
  },
  {
    "output": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import kurtosis\n\ndef generate_and_analyze():\n    np.random.seed(0)\n    num_intervals = 1000\n    random_numbers = np.random.normal(size=num_intervals)\n    plt.plot(random_numbers)\n    plt.xlabel('Time')\n    plt.ylabel('Value')\n    plt.title('Random Numbers Over Time')\n    plt.show()\n    kurt = kurtosis(random_numbers)\n    return kurt"
  },
  {
    "output": "import hmac\nimport hashlib\n\ndef task_func(message, secret_key):\n    signature = hmac.new(secret_key.encode(), msg=message.encode(), digestmod=hashlib.sha256).hexdigest()\n    return len(signature) == 64 and signature"
  },
  {
    "output": "def clean_and_hash(input_string):\n    import re\n    cleaned = re.sub(r'[^a-zA-Z0-9]', '', input_string)\n    import hashlib\n    return hashlib.sha256(cleaned.encode()).hexdigest()"
  },
  {
    "output": "import requests\nfrom bs4 import BeautifulSoup\nimport ast\n\ndef task_func(url):\n    response = requests.get(url)\n    soup = BeautifulSoup(response.text, 'html.parser')\n    script_tags = soup.find_all('script')\n    result = []\n    for tag in script_tags:\n        content = tag.get_text()\n        try:\n            data = ast.literal_eval(content)\n            result.append(data)\n        except:\n            pass\n    return result"
  },
  {
    "output": "import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(df1, df2):\n    merged_df = pd.merge(df1, df2, on='id', how='outer')\n    numeric_cols = merged_df.select_dtypes(include=np.number).columns\n    merged_df[numeric_cols] = merged_df[numeric_cols].div(merged_df[numeric_cols].abs().max(axis=0), axis=1)\n    sns.pairplot(merged_df[numeric_cols])\n    plt.show()\n    return merged_df[numeric_cols]"
  },
  {
    "output": "import os\nimport csv\nfrom datetime import datetime, timedelta\n\ndef task_func(num_hours):\n    base_dir = \"weather_data\"\n    backup_dir = \"backup\"\n    os.makedirs(base_dir, exist_ok=True)\n    os.makedirs(backup_dir, exist_ok=True)\n    \n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    filename = f\"{timestamp}.csv\"\n    filepath = os.path.join(base_dir, filename)\n    \n    with open(filepath, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerow(['Time', 'Condition'])\n        for hour in range(num_hours):\n            time_str = (datetime.now() + timedelta(hours=hour)).strftime(\"%Y-%m-%d %H:%M:%S\")\n            condition = \"Sunny\" if hour % 2 == 0 else \"Cloudy\"\n            writer.writerow([time_str, condition])\n    \n    backup_path = os.path.join(backup_dir, filename)\n    os.replace(filepath, backup_path)\n    \n    return backup_path"
  },
  {
    "output": "def task_func(data_list):\n    if not data_list:\n        raise ValueError(\"Input data_list is empty.\")\n    from collections import Counter\n    import matplotlib.pyplot as plt\n    import warnings\n    predefined_categories = ['A', 'B', 'C']\n    counts = Counter(data_list)\n    predefined_counts = {cat: counts.get(cat, 0) for cat in predefined_categories}\n    total_predefined = sum(predefined_counts.values())\n    if total_predefined > 0 and any(v == 0 for v in predefined_counts.values()):\n        warnings.warn(\"Distribution of predefined categories is not uniform.\")\n    all_categories = list(counts.keys())\n    all_counts = list(counts.values())\n    plt.bar(all_categories, all_counts)\n    plt.xlabel('Categories')\n    plt.ylabel('Frequency')\n    plt.title('Category Distribution')\n    plt.show()"
  },
  {
    "output": "from sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\ndef task_func(l):\n    pca = PCA(n_components=2)\n    components = pca.fit_transform(l)\n    plt.figure()\n    plt.title(\"PCA Result\")\n    plt.xlabel(\"First Principal Component\")\n    plt.ylabel(\"Second Principal Component\")\n    plt.scatter(components[:, 0], components[:, 1])\n    ax = plt.gca()\n    return ax"
  },
  {
    "output": "from collections import Counter\nimport random\n\nHAND_RANKS = ['2', '3', '4', '5', '6', '7', '8', '9', '10', 'J', 'Q', 'K', 'A']\nSUITS = ['H', 'D', 'C', 'S']\n\ndef task_func():\n    hand = []\n    for _ in range(5):\n        rank = random.choice(HAND_RANKS)\n        suit = random.choice(SUITS)\n        card = f\"{rank}{suit}\"\n        hand.append(card)\n    rank_count = Counter()\n    for card in hand:\n        rank = card[:-1]\n        rank_count[rank] += 1\n    return (hand, rank_count)"
  },
  {
    "output": "import os\nimport re\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef search_and_plot_sales_data(directory, pattern):\n    files = [f for f in os.listdir(directory) if re.match(pattern, f)]\n    axes = []\n    for file in files:\n        file_path = os.path.join(directory, file)\n        df = pd.read_csv(file_path)\n        df['Month'] = pd.to_datetime(df['Month']).dt.strftime('%Y-%m')\n        ax = plt.subplot()\n        df.plot(x='Month', y='Sales', ax=ax)\n        axes.append(ax)\n    return axes"
  },
  {
    "output": "def plot_cumulative_probability(data):\n    import numpy as np\n    import matplotlib.pyplot as plt\n    if not all(isinstance(x, (int, float)) for x in data) or any(np.isnan(x) for x in data):\n        raise ValueError(\"Input data must contain only non-negative numbers and no NaNs.\")\n    if not data:\n        raise ValueError(\"Input data cannot be empty.\")\n    sorted_data = sorted(data)\n    n = len(sorted_data)\n    cumulative_prob = [ (i + 1) / n for i in range(n) ]\n    plt.plot(sorted_data, cumulative_prob, marker='o')\n    plt.xlabel('Value')\n    plt.ylabel('Cumulative Probability')\n    plt.title('Cumulative Probability Distribution')\n    plt.grid(True)\n    plt.show()"
  },
  {
    "output": "import re\nimport csv\nimport requests\nimport os\n\ndef task_func():\n    response = requests.get('https://api.example.com/data')\n    data = response.text\n    pattern = re.compile(r'pattern')\n    matches = pattern.findall(data)\n    with open('matched_data.csv', 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        for match in matches:\n            writer.writerow([match])\n    return os.path.abspath('matched_data.csv')"
  },
  {
    "output": "def task_func(input_dict, letter):\n    import pandas as pd\n    df = pd.DataFrame(input_dict)\n    filtered = df[df['Word'].str.startswith(letter)]\n    lengths = filtered['Word'].str.len()\n    mean = lengths.mean()\n    median = lengths.median()\n    mode = lengths.mode().iloc[0] if not lengths.mode().empty else None\n    return {'mean': mean, 'median': median, 'mode': mode}"
  },
  {
    "output": "def task_func(data):\n    import numpy as np\n    from scipy import stats\n    import numpy.fft as fft\n    counts, bins = np.histogram(data, bins=np.unique(data))\n    mode = bins[np.argmax(counts)]\n    count = np.max(counts)\n    fft_result = fft.fft(counts)\n    return {'mode': np.array([mode]), 'count': np.array([count]), 'fft': fft_result}"
  },
  {
    "output": "```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(my_list, seed=42):\n    # Part A: Validate the input\n    if not isinstance(my_list, list):\n        raise TypeError(\"my_list must be a list.\")\n    \n    # Part B: Add '12' to the list\n    my_list.append('12')\n    \n    # Part C: Simulate sales data\n    categories = ['Electronics', 'Fashion', 'Home & Kitchen', 'Automotive', 'Sports']\n    np.random.seed(seed)\n    sales_data = np.random.randint(100, 1000, size=len(categories))\n    \n    # Create DataFrame\n    df = pd.DataFrame({"
  },
  {
    "output": "def standardize_columns(df):\n    required_columns = ['age', 'income', 'id']\n    if not all(col in df.columns for col in required_columns):\n        raise ValueError(\"DataFrame is missing required columns\")\n    df['age_std'] = df.groupby('id')['age'].transform(lambda x: (x - x.mean()) / x.std())\n    df['income_std'] = df.groupby('id')['income'].transform(lambda x: (x - x.mean()) / x.std())\n    return df.drop(columns=['age', 'income'])"
  },
  {
    "output": "def process_files(input_list):\n    if not isinstance(input_list, list):\n        raise TypeError(\"Input must be a list\")\n    input_list.append('12')\n    total = sum(map(int, input_list))\n    import os\n    import pandas as pd\n    files = [f for f in os.listdir() if f.endswith('.csv')]\n    if not files:\n        raise FileNotFoundError(\"No CSV files found\")\n    df = pd.concat([pd.read_csv(f) for f in files], ignore_index=True)\n    return df"
  },
  {
    "output": "from scipy.stats import zscore\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n\ndef task_func(df):\n    numeric_cols = df.select_dtypes(include='number').columns\n    df_numeric = df[numeric_cols].copy()\n    df_numeric.fillna(df_numeric.mean(), inplace=True)\n    z_scores = (df_numeric - df_numeric.mean()) / df_numeric.std()\n    z_scores_df = pd.DataFrame(z_scores)\n    figs = []\n    for col in numeric_cols:\n        fig, ax = plt.subplots()\n        ax.hist(df_numeric[col], bins=10)\n        figs.append(ax)\n    return z_scores_df, figs"
  },
  {
    "output": "import collections\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(dictionary, new_key, new_value):\n    dictionary[new_key] = new_value\n    data = list(dictionary.values())\n    plt.figure(figsize=(8, 6))\n    axes = plt.subplot()\n    sns.barplot(x=range(len(data)), y=data, ax=axes)\n    axes.set_xlabel('Key Index')\n    axes.set_ylabel('Value')\n    axes.set_title('Distribution of Dictionary Values')\n    return dictionary, axes"
  },
  {
    "output": "def create_complex_distribution(data):\n    import numpy as np\n    import matplotlib.pyplot as plt\n    if not isinstance(data, np.ndarray):\n        raise TypeError(\"Input must be a numpy.ndarray\")\n    mean1, std1 = np.mean(data), np.std(data)\n    data1 = np.random.normal(mean1, std1, 1000)\n    data2 = np.random.normal(mean1, std1, 1000)\n    combined = np.concatenate([data1, data2])\n    plt.hist(combined, bins=30, density=True)\n    plt.title(\"Complex Distribution from Two Gaussians\")\n    plt.xlabel(\"Value\")\n    plt.ylabel(\"Density\")\n    plt.show()"
  },
  {
    "output": "import pandas as pd\nimport sqlite3\n\ndef task_func(db_path: str, table_name: str, column_name: str) -> pd.DataFrame:\n    conn = sqlite3.connect(db_path)\n    df = pd.read_sql_query(f\"SELECT * FROM {table_name}\", conn)\n    df[column_name] = df[column_name].str.replace('\\n', '<br>')\n    conn.close()\n    return df"
  },
  {
    "output": "def move_files_by_extension(source_dir, dest_dir, extension):\n    import os\n    import shutil\n    count = 0\n    for filename in os.listdir(source_dir):\n        if filename.endswith(extension):\n            file_path = os.path.join(source_dir, filename)\n            dest_path = os.path.join(dest_dir, filename)\n            shutil.move(file_path, dest_path)\n            count += 1\n    return count"
  },
  {
    "output": "```python\nimport pandas as pd\nfrom statistics import mean\n\ndef task_func(df: pd.DataFrame) -> dict:\n    if 'Name' not in df.columns or 'Score' not in df.columns:\n        raise ValueError(\"DataFrame must contain 'Name' and 'Score' columns"
  },
  {
    "output": "import base64\nimport hashlib\nimport hmac\n\ndef task_func(s, signature, secret_key):\n    decoded_message = base64.b64decode(s)\n    hmac_hash = hmac.new(secret_key.encode('utf-8'), decoded_message, hashlib.sha1).digest()\n    computed_signature = base64.b64encode(hmac_hash).decode('utf-8')\n    return computed_signature == signature"
  },
  {
    "output": "import os\nimport csv\n\ndef count_words_in_txt_files(directory):\n    word_counts = {}\n    total_words = 0\n    for filename in os.listdir(directory):\n        if filename.endswith('.txt'):\n            file_path = os.path.join(directory, filename)\n            with open(file_path, 'r', encoding='utf-8') as file:\n                words = file.read().split()\n                for word in words:\n                    word_counts[word] = word_counts.get(word, 0) + 1\n                    total_words += 1\n    with open('word_counts.csv', 'w', newline='', encoding='utf-8') as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerow(['Word', 'Count'])\n        for word, count in word_counts.items():\n            writer.writerow([word, count])\n    return total_words"
  },
  {
    "output": "from collections import Counter\nimport itertools\n\ndef task_func(list_of_menuitems):\n    flattened = list(itertools.chain.from_iterable(list_of_menuitems))\n    counts = Counter(flattened)\n    most_common_item = counts.most_common(1)[0][0]\n    return most_common_item"
  },
  {
    "output": "def task_func(input_list, directory):\n    import os\n    import random\n    import matplotlib.pyplot as plt\n    \n    deduplicated = list(dict.fromkeys(input_list))\n    os.makedirs(directory, exist_ok=True)\n    file_names = []\n    \n    for plot_name in deduplicated:\n        data = [random.random() for _ in range(10)]\n        plt.bar(range(10), data)\n        plt.title(plot_name)\n        file_name = os.path.join(directory, f\"{plot_name}.png\")\n        plt.savefig(file_name)\n        plt.close()\n        file_names.append(file_name)\n    \n    if not os.path.exists(directory):\n        raise FileNotFoundError(f\"The directory {directory} does not exist and could not be created.\")\n    \n    return file_names"
  },
  {
    "output": "import codecs\nimport os\nimport glob\n\nDIRECTORY_PATH = './files/'\n\ndef task_func(directory=DIRECTORY_PATH, from_encoding='cp1251', to_encoding='utf8'):\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n    file_paths = glob.glob(os.path.join(directory, \"*.txt\"))\n    for file_path in file_paths:\n        try:\n            with codecs.open(file_path, 'r', encoding=from_encoding) as file:\n                content = file.read()\n            with codecs.open(file_path, 'w', encoding=to_encoding) as file:\n                file.write(content)\n        except Exception as e:\n            print(f\"Error converting file {file_path}: {e}\")\n    return None"
  },
  {
    "output": "def visualize_stock_distribution(data):\n    import matplotlib.pyplot as plt\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n    ax1.boxplot(data)\n    ax1.set_title('Box Plot of Stock Closing Prices')\n    ax2.hist(data, bins=20, color='skyblue', edgecolor='black')\n    ax2.set_title('Histogram of Stock Closing Prices')\n    return (ax1, ax2)"
  },
  {
    "output": "import re\nimport string\n\nPUNCTUATION = string.punctuation\n\ndef task_func(text):\n    words = re.findall(r'\\b\\w+\\b', text)\n    num_words = len(words)\n    num_punctuation = 0\n    for char in text:\n        if char in PUNCTUATION:\n            num_punctuation += 1\n    return (num_words, num_punctuation)"
  },
  {
    "output": "def count_words(sentence):\n    import re\n    from collections import Counter\n    words = re.findall(r'\\b\\w+\\b', sentence)\n    return dict(Counter(words))"
  },
  {
    "output": "def rotate_and_display_image(image_path, angle):\n    import numpy as np\n    from PIL import Image\n    import matplotlib.pyplot as plt\n    \n    try:\n        img = Image.open(image_path)\n    except FileNotFoundError:\n        raise FileNotFoundError(f\"The image file {image_path} does not exist.\")\n    \n    img_array = np.array(img)\n    height, width = img_array.shape[:2]\n    center = (width // 2, height // 2)\n    \n    rotated = img.rotate(angle, expand=True)\n    rotated_array = np.array(rotated)\n    \n    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n    axes[0].imshow(img)\n    axes[0].set_title('Original')\n    axes[1].imshow(rotated)\n    axes[1].set_title('Rotated')\n    plt.show()\n    \n    return img_array, rotated_array"
  },
  {
    "output": "from collections import Counter\nimport random\n\ndef task_func(seed=None):\n    random.seed(seed)\n    letters = [random.choice('abcdefghijklmnopqrstuvwxyz') for _ in range(100)]\n    return dict(Counter(letters))"
  },
  {
    "output": "def task_func(headers, data, file_path):\n    import os\n    import csv\n    if file_path is None:\n        raise ValueError(\"file_path cannot be None\")\n    with open(file_path, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerow(headers)\n        for row in data:\n            writer.writerow(row + [None] * (len(headers) - len(row)))\n    return os.path.abspath(file_path)"
  },
  {
    "output": "def task_func(text):\n    import matplotlib.pyplot as plt\n    import numpy as np\n    from matplotlib import style\n    style.use('ggplot')\n    words = text.split()\n    word_lengths = [len(word) for word in words]\n    plt.figure(figsize=(10, 6))\n    plt.hist(word_lengths, bins=range(1, max(word_lengths)+2), edgecolor='black', alpha=0.7, label='Histogram')\n    plt.hist(word_lengths, bins=range(1, max(word_lengths)+2), density=True, alpha=0.5, color='blue', label='KDE')\n    plt.title('Distribution of Word Lengths')\n    plt.xlabel('Word Length')\n    plt.ylabel('Frequency')\n    plt.legend()\n    plt.grid(True)\n    plt.show()"
  },
  {
    "output": "from itertools import combinations\n\ndef generate_pairs(n):\n    if n < 1:\n        raise ValueError\n    return list(combinations(range(1, n + 1), 2))"
  },
  {
    "output": "# Find common rows across all DataFrames\n    common_rows = set(df_list[0].to_dict_list())\n    for df in df_list[1:]:\n        current_rows = set(df.to_dict_list())\n        common_rows = common_rows.intersection(current_rows)\n    \n    # Convert common rows back to list of dictionaries\n    common_rows = [dict(row) for row in common_rows]\n    \n    # Return the first DataFrame and the list of common rows\n    return df_list[0], common_rows"
  },
  {
    "output": "from matplotlib import pyplot as plt\nfrom sklearn.decomposition import PCA\ndef task_func(arr):\n    summed_data = arr.sum(axis=1).reshape(-1, 1)\n    pca = PCA(n_components=1)\n    pca.fit(summed_data)\n    explained_variance_ratio = pca.explained_variance_ratio_\n    fig, ax = plt.subplots()\n    ax.bar(range(1), explained_variance_ratio, align='center')\n    ax.set_title(\"Explained Variance Ratio\")"
  },
  {
    "output": "def task_func(input_str):\n    import re\n    from collections import Counter\n    stopwords = {'the', 'and', 'a', 'an', 'in', 'on', 'at', 'to', 'for', 'of', 'with'}\n    lines = input_str.strip().split('\\n')\n    words = []\n    for line in lines:\n        words_in_line = re.findall(r'\\b\\w+\\b', line.lower())\n        words.extend([word for word in words_in_line if word not in stopwords])\n    return dict(Counter(words))"
  },
  {
    "output": "python_code_returner(\"Implement a function to find the n most common letters in a dictionary using a max-heap.\")\n\nUSE TOOL: python_code_returner(\"import heapq\nimport collections\n\ndef task_func(x, n):\n    # Create a heap of tuples with negative frequency to simulate a max-heap\n    heap = []\n    for letter, freq in x.items():\n        heapq.heappush(heap, (-freq, letter))\n    \n    # Extract the top n elements\n    result = []\n    for _ in range(n):\n        if heap:\n            freq, letter = heapq.heappop(heap)\n            result.append(letter)\n    \n    return result\")"
  },
  {
    "output": "def task_func(input_list):\n    from math import factorial\n    if not isinstance(input_list, list) or any(not isinstance(x, int) or x < 0 for x in input_list):\n        return \"Invalid input\"\n    from itertools import permutations\n    results = []\n    for perm in permutations(input_list):\n        total = sum(factorial(num) for num in perm)\n        results.append(total)\n    return results"
  },
  {
    "output": "def generate_and_hash_password(length, salt):\n    import secrets\n    import string\n    import hashlib\n    chars = string.ascii_letters + string.digits + string.punctuation\n    password = ''.join(secrets.choice(chars) for _ in range(length))\n    combined = password + salt\n    hashed = hashlib.sha256(combined.encode()).hexdigest()\n    return hashed"
  },
  {
    "output": "def task_func(source_dir, target_dir, prefix):\n    import os\n    import hashlib\n    if not os.path.exists(source_dir):\n        raise FileNotFoundError(f\"Source directory '{source_dir}' does not exist.\")\n    os.makedirs(target_dir, exist_ok=True)\n    files = [os.path.join(source_dir, f) for f in os.listdir(source_dir) if os.path.isfile(os.path.join(source_dir, f))]\n    result = []\n    for file_path in files:\n        with open(file_path, 'rb') as f:\n            content = f.read()\n        hash_md5 = hashlib.md5(content).hexdigest()\n        modified_content = f\"{prefix}{hash_md5}{content.decode('utf-8', 'ignore')}\"\n        target_path = os.path.join(target_dir, os.path.basename(file_path))\n        with open(target_path, 'wb') as f:\n            f.write(modified_content.encode('utf-8'))\n        result.append(target_path)\n    return result"
  },
  {
    "output": ""
  },
  {
    "output": "import pandas as pd\nimport random\n\ndef task_func(n_data_points=10000):\n    if n_data_points <= 0:\n        return pd.DataFrame(columns=['Value'])\n    \n    data = [round(random.uniform(0.0, 10.0), 3) for _ in range(n_data_points)]\n    return pd.DataFrame(data, columns=['Value'])"
  },
  {
    "output": "import os\nimport json\n\ndef count_words_and_export(directory):\n    word_counts = {}\n    total_words = 0\n    for filename in os.listdir(directory):\n        if filename.endswith('.txt'):\n            file_path = os.path.join(directory, filename)\n            with open(file_path, 'r') as file:\n                text = file.read()\n                words = text.split()\n                count = len(words)\n                word_counts[filename] = count\n                total_words += count\n    json_file = os.path.join(directory, 'word_counts.json')\n    with open(json_file, 'w') as json_file:\n        json.dump(word_counts, json_file)\n    return total_words"
  },
  {
    "output": "import pandas as pd\nimport numpy as np\n\ndef generate_grades_data(num_students=100, num_courses=5):\n    np.random.seed(42)\n    students = [f'Student_{i}' for i in range(1, num_students + 1)]\n    courses = [f'Course_{i}' for i in range(1, num_courses + 1)]\n    grades = np.random.uniform(50, 100, size=(num_students, num_courses))\n    df = pd.DataFrame(grades, columns=courses, index=students)\n    df['Average'] = df.mean(axis=1)\n    return df"
  },
  {
    "output": "def import_csv_to_sqlite_and_return_df(csv_file_path, db_file_path, table_name):\n    import sqlite3\n    import pandas as pd\n    import os\n    import csv\n    if not os.path.exists(db_file_path):\n        os.makedirs(os.path.dirname(db_file_path), exist_ok=True)\n        conn = sqlite3.connect(db_file_path)\n        cursor = conn.cursor()\n        with open(csv_file_path, 'r') as f:\n            reader = csv.reader(f)\n            headers = next(reader)\n            create_table_sql = f\"CREATE TABLE {table_name} ({', '.join([f'\"{col}\" TEXT' for col in headers])})\"\n            cursor.execute(create_table_sql)\n            for row in reader:\n                insert_sql = f\"INSERT INTO {table_name} ({', '.join(headers)}) VALUES ({', '.join(['?' for _ in headers])})\"\n                cursor.execute(insert_sql, row)\n        conn.commit()\n        conn.close()\n    conn = sqlite3.connect(db_file_path)\n    df = pd.read_sql_query(f\"SELECT * FROM {table_name}\", conn)\n    conn.close()\n    return df"
  },
  {
    "output": "def update_and_plot(data, key, value, n):\n    import numpy as np\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    if isinstance(value, (int, float)):\n        data[key] = value\n        mean = data[key]\n        std_dev = data[key]\n        dataset = np.random.normal(mean, std_dev, n)\n        series = pd.Series(dataset)\n        plt.hist(dataset, bins=30)\n        plt.title('Histogram of Generated Dataset')\n        plt.xlabel('Value')\n        plt.ylabel('Frequency')\n        plt.show()\n        return data, series, plt.gcf()"
  },
  {
    "output": "def task_func():\n    return \"Hello, World!\""
  },
  {
    "output": "def generate_performance_report(data):\n    import pandas as pd\n    return pd.DataFrame(data).set_index('timestamp').resample('D').mean().reset_index()"
  },
  {
    "output": "def task_func(input_string, directory):\n    import os\n    import hashlib\n    os.makedirs(directory, exist_ok=True)\n    hashes = []\n    lines = [line.strip() for line in input_string.splitlines() if line.strip()]\n    for line in lines:\n        hash_obj = hashlib.sha256(line.encode())\n        hash_hex = hash_obj.hexdigest()\n        filename = hash_hex[:10]\n        filepath = os.path.join(directory, filename)\n        with open(filepath, 'w') as f:\n            f.write(line)\n        hashes.append(filepath)\n    return hashes"
  },
  {
    "output": "import pandas as pd\n\ndef load_and_clean_csv(file_path, column_name):\n    df = pd.read_csv(file_path)\n    df[column_name] = df[column_name].str.replace('\\n', '<br>')\n    return df"
  },
  {
    "output": "def task_func(input_list):\n    import matplotlib.pyplot as plt\n    import pickle\n    if not isinstance(input_list, list) or not all(isinstance(x, (int, float)) for x in input_list):\n        raise ValueError(\"Input must be a list of numbers\")\n    fig, ax = plt.subplots()\n    ax.plot(input_list)\n    plt.close(fig)\n    with open(\"temp_plot.pkl\", \"wb\") as f:\n        pickle.dump(fig, f)\n    with open(\"temp_plot.pkl\", \"rb\") as f:\n        loaded_fig = pickle.load(f)\n    import os\n    os.remove(\"temp_plot.pkl\")\n    return loaded_fig"
  },
  {
    "output": "def count_adjacent_pairs(word):\n    from collections import Counter\n    pairs = []\n    for i in range(len(word) - 1):\n        pairs.append(word[i:i+2])\n    return dict(Counter(pairs))"
  },
  {
    "output": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom scipy.stats import ttest_ind\nfrom sklearn.utils import check_array\nfrom numpy import nan\n\ndef analyze_data(data, group_column, value_column):\n    data = data.dropna()\n    groups = data.groupby(group_column)\n    group_data = {group: group_data[value_column].values for group, group_data in groups}\n    descriptive_stats = {group: group_data[value_column].describe() for group, group_data in groups}\n    sns.boxplot(x=group_column, y=value_column, data=data)\n    plt.title('Boxplot of Values by Group')\n    plt.show()\n    sns.histplot(data=value_column, multiple=\"stack\", hue=group_column, kde=False)\n    plt.title('Histogram of Values by Group')\n    plt.show()\n    t_stat, p_value = ttest_ind(group_data[list(group_data.keys())[0]], group_data[list(group_data.keys())[1]])\n    result = {\n        'descriptive_statistics': descriptive_stats,\n        't_statistic': t_stat,\n        'p_value': p_value\n    }\n    return result"
  },
  {
    "output": "import base64\nimport json\nimport requests\n\ndef convert_and_send(data, api_endpoint):\n    json_str = json.dumps(data)\n    base64_str = base64.b64encode(json_str.encode()).decode()\n    response = requests.post(api_endpoint, data={'payload': base64_str})\n    return response"
  },
  {
    "output": "import pandas as pd\nimport numpy as np\n\ndef task_func(num_rows, columns):\n    np.random.seed(42)\n    data = {\n        col: np.random.randint(100, 1000, size=num_rows).astype(int) for col in columns\n    }\n    return pd.DataFrame(data)"
  },
  {
    "output": "def task_func(directory, search_string):\n    import os\n    import json\n    results = []\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            if file.endswith('.json'):\n                file_path = os.path.join(root, file)\n                try:\n                    with open(file_path, 'r') as f:\n                        data = json.load(f)\n                        if isinstance(data, (dict, list)):\n                            if search_string in json.dumps(data):\n                                results.append(file_path)\n                except Exception:\n                    pass\n    return results"
  },
  {
    "output": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    if df.empty or 'Word' not in df.columns:\n        return None\n    filtered = df[df['Word'].str[0].str.lower().isin(['a', 'b', 'c', 'd', 'e'])]\n    if filtered.empty:\n        return None\n    lengths = filtered['Word'].str.len()\n    plt.boxplot(lengths)\n    plt.ylabel('Length')\n    plt.title('Word Length Distribution')\n    plt.show()"
  },
  {
    "output": "def process_data(data):\n    try:\n        result = {}\n        for item in data:\n            if isinstance(item, dict):\n                result.update(item)\n            elif isinstance(item, list):\n                result['lists'] = result.get('lists', []) + item\n            else:\n                result['other'] = result.get('other', []) + [item]\n        return result\n    except Exception as e:\n        import logging\n        logging.error(f\"An error occurred: {e}\")\n        return {}"
  },
  {
    "output": "def task_func(source_dir, target_dir, extensions):\n    import os\n    import shutil\n    import warnings\n    warnings.filterwarnings(\"ignore\", category=UserWarning)\n    if not os.path.exists(target_dir):\n        os.makedirs(target_dir)\n    for root, dirs, files in os.walk(source_dir):\n        for file in files:\n            file_path = os.path.join(root, file)\n            _, ext = os.path.splitext(file)\n            if ext in extensions:\n                try:\n                    shutil.move(file_path, target_dir)\n                except Exception as e:\n                    warnings.warn(f\"Failed to move {file_path}: {str(e)}\")\n    return True"
  },
  {
    "output": "import re\nimport requests\n\ndef extract_and_send(url_str, token):\n    url_pattern = re.compile(r'https?://\\S+')\n    url = url_pattern.search(url_str)\n    if url:\n        url = url.group(0)\n        headers = {'Authorization': f'Bearer {token}'}\n        response = requests.post('https://api.example.com/endpoint', json={'url': url}, headers=headers)\n        return response.json()\n    return None"
  },
  {
    "output": "```python\nimport subprocess\nimport time\nimport json\nimport platform\nimport os\nimport psutil\n\nLOGFILE_PATH = \"logfile.log\"\n\ndef task_func(interval, duration):\n    if interval <= 0 or duration <= 0:\n        raise ValueError(\"Both 'interval' and 'duration' must be positive.\")\n    \n    try:\n        # Detect OS\n        os_name = platform.system()\n        cpu_usage_data = []\n        \n        start_time = time.time()\n        current_time = start_time\n        \n        while (current_time - start_time) < duration:\n            # Get CPU usage\n            cpu_usage = psutil.cpu_percent(interval=1)\n            \n            # Record timestamp and CPU usage\n            timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n            cpu_usage_data.append({\n                \"timestamp\": timestamp,"
  },
  {
    "output": "def task_func(process_name: str) -> int:\n    processes = []\n    try:\n        result = subprocess.check_output(['ps', 'aux'], text=True)\n        for line in result.split('\\n'):\n            if process_name in line:\n                pid = line.split()[1]\n                processes.append(int(pid))\n    except subprocess.CalledProcessError:\n        return 0\n\n    stopped_count = 0\n    for pid in processes:\n        try:\n            os.kill(pid, signal.SIGTERM)\n            stopped_count += 1\n        except ProcessLookupError:\n            continue\n\n    time.sleep(1)\n\n    return stopped_count"
  },
  {
    "output": "import json\nimport datetime\nimport socket\n\ndef send_greeting_to_client(client_socket):\n    current_time = datetime.datetime.now().isoformat()\n    greeting = \"Hello, client!\"\n    message = json.dumps({\"time\": current_time, \"greeting\": greeting})\n    client_socket.sendall(message.encode())"
  },
  {
    "output": "import json\nimport csv\nimport statistics\n\ndef process_json_to_csv(json_file_path, csv_file_path):\n    with open(json_file_path, 'r') as file:\n        data = json.load(file)\n    results = {}\n    for key, values in data.items():\n        mean = statistics.mean(values)\n        median = statistics.median(values)\n        results[key] = [mean, median]\n    with open(csv_file_path, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow(['Key', 'Mean', 'Median'])\n        for key, values in results.items():\n            writer.writerow([key, values[0], values[1]])"
  },
  {
    "output": "def task_func(n_samples=100, n_features=2, plot_path=None):\n    from sklearn.datasets import make_blobs\n    import matplotlib.pyplot as plt\n    import numpy as np\n    \n    X, y = make_blobs(n_samples=n_samples, n_features=n_features, random_state=42)\n    fig, ax = plt.subplots()\n    ax.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis')\n    ax.set_title('Generated Dataset')\n    \n    distances = np.zeros((n_samples, n_samples))\n    for i in range(n_samples):\n        for j in range(n_samples):\n            distances[i, j] = np.linalg.norm(X[i] - X[j])\n    \n    if plot_path is None:\n        return (distances, ax)\n    else:\n        plt.savefig(plot_path)\n        return (distances, None)"
  },
  {
    "output": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef generate_and_plot_time_series(num_series=5, start_date='2023-01-01', days=30):\n    dates = pd.date_range(start=start_date, periods=days)\n    data = {f'Series_{i}': np.random.randint(0, 100, size=days) for i in range(num_series)}\n    df = pd.DataFrame(data, index=dates)\n    plt.figure(figsize=(12, 6))\n    for col in df.columns:\n        plt.plot(df.index, df[col], label=col)\n    plt.title('Random Time Series')\n    plt.xlabel('Date')\n    plt.ylabel('Value')\n    plt.legend()\n    plt.grid(True)\n    try:\n        plt.show()\n    except Exception as e:\n        print(f\"Error displaying plot: {e}\")\n    return df"
  },
  {
    "output": "import numpy as np\nimport matplotlib.pyplot as plt\ndef create_histogram(image):\n    try:\n        if not isinstance(image, np.ndarray) or image.ndim != 2:\n            raise ValueError(\"Input must be a 2D numpy array representing a grayscale image.\")\n        plt.hist(image.ravel(), bins=256, range=(0, 256), density=True)\n        plt.xlabel('Pixel Value')\n        plt.ylabel('Frequency')\n        plt.title('Grayscale Image Histogram')\n        return plt.gcf().canvas.renderer._renderer.tostring_rgb()\n    except Exception as e:\n        return str(e)"
  },
  {
    "output": "def task_func(LETTERS):\n    import random\n    import numpy as np\n    random_dict = {}\n    for letter in LETTERS:\n        length = random.randint(1, 10)\n        random_list = [random.randint(0, 100) for _ in range(length)]\n        random_dict[letter] = random_list\n    means_dict = {}\n    for key, value in random_dict.items():\n        mean = np.mean(value)\n        means_dict[key] = mean\n    return means_dict"
  },
  {
    "output": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n\ndef task_func(data_matrix):\n    scaler = StandardScaler()\n    standardized_data = scaler.fit_transform(data_matrix)\n    standardized_df = pd.DataFrame(standardized_data, columns=[\"Feature 1\", \"Feature 2\", \"Feature 3\", \"Feature 4\", \"Feature 5\"])\n    row_means = standardized_df.mean(axis=1)\n    standardized_df['Mean'] = row_means\n    fig, ax = plt.subplots()\n    ax.hist(row_means, bins=10, edgecolor='black')\n    ax.set_title('Distribution of Means')\n    return (standardized_df, ax)"
  },
  {
    "output": "import numpy as np\nimport itertools\n\ndef task_func(dimension, seed=42):\n    np.random.seed(seed)\n    matrix = np.random.randint(1, 101, size=dimension)\n    flat_list = list(itertools.chain.from_iterable(matrix))\n    return (matrix, flat_list)"
  },
  {
    "output": "def process_json_file(file_path):\n    import json\n    import pandas as pd\n    data = json.load(open(file_path))\n    results = {}\n    for key in data[0].keys():\n        values = [d[key] for d in data]\n        numeric_values = [v for v in values if isinstance(v, (int, float))]\n        mean = sum(numeric_values) / len(numeric_values) if numeric_values else None\n        median = sorted(numeric_values)[len(numeric_values) // 2] if numeric_values else None\n        results[key] = {'mean': mean, 'median': median}\n    df = pd.DataFrame(results).T\n    df = df.sort_index()\n    return df"
  },
  {
    "output": "def generate_combination_dataframe(colors, states):\n    import pandas as pd\n    from itertools import product\n    import random\n    \n    combinations = ['{}:{}'.format(color, state) for color, state in product(colors, states)]\n    random.shuffle(combinations)\n    \n    num_columns = min(len(colors), len(states))\n    num_rows = (len(combinations) + num_columns - 1) // num_columns\n    \n    data = [[] for _ in range(num_columns)]\n    for i, combo in enumerate(combinations):\n        col = i % num_columns\n        data[col].append(combo)\n    \n    return pd.DataFrame(data).transpose()"
  },
  {
    "output": "import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport ast\n\ndef task_func(csv_file):\n    df = pd.read_csv(csv_file)\n    df['list'] = df['list'].apply(ast.literal_eval)\n    df['sum'] = df['list'].apply(lambda x: sum(x))\n    df['mean'] = df['list'].apply(lambda x: np.mean(x))\n    df['std'] = df['list'].apply(lambda x: np.std(x))\n    df = df.drop(columns=['list'])\n    sns.histplot(df['mean'], kde=False)\n    return df, sns.histplot(df['mean'], kde=False)"
  },
  {
    "output": "import matplotlib.pyplot as plt\nimport numpy as np\nimport random\n\ndef simulate_dice_rolls(num_dice, num_rolls):\n    sums = []\n    for _ in range(num_rolls):\n        total = 0\n        for _ in range(num_dice):\n            total += random.randint(1, 6)\n        sums.append(total)\n    counts = np.bincount(np.array(sums), minlength=6*num_dice + 1)\n    plt.bar(range(len(counts)), counts)\n    plt.xlabel('Sum')\n    plt.ylabel('Frequency')\n    plt.title(f'Distribution of Sums for {num_dice} Dice Rolled {num_rolls} Times')\n    plt.show()"
  },
  {
    "output": "import pandas as pd\nimport numpy as np\n\ndef generate_random_gdp_data(countries):\n    np.random.seed(42)\n    gdp_data = np.random.uniform(1000, 100000, size=len(countries))\n    return pd.DataFrame({\n        'Country': countries,\n        'GDP': gdp_data\n    })"
  },
  {
    "output": "def generate_sales_data(num_days, num_products, start_date='2023-01-01'):\n    import pandas as pd\n    import numpy as np\n    import matplotlib.pyplot as plt\n    np.random.seed(42)\n    dates = pd.date_range(start=start_date, periods=num_days)\n    products = [f'Product_{i}' for i in range(num_products)]\n    sales_data = np.random.randint(100, 1000, size=(num_days, num_products))\n    df = pd.DataFrame(sales_data, columns=products, index=dates)\n    fig, ax = plt.subplots()\n    df.plot(ax=ax)\n    return df, ax"
  },
  {
    "output": "from collections import defaultdict\nfrom operator import itemgetter\nfrom itertools import groupby\n\ndef task_func(news_articles):\n    for article in news_articles:\n        if \"category\" not in article or \"title\" not in article:\n            raise ValueError(\"Each article must have 'category' and 'title' keys.\")\n    grouped_articles = defaultdict(list)\n    for article in news_articles:\n        category = article[\"category\"]\n        grouped_articles[category].append(article)\n    for category in grouped_articles:\n        grouped_articles[category].sort(key=lambda x: x[\"title\"])\n    return grouped_articles"
  },
  {
    "output": "import json\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef process_data(json_data):\n    data = json.loads(json_data)\n    df = pd.DataFrame(data)\n    stats = df.describe()\n    df.boxplot()\n    plt.show()\n    return stats.to_dict()"
  },
  {
    "output": "def task_func(df, column1, column2):\n    try:\n        filtered_df = df[[column1, column2]]\n        contingency_table = pd.crosstab(filtered_df[column1], filtered_df[column2])\n        chi2, p, _, _ = chi2_contingency(contingency_table)\n        return chi2, p\n    except KeyError as e:\n        raise ValueError(f\"Column not found: {e}\") from e\n    except Exception as e:\n        raise ValueError(f\"An error occurred: {e}\") from e"
  },
  {
    "output": "def task_func(df, col1, col2, N=10):\n    if col1 not in df.columns or col2 not in df.columns:\n        raise ValueError('ValueError: If specified columns are not in the provided DataFrame.')\n    scaler = StandardScaler()\n    scaled_values = scaler.fit_transform(df[[col1, col2]])\n    abs_diff = np.abs(scaled_values[:, 0] - scaled_values[:, 1])\n    top_n_indices = heapq.nlargest(N, range(len(abs_diff)), key=lambda i: abs_diff[i])\n    return top_n_indices"
  },
  {
    "output": "def task_func(json_str):\n    import json\n    data = json.loads(json_str)\n    cleaned_data = {k: v for k, v in data.items() if v is not None}\n    from collections import Counter\n    freq = Counter()\n    for key, value in cleaned_data.items():\n        if isinstance(value, str) and '@' in value:\n            value = \"None\"\n        freq[value] += 1\n    return {\"processed_data\": cleaned_data, \"frequency_counts\": dict(freq)}"
  },
  {
    "output": "def backup_log_files(output_path):\n    import os\n    import tarfile\n    try:\n        log_files = [f for f in os.listdir() if f.endswith('.log')]\n        if not log_files:\n            print(\"No .log files found.\")\n            return\n        with tarfile.open(output_path, \"w:gz\") as tar:\n            for log_file in log_files:\n                tar.add(log_file)\n        print(f\"Backup completed successfully. Files archived to {output_path}\")\n    except Exception as e:\n        print(f\"An error occurred: {e}\")"
  },
  {
    "output": "import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n\ndef standardize_and_visualize(list1, list2):\n    data = pd.DataFrame({'List1': list1, 'List2': list2})\n    scaler = StandardScaler()\n    standardized = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n    fig, ax = plt.subplots()\n    standardized.plot(kind='bar', ax=ax)\n    return standardized, ax"
  },
  {
    "output": "def task_func(url, headers=None, timeout=10):\n    import requests\n    from bs4 import BeautifulSoup\n    try:\n        response = requests.get(url, headers=headers, timeout=timeout)\n        response.raise_for_status()\n        return BeautifulSoup(response.content, 'html.parser')\n    except Exception as e:\n        return None"
  },
  {
    "output": "import base64\nimport os\nimport random\n\ndef task_func():\n    # Generate a random float number\n    random_float = random.random()\n    \n    # Convert the float to a hexadecimal string\n    hex_string = format(random_float, 'x')\n    \n    # Encode the hexadecimal string in base64\n    base64_encoded = base64.b64encode(hex_string.encode('utf-8')).decode('utf-8')\n    \n    return base64_encoded"
  },
  {
    "output": "def create_report(students_data):\n    report = {}\n    for student, subjects in students_data.items():\n        student_report = {}\n        for subject, grades in subjects.items():\n            average = sum(grades) / len(grades)\n            student_report[subject] = average\n        report[student] = student_report\n    return report"
  },
  {
    "output": "def shuffle_columns_and_train(X, y):\n    import numpy as np\n    from sklearn.ensemble import RandomForestClassifier\n    np.random.shuffle(X.T)\n    model = RandomForestClassifier().fit(X, y)\n    return model"
  },
  {
    "output": "def plot_normal_distributions(x, y, labels):\n    import matplotlib.pyplot as plt\n    fig, ax = plt.subplots()\n    for xi, yi, label in zip(x, y, labels):\n        ax.plot(xi, yi, label=label)\n    ax.legend()\n    return fig"
  },
  {
    "output": "import pytz\nfrom dateutil.parser import parse\nfrom datetime import datetime\n\ndef task_func(date_str, from_tz, to_tz):\n    naive_date = parse(date_str)\n    from_tz = pytz.timezone(from_tz)\n    localized_date = from_tz.localize(naive_date)\n    to_tz = pytz.timezone(to_tz)\n    converted_date = localized_date.astimezone(to_tz)\n    current_time = datetime.now(to_tz)\n    time_difference = (current_time - converted_date).total_seconds()\n    return int(time_difference)"
  },
  {
    "output": "```python\nimport itertools\nfrom typing import Any\nfrom scipy import stats\n\ndef task_func(input_list: list, repetitions: int) -> Any:\n    # Flatten the list by repeating it 'repetitions' times\n    flattened_list = list(itertools.chain.from_iterable(itertools.repeat(input_list, repetitions)))\n    \n    # Calculate the mode of the flattened list\n    mode_result = stats.mode(flattened_list)\n    \n    return mode_result\n```"
  },
  {
    "output": "from sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\nimport warnings\n\nX, y = datasets.load_iris(return_X_y=True)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nclf = SVC().fit(X_train, y_train)\ny_pred = clf.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\nif accuracy < 0.9:\n    warnings.warn(\"Accuracy is below 0.9\")"
  },
  {
    "output": "I will now implement the function to perform the described operations."
  },
  {
    "output": "def task_func(locations, location_type, zoom_start=13, width='100%', height='100%'):\n    import folium\n    import requests\n    from geopy.geocoders import Photon\n\n    geolocator = Photon()\n    map_center = [0, 0]\n\n    if location_type == 'coordinates':\n        map_center = locations[0]\n    elif location_type == 'addresses':\n        resolved_locations = []\n        for loc in locations:\n            location = geolocator.geocode(loc)\n            if location:\n                resolved_locations.append((location.latitude, location.longitude))\n            else:\n                resolved_locations.append((0, 0))\n        map_center = resolved_locations[0]\n\n    m = folium.Map(location=map_center, zoom_start=zoom_start, width=width, height=height)\n\n    for loc in locations:\n        if location_type == 'coordinates':\n            lat, lon = loc\n        elif location_type == 'addresses':\n            location = geolocator.geocode(loc)\n            if location:\n                lat, lon = location.latitude, location.longitude\n            else:\n                lat, lon = 0, 0\n        folium.Marker([lat, lon], popup=loc).add_to(m)\n\n    return m._repr_html_()"
  },
  {
    "output": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef generate_random_rgb_image(width, height, range_low, range_high):\n    if range_low >= range_high:\n        raise ValueError(\"range_low must be less than range_high\")\n    image = np.random.randint(range_low, range_high, (height, width, 3))\n    fig, ax = plt.subplots()\n    ax.imshow(image)\n    return ax, image"
  },
  {
    "output": "def task_func():\n    return \"Hello, World!\""
  },
  {
    "output": "import random\nimport matplotlib.pyplot as plt\n\ndef task_func(points: int):\n    random_numbers = [random.random() for _ in range(points)]\n    fig, ax = plt.subplots()\n    ax.plot(range(points), random_numbers)\n    return random_numbers, ax"
  },
  {
    "output": "from gensim.models import Word2Vec\nfrom nltk.corpus import stopwords\nimport nltk\nnltk.download('stopwords')\n\ndef task_func(texts):\n    stop_words = set(stopwords.words('english'))\n    cleaned_texts = [[word for word in text if word.isalpha() and word not in stop_words] for text in texts]\n    model = Word2Vec(sentences=cleaned_texts, vector_size=100, window=5, min_count=1, workers=4)\n    return model.vectors, model.index_to_key"
  },
  {
    "output": "def extract_and_request_api_endpoint(input_string):\n    import re\n    import requests\n    url_match = re.search(r'https?://\\S+', input_string)\n    if not url_match:\n        return {}\n    url = url_match.group(0)\n    response = requests.get(url)\n    return response.json()"
  },
  {
    "output": "import matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(categories, store1_sales, store2_sales):\n    filtered = [cat for cat, s1, s2 in zip(categories, store1_sales, store2_sales) if s1 > 200 and s2 > 200]\n    filtered_sales1 = [s1 for s1, s2 in zip(store1_sales, store2_sales) if s1 > 200 and s2 > 200]\n    filtered_sales2 = [s2 for s1, s2 in zip(store1_sales, store2_sales) if s1 > 200 and s2 > 200]\n    plt.bar(filtered, filtered_sales1, label='Store 1')\n    plt.bar(filtered, filtered_sales2, bottom=filtered_sales1, label='Store 2')\n    plt.xlabel('Categories')\n    plt.ylabel('Sales')\n    plt.title('Sales by Category')\n    plt.legend()\n    plt.show()\n    distances = np.sqrt((np.array(filtered_sales1) - np.array(filtered_sales2))**2)\n    return plt.gcf(), distances"
  },
  {
    "output": "import pandas as pd\nimport numpy as np\n\ndef generate_ratings_df(weights, num_users=1000, num_items=500):\n    np.random.seed(42)\n    ratings = np.random.choice(list(weights.keys()), size=num_users * num_items, p=list(weights.values()))\n    ratings = ratings.reshape(num_users, num_items)\n    df = pd.DataFrame(ratings, columns=weights.keys())\n    df = df.melt(var_name='item', value_name='rating')\n    df = df.sort_values('rating', ascending=False)\n    return df"
  },
  {
    "output": "def task_func(filepath):\n    import hashlib\n    with open(filepath, 'rb') as f:\n        data = f.read()\n    md5_hash = hashlib.md5(data).hexdigest()\n    sha256_hash = hashlib.sha256(data).hexdigest()\n    print(f\"MD5: {md5_hash}\")\n    print(f\"SHA256: {sha256_hash}\")\n    print(f\"File name: {filepath.split('/')[-1]}\")"
  },
  {
    "output": "import numpy as np\nfrom scipy.stats import norm\n\ndef task_func(data: np.ndarray, threshold: float = 2.0) -> list:\n    mean = np.mean(data)\n    std = np.std(data)\n    \n    if std == 0:\n        return [], mean, std**2\n    \n    z_scores = (data - mean) / std\n    outliers = np.where(np.abs(z_scores) > threshold)[0].tolist()\n    \n    return outliers, mean, std**2"
  },
  {
    "output": "def task_func(df):\n    import pandas as pd\n    import numpy as np\n    from sklearn.linear_model import LinearRegression\n    import matplotlib.pyplot as plt\n\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input must be a pandas DataFrame\")\n    if 'date' not in df.columns or 'value' not in df.columns:\n        raise ValueError(\"DataFrame must contain 'date' and 'value' columns\")\n\n    df['date'] = pd.to_datetime(df['date']).map(lambda x: x.toordinal())\n    X = df[['date']].values\n    y = df['value'].values\n\n    model = LinearRegression().fit(X, y)\n    predictions = model.predict(X)\n\n    fig, ax = plt.subplots()\n    ax.plot(df['date'], df['value'], label='Original')\n    ax.plot(df['date'], predictions, label='Predicted', linestyle='--')\n    ax.legend()\n    ax.set_title('Original vs Predicted Values')\n    ax.set_xlabel('Date (ordinal)')\n    ax.set_ylabel('Value')\n\n    return model, predictions, ax"
  },
  {
    "output": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import f_oneway\n\ndef analyze_data(file_path):\n    df = pd.read_csv(file_path)\n    numeric_cols = df.select_dtypes(include=np.number).columns\n    for col in numeric_cols:\n        df[col] = pd.to_numeric(df[col], errors='coerce')\n    df.dropna(inplace=True)\n    for col in numeric_cols:\n        mean = df[col].mean()\n        std_dev = df[col].std()\n        print(f\"Mean of {col}: {mean}, Standard Deviation: {std_dev}\")\n        plt.hist(df[col], bins=10, edgecolor='black')\n        plt.title(f'Histogram of {col}')\n        plt.xlabel(col)\n        plt.ylabel('Frequency')\n        plt.show()\n    if len(numeric_cols) >= 2:\n        group_cols = numeric_cols[:2]\n        group_data = [df[col] for col in group_cols]\n        f_stat, p_val = f_oneway(*group_data)\n        print(f\"ANOVA F-statistic: {f_stat}, p-value: {p_val}\")"
  },
  {
    "output": "def extract_ssl_expiration_dates(text):\n    import re\n    import ssl\n    import socket\n    from datetime import datetime, timezone\n\n    urls = re.findall(r'https://([^\"\\s]+)', text)\n    result = {}\n\n    for url in urls:\n        domain = url.split('//')[1].split('/')[0]\n        try:\n            context = ssl.create_default_context()\n            with socket.create_connection((domain, 443)) as sock:\n                with context.wrap_socket(sock, server_hostname=domain) as ssock:\n                    cert = ssock.getpeercert()\n                    expires = cert['notAfter']\n                    expiration_date = datetime.strptime(expires, \"%b %d %H:%M:%S %Y %Z\")\n                    expiration_date = expiration_date.replace(tzinfo=timezone.utc)\n                    result[domain] = expiration_date\n        except (ssl.SSLError, socket.gaierror, socket.timeout, ssl.CertificateError) as e:\n            result[domain] = None\n\n    return result"
  },
  {
    "output": "ax.bar(letters, counts, label='Letter Counts')\nax.set_xlabel('Letter')\nax.set_ylabel('Count')\nax.set_title('Letter Counts with Max Value Letter Highlighted')\nax.legend()\nax.bar([max_count_letter], [letter_counts[max_count_letter]], label='Max Value Letter', color='red')\nax.legend()\nplt.show()\nax"
  },
  {
    "output": "def process_dataframe(df):\n    if 'Date' not in df.columns or 'Value' not in df.columns:\n        raise ValueError(\"DataFrame must contain 'Date' and 'Value' columns\")\n    df['Date'] = pd.to_datetime(df['Date'])\n    values = pd.DataFrame(df['Value'].apply(pd.Series))\n    df = pd.concat([df, values], axis=1)\n    df.columns = ['Date'] + [f'Value_{i}' for i in range(values.shape[1])]\n    for col in df.columns[1:]:\n        df[col] = (df[col] - df[col].mean()) / df[col].std()\n    df.set_index('Date', inplace=True)\n    df.plot(kind='box')"
  },
  {
    "output": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n\ndef generate_distribution(mean, std_dev):\n    samples = np.random.normal(mean, std_dev, 1000)\n    fig = plt.figure()\n    plt.hist(samples, bins=30, density=True, alpha=0.6, color='g')\n    stats.probplot(samples, dist=\"norm\", plot=plt)\n    return fig"
  },
  {
    "output": "def task_func(data):\n    from collections import defaultdict\n    import math\n    aggregated = defaultdict(float)\n    for key, value in data.items():\n        if key != \"ele\":\n            aggregated[key] += value\n    return {k: math.sin(v) for k, v in aggregated.items()}"
  },
  {
    "output": "def task_func(tuples_list):\n    import numpy as np\n    max_len = max(len(t) for t in tuples_list) if tuples_list else 0\n    means = []\n    for i in range(max_len):\n        values = [t[i] if i < len(t) else 0 for t in tuples_list]\n        numeric_values = [v for v in values if isinstance(v, (int, float))]\n        if not numeric_values:\n            means.append(np.nan)\n        else:\n            means.append(np.mean(numeric_values))\n    return means"
  },
  {
    "output": "def task_func(text):\n    import re\n    from collections import Counter\n    import matplotlib.pyplot as plt\n    import numpy as np\n    names = re.findall(r'\\b([A-Za-z]+)\\b', text)\n    name_counts = Counter(names)\n    names, counts = zip(*name_counts.items())\n    plt.bar(names, counts)\n    plt.xlabel('Names')\n    plt.ylabel('Frequency')\n    plt.title('Name Frequencies')\n    plt.show()\n    skewness = np.ma.masked_invalid(counts).skew()\n    kurtosis = np.ma.masked_invalid(counts).kurtosis()\n    return {'name_counts': dict(name_counts), 'skewness': skewness, 'kurtosis': kurtosis}"
  },
  {
    "output": "def process_data(df):\n    if df.empty or df['age'].min() < 0:\n        raise ValueError(\"DataFrame is empty or contains negative ages\")\n    df['age'] = df['age'].apply(lambda x: int(x // 1))\n    name_duplicates = df[df.duplicated('name', keep=False)].groupby('name').size().reset_index(name='count')\n    duplicate_names = name_duplicates[name_duplicates['count'] > 1]['name'].tolist()\n    duplicate_ages = df[df['name'].isin(duplicate_names)].groupby('name')['age'].value_counts().unstack().fillna(0).astype(int)\n    from collections import Counter\n    import matplotlib.pyplot as plt\n    import numpy as np\n    age_distribution = Counter()\n    for name, group in df.groupby('name'):\n        if len(group) > 1:\n            age_distribution[name] = group['age'].value_counts().to_dict()\n    plt.figure(figsize=(10, 6))\n    plt.hist(df['age'], bins=range(int(df['age'].min()), int(df['age'].max()) + 2), align='left', rwidth=0.8)\n    plt.title('Age Distribution')\n    plt.xlabel('Age')\n    plt.ylabel('Frequency')\n    plt.grid(axis='y', alpha=0.75)\n    plt.show()\n    return age_distribution, plt.gcf()"
  },
  {
    "output": "def generate_plot_from_date(date_str):\n    import matplotlib.pyplot as plt\n    import random\n    from datetime import datetime\n    day_of_month = datetime.strptime(date_str, \"%Y-%m-%d\").day\n    data = [random.randint(1, 100) for _ in range(day_of_month)]\n    fig, ax = plt.subplots()\n    ax.plot(data)\n    return ax"
  },
  {
    "output": "import string\nimport re\n\ndef task_func(input_strings):\n    punctuation = string.punctuation\n    pattern = re.compile(f'[{re.escape(punctuation)}]')\n    cleaned = tuple(pattern.sub('', s) for s in input_strings)\n    return cleaned"
  },
  {
    "output": "from collections import Counter\nimport random\nimport string\n\ndef task_func(list_of_lists):\n    random_letters = [random.choice(string.ascii_letters) for _ in list_of_lists]\n    return Counter(random_letters)"
  },
  {
    "output": "import json\nimport requests\n\ndef task_func(prefix, endpoint):\n    try:\n        response = requests.get(endpoint)\n        response.raise_for_status()\n        data = response.json()\n        filename = f\"{prefix}{endpoint.split('/')[-1]}.json\"\n        with open(filename, 'w') as file:\n            json.dump(data, file)\n        return filename\n    except Exception as e:\n        raise RuntimeError(f\"Error occurred: {str(e)}\")"
  },
  {
    "output": "import pandas as pd\nimport numpy as np\n\ndef generate_random_dataframe(n_rows=100):\n    np.random.seed(42)\n    strings = np.random.choice(['A', 'B', 'C', 'D'], size=n_rows)\n    floats = np.random.uniform(0, 100, size=n_rows).astype(float)\n    df = pd.DataFrame({\n        'Random_String': strings,\n        'Formatted_Float': np.round(floats, 2)\n    })\n    return df"
  },
  {
    "output": "class EmailHandler:\n    def handle_post(self, data):\n        try:\n            import smtplib\n            from email.mime.text import MIMEText\n            from email.mime.multipart import MIMEMultipart\n\n            sender_email = \"your_email@example.com\"\n            receiver_email = \"receiver@example.com\"\n            password = \"your_password\"\n\n            message = MIMEMultipart()\n            message[\"From\"] = sender_email\n            message[\"To\"] = receiver_email\n            message[\"Subject\"] = \"New Request\"\n\n            body = \"Data received: \" + str(data)\n            message.attach(MIMEText(body, \"plain\"))\n\n            server = smtplib.SMTP(\"smtp.example.com\", 587)\n            server.starttls()\n            server.login(sender_email, password)\n            text = message.as_string()\n            server.sendmail(sender_email, receiver_email, text)\n            server.quit()\n\n            return \"Email sent successfully\"\n        except smtplib.SMTPException as e:\n            return \"SMTP error: \" + str(e)\n        except Exception as e:\n            return \"An error occurred: \" + str(e)"
  },
  {
    "output": "```python\nimport xmltodict\nimport json\n\ndef task_func(s, save_json, json_file_path):\n    # Input validation\n    if not s.strip():\n        raise ValueError(\"The input XML string is empty or contains only whitespace.\")\n    \n    # Parse XML string into a dictionary\n    parsed_xml = xmltodict.parse(s)\n    \n    # Convert the parsed XML to a dictionary\n    xml_dict = parsed_xml.get('school', {})\n    \n    # Save as JSON if required\n    if save_json and json_file_path:\n        with open(json_file_path, 'w') as json_file:\n            json.dump(xml_dict, json_file)\n    \n    return xml_dict\n```"
  },
  {
    "output": "import cv2\nimport numpy as np\nimport os\n\ndef task_func(img_path):\n    try:\n        if not os.path.exists(img_path):\n            raise FileNotFoundError(f\"The image file does not exist at the specified path: {img_path}\")\n        original_image = cv2.imread(img_path)\n        if original_image is None:\n            raise FileNotFoundError(f\"The image file is not readable or does not exist: {img_path}\")\n        gray_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)\n        contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n        return (original_image, contours)\n    except Exception as e:\n        raise e"
  },
  {
    "output": "(mode_result := mode(merged_list)), (mode_value, mode_count := mode_result.mode[0], mode_result.count[0]), np.array([mode_value])"
  },
  {
    "output": "```python\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Constants defining the range of random integers and the size of the DataFrame\nRANGE = 100\nSIZE = 1000\n\ndef task_func():\n    # Generate random integers for 'X' and 'Y' columns\n    np.random.seed(42)  # For reproducibility\n    data = {\n        'X': np.random.randint(0, RANGE, SIZE),\n        'Y': np.random.randint(0, RANGE, SIZE)\n    }\n    df = pd.DataFrame(data)\n    \n    # Plot the scatter plot using Seaborn\n    sns.scatterplot(data=df, x='X', y='Y')\n    plt.title('Scatter Plot of Random Integers')\n    plt.xlabel('X')\n    plt.ylabel('Y')\n    plt.show()\n    \n    return df\n```"
  },
  {
    "output": "def task_func(df):\n    y = df['target']\n    X = df.drop('target', axis=1)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n    return (X_train, X_test, y_train, y_test)"
  },
  {
    "output": "import numpy as np\n\ndef calculate_product_of_seconds(tuples_list):\n    second_values = [t[1] for t in tuples_list]\n    product = np.prod(second_values)\n    return np.array([product])"
  },
  {
    "output": "def perform_kmeans_clustering(data_series1, data_series2, n_clusters=3):\n    import pandas as pd\n    import numpy as np\n    from sklearn.cluster import KMeans\n    import matplotlib.pyplot as plt\n    \n    if not isinstance(data_series1, pd.Series) or not isinstance(data_series2, pd.Series):\n        raise ValueError(\"Both inputs must be pandas Series.\")\n    \n    if data_series1.shape[0] != data_series2.shape[0]:\n        raise ValueError(\"Both Series must have the same length.\")\n    \n    data = pd.DataFrame({\n        'x': data_series1,\n        'y': data_series2\n    })\n    \n    kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(data)\n    labels = kmeans.labels_\n    centroids = kmeans.cluster_centers_\n    \n    plt.scatter(data['x'], data['y'], c=labels, s=50, cmap='viridis')\n    plt.scatter(centroids[:, 0], centroids[:, 1], c='red', s=200, marker='x', label='Centroids')\n    plt.xlabel('Feature 1')\n    plt.ylabel('Feature 2')\n    plt.title('K-Means Clustering')\n    plt.legend()\n    plt.show()"
  },
  {
    "output": "def generate_normal_distribution(length):\n    import numpy as np\n    import matplotlib.pyplot as plt\n    np.random.seed(0)\n    data = np.random.normal(0, 1, length)\n    x = np.linspace(-4, 4, 1000)\n    pdf = (1/(np.sqrt(2*np.pi))) * np.exp(-x**2/2)\n    plt.hist(data, bins=30, density=True, alpha=0.6, color='g')\n    plt.plot(x, pdf, 'k', linewidth=2)\n    plt.title('Histogram and PDF of Normal Distribution')\n    plt.xlabel('Value')\n    plt.ylabel('Density')\n    plt.grid(True)\n    return data, plt.gca()"
  },
  {
    "output": "```python\nimport numpy as np\nimport base64\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import padding\nfrom cryptography.hazmat.primitives.asymmetric.rsa import RSAPrivateKey\nfrom cryptography.hazmat.primitives import serialization\n\ndef task_func(num, from_base, to_base, private_key, alphabet):\n    # Step 1: Convert the input number from the source base to a decimal (base 10) integer\n    num_decimal ="
  },
  {
    "output": "def task_func(metric, log_file_path):\n    import os\n    import datetime\n    try:\n        os.makedirs(os.path.dirname(log_file_path), exist_ok=True)\n        timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n        with open(log_file_path, 'a') as f:\n            f.write(f\"{timestamp} - {metric}\\n\")\n        return True\n    except Exception as e:\n        return False"
  },
  {
    "output": "def perform_feature_selection_and_heatmap(X, y):\n    from sklearn.feature_selection import SelectKBest, f_classif\n    from sklearn.preprocessing import StandardScaler\n    import seaborn as sns\n    import matplotlib.pyplot as plt\n    import numpy as np\n    \n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(X)\n    \n    selector = SelectKBest(score_func=f_classif, k=2)\n    selected_features = selector.fit_transform(X_scaled, y)\n    selected_indices = selector.get_support(indices=True)\n    selected_features_names = X.columns[selected_indices].tolist()\n    \n    corr = np.corrcoef(selected_features.T)\n    sns.heatmap(corr, annot=True, fmt=\".2f\", xticklabels=selected_features_names, yticklabels=selected_features_names)\n    plt.tight_layout()\n    fig = plt.gcf()\n    \n    return selected_features_names, fig.axes[0]"
  },
  {
    "output": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(df):\n    scaler = StandardScaler()\n    df_standardized = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n    return df_standardized"
  },
  {
    "output": "def task_func(data):\n    import pandas as pd\n    import seaborn as sns\n    import matplotlib.pyplot as plt\n    from scipy.stats import normaltest\n    if data.shape[1] != 8:\n        raise ValueError(\"Input data must have exactly eight columns.\")\n    averages = data.mean(axis=1)\n    data['average'] = averages\n    plt.figure()\n    sns.distplot(data['average'], kde=True)\n    plt.title('Distribution of Averages')\n    stat, p = normaltest(data['average'])\n    return data, plt.gcf(), p if p is not None else None"
  },
  {
    "output": "import numpy as np\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nSENTENCES = [\"I love programming\", \"I hate bugs\", \"Programming is fun\"]\n\ndef task_func(string):\n    vectorizer = CountVectorizer(vocabulary=SENTENCES)\n    return vectorizer.transform([string]).toarray()"
  },
  {
    "output": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(rows=3, columns=2, seed=42):\n    np.random.seed(seed)\n    random_matrix = np.random.rand(rows, columns)\n    scaler = MinMaxScaler()\n    scaled_matrix = scaler.fit_transform(random_matrix)\n    return scaled_matrix"
  },
  {
    "output": "True"
  },
  {
    "output": "def closest_pair(n):\n    import random\n    import math\n    if n < 2:\n        return None\n    points = [(random.random(), random.random()) for _ in range(n)]\n    min_dist = float('inf')\n    closest = None\n    for i in range(n):\n        for j in range(i + 1, n):\n            dx = points[i][0] - points[j][0]\n            dy = points[i][1] - points[j][1]\n            dist = math.hypot(dx, dy)\n            if dist < min_dist:\n                min_dist = dist\n                closest = (points[i], points[j])\n    return closest"
  },
  {
    "output": "import os\nimport json\nimport pandas as pd\nfrom pathlib import Path\n\ndef task_func(directory):\n    processed_dir = Path(directory) / \"processed\"\n    processed_dir.mkdir(exist_ok=True)\n    df = pd.DataFrame()\n    for filename in os.listdir(directory):\n        if filename.endswith(\".json\"):\n            file_path = os.path.join(directory, filename)\n            with open(file_path, 'r') as f:\n                data = json.load(f)\n            df_file = pd.DataFrame(data)\n            df_file['Source'] = filename\n            df = pd.concat([df, df_file], ignore_index=True)\n            os.rename(file_path, os.path.join(processed_dir, filename))\n    return df"
  },
  {
    "output": "import re\nimport csv\nimport os\n\ndef save_dollar_words(text, output_path):\n    words = re.findall(r'\\b\\$\\w+\\b', text)\n    filtered_words = [word for word in words if not re.fullmatch(r'[$\\w]+', word)]\n    with open(output_path, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerow(['Word'])\n        for word in filtered_words:\n            writer.writerow([word])\n    return os.path.abspath(output_path)"
  },
  {
    "output": "import os\nimport re\nimport shutil\n\ndef task_func(source_dir, target_dir, pattern):\n    if not os.path.exists(target_dir):\n        os.makedirs(target_dir)\n    count = 0\n    for filename in os.listdir(source_dir):\n        if re.match(pattern, filename):\n            source_path = os.path.join(source_dir, filename)\n            target_path = os.path.join(target_dir, filename)\n            shutil.move(source_path, target_path)\n            count += 1\n    return count"
  },
  {
    "output": "def task_func(input_list):\n    import random\n    from collections import Counter\n    alphabet = 'abcdefghijklmnopqrstuvwxyz'\n    result = []\n    for lst in input_list:\n        if not lst:\n            lst = random.sample(alphabet, 5)\n        result.append(lst)\n    return Counter([item for sublist in result for item in sublist])"
  },
  {
    "output": "def task_func(cities_list):\n    population_data = []\n    for city in cities_list:\n        population = randint(100000, 1000000)\n        population = math.ceil(population / 1000) * 1000\n        population_data.append({'City': city, 'Population': population})\n    return pd.DataFrame(population_data)"
  },
  {
    "output": "plt.ylabel('Frequency')\nplt.title('Character Occurrences Histogram')\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()"
  },
  {
    "output": "import os\nimport random\nimport string\n\ndef create_random_files(directory, n_files):\n    os.makedirs(directory, exist_ok=True)\n    for i in range(n_files):\n        filename = os.path.join(directory, f'file_{i}.txt')\n        random_string = ''.join(random.choices(string.ascii_letters + string.digits, k=10))\n        with open(filename, 'w') as f:\n            f.write(random_string)\n        with open(filename, 'r') as f:\n            f.seek(0)\n    return directory"
  },
  {
    "output": "def task_func(file_path, private_key_path):\n    import rsa\n    import hashlib\n    import base64\n    with open(file_path, 'rb') as f:\n        file_data = f.read()\n    hash_object = hashlib.sha256(file_data)\n    hash_hex = hash_object.hexdigest()\n    with open(private_key_path, 'rb') as pk:\n        private_key = rsa.PrivateKey.load_pkcs1(pk.read())\n    signature = rsa.sign_hash(hash_hex.encode('utf-8'), private_key, 'sha256')\n    return base64.b64encode(signature).decode('utf-8')"
  },
  {
    "output": "from itertools import groupby\nfrom operator import itemgetter\n\nKEY_FUNC = itemgetter(0)\n\ndef task_func(my_dict):\n    sorted_items = sorted(my_dict.items(), key=KEY_FUNC)\n    grouped = groupby(sorted_items, key=KEY_FUNC)\n    aggregated_dict = {}\n    for key, group in grouped:\n        total = 0\n        for item in group:\n            total += item[1]\n        aggregated_dict[key] = total\n    return aggregated_dict"
  },
  {
    "output": "import pandas as pd\nimport numpy as np\n\ndef task_func(df):\n    if not all(pd.api.types.is_numeric_dtype(col) for col in df.columns):\n        raise TypeError(\"DataFrame contains non-numeric data types\")\n    if df.empty or df.isnull().any().any():\n        raise ValueError(\"DataFrame is empty or contains NaN values\")\n    cumulative_sums = df.cumsum()\n    min_vals = cumulative_sums.min()\n    max_vals = cumulative_sums.max()\n    normalized = (cumulative_sums - min_vals) / (max_vals - min_vals)\n    return normalized.rename(columns=lambda x: x)"
  },
  {
    "output": "import os\nimport pandas as pd\nimport numpy as np\n\ndef task_func(data_dir: str, csv_file: str) -> pd.DataFrame:\n    file_path = os.path.join(data_dir, csv_file)\n    if not os.path.exists(file_path):\n        raise FileNotFoundError(f\"File {csv_file} not found in directory {data_dir}\")\n    df = pd.read_csv(file_path)\n    numeric_cols = df.select_dtypes(include=np.number).columns\n    if not numeric_cols.empty:\n        df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())\n    return df"
  },
  {
    "output": "else:\n            # If not valid, skip\n            pass\n    \n    # Convert to valid timezones\n    localized_datetime = utc_datetime\n    for tz in valid_timezones:\n        localized_datetime = pytz.timezone(tz).localize(utc_datetime)\n    \n    # Generate fake event name\n    event_name = fake.catch_phrase()\n    \n    # Return dictionary with event details\n    return {\n        \"event_name\": event_name,\n        \"timestamp\": epoch_milliseconds,\n        \"timezone\": valid_timezones[0] if valid_timezones else \"UTC\",\n        \"datetime\": localized_datetime.strftime(\"%Y-%m-%d %H:%M:%S %Z\")\n    }"
  },
  {
    "output": "task_func([\"A\", \"E\", \"I\"]) 45"
  },
  {
    "output": "python_code_returner(task_func(time_string, from_tz, to_tz))"
  },
  {
    "output": "def task_func(text):\n    import string\n    from collections import Counter\n    text = text.lower()\n    text = text.translate(str.maketrans('', '', string.punctuation))\n    stopwords = {'the', 'and', 'of', 'to', 'a', 'in', 'is', 'it', 'that', 'for', 'on', 'with', 'as', 'by', 'at', 'an', 'this', 'are', 'be', 'was', 'were', 'has', 'have', 'had', 'do', 'does', 'did', 'will', 'shall', 'may', 'can', 'could', 'should', 'would', 'must', 'ought', 'need', 'dare', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', 'nay', '"
  },
  {
    "output": "task_func(text)"
  },
  {
    "output": "class MyRequestHandler(http.server.BaseHTTPRequestHandler):\n    def do_POST(self):\n        content_length = int(self.headers['Content-Length'])\n        post_data = self.rfile.read(content_length)\n        self.send_response(200)\n        self.send_header('Content-type', 'text/plain')\n        self.end_headers()\n        self.wfile.write(b'POST request received')"
  },
  {
    "output": ""
  },
  {
    "output": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport requests\n\ndef retrieve_and_visualize_data(url):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        data = response.json()\n        if not data or not isinstance(data, list):\n            raise ValueError(\"Invalid or empty data\")\n        df = pd.DataFrame(data)\n        if df.select_dtypes(include=['number']).shape[1] < 2:\n            raise ValueError(\"Not enough numerical columns for correlation\")\n        corr = df.select_dtypes(include=['number']).corr()\n        fig, ax = plt.subplots()\n        cax = ax.matshow(corr, cmap='coolwarm')\n        plt.colorbar(cax)\n        return df, ax\n    except requests.exceptions.RequestException as e:\n        raise Exception(\"URL cannot be accessed\") from e\n    except ValueError as e:\n        raise e\n    except Exception as e:\n        raise Exception(\"Invalid data\") from e"
  },
  {
    "output": "def task_func(file_list):\n    import random\n    import subprocess\n    if not file_list:\n        return None\n    selected_file = random.choice(file_list)\n    process = subprocess.Popen([selected_file], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    exit_code = process.wait()\n    return exit_code"
  },
  {
    "output": "data[key] = np.random.uniform(min_value, max_value, size=len(data))"
  },
  {
    "output": "import matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\ndef create_swarm_plot(data, x, y, intersecting_points):\n    fig, ax = plt.subplots()\n    sns.swarmplot(x=x, y=y, data=data, ax=ax)\n    for point in intersecting_points:\n        ax.scatter(point[x], point[y], color='red', s=100, edgecolor='black')\n    return ax, len(intersecting_points)"
  },
  {
    "output": "from collections import Counter\nimport json\nimport random\n\ndef task_func(n, file_name, seed=77):\n    random.seed(seed)\n    selected_words = random.sample(WORDS, n)\n    with open(file_name, 'w') as f:\n        json.dump(selected_words, f)\n    return file_name"
  },
  {
    "output": "import os\nimport json\n\ndef task_func(config_path: str) -> dict:\n    if not os.path.exists(config_path):\n        raise FileNotFoundError(f\"The configuration file '{config_path}' does not exist.\")\n    with open(config_path, 'r') as file:\n        config = json.load(file)\n    return config"
  },
  {
    "output": "False"
  },
  {
    "output": "def task_func(source_dir, target_dir, extensions):\n    import os\n    import shutil\n    import uuid\n\n    if not os.path.exists(source_dir):\n        raise FileNotFoundError(f\"Source directory '{source_dir}' does not exist.\")\n\n    os.makedirs(target_dir, exist_ok=True)\n\n    file_count = 0\n    for root, _, files in os.walk(source_dir):\n        for file in files:\n            if any(file.endswith(ext) for ext in extensions):\n                src_path = os.path.join(root, file)\n                base_name = os.path.splitext(file)[0]\n                ext = os.path.splitext(file)[1]\n                new_name = f\"{base_name}{uuid.uuid4().hex}{ext}\"\n                dst_path = os.path.join(target_dir, new_name)\n                shutil.move(src_path, dst_path)\n                file_count += 1\n\n    return file_count"
  },
  {
    "output": "import select\nimport socket\nimport time\n\ndef echo_server(host='127.0.0.1', port=65432, duration=10):\n    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n    server_socket.bind((host, port))\n    server_socket.listen(5)\n    server_socket.setblocking(False)\n    sockets = [server_socket]\n    start_time = time.time()\n    while time.time() - start_time < duration:\n        readable, writable, exceptional = select.select(sockets, [], sockets, 0)\n        for sock in readable:\n            if sock is server_socket:\n                client_socket, addr = sock.accept()\n                client_socket.setblocking(False)\n                sockets.append(client_socket)\n            else:\n                data = sock.recv(1024)\n                if data:\n                    current_time = time.ctime()\n                    response = data + current_time.encode()\n                    sock.sendall(response)\n        for sock in exceptional:\n            sockets.remove(sock)\n            sock.close()\n    print(\"Server stopped after duration.\")"
  },
  {
    "output": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef generate_and_visualize_df(num_rows):\n    data = np.random.randint(0, 10, size=(num_rows, 5))\n    df = pd.DataFrame(data, columns=['A', 'B', 'C', 'D', 'E'])\n    non_zero_counts = df.apply(lambda col: col[col != 0].count())\n    fig, ax = plt.subplots()\n    non_zero_counts.plot(kind='bar', ax=ax)\n    return df, ax"
  },
  {
    "output": "return df.to_dict()"
  },
  {
    "output": "def task_func(data, ALPHA=0.05):\n    import numpy as np\n    import scipy.stats as stats\n    import matplotlib.pyplot as plt\n    \n    row_means = np.mean(data, axis=1)\n    population_mean = np.mean(data)\n    \n    p_values = []\n    for row in data:\n        t_stat, p_val = stats.ttest_1samp(row, population_mean)\n        p_values.append(p_val)\n    \n    significant_indices = np.where(np.array(p_values) < ALPHA)[0]\n    \n    plt.figure(figsize=(10, 6))\n    plt.plot(row_means, color='red', label='Means')\n    plt.plot(row_means[significant_indices], color='blue', label='Significant Means')\n    plt.axhline(population_mean, color='green', linestyle='--', label='Population Mean')\n    plt.legend()\n    plt.xlabel('Row Index')\n    plt.ylabel('Mean Value')\n    plt.title('Row Means and Significant Means')\n    plt.grid(True)\n    plt.show()"
  },
  {
    "output": "import pandas as pd\nimport regex as re\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nCOLUMN_NAMES = [\"Name\", \"Email\", \"Age\", \"Country\"]\n\ndef task_func(text):\n    pattern = r\"Name: (.*?), Email: (.*?), Age: (.*?), Country: (.*?)($|\\n)\"\n    matches = re.finditer(pattern, text)\n    data = []\n    for match in matches:\n        name = match.group(1)\n        email = match.group(2)\n        age = int(match.group(3))\n        country = match.group(4)\n        data.append([name, email, age, country])\n    df = pd.DataFrame(data, columns=COLUMN_NAMES)\n    sns.histplot(df['Age'], bins=10, kde=False)\n    plt.title('Age Distribution')\n    plt.xlabel('Age')\n    plt.ylabel('Frequency')\n    plt.show()\n    return df"
  },
  {
    "output": "def task_func(df):\n    from sklearn.preprocessing import StandardScaler\n    import matplotlib.pyplot as plt\n    import pandas as pd\n    scaler = StandardScaler()\n    scaled_df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n    for col in scaled_df.columns:\n        plt.hist(scaled_df[col], bins=20)\n        plt.title(f'Histogram of {col}')\n        plt.xlabel('Value')\n        plt.ylabel('Frequency')\n        plt.show()"
  },
  {
    "output": "def fit_quadratic(data, plot=False):\n    import numpy as np\n    from scipy.optimize import curve_fit\n    x = np.array([i for i in range(len(data))])\n    y = np.array(data)\n    def quadratic_func(x, a, b, c):\n        return a * x**2 + b * x + c\n    params, _ = curve_fit(quadratic_func, x, y)\n    fitted_values = quadratic_func(x, *params)\n    if plot:\n        import matplotlib.pyplot as plt\n        plt.scatter(x, y, label='Data')\n        plt.plot(x, fitted_values, color='red', label='Fit')\n        plt.legend()\n        plt.show()\n    return params, fitted_values"
  },
  {
    "output": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(input_dict, target_value):\n    df = pd.DataFrame(input_dict)\n    matching_rows = df.apply(lambda row: all(cell == target_value for cell in row), axis=1)\n    counts = df.apply(lambda col: (col == target_value).sum(), axis=0)\n    fig, ax = plt.subplots()\n    counts.plot(kind='bar', ax=ax)\n    return counts, ax"
  },
  {
    "output": "def process_log_file(file_path):\n    import pandas as pd\n    import re\n    try:\n        with open(file_path, 'r') as file:\n            lines = file.readlines()\n        pattern = r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2} \\d{2}:\\d{2}:\\d{2} \\S+ \\S+ \\d+'\n        matches = re.findall(pattern, ''.join(lines))\n        data = []\n        for match in matches:\n            date, time, user, action, pid = match.split()\n            data.append({\n                'date': date,\n                'time': time,\n                'user': user,\n                'action': action,\n                'pid': pid\n            })\n        df = pd.DataFrame(data)\n        return df\n    except FileNotFoundError:\n        return pd.DataFrame()"
  },
  {
    "output": "import re\nfrom urllib import request\nimport json\n# Constants\nIP_REGEX = r'\\b(?:[0-9]{1,3}\\.){3}[0-9]{1,3}\\b'\ndef task_func(ip_address):\n    if not re.fullmatch(IP_REGEX, ip_address):\n        return 'Invalid IP address received'\n    try:\n        with request.urlopen('https://api.ipify.org?format=json') as response:\n            data = json.load(response)\n            return data['ip']\n    except Exception as e:\n        return 'Invalid IP address received'"
  },
  {
    "output": "def task_func(file_path, delimiter): \n    import os\n    invalid_chars = '<>:\"/\\\\|?*'\n    for char in file_path:\n        if char in invalid_chars:\n            return \"Invalid file path\"\n    components = file_path.split(delimiter)\n    return components"
  },
  {
    "output": "from collections import defaultdict\n\ndef count_letter_frequencies(word_dict):\n    frequency = defaultdict(int)\n    for word in word_dict:\n        for letter in word:\n            frequency[letter] += 1\n    return frequency"
  },
  {
    "output": "import numpy as np\nimport math\n\ndef task_func(L):\n    flat_list = []\n    for sublist in L:\n        for item in sublist:\n            flat_list.append(item)\n    median = np.median(flat_list)\n    return median"
  },
  {
    "output": "def task_func(file_path, goals, penalties):\n    import csv\n    from collections import Counter\n\n    with open(file_path, 'r') as file:\n        reader = csv.DictReader(file)\n        data = [row for row in reader]\n\n    total_goals = int(data[0]['goals']) + goals\n    total_penalties = int(data[0]['penalties']) + penalties\n\n    return Counter({'total_goals': total_goals, 'total_penalties': total_penalties})"
  },
  {
    "output": "def task_func(file_path):\n    import os\n    import csv\n    import random\n    if not os.path.exists(file_path) or not file_path.endswith('.csv'):\n        return []\n    with open(file_path, 'r') as f:\n        lines = f.readlines()\n    random.shuffle(lines)\n    split_files = []\n    for i in range(0, len(lines), 1000):\n        chunk = lines[i:i+1000]\n        split_file = f'split_{i}.csv'\n        with open(split_file, 'w') as f:\n            f.writelines(chunk)\n        split_files.append(split_file)\n    return split_files"
  },
  {
    "output": "from collections import Counter\nimport random\n\ndef generate_and_analyze_letter_pairs():\n    predefined_list = ['AA', 'AB', 'AC', 'AD', 'AE', 'AF', 'AG', 'AH', 'AI', 'AJ', 'AK', 'AL', 'AM', 'AN', 'AO', 'AP', 'AQ', 'AR', 'AS', 'AT', 'AU', 'AV', 'AW', 'AX', 'AY', 'AZ', 'BA', 'BB', 'BC', 'BD', 'BE', 'BF', 'BG', 'BH', 'BI', 'BJ', 'BK', 'BL', 'BM', 'BN', 'BO', 'BP', 'BQ', 'BR', 'BS', 'BT', 'BU', 'BV', 'BW', 'BX', 'BY', 'BZ']\n    sample_size = 1000\n    random_pairs = [random.choice(predefined_list) for _ in range(sample_size)]\n    frequency = Counter(random_pairs)\n    return frequency"
  },
  {
    "output": "def plot_histogram_with_normal(df, column):\n    import matplotlib.pyplot as plt\n    import numpy as np\n    import pandas as pd\n    fig, ax = plt.subplots()\n    data = df[column]\n    n, bins, patches = ax.hist(data, bins=30, density=True, edgecolor='black')\n    mu, std = np.mean(data), np.std(data)\n    pdf = np.exp(-((bins - mu)**2)/(2*std**2)) / (std*np.sqrt(2*np.pi))\n    ax.plot(bins, pdf, 'r-', lw=2)\n    return ax"
  },
  {
    "output": "def task_func(file_path, delimiter):\n    import os\n    import shutil\n    parts = file_path.split(delimiter)\n    for part in parts:\n        if not os.path.exists(part):\n            raise FileNotFoundError(f\"Directory {part} does not exist\")\n    total_size = 0\n    for part in parts:\n        total_size += shutil.disk_usage(part).used\n    return total_size"
  },
  {
    "output": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport os\n\ndef analyze_csv_data(csv_path, plot_path):\n    if not os.path.exists(csv_path):\n        raise FileNotFoundError(f\"The file {csv_path} does not exist.\")\n    df = pd.read_csv(csv_path)\n    df = df.dropna()\n    df = df.apply(pd.to_numeric, errors='coerce')\n    df = df.dropna()\n    numeric_data = df.values.flatten()\n    mean = numeric_data.mean()\n    median = numeric_data.median()\n    plt.plot(numeric_data)\n    plt.title(\"Data Distribution\")\n    plt.xlabel(\"Index\")\n    plt.ylabel(\"Value\")\n    plt.savefig(plot_path)\n    plt.close()\n    return (mean, median, plot_path)"
  },
  {
    "output": "def task_func(l=None):\n    if l is None:\n        l = random.sample(ELEMENTS, 10)\n    arr = np.array(l)\n    if len(arr) < 3:\n        return arr\n    return np.concatenate((arr[3:], arr[:3]))"
  },
  {
    "output": "def task_func(python_version=PYTHON_VERSION, path_to_append=PATH_TO_APPEND):\n    current_version = sys.version.split()[0]\n    if current_version != python_version:\n        try:\n            subprocess.check_output(['hash', '-r'], stderr=subprocess.STDOUT, shell=True)\n            subprocess.check_output([f'hash -d python'], stderr=subprocess.STDOUT, shell=True)\n            subprocess.check_output([f'hash -d python3'], stderr=subprocess.STDOUT, shell=True)\n            subprocess.check_output([f'hash -d python{python_version[0]}'], stderr=subprocess.STDOUT, shell=True)\n            subprocess.check_output([f'hash -d python{python_version[0]}'], stderr=subprocess.STDOUT, shell=True)\n            subprocess.check_output([f'hash -d python{python_version[0]}'], stderr=subprocess.STDOUT, shell=True)\n            subprocess.check_output([f'hash -d python{python_version[0]}'], stderr=subprocess.STDOUT, shell=True)"
  },
  {
    "output": "def calculate_letter_frequencies(s):\n    if not isinstance(s, str):\n        raise ValueError(\"Input must be a string\")\n    from collections import Counter\n    import matplotlib.pyplot as plt\n    counts = Counter()\n    for char in s:\n        if char.isalpha():\n            counts[char.lower()] += 1\n    letters = list(counts.keys())\n    frequencies = list(counts.values())\n    plt.bar(letters, frequencies)\n    plt.xlabel('Letters')\n    plt.ylabel('Frequency')\n    plt.title('Letter Frequency')\n    plt.show()"
  },
  {
    "output": "import time\nimport threading\n\ndef task_func(delay_time: float = 1.0, num_threads: int = 5):\n    completion_messages = []\n    lock = threading.Lock()\n    \n    def thread_target(thread_id):\n        time.sleep(delay_time)\n        with lock:\n            completion_messages.append(f'Delay in thread {thread_id} completed')\n    \n    threads = []\n    for i in range(num_threads):\n        thread = threading.Thread(target=thread_target, args=(i,))\n        threads.append(thread)\n        thread.start()\n    \n    for thread in threads:\n        thread.join()\n    \n    return completion_messages"
  },
  {
    "output": "return ax, empirical_mean, empirical_std"
  },
  {
    "output": "import pandas as pd\nimport collections\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input must be a DataFrame.\")\n    total_sales = df['Sales'].sum()\n    category_sales = df.groupby('Category')['Sales'].sum().reset_index()\n    category_sales.sort_values(by=['Sales', 'Category'], ascending=[False, True], inplace=True)\n    most_popular_category = category_sales.iloc[0]['Category']\n    return {\n        'Total Sales': total_sales,\n        'Most Popular Category': most_popular_category\n    }"
  },
  {
    "output": "def create_series_list(list_of_lists):\n    import pandas as pd\n    import numpy as np\n    result = []\n    for sublist in list_of_lists:\n        indices = sublist\n        values = np.random.permutation(range(1, len(indices) + 1))\n        series = pd.Series(values, index=indices)\n        result.append(series)\n    return result"
  },
  {
    "output": "def execute_script_in_temp_dir(script_content):\n    import tempfile\n    import os\n    import subprocess\n    import uuid\n    temp_dir = tempfile.mkdtemp()\n    script_path = os.path.join(temp_dir, f\"script_{uuid.uuid4().hex}.py\")\n    with open(script_path, 'w') as f:\n        f.write(script_content)\n    try:\n        result = subprocess.run(['python', script_path], capture_output=True, text=True, check=True)\n        return 0\n    except subprocess.CalledProcessError as e:\n        return 1\n    finally:\n        os.rmdir(temp_dir)"
  },
  {
    "output": "def convert_dict_files(directory):\n    import os\n    import json\n    dicts = []\n    for filename in os.listdir(directory):\n        file_path = os.path.join(directory, filename)\n        if os.path.isfile(file_path) and filename.endswith('.txt'):\n            try:\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    content = f.read()\n                try:\n                    dicts.append(json.loads(content))\n                except json.JSONDecodeError:\n                    raise ValueError(f\"Invalid JSON in file: {file_path}\")\n            except Exception as e:\n                raise ValueError(f\"Error reading file {file_path}: {str(e)}\")\n    return dicts"
  },
  {
    "output": "def generate_sales_report():\n    import pandas as pd\n    import random\n    data = {\n        'Product': [f'Product {i}' for i in range(1, 11)],\n        'Units Sold': [random.randint(50, 500) for _ in range(10)],\n        'Price': [round(random.uniform(10, 100), 2) for _ in range(10)],\n        'Cost': [round(random.uniform(5, 50), 2) for _ in range(10)]\n    }\n    df = pd.DataFrame(data)\n    df['Revenue'] = df['Units Sold'] * df['Price']\n    df['Cost'] = df['Units Sold'] * df['Cost']\n    df['Profit'] = df['Revenue'] - df['Cost']\n    return df.to_string(index=False)"
  },
  {
    "output": "import pandas as pd\nimport numpy as np\n\ndef task_func(rows=100, columns=3):\n    data = np.random.choice(list('abcdefghijklmnopqrstuvwxyz'), size=(rows, columns))\n    columns_names = [chr(ord('a') + i) for i in range(columns)]\n    df = pd.DataFrame(data, columns=columns_names)\n    return df"
  },
  {
    "output": "import matplotlib.pyplot as plt\nimport pandas as pd\n\ndef process_dataframe(df, target_values):\n    for col in df.columns:\n        df[col] = df[col].apply(lambda x: x if x in target_values else 0)\n    axes = []\n    for col in df.columns:\n        ax = plt.subplot(len(df.columns), 1, df.columns.get_loc(col) + 1)\n        df[col].plot(kind='hist', ax=ax)\n        ax.set_title(col)\n        axes.append(ax)\n    return axes"
  },
  {
    "output": "def task_func(file_path: str, column_name: str) -> pd.DataFrame:\n    df = pd.read_csv(file_path)\n    df[column_name] = df[column_name].str.replace('\\n', '<br>')\n    le = LabelEncoder()\n    df[column_name] = le.fit_transform(df[column_name])\n    return df"
  },
  {
    "output": "import pandas as pd\nimport numpy as np\n\ndef generate_random_student_data(num_students):\n    np.random.seed(42)\n    data = {\n        'StudentID': np.random.randint(1000, 9999, size=num_students),\n        'Name': [f\"Student {i}\" for i in range(1, num_students + 1)],\n        'Age': np.random.randint(18, 30, size=num_students),\n        'GPA': np.round(np.random.uniform(2.0, 4.0, size=num_students), 2),\n        'Major': np.random.choice(['Computer Science', 'Mathematics', 'Physics', 'Engineering'], size=num_students)\n    }\n    return pd.DataFrame(data)"
  },
  {
    "output": "def task_func(api_url):\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    import requests\n    if not isinstance(api_url, str):\n        raise ValueError(\"api_url must be a string\")\n    try:\n        response = requests.get(api_url)\n        response.raise_for_status()\n    except requests.exceptions.RequestException as e:\n        raise Exception(\"API request failed\") from e\n    try:\n        data = response.json()\n    except Exception as e:\n        raise Exception(\"Failed to parse JSON response\") from e\n    if not data:\n        raise ValueError(\"API returned empty data\")\n    df = pd.DataFrame(data)\n    if not df.empty:\n        df.plot()\n        plt.show()\n    else:\n        raise ValueError(\"DataFrame is empty after processing\")"
  },
  {
    "output": "linestyle='-', color='r')\n    plt.title('Transformed Signal')\n    plt.xlabel('Frequency Bin')\n    plt.ylabel('Magnitude')\n    plt.tight_layout()\n    plt.show()\n    \n    return transformed_signal, rounded_transformed_signal"
  },
  {
    "output": "import os\nimport re\nfrom collections import defaultdict\n\ndef organize_files(directory):\n    subdirs = defaultdict(list)\n    pattern = re.compile(r'(?:(?<!\\])[^[\\]]+)(?=\\[|$)')\n    for filename in os.listdir(directory):\n        match = pattern.search(filename)\n        if match:\n            subdir = match.group(1)\n            filepath = os.path.join(directory, filename)\n            subdirs[subdir].append(filepath)\n    for subdir, files in subdirs.items():\n        subdir_path = os.path.join(directory, subdir)\n        os.makedirs(subdir_path, exist_ok=True)\n        for file in files:\n            os.rename(file, os.path.join(subdir_path, os.path.basename(file)))\n    return (directory, dict(subdirs))"
  },
  {
    "output": "def create_value_distribution_chart(df):\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input must be a pandas DataFrame\")\n    counts = df['value'].value_counts().sort_index()\n    fig, ax = plt.subplots()\n    counts.plot(kind='bar', ax=ax)\n    ax.set_title('Value Distribution')\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Count')\n    return ax"
  },
  {
    "output": "import numpy as np\nimport pandas as pd\nimport csv\nimport os\n\ndef generate_and_write_matrix(filename, rows, cols):\n    letters = [chr(i) for i in range(ord('a'), ord('z') + 1)]\n    matrix = np.random.choice(letters, size=(rows, cols))\n    df = pd.DataFrame(matrix)\n    df.to_csv(filename, index=False, header=False)"
  },
  {
    "output": "import json\nimport csv\nimport os\nimport base64\n\ndef task_func(raw_string, filename, output_dir):\n    decoded_data = base64.b64decode(raw_string).decode('utf-8')\n    json_data = json.loads(decoded_data)\n    os.makedirs(output_dir, exist_ok=True)\n    file_path = os.path.join(output_dir, filename)\n    with open(file_path, 'w', newline='') as csvfile:\n        csv_writer = csv.writer(csvfile)\n        csv_writer.writerow(json_data.keys())\n        csv_writer.writerow(json_data.values())"
  },
  {
    "output": "def analyze_fitness_data(data):\n    import numpy as np\n    import matplotlib.pyplot as plt\n    if not data or not all(isinstance(x, (int, float)) for x in data):\n        raise ValueError(\"Invalid data format\")\n    mean = np.mean(data)\n    std_dev = np.std(data)\n    plt.plot(data)\n    plt.title(\"Fitness Data\")\n    plt.xlabel(\"Sample\")\n    plt.ylabel(\"Value\")\n    plt.show()\n    return mean, std_dev"
  },
  {
    "output": "def generate_random_csv(file_path, num_rows, num_cols, min_val, max_val):\n    import pandas as pd\n    import numpy as np\n    data = np.random.uniform(min_val, max_val, (num_rows, num_cols))\n    df = pd.DataFrame(data, columns=[f'col_{i}' for i in range(num_cols)])\n    df.to_csv(file_path, index=False)"
  },
  {
    "output": "```python\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(d):\n    if not d:\n        return pd.DataFrame()\n    df = pd.DataFrame(d)\n    scaler = MinMaxScaler()\n    scaled_data = scaler.fit_transform(df[['x', 'y', 'z']])\n    scaled_df = pd.DataFrame(scaled_data, columns=['x', 'y', 'z'])\n    return scaled_df\n```"
  },
  {
    "output": "def create_app(templates_folder, external_api_url):\n    from flask import Flask, jsonify\n    app = Flask(__name__, template_folder=templates_folder)\n    \n    @app.route('/data')\n    def get_data():\n        import requests\n        response = requests.get(external_api_url)\n        return jsonify(response.json())\n    \n    return app"
  },
  {
    "output": "def normalize_and_visualize(data):\n    import numpy as np\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    \n    df = pd.DataFrame(data)\n    min_vals = df.min()\n    max_vals = df.max()\n    normalized = (df - min_vals) / (max_vals - min_vals)\n    row_averages = normalized.mean(axis=1)\n    normalized['average'] = row_averages\n    normalized.plot(kind='line')\n    plt.show()"
  },
  {
    "output": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(data):\n    corr = data.corr()\n    plt.figure(figsize=(10, 8))\n    ax = sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm', square=True)\n    ax.set_title('Correlation Matrix')\n    return ax"
  },
  {
    "output": "def task_func(data=None):\n    if not isinstance(data, pd.DataFrame):\n        data = pd.DataFrame(data)\n    data = data.applymap(lambda x: 0 if x < 0.5 else x)\n    scaler = StandardScaler()\n    data_scaled = scaler.fit_transform(data)\n    data_preprocessed = pd.DataFrame(data_scaled, columns=data.columns)\n    return data_preprocessed"
  },
  {
    "output": "def find_target_in_csv(directory, target, move_to=None):\n    import os\n    import csv\n    import shutil\n    files = [f for f in os.listdir(directory) if f.endswith('.csv')]\n    results = []\n    for file in files:\n        file_path = os.path.join(directory, file)\n        with open(file_path, 'r') as f:\n            reader = csv.reader(f)\n            for idx, row in enumerate(reader):\n                if row and row[0] == target:\n                    results.append((file, idx))\n                    break\n        if move_to and os.path.exists(file_path):\n            shutil.move(file_path, os.path.join(move_to, file))\n    return results"
  },
  {
    "output": "(train_set, test_set)"
  },
  {
    "output": "def extract_and_calculate_tfidf(text):\n    import re\n    from sklearn.feature_extraction.text import TfidfVectorizer\n    import numpy as np\n    cleaned_text = re.sub(r'\\[.*?\\]', ' ', text)\n    vectorizer = TfidfVectorizer()\n    tfidf_matrix = vectorizer.fit_transform([cleaned_text])\n    feature_names = vectorizer.get_feature_names_out()\n    tfidf_dict = {word: tfidf_matrix[0, i] for i, word in enumerate(feature_names)}\n    return tfidf_dict"
  },
  {
    "output": "from collections import defaultdict\nimport re\n\ndef task_func(text):\n    words = re.findall(r'\\b\\w+\\b', text)\n    if not words:\n        return {}\n    stemmed_words = [word[:-1] if i != len(words)-1 else word for i, word in enumerate(words)]\n    freq = defaultdict(int)\n    for word in stemmed_words:\n        freq[word] += 1\n    return dict(freq)"
  },
  {
    "output": "```python\nimport pandas as pd\nimport numpy as np\n\ndef task_func(test_scores, student):\n    # Convert the dictionary to a DataFrame\n    df = pd.DataFrame(test_scores)\n    \n    # Check if the student exists in the DataFrame\n    if student not in df.columns:\n        raise ValueError(\"student is not present in the"
  },
  {
    "output": "import matplotlib.pyplot as plt\nimport numpy as np\ndef draw_histogram_with_gaussian_fit(data, title):\n    plt.hist(data, bins=30, density=True, alpha=0.6, color='g')\n    mu, sigma = np.mean(data), np.std(data)\n    x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n    plt.plot(x, 1/(sigma*np.sqrt(2*np.pi)) * np.exp(- (x - mu)**2 / (2*sigma**2)), 'r--')\n    plt.title(title)\n    plt.show()"
  },
  {
    "output": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef process_fft(data):\n    if not data:\n        return np.array([]), np.array([]), None\n    arr = np.array(data)\n    fft_data = np.fft.fft(arr)\n    plt.hist(np.abs(fft_data), bins=20)\n    fig = plt.gcf()\n    return arr, fft_data, fig.axes[0] if fig.axes else None"
  },
  {
    "output": "def task_func(directory):\n    import os\n    import json\n    processed_files = []\n    for filename in os.listdir(directory):\n        file_path = os.path.join(directory, filename)\n        try:\n            with open(file_path, 'r') as f:\n                data = json.load(f)\n            with open(file_path, 'w') as f:\n                json.dump(data, f, ensure_ascii=False)\n            processed_files.append(filename)\n        except FileNotFoundError:\n            pass\n    return processed_files"
  },
  {
    "output": "import matplotlib.pyplot as plt\nimport numpy as np\n\ndef plot_sales_trends_with_std_dev(sales_data):\n    fig, ax = plt.subplots()\n    products = list(sales_data.keys())\n    dates = np.arange(1, 13)\n    for i, product in enumerate(products):\n        sales = sales_data[product]\n        mean = np.mean(sales)\n        std_dev = np.std(sales)\n        ax.plot(dates, sales, label=product)\n        ax.fill_between(dates, mean - std_dev, mean + std_dev, alpha=0.3)\n    ax.set_xlabel('Month')\n    ax.set_ylabel('Sales')\n    ax.set_title('Sales Trends with Standard Deviation')\n    ax.legend()\n    return ax"
  },
  {
    "output": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef generate_complex_wave_with_hann_window(amplitude, frequency, time_points):\n    wave = amplitude * np.exp(1j * 2 * np.pi * frequency * time_points)\n    hann_window = 0.5 * (1 - np.cos(2 * np.pi * np.arange(len(time_points)) / (len(time_points) - 1)))\n    wave *= hann_window\n    fig, ax = plt.subplots(2, 1, figsize=(10, 6))\n    ax[0].plot(time_points, np.real(wave), label='Real Part')\n    ax[0].set_title('Real Part of Complex Wave')\n    ax[0].grid(True)\n    ax[1].plot(time_points, np.imag(wave), label='Imaginary Part')\n    ax[1].set_title('Imaginary Part of Complex Wave')\n    ax[1].grid(True)\n    plt.tight_layout()\n    return wave, fig, ax"
  },
  {
    "output": "def task_func(url):\n    import subprocess\n    import platform\n    import time\n    if platform.system() == \"Windows\":\n        command = [\"start\", \"\", url]\n    elif platform.system() == \"Darwin\":\n        command = [\"open\", url]\n    elif platform.system() == \"Linux\":\n        command = [\"xdg-open\", url]\n    else:\n        raise OSError(\"Unsupported operating system\")\n    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, stdin=subprocess.PIPE, start_new_session=True)\n    time.sleep(1)\n    return process.returncode"
  },
  {
    "output": "import random\nimport statistics\n\ndef create_population_std_dict(data):\n    return {key: statistics.pstdev(values) for key, values in data.items()}"
  },
  {
    "output": "def decode_unicode_strings(df):\n    import pandas as pd\n    import re\n    import unicodedata\n    def decode_unicode(s):\n        try:\n            return s.encode('utf-8').decode('unicode_escape').encode('latin1').decode('utf-8')\n        except Exception as e:\n            return str(e)\n    df['UnicodeString'] = df['UnicodeString'].apply(decode_unicode)\n    return df"
  },
  {
    "output": "def process_data(d):\n    if not isinstance(d, list) or any(not isinstance(item, dict) for item in d):\n        raise ValueError(\"Input must be a list of dictionaries\")\n    stats = {}\n    for key in ['x', 'y', 'z']:\n        values = [item[key] for item in d]\n        mean = sum(values) / len(values)\n        sum_val = sum(values)\n        max_val = max(values)\n        min_val = min(values)\n        variance = sum((x - mean)**2 for x in values) / len(values)\n        std_dev = variance**0.5\n        stats[key] = {\n            'mean': mean,\n            'sum': sum_val,\n            'max': max_val,\n            'min': min_val,\n            'std_dev': std_dev\n        }\n    return stats"
  },
  {
    "output": "True"
  },
  {
    "output": "def task_func(X, y):\n    from sklearn.model_selection import train_test_split\n    from tensorflow.keras.models import Sequential\n    from tensorflow.keras.layers import Dense\n    from tensorflow.keras.optimizers import SGD\n    from sklearn.metrics import precision_recall_curve\n    import matplotlib.pyplot as plt\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    model = Sequential()\n    model.add(Dense(10, activation='sigmoid', input_shape=(X.shape[1],)))\n    model.compile(loss='binary_crossentropy', optimizer=SGD(), metrics=['accuracy'])\n    model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n    y_scores = model.predict(X_test)\n    precision, recall, _ = precision_recall_curve(y_test, y_scores)\n    fig, ax = plt.subplots()\n    ax.plot(recall, precision)\n    ax.set_xlabel('Recall')\n    ax.set_ylabel('Precision')\n    return model, ax"
  },
  {
    "output": "def task_func(**kwargs):\n    import os\n    import shutil\n    target_dir = kwargs.get('target_dir', '.')\n    copied_files = []\n    for file_path, source_path in kwargs.items():\n        if os.path.exists(source_path):\n            if os.path.isfile(source_path):\n                shutil.copy2(source_path, target_dir)\n                copied_files.append(os.path.join(target_dir, os.path.basename(source_path)))\n    return copied_files"
  },
  {
    "output": "import random\n\nLETTERS = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n\ndef task_func(n_keys, n_values):\n    n_keys = min(n_keys, len(LETTERS))\n    selected_keys = random.sample(LETTERS, n_keys)\n    values = list(range(1, n_values + 1))\n    result_dict = {key: values for key in selected_keys}\n    return result_dict"
  },
  {
    "output": "import os\nimport requests\nimport zipfile\n\ndef task_func(url, extract_to):\n    zip_path = os.path.join(extract_to, os.path.basename(url))\n    response = requests.get(url)\n    with open(zip_path, 'wb') as f:\n        f.write(response.content)\n    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n        zip_ref.extractall(extract_to)\n    os.remove(zip_path)\n    return extract_to"
  },
  {
    "output": "import matplotlib.pyplot as plt\nimport seaborn as sns\ndef task_func(dataframe, target_value='332'):\n    # Create a Boolean DataFrame indicating the presence of the target value\n    boolean_df = dataframe == target_value\n    \n    # Create a heatmap using seaborn\n    plt.figure(figsize=(10, 8))\n    ax = sns.heatmap(boolean_df, annot=True, cmap='viridis', cbar=False)\n    \n    # Return the tuple\n    return boolean_df, ax"
  },
  {
    "output": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_csv_data(file_path):\n    df = pd.read_csv(file_path)\n    numeric_cols = df.select_dtypes(include=['number']).columns\n    if len(numeric_cols) == 0:\n        raise ValueError(\"No numeric columns found\")\n    scaler = MinMaxScaler()\n    df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n    return df.to_csv(index=False)"
  },
  {
    "output": "from pathlib import Path\nimport zipfile\n\ndef task_func(directory_path):\n    directory = Path(directory_path)\n    if not directory.exists():\n        raise FileNotFoundError\n    files = list(directory.iterdir())\n    if not any(file.is_file() for file in files):\n        return None\n    zip_path = directory / f\"{directory.name}.zip\"\n    with zipfile.ZipFile(zip_path, 'w') as zipf:\n        for file in files:\n            if file.is_file():\n                zipf.write(file, arcname=file.name)\n    return str(zip_path)"
  },
  {
    "output": "import os\nimport sqlite3\nimport pandas as pd\nimport re\n\ndef task_func(database_path, table_name, column_name, regex_pattern):\n    if not os.path.exists(database_path):\n        return pd.DataFrame()\n    conn = sqlite3.connect(database_path)\n    query = f\"SELECT {column_name} FROM {table_name}\"\n    df = pd.read_sql_query(query, conn)\n    conn.close()\n    matches = df[column_name].apply(lambda x: re.findall(regex_pattern, str(x)))\n    matches_df = pd.DataFrame(matches)\n    return matches_df"
  },
  {
    "output": "import binascii\nimport urllib.parse\n\ndef task_func(url):\n    parsed_url = urllib.parse.urlparse(url)\n    query_params = urllib.parse.parse_qs(parsed_url.query)\n    if 'q' in query_params:\n        hex_string = query_params['q'][0]\n        try:\n            decoded_bytes = binascii.unhexlify(hex_string)\n            decoded_str = decoded_bytes.decode('utf-8')\n            return decoded_str\n        except (binascii.Error, UnicodeDecodeError):\n            return None\n    return None"
  },
  {
    "output": "def task_func(param1, param2):\n    return param1 + param2"
  },
  {
    "output": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef fit_and_plot_quadratic(X, Y):\n    X = np.array(X).reshape(-1, 1)\n    Y = np.array(Y)\n    A = np.c_[np.ones(X.shape[0]), X, X**2]\n    params, _ = np.linalg.lstsq(A, Y, rcond=None)\n    x_fit = np.linspace(min(X), max(X), 100)\n    y_fit = params[0] + params[1] * x_fit + params[2] * x_fit**2\n    fig, ax = plt.subplots()\n    ax.scatter(X, Y, color='blue')\n    ax.plot(x_fit, y_fit, color='red')\n    return params, ax"
  },
  {
    "output": "def download_and_extract_zip(url, extract_to):\n    import os\n    import requests\n    import zipfile\n    response = requests.get(url)\n    response.raise_for_status()\n    zip_path = os.path.join(extract_to, \"downloaded_file.zip\")\n    with open(zip_path, 'wb') as f:\n        f.write(response.content)\n    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n        zip_ref.extractall(extract_to)\n    extracted_files = [os.path.join(extract_to, f) for f in zip_ref.namelist()]\n    os.remove(zip_path)\n    return extracted_files"
  },
  {
    "output": "def find_latest_log_file(directory, pattern):\n    import re\n    import os\n    files = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n    regex = re.compile(pattern)\n    matches = [f for f in files if regex.search(f)]\n    if not matches:\n        return None\n    latest = max(matches, key=lambda x: os.path.getmtime(os.path.join(directory, x)))\n    return os.path.join(directory, latest)"
  },
  {
    "output": "import subprocess\nimport random\n\nSCRIPTS = ['script1.sh', 'script2.sh', 'script3.sh']\nSCRIPTS_DIR = '/path/to/scripts'  \n\ndef task_func():\n    selected_script = random.choice(SCRIPTS)\n    full_path = f\"{SCRIPTS_DIR}/{selected_script}\"\n    subprocess.run([full_path], check=True)\n    return full_path"
  },
  {
    "output": "from collections import Counter\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk import ngrams\n\ndef task_func(text, n=2):\n    text = re.sub(r'\\W+', ' ', text).lower()\n    stop_words = set(stopwords.words('english'))\n    words = [word for word in text.split() if word not in stop_words]\n    grams = ngrams(words, n)\n    return dict(Counter(grams))"
  },
  {
    "output": "import numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\ndef task_func(X, y):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    mse = mean_squared_error(y_test, y_pred)\n    return mse"
  },
  {
    "output": "def task_func(db_path, users, salt):\n    import sqlite3\n    import hashlib\n    conn = sqlite3.connect(db_path)\n    cursor = conn.cursor()\n    updated_count = 0\n    for user in users:\n        if not isinstance(salt, str):\n            raise TypeError(\"Salt must be a string\")\n        hashed_password = hashlib.sha256(salt.encode() + user['password'].encode()).hexdigest()\n        cursor.execute(\"UPDATE user SET password = ? WHERE id = ?\", (hashed_password, user['id']))\n        updated_count += 1\n    conn.commit()\n    conn.close()\n    return updated_count"
  },
  {
    "output": "def calculate_pearson_and_plot(data):\n    import pandas as pd\n    import numpy as np\n    import matplotlib.pyplot as plt\n    df = pd.DataFrame(data)\n    x = df.iloc[:, 0]\n    y = df.iloc[:, 1]\n    mean_x = np.mean(x)\n    mean_y = np.mean(y)\n    numerator = np.sum((x - mean_x) * (y - mean_y))\n    denominator = np.sqrt(np.sum((x - mean_x)**2) * np.sum((y - mean_y)**2))\n    pearson = numerator / denominator\n    plt.scatter(x, y)\n    m, b = np.polyfit(x, y, 1)\n    plt.plot(x, m*x + b, color='red')\n    plt.xlabel('X')\n    plt.ylabel('Y')\n    plt.title('Scatter plot with regression line')\n    plt.show()\n    return pearson"
  },
  {
    "output": "def task_func(df):\n    pca = PCA(n_components=2)\n    df_pca = pca.fit_transform(df)\n    df_pca = pd.DataFrame(df_pca, columns=['PC1', 'PC2'])\n    return df_pca"
  },
  {
    "output": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef process_dataframe(df):\n    df['row_average'] = df.mean(axis=1)\n    df.plot(x=range(len(df)), y='row_average', kind='line')\n    plt.show()"
  },
  {
    "output": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(df, bins=20):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input is not a DataFrame\")\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n    \n    last_column = df.columns[-1]\n    ax = df[last_column].plot(kind='hist', bins=bins)\n    ax.set_title(f'Histogram of {last_column}')\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Frequency')\n    return ax"
  },
  {
    "output": "```python\nimport pandas as pd\nimport os\nimport numpy as np\nimport ast\n\ndef task_func(directory):\n    # Check if directory exists\n    if not os.path.exists(directory):\n        return pd.DataFrame(columns=['email', 'list', 'sum', 'mean', 'median']), None\n    \n    # Traverse directory for CSV files\n    csv_files = [f for f in os.listdir(directory) if f.endswith('.csv')]\n    \n    # If no CSV files, return empty DataFrame and None\n    if not csv_files:\n        return pd.DataFrame(columns=['email', 'list', 'sum', 'mean', 'median']), None\n    \n    # Find CSV file with the longest filename\n    longest_file = max(csv_files, key=lambda x: len(x))\n    file_path = os.path.join(directory, longest_file)\n    \n    #"
  },
  {
    "output": "import matplotlib.pyplot as plt\nfrom collections import Counter\n\nFRUITS = ['Apple', 'Banana', 'Cherry', 'Date', 'Elderberry', 'Fig', 'Grape', 'Honeydew', 'Indian Prune', 'Jackfruit']\n\ndef task_func(fruit_dict):\n    fruit_counts = Counter(fruit_dict.values())\n    fruits = list(fruit_counts.keys())\n    counts = list(fruit_counts.values())\n    fig, ax = plt.subplots()\n    ax.bar(fruits, counts)\n    ax.set_xlabel('Fruit')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Fruit Frequency')\n    return fruit_counts, ax"
  },
  {
    "output": "import pandas as pd\nimport os\n\nOUTPUT_DIR = './output'\n\ndef task_func(df, filename, output_dir=OUTPUT_DIR):\n    os.makedirs(output_dir, exist_ok=True)\n    file_path = os.path.join(output_dir, filename)\n    df.to_json(file_path, orient='records')\n    return file_path"
  },
  {
    "output": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef generate_exponential_values(start, end, step):\n    for x in np.arange(start, end, step):\n        yield (x, np.exp(x))\n\ndef plot_exponential_function(values):\n    xs, es = zip(*values)\n    plt.plot(xs, es)\n    plt.xlabel('x')\n    plt.ylabel('e^x')\n    plt.title('Exponential Function')\n    plt.grid(True)\n    plt.show()"
  },
  {
    "output": "import pandas as pd\nimport random\n\ndef task_func(product_list, categories, min_value=10, max_value=100):\n    data = []\n    for product in product_list:\n        category = random.choice(categories)\n        quantity_sold = random.randint(min_value, max_value)\n        revenue = quantity_sold * random.randint(min_value, max_value)\n        data.append({\n            'Product': product,\n            'Category': category,\n            'Quantity Sold': quantity_sold,\n            'Revenue': revenue,\n            'Total Revenue': revenue\n        })\n    df = pd.DataFrame(data)\n    return df"
  },
  {
    "output": "def task_func(text):\n    from textblob import TextBlob\n    from nltk.corpus import stopwords\n    from nltk.tokenize import word_tokenize\n    import re\n\n    stop_words = set(stopwords.words('english'))\n    words = word_tokenize(text.lower())\n    filtered = [word for word in words if word.isalpha() and word not in stop_words]\n    cleaned_text = ' '.join(filtered)\n    return TextBlob(cleaned_text).sentiment.polarity"
  },
  {
    "output": "from scipy import fftpack\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\ndef task_func(arr):\n    row_sums = np.sum(arr, axis=1)\n    fft_coefficients = fftpack.fft(row_sums)\n    abs_fft = np.abs(fft_coefficients)\n    fig, ax = plt.subplots()\n    ax.plot(abs_fft)\n    ax.set_title(\"Absolute Values of FFT Coefficients\")\n    ax.set_xlabel(\"Frequency\")\n    ax.set_ylabel(\"Magnitude\")\n    return ax"
  },
  {
    "output": "```python\nimport pandas as pd\nfrom scipy.stats import skew\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame) or df.shape[1] == 0:\n        raise ValueError(\"Input is not a DataFrame or has no columns.\")\n    last_column = df.iloc[:, -1]\n    return float(skew(last_column))\n```"
  },
  {
    "output": "import pandas as pd\n\ndef process_json_data(input_file, output_file, key_to_remove):\n    df = pd.read_json(input_file, orient='records')\n    df = df.drop(columns=[key_to_remove], errors='ignore')\n    df.to_json(output_file, orient='records', indent=4)"
  },
  {
    "output": "```python\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Constants\nCOLORS = ['r', 'g', 'b']\n\ndef task_func(df, group_col, value_col):\n    # Check if the value column contains non-numeric values\n    if not pd.api.types.is_numeric_dtype(df[value_col]):\n        raise TypeError(\""
  },
  {
    "output": "def task_func(url):\n    urllib.request.urlretrieve(url, 'downloaded_file.txt')\n    with open('downloaded_file.txt', 'r') as file:\n        content = file.read()\n    occurrences = len(re.findall(r'\\bERROR\\b', content))\n    print(occurrences)\n    os.remove('downloaded_file.txt')\n    return occurrences"
  },
  {
    "output": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef create_dataframe_and_scatter_plot(data):\n    df = pd.DataFrame(data)\n    plt.scatter(df.iloc[:, 0], df.iloc[:, 1])\n    plt.show()"
  },
  {
    "output": "def task_func(data, letter):\n    df = pd.DataFrame(data)\n    filtered_names = df[df['Name'].str.startswith(letter)]['Name']\n    return filtered_names"
  },
  {
    "output": "def task_func(T1, row_num, seed):\n    import pandas as pd\n    import numpy as np\n    np.random.seed(seed)\n    col_num = sum(int(x) for x in T1)\n    data = np.random.rand(row_num, col_num)\n    return pd.DataFrame(data)"
  },
  {
    "output": "```python\nimport pandas as pd\nfrom datetime import datetime, timedelta\nfrom random import randint, seed as random_seed\nfrom dateutil.relativedelta import relativedelta\n\ndef task_func(start_date=datetime(2020, 1, 1), end_date=datetime(2020, 12, 31), seed=42):\n    # Input validation\n    if not isinstance(start_date, datetime) or not isinstance(end_date, datetime):\n        raise ValueError(\"start_date and end_date must be datetime.datetime objects\")\n    if start_date > end_date:\n        raise ValueError(\"start_date cannot be later than end_date\")\n    \n    # Calculate the number of days in the range\n    num_days = relativedelta(end_date, start_date).days + 1\n    \n    # Set seed for reproducibility\n    random_seed(seed)\n    \n    # Generate random dates\n    random_dates = []\n    for _ in range(num_days):\n        # Generate a random number of days between 0 and num_days - 1"
  },
  {
    "output": "def task_func():\n    return \"Hello, world!\""
  },
  {
    "output": "def task_func(df):\n    if df.empty or not all(col in df.columns for col in ['A', 'B', 'C']) or not all(df[col].dtype.kind in 'fci' for col in ['A', 'B', 'C']):\n        return None\n    filtered = df[(df['B'] > 50) & (df['C'] == 900)]\n    if filtered.empty:\n        return None\n    from sklearn.model_selection import train_test_split\n    from sklearn.linear_model import LinearRegression\n    X, y = filtered[['A']], filtered['B']\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    model = LinearRegression().fit(X_train, y_train)\n    predictions = model.predict(X_test)\n    return predictions, model"
  },
  {
    "output": "```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(df, letters=list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')):\n    # Check if the input is a DataFrame\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"If 'df' is not a DataFrame or lacks the 'Letters' column.\")\n    # Check if the 'Letters' column exists\n    if 'Letters' not in df.columns:\n        raise ValueError(\"If 'df' is not a DataFrame or lacks the 'Letters' column.\")\n    \n    # Count the frequency of each letter\n    letter_counts = df['Letters'].value_counts()\n    \n    # Create a bar chart\n    fig, ax = plt.subplots()\n    letter_counts.plot(kind='bar', ax=ax)\n    \n    # Set labels and title\n    ax.set_xlabel('Letters')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Letter Frequency')\n    \n    #"
  },
  {
    "output": "from itertools import chain\nimport numpy as np\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\ndef task_func(L):\n    data = list(chain.from_iterable(L))\n    data_array = np.array(data).reshape(-1, 1)\n    kmeans = KMeans(n_clusters=3, random_state=0).fit(data_array)\n    labels = kmeans.labels_\n    fig, ax = plt.subplots()\n    ax.scatter(data_array, np.zeros_like(data_array), c=labels, cmap='viridis', s=10)\n    return ax"
  },
  {
    "output": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func():\n    x = np.linspace(0, 2*np.pi, 1000)\n    sin_x = np.sin(x)\n    cos_x = np.cos(x)\n    abs_diff = np.abs(sin_x - cos_x)\n    sequence = list(zip(x, sin_x, cos_x, abs_diff))\n    plt.plot(x, sin_x, label='sin(x)')\n    plt.plot(x, cos_x, label='cos(x)')\n    plt.legend()\n    fft_abs_diff = np.fft.fft(abs_diff)\n    mean_fft = np.mean(np.abs(fft_abs_diff))\n    median_fft = np.median(np.abs(fft_abs_diff))\n    return mean_fft, median_fft, sequence"
  },
  {
    "output": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom random import randint\n\ndef task_func(num_types=5, integer_range=(0, 100)):\n    data = {f'Type {i+1}': [randint(*integer_range) for _ in range(num_types)] for i in range(num_types)}\n    df = pd.DataFrame(data)\n    fig, ax = plt.subplots()\n    df.plot(kind='barh', stacked=True, ax=ax)\n    ax.set_xlabel('Values')\n    ax.set_ylabel('Categories')\n    ax.set_title('Horizontal Stacked Bar Chart')\n    return (fig, ax)"
  },
  {
    "output": "def remove_urls_and_count(text, n):\n    import re\n    from collections import Counter\n    text = re.sub(r'http\\S+', '', text)\n    words = re.findall(r'\\b\\w+\\b', text.lower())\n    counts = Counter(words)\n    return counts.most_common(n)"
  },
  {
    "output": "import xlwt\nimport os\n\ndef task_func(values, filename):\n    workbook = xlwt.Workbook()\n    worksheet = workbook.add_sheet('Sheet1')\n    for i, field in enumerate(['ID', 'Name', 'Age']):\n        worksheet.write(0, i, field)\n    for i, row in enumerate(values):\n        for j, key in enumerate(['ID', 'Name', 'Age']):\n            worksheet.write(i + 1, j, row.get(key, ''))\n    path = os.path.abspath(filename)\n    workbook.save(path)\n    return path"
  },
  {
    "output": "import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef task_func(num_samples=100, num_features=5):\n    np.random.seed(42)\n    data = np.random.rand(num_samples, num_features)\n    df = pd.DataFrame(data, columns=[f'Feature_{i+1}' for i in range(num_features)])\n    corr = df.corr()\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\")\n    plt.title('Correlation Matrix Heatmap')\n    plt.show()\n    return df, plt.gca()"
  },
  {
    "output": "def task_func(L):\n    import numpy as np\n    from collections import Counter\n    import matplotlib.pyplot as plt\n\n    mean = np.mean(L)\n    median = np.median(L)\n    counter = Counter(L)\n    mode = counter.most_common(1)[0][0]\n    std_dev = np.std(L)\n    fig, ax = plt.subplots()\n    ax.hist(L, bins=10, edgecolor='black')\n    return {\n        'mean': mean,\n        'median': median,\n        'mode': mode,\n        'std_dev': std_dev,\n        'plot': ax\n    }"
  },
  {
    "output": "def inspect_function(f):\n    import inspect\n    import types\n    result = {}\n    result['name'] = f.__name__\n    result['is_lambda'] = isinstance(f, types.LambdaType)\n    signature = inspect.signature(f)\n    result['arguments'] = []\n    for name, param in signature.parameters.items():\n        arg_info = {\n            'name': name,\n            'default': param.default if param.default is not inspect.Parameter.empty else None,\n            'annotation': param.annotation if param.annotation is not inspect.Parameter.empty else None\n        }\n        result['arguments'].append(arg_info)\n    return result"
  },
  {
    "output": "def process_log_file(log_file_path, output_csv_path):\n    import csv\n    import re\n    from datetime import datetime\n    \n    valid_entries = []\n    with open(log_file_path, 'r') as file:\n        for line in file:\n            match = re.match(r'(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}),(.*)', line.strip())\n            if match:\n                timestamp_str, message = match.groups()\n                try:\n                    timestamp = datetime.strptime(timestamp_str, '%Y-%m-%d %H:%M:%S')\n                    valid_entries.append((timestamp, message))\n                except ValueError:\n                    pass\n    if not valid_entries:\n        raise ValueError(\"No valid log entries found\")\n    with open(output_csv_path, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerow(['Timestamp', 'Message'])\n        for timestamp, message in valid_entries:\n            writer.writerow([timestamp, message])"
  },
  {
    "output": "```python\nimport pandas as pd\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\ndef task_func(df, n_clusters=3, random_state=0):\n    # Check if the DataFrame is empty or lacks required columns\n    if df.empty or 'date' not in df.columns or 'value' not in df.columns:\n        raise ValueError(\"DataFrame is empty or lacks required columns.\")\n    \n    # Convert 'date' to datetime\n    df['date'] = pd.to_datetime(df['date'])\n    \n    # Convert to ordinal (number of days since 0001-01-01)\n    df['date_ordinal'] = df['date'].dt.toordinal\n    \n    # Prepare the data for clustering\n    X"
  },
  {
    "output": "import mechanize\nfrom bs4 import BeautifulSoup\n\ndef task_func(url, form_id, data):\n    br = mechanize.Browser()\n    br.open(url)\n    br.select_form(nr=0)\n    br.form['form_id'] = form_id\n    br.form.set_all_readonly(False)\n    br.form['data'] = data\n    response = br.submit()\n    soup = BeautifulSoup(response.read(), 'html.parser')\n    title = soup.find('title')\n    return title.get_text() if title else 'No Title'"
  },
  {
    "output": "plt.figure(figsize=(10, 6))\nplt.plot(df['Date'], df['Sales'], marker='o', linestyle='-')\nplt.title('Daily Turnover Line Chart')\nplt.xlabel('Date')\nplt.ylabel('Sales')\nplt.grid(True)\nreturn plt.gca()"
  },
  {
    "output": "plt.plot(history.history['val_loss'])\nplt.title('Training and Validation Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper right')\nplt.show()"
  },
  {
    "output": "from sklearn.preprocessing import MinMaxScaler\n\ndef task_func(my_dict):\n    if 'array' not in my_dict or not isinstance(my_dict['array'], (list, tuple, np.ndarray)):\n        raise TypeError(\"The 'array' key is missing or not a valid array type.\")\n    arr = my_dict['array']\n    if isinstance(arr, (list, tuple)):\n        arr = np.array(arr)\n    scaler = MinMaxScaler()\n    normalized = scaler.fit_transform(arr.reshape(-1, 1)).flatten()\n    my_dict['normalized_array'] = normalized\n    return my_dict"
  },
  {
    "output": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(data_str, separator=\",\", bins=20):\n    try:\n        data_list = list(map(int, data_str.split(separator)))\n        if not data_list:\n            raise ValueError(\"Data is empty.\")\n        series = pd.Series(data_list, dtype=np.int64)\n        fig, ax = plt.subplots()\n        ax.hist(series, bins=bins, color='#607c8e', rwidth=0.9, grid=True)\n        return (series, ax)\n    except ValueError as e:\n        raise ValueError(\"Failed to convert data or data is empty.\") from e"
  },
  {
    "output": "from scipy import stats\nimport matplotlib.pyplot as plt\n\ndef task_func(data_dict, data_keys):\n    x = data_dict[data_keys[0]]\n    y = data_dict[data_keys[1]]\n    correlation_coefficient = stats.pearsonr(x, y)[0]\n    plt.figure(figsize=(8, 6))\n    plt.scatter(x, y, alpha=0.6)\n    plt.xlabel(data_keys[0])\n    plt.ylabel(data_keys[1])\n    plt.title(f'Scatter Plot of {data_keys[0]} vs {data_keys[1]}')\n    return (correlation_coefficient, plt.gca())"
  },
  {
    "output": "import random\n\ndef generate_palindrome_sentence(word_pool, MIN_WORDS, MAX_WORDS):\n    length = random.randint(MIN_WORDS, MAX_WORDS)\n    if length % 2 == 0:\n        first_half = [random.choice(word_pool) for _ in range(length // 2)]\n        second_half = first_half[::-1]\n    else:\n        first_half = [random.choice(word_pool) for _ in range((length - 1) // 2)]\n        middle = [random.choice(word_pool)]\n        second_half = first_half[::-1]\n    sentence = ' '.join(first_half + middle + second_half)\n    return sentence"
  },
  {
    "output": "def task_func(my_obj):\n    return json.dumps(my_obj, cls=CustomJSONEncoder)"
  },
  {
    "output": "def scale_and_plot(data_dict):\n    import pandas as pd\n    import numpy as np\n    import matplotlib.pyplot as plt\n    from sklearn.preprocessing import MinMaxScaler\n\n    df = pd.DataFrame(data_dict)\n    scaler = MinMaxScaler()\n    scaled_data = scaler.fit_transform(df)\n    scaled_df = pd.DataFrame(scaled_data, columns=df.columns)\n    fig, ax = plt.subplots()\n    scaled_df.plot(ax=ax)\n    return scaled_df, ax"
  },
  {
    "output": "import pandas as pd\nimport random\n\ndef process_strings(strings):\n    modified = []\n    for s in strings:\n        if ',' in s:\n            parts = s.split(',')\n            random_index = random.randint(0, len(parts)-1)\n            modified_str = ','.join(parts[:random_index] + parts[random_index+1:])\n            modified.append(modified_str)\n        else:\n            modified.append(s)\n    return pd.DataFrame({'Original': strings, 'Modified': modified})"
  },
  {
    "output": "```python\nfrom sklearn.preprocessing import MinMaxScaler\nimport pandas as pd\n\ndef task_func(l):\n    scaler = MinMaxScaler()\n    scaled_array = scaler.fit_transform(l)\n    df = pd.DataFrame(scaled_array, columns=['Scaled Values'])\n    return df\n```"
  },
  {
    "output": "def scan_logs_for_ip_counts(directory):\n    import os\n    import re\n    ip_count = {}\n    ip_pattern = re.compile(r'\\b(?:[0-9]{1,3}\\.){3}[0-9]{1,3}\\b')\n    for filename in os.listdir(directory):\n        file_path = os.path.join(directory, filename)\n        if os.path.isfile(file_path):\n            with open(file_path, 'r') as file:\n                for line in file:\n                    ips = ip_pattern.findall(line)\n                    for ip in ips:\n                        ip_count[ip] = ip_count.get(ip, 0) + 1\n    return ip_count"
  },
  {
    "output": "def archive_processed_files(source_dir, target_dir, archive_name):\n    import os\n    import shutil\n    processed_files = [f for f in os.listdir(source_dir) if f.endswith('_processed')]\n    if not processed_files:\n        return\n    archive_path = os.path.join(target_dir, archive_name)\n    with shutil.make_archive(archive_path, 'zip', source_dir, processed_files) as _:\n        pass\n    for file in processed_files:\n        os.remove(os.path.join(source_dir, file))"
  },
  {
    "output": "import numpy as np\nfrom itertools import chain\n\ndef task_func(L):\n    flat_list = list(chain.from_iterable(L))\n    arr = np.array(flat_list)\n    mean = np.mean(arr)\n    variance = np.var(arr)\n    return {'mean': mean, 'variance': variance}"
  },
  {
    "output": "def analyze_weather_data(data_column):\n    import matplotlib.pyplot as plt\n    import numpy as np\n    import pandas as pd\n    \n    if not data_column or not isinstance(data_column, pd.Series):\n        return {\n            \"mean\": None,\n            \"median\": None,\n            \"std_dev\": None,\n            \"min\": None,\n            \"max\": None,\n            \"plot\": None\n        }\n    \n    data = data_column.dropna()\n    if data.empty:\n        return {\n            \"mean\": None,\n            \"median\": None,\n            \"std_dev\": None,\n            \"min\": None,\n            \"max\": None,\n            \"plot\": None\n        }\n    \n    mean = np.mean(data)\n    median = np.median(data)\n    std_dev = np.std(data)\n    min_val = data.min()\n    max_val = data.max()\n    \n    plt.figure(figsize=(10, 6))\n    plt.hist(data, bins=20, color='skyblue', edgecolor='black')\n    plt.title('Distribution of Weather Data')\n    plt.xlabel('Value')\n    plt.ylabel('Frequency')\n    plot = plt.gcf()\n    \n    plt.close()\n    \n    return {\n        \"mean\": mean,\n        \"median\": median,\n        \"std_dev\": std_dev,\n        \"min\": min_val,\n        \"max\": max_val,\n        \"plot\": plot\n    }"
  },
  {
    "output": "import pandas as pd\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nimport string\n\ndef task_func(text):\n    sentences = sent_tokenize(text)\n    stop_words = set(stopwords.words('english'))\n    word_counts = {}\n    for sentence in sentences:\n        words = word_tokenize(sentence)\n        words = [word.lower() for word in words if word.isalpha()]\n        for word in words:\n            if word not in stop_words:\n                word_counts[word] = word_counts.get(word, 0) + 1\n    return pd.Series(word_counts)"
  },
  {
    "output": "import os\nimport requests\nimport gzip\nimport tempfile\n\ndef fetch_and_compress_json(url):\n    response = requests.get(url)\n    data = response.json()\n    with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.json.gz') as tmpfile:\n        with gzip.open(tmpfile.name, 'wb') as gzip_file:\n            gzip_file.write(data.encode('utf-8'))\n        return tmpfile.name"
  },
  {
    "output": "def task_func(filepath, destination_dir):\n    import os\n    import shutil\n    import ctypes\n    dll_name = os.path.basename(filepath)\n    dll_path = os.path.abspath(filepath)\n    dll_dir = os.path.dirname(dll_path)\n    dll_files = [f for f in os.listdir(dll_dir) if f.endswith('.dll')]\n    for dll_file in dll_files:\n        src = os.path.join(dll_dir, dll_file)\n        dst = os.path.join(destination_dir, dll_file)\n        shutil.move(src, dst)\n    dll_handle = ctypes.windll.LoadLibrary(dll_path)\n    return dll_name"
  },
  {
    "output": "def task_func(source_file, backup_dir):\n    import os\n    import shutil\n    import subprocess\n    if not os.path.exists(source_file):\n        return -1\n    try:\n        backup_path = os.path.join(backup_dir, os.path.basename(source_file))\n        shutil.copy2(source_file, backup_path)\n        result = subprocess.run([source_file], capture_output=True, text=True)\n        return result.returncode\n    except Exception:\n        return -1"
  },
  {
    "output": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(df, age, weight):\n    required_columns = ['Age', 'Weight']\n    if not all(col in df.columns for col in required_columns):\n        return pd.DataFrame()\n    filtered_df = df[(df['Age'] == age) & (df['Weight'] == weight)]\n    if filtered_df.empty:\n        return pd.DataFrame()\n    scaler = StandardScaler()\n    scaled_values = scaler.fit_transform(filtered_df)\n    return pd.DataFrame(scaled_values, columns=filtered_df.columns)"
  },
  {
    "output": "ax.set_yticks([0, 1])\nplt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\")\nplt.setp(ax.get_yticklabels(), rotation=45, ha=\"right\")\nax.set_xticklabels(['', ''], fontsize=12)\nax.set_yticklabels(['', ''], fontsize=12)\nax.set_title(\"Confusion matrix\", fontsize=12)\nfig.tight_layout()\nreturn cm, ax"
  },
  {
    "output": "def task_func():\n    return \"Hello, World!\""
  },
  {
    "output": "import ipaddress\nimport requests\nfrom requests.exceptions import ConnectionError, Timeout\n\ndef task_func(ip_range, timeout):\n    try:\n        network = ipaddress.ip_network(ip_range, strict=False)\n    except ValueError:\n        raise ValueError(\"Invalid IP range\")\n    \n    active_servers = []\n    \n    for ip in network.hosts():\n        ip_str = str(ip)\n        try:\n            response = requests.get(f\"http://{ip_str}\", timeout=timeout)\n            if response.status_code == 200:\n                active_servers.append(ip_str)\n        except (ConnectionError, Timeout):\n            continue\n    \n    return active_servers"
  },
  {
    "output": "def task_func(hex_keys=KEYS):\n    hex_str = random.choice(hex_keys)\n    ascii_bytes = bytes.fromhex(hex_str)\n    ascii_str = ascii_bytes.decode('ascii')\n    try:\n        float_num = float(ascii_str)\n    except ValueError:\n        float_num = random.uniform(0.0, 100.0)\n    float_str = str(float_num)\n    utf8_bytes = float_str.encode('utf-8')\n    return utf8_bytes"
  },
  {
    "output": "import pandas as pd\nfrom collections import Counter\n\ndef task_func(data):\n    required_keys = {'Name', 'Age', 'Scores'}\n    if not required_keys.issubset(data.keys()):\n        raise ValueError(\"The dictionary does not have the required keys.\")\n    df = pd.DataFrame(data)\n    df_sorted = df.sort_values(by=['Name', 'Age'])\n    avg_scores = df.groupby('Name')['Scores'].mean()\n    most_common_age = df_sorted['Age'].mode()[0] if not df_sorted.empty else None\n    return df_sorted, avg_scores, most_common_age"
  },
  {
    "output": "color='purple', linestyle='--', label=f'Std Dev: {std_dev:.2f}')\n    ax.legend()\n    \n    # Save the plot as a PNG file\n    plt.savefig('random_histogram.png')\n    plt.close()"
  },
  {
    "output": "def task_func(directory, zip_filename):\n    import os\n    import zipfile\n    from Crypto.PublicKey import RSA\n    from Crypto.Cipher import PKCS1_OAEP\n    from Crypto.Random import get_random_bytes\n    import base64\n    \n    key = RSA.generate(2048)\n    public_key = key.publickey()\n    \n    encrypted_files = []\n    \n    for filename in os.listdir(directory):\n        file_path = os.path.join(directory, filename)\n        if os.path.isfile(file_path):\n            with open(file_path, 'rb') as f:\n                data = f.read()\n            cipher = PKCS1_OAEP.new(public_key)\n            encrypted_data = cipher.encrypt(data)\n            encrypted_filename = f\"encrypted_{filename}\"\n            with open(encrypted_filename, 'wb') as f:\n                f.write(encrypted_data)\n            encrypted_files.append(encrypted_filename)\n    \n    with zipfile.ZipFile(zip_filename, 'w') as zipf:\n        for file in encrypted_files:\n            zipf.write(file)\n    \n    os.makedirs('encrypted_files', exist_ok=True)\n    for file in encrypted_files:\n        os.rename(file, os.path.join('encrypted_files', file))\n    \n    return public_key, zip_filename"
  },
  {
    "output": "def merge_and_encode(lists):\n    import numpy as np\n    from sklearn.preprocessing import OneHotEncoder\n    merged = [item for sublist in lists for item in sublist]\n    encoder = OneHotEncoder(sparse_output=False)\n    encoded = encoder.fit_transform(np.array(merged).reshape(-1, 1))\n    return encoded.flatten().tolist()"
  },
  {
    "output": "import pandas as pd\nimport requests\nfrom io import StringIO\n\ndef task_func(csv_url, sort_by_column=\"title\"):\n    response = requests.get(csv_url)\n    if response.status_code != 200:\n        raise Exception(\"Failed to fetch data\")\n    df = pd.read_csv(StringIO(response.text))\n    df_sorted = df.sort_values(by=sort_by_column)\n    return df_sorted"
  },
  {
    "output": "def make_https_get_request(server, path):\n    import socket\n    import ssl\n    import urllib.parse\n    import http.client\n\n    url = urllib.parse.urlunsplit(['https', server, path, '', ''])\n    try:\n        conn = http.client.HTTPSConnection(server)\n        conn.request(\"GET\", path)\n        response = conn.getresponse()\n        return response.read().decode('utf-8')\n    except (socket.error, ssl.SSLError, http.client.HTTPException) as e:\n        return str(e)"
  },
  {
    "output": "def task_func(latin_names, other_names, start_date, end_date, email_domain):\n    import pandas as pd\n    import numpy as np\n    np.random.seed(42)\n    ids = np.random.randint(1, 101, size=100)\n    names = np.random.choice(latin_names + other_names, size=100)\n    names = [name.replace('ç', 'c').replace('ñ', 'n').replace('ö', 'o') for name in names]\n    dob = pd.date_range(start=start_date, end=end_date, freq='D').tolist()\n    dob = np.random.choice(dob, size=100)\n    years = dob.apply(lambda x: x.year).values\n    emails = np.array([f\"{name}.{year}@{email_domain}\" for name, year in zip(names, years)])\n    df = pd.DataFrame({\n        'ID': ids,\n        'Name': names,\n        'Date of Birth': dob,\n        'Email': emails\n    })\n    return df"
  },
  {
    "output": ", alpha=0.6)\n    plt.title('KMeans Clustering Result')\n    plt.xlabel('Index')\n    plt.ylabel('Value')\n    plt.colorbar()\n    return flattened_data, plt.gca()"
  },
  {
    "output": "```python\nfrom random import randint, seed\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Constants (they can be overridden with default parameters)\nTEAMS = ['Team A', 'Team B', 'Team C', 'Team D', 'Team E']\nPENALTY_COST = 1000  # in dollars\n\ndef task_func(goals, penalties, teams=TEAMS, penalty_cost=PENALTY_COST, rng_seed=None):\n    # Set random seed for reproducibility\n    if rng_seed is not None:\n        seed(rng_seed)\n    \n    # Generate random data for teams\n    if teams is None:\n        teams = TEAMS\n    if goals is None:\n        goals = [randint(0, 10) for _ in range(len(teams))]\n    if penalties is None:\n        penalties = [randint(0, 5) for _ in range(len(teams))]"
  },
  {
    "output": "def task_func(df):\n    if len(df) < 2:\n        return float('nan')\n    scores = df['scores'].astype(float)\n    grades = df['grades'].str.replace('A', '4').str.replace('B', '3').str.replace('C', '2').str.replace('D', '1').astype(float)\n    return (scores - scores.mean()) * (grades - grades.mean()).sum() / ( (scores - scores.mean()).pow(2).sum() * (grades - grades.mean()).pow(2).sum() )**0.5"
  },
  {
    "output": "import json\nimport random\nimport os\n\ndef task_func(file_path, seed):\n    random.seed(seed)\n    activity_data = [\n        {\"user\": \"user1\", \"activity\": \"login\", \"timestamp\": random.randint(1000, 9999)},\n        {\"user\": \"user2\", \"activity\": \"logout\", \"timestamp\": random.randint(1000, 9999)},\n        {\"user\": \"user3\", \"activity\": \"click\", \"timestamp\": random.randint(1000, 9999)}\n    ]\n    with open(file_path, 'w') as f:\n        json.dump(activity_data, f)\n    return file_path"
  },
  {
    "output": "def task_func(df):\n    if not isinstance(df, pd.DataFrame) or 'Name' not in df.columns:\n        return \"Invalid input\"\n    unique_names = df['Name'].unique()\n    scores = df[df['Name'].isin(unique_names)]['Score']\n    countries = df[df['Name'].isin(unique_names)]['Country']\n    plt.figure(figsize=(12, 6))\n    plt.hist(scores, bins=10, color='blue', alpha=0.7)\n    plt.title('Histogram of Scores')\n    plt.xlabel('Score')\n    plt.ylabel('Frequency')\n    plt.show()\n    plt.figure(figsize=(12, 6))\n    countries = countries.dropna()\n    scores = scores.loc[countries.index]\n    plt.boxplot([scores[countries == country] for country in countries.unique()], labels=countries.unique())\n    plt.title('Boxplot of Scores by Country')\n    plt.xlabel('Country')\n    plt.ylabel('Score')\n    plt.show()"
  },
  {
    "output": "def task_func(data, columns, target_column):\n    X = data[columns]\n    y = data[target_column]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    model = LogisticRegression()\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    return accuracy"
  },
  {
    "output": "True"
  },
  {
    "output": "def task_func(days_in_past=7):\n    if days_in_past < 0:\n        raise ValueError(\"days_in_past cannot be negative\")\n    today_utc = datetime.now(pytz.utc)\n    past_date = today_utc - timedelta(days=days_in_past)\n    weekday_name = calendar.day_name[past_date.weekday()]\n    return weekday_name"
  },
  {
    "output": "import pandas as pd\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input is not a DataFrame\")\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n    \n    pca = PCA(n_components=2)\n    principal_components = pca.fit_transform(df)\n    \n    pc_df = pd.DataFrame(data=principal_components, columns=['Principal Component 1', 'Principal Component 2'])\n    \n    plt.figure(figsize=(8, 6))\n    plt.scatter(pc_df['Principal Component 1'], pc_df['Principal Component 2'])\n    plt.title('2 Component PCA')\n    plt.xlabel('Principal Component 1')\n    plt.ylabel('Principal Component 2')\n    axes = plt.gca()\n    \n    return pc_df, axes"
  },
  {
    "output": "import sys\nimport sqlite3\n\ndef task_func(path):\n    sys.path.append(path)\n    conn = sqlite3.connect('path.db')\n    c = conn.cursor()\n    c.execute('''CREATE TABLE IF NOT EXISTS paths (path TEXT PRIMARY KEY)''')\n    c.execute(\"SELECT * FROM paths WHERE path = ?\", (path,))\n    if not c.fetchone():\n        c.execute(\"INSERT INTO paths (path) VALUES (?)\", (path,))\n        conn.commit()\n    conn.close()\n    return path"
  },
  {
    "output": "import random\nimport math\n\ndef generate_random_float_from_hex(hex_list):\n    hex_str = random.choice(hex_list)\n    float_val = float.fromhex(hex_str)\n    return round(float_val, 2)"
  },
  {
    "output": "import os\nimport zipfile\n\ndef zip_files_with_extensions(source_dir, target_dir, zip_name, valid_extensions):\n    if not os.path.exists(source_dir):\n        raise OSError(f\"Source directory '{source_dir}' does not exist.\")\n    files = [f for f in os.listdir(source_dir) if os.path.isfile(os.path.join(source_dir, f)) and os.path.splitext(f)[1].lower() in valid_extensions]\n    zip_path = os.path.join(target_dir, zip_name)\n    with zipfile.ZipFile(zip_path, 'w') as zipf:\n        for file in files:\n            file_path = os.path.join(source_dir, file)\n            zipf.write(file_path, os.path.basename(file_path))\n    return zip_path"
  },
  {
    "output": "def generate_random_dataframe(rows, columns):\n    import pandas as pd\n    import numpy as np\n    data = {}\n    for col in columns:\n        if np.random.rand() > 0.5:\n            data[col] = np.random.randint(0, 100, size=rows)\n        else:\n            data[col] = np.random.choice(['low', 'medium', 'high'], size=rows)\n    return pd.DataFrame(data)"
  },
  {
    "output": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(d, target='y'):\n    X = [[item['x'], item['z']] for item in d]\n    y = [item[target] for item in d]\n    model = LinearRegression()\n    model.fit(X, y)\n    return model"
  },
  {
    "output": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import gaussian_kde\n\ndef generate_and_plot_gaussian_kde(mean, std_dev, sample_size):\n    np.random.seed(42)\n    data = np.random.normal(mean, std_dev, sample_size)\n    kde = gaussian_kde(data)\n    x = np.linspace(data.min(), data.max(), 1000)\n    y = kde(x)\n    fig, ax = plt.subplots()\n    ax.plot(x, y)\n    return ax"
  },
  {
    "output": "def task_func(text):\n    import nltk\n    from nltk.corpus import stopwords\n    import numpy as np\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    nltk.download('stopwords')\n    stop_words = set(stopwords.words('english'))\n    words = text.split()\n    words = [word for word in words if word not in stop_words]\n    unique_words = []\n    prev = None\n    for word in words:\n        if word != prev:\n            unique_words.append(word)\n        prev = word\n    word_to_index = {word: i for i, word in enumerate(unique_words)}\n    n = len(unique_words)\n    co_occurrence = np.zeros((n, n), dtype=int)\n    for i in range(len(unique_words) - 1):\n        current = unique_words[i]\n        next_word = unique_words[i + 1]\n        co_occurrence[word_to_index[current], word_to_index[next_word]] += 1\n    df = pd.DataFrame(co_occurrence, index=unique_words, columns=unique_words)\n    plt.figure(figsize=(10, 10))\n    plt.imshow(df, cmap='viridis', interpolation='nearest')\n    plt.colorbar()\n    plt.title('Co-occurrence Matrix')\n    plt.xlabel('Words')\n    plt.ylabel('Words')\n    plot_obj = plt.gcf()\n    return (df, plot_obj)"
  },
  {
    "output": "feast object e from object d"
  },
  {
    "output": "def next_action(): return 'pick up the red block'"
  },
  {
    "output": "Please provide the complete initial conditions to proceed."
  },
  {
    "output": "False"
  },
  {
    "output": "Use hoist1 to lift crate0 from pallet1 at depot1."
  },
  {
    "output": "feast object d from object"
  },
  {
    "output": ""
  },
  {
    "output": "The first step is valid."
  },
  {
    "output": "False"
  },
  {
    "output": "Feast object b from object a"
  },
  {
    "output": "def next_step():\n    return \"Pick up the blue block\""
  },
  {
    "output": "load package_0 into airplane_0 at location_2_0"
  },
  {
    "output": ""
  },
  {
    "output": "pick up the white"
  },
  {
    "output": "def next_step(): return 'unstack the orange block from the table'"
  },
  {
    "output": "unstack the red block from on top of the yellow block"
  },
  {
    "output": "unstack the yellow block from on top of the red block"
  },
  {
    "output": ""
  },
  {
    "output": "def next_action():\n    return \"Pick up the orange block\""
  },
  {
    "output": "Use hoist1 to lift crate2 from pallet2 at depot1."
  },
  {
    "output": "Drive truck0 from depot1 to depot2"
  },
  {
    "output": ""
  },
  {
    "output": "def simulate_plan(initial_conditions, plan, rules):\n    state = initial_conditions.copy()\n    for action in plan:\n        if action in rules:\n            state = rules[action](state)\n        else:\n            raise ValueError(f\"Unknown action: {action}\")\n    return state == desired_outcome(state)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "def next_action(): return 'pick up the blue block'"
  },
  {
    "output": ""
  },
  {
    "output": "unstack the orange block from on top of the red block"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Feast object d from object a."
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "\"Use hoist1 to lift crate0 from pallet1 at depot1\""
  },
  {
    "output": ""
  },
  {
    "output": "def execute_action():\n    return \"Feast object c from object b\""
  },
  {
    "output": ""
  },
  {
    "output": "def feast_object_a_from_object_c(): return 'Feast object a from object c'"
  },
  {
    "output": "Use hoist3 to lift crate0 from pallet3 at distributor0."
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "I will evaluate the plan step-by-step to determine if it can achieve the desired outcome."
  },
  {
    "output": ""
  },
  {
    "output": "unstack the yellow block from on top of the blue block"
  },
  {
    "output": "Insufficient information to proceed."
  },
  {
    "output": ""
  },
  {
    "output": "Use hoist1 to lift crate1 from pallet1 at depot1."
  },
  {
    "output": "Please provide the complete plan to evaluate its feasibility."
  },
  {
    "output": ""
  },
  {
    "output": "The current state is not fully described, and the next action cannot be determined without further information."
  },
  {
    "output": "Attack object"
  },
  {
    "output": "pick up the blue block"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "feast object a from object d"
  },
  {
    "output": "True"
  },
  {
    "output": "pick up the yellow block"
  },
  {
    "output": "def feast_action(): return 'Feast action performed'"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "False"
  },
  {
    "output": "\"Pick up the red block.\""
  },
  {
    "output": "def next_action(): return 'Feast object b from object a'"
  },
  {
    "output": "The plan is not provided, so I cannot determine the next action."
  },
  {
    "output": "Adjust the plan to include the movement of package_0 using truck_1 and ensure that the movement of package_1 is correctly executed using airplane_1 and truck_2."
  },
  {
    "output": "unstack the red block from on top of the orange block"
  },
  {
    "output": ""
  },
  {
    "output": "20"
  },
  {
    "output": ""
  },
  {
    "output": "Please provide the complete list of initial conditions."
  },
  {
    "output": "True"
  },
  {
    "output": "pick up the red block"
  },
  {
    "output": ""
  },
  {
    "output": "unstack the orange block from on top of the blue block"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Please provide the complete current state of the system to proceed with evaluating the plan."
  },
  {
    "output": ""
  },
  {
    "output": "def solve():\n    return \"plan\""
  },
  {
    "output": "def next_action():\n    return \"Pick up the red block and stack it under the yellow block.\""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Please provide the plan or the next action you want to take."
  },
  {
    "output": "feast object b from object d"
  },
  {
    "output": "The plan cannot be evaluated for validity without the initial conditions, rules, and the actual plan."
  },
  {
    "output": "Please provide the complete plan for evaluation."
  },
  {
    "output": "Feast object a from object"
  },
  {
    "output": ""
  },
  {
    "output": "Insufficient information to determine next step."
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "unstack the blue block from on top of the orange block"
  },
  {
    "output": ""
  },
  {
    "output": "def simulate_actions(state):\n    if not state:\n        return False\n    actions = [\n        ('move', 'A', 'B'),\n        ('rotate', 'B', 'C'),\n        ('check', 'C', 'D'),\n        ('activate', 'D', 'E')\n    ]\n    for action in actions:\n        if action[0] == 'move':\n            if state[action[1]] != 'free':\n                return False\n            state[action[2]] = state[action[1]]\n            state[action[1]] = 'free'\n        elif action[0] == 'rotate':\n            if state[action[1]] != 'rotatable':\n                return False\n            state[action[2]] = state[action[1]]\n            state[action[1]] = 'free'\n        elif action[0] == 'check':\n            if state[action[1]] != 'checked':\n                return False\n            state[action[2]] = state[action[1]]\n            state[action[1]] = 'free'\n        elif action[0] == 'activate':\n            if state[action[1]] != 'active':\n                return False\n            state[action[2]] = state[action[1]]\n            state[action[1]] = 'free'\n    return True"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Attack object b"
  },
  {
    "output": "Step 1: Evaluate the initial conditions and the plan to determine the next action."
  },
  {
    "output": ""
  },
  {
    "output": "False"
  },
  {
    "output": ""
  },
  {
    "output": "python_code_returner(\"Next action: Use hoist1 to lift crate1 from crate0 at depot1\")"
  },
  {
    "output": ""
  },
  {
    "output": "Use hoist3 to lift crate0 from pallet3 at distributor0."
  },
  {
    "output": "Attack object b"
  },
  {
    "output": "def next_step():\n    return \"Lift crate0 from pallet1 at depot1 using hoist1\""
  },
  {
    "output": ""
  },
  {
    "output": "The next step is to use hoist3 to lift crate0 from pallet3 at distributor0 and load it into truck1 or truck2."
  },
  {
    "output": ""
  },
  {
    "output": "pick up the yellow block"
  },
  {
    "output": ""
  },
  {
    "output": "pick up the red block"
  },
  {
    "output": ""
  },
  {
    "output": "Insufficient information to determine the next action."
  },
  {
    "output": "feast object c from object b"
  },
  {
    "output": ""
  },
  {
    "output": "drive truck0 from depot1 to depot0"
  },
  {
    "output": ""
  },
  {
    "output": "drive truck0 from distributor0 to depot1"
  },
  {
    "output": "load package_0 into airplane_0 at location_0_0"
  },
  {
    "output": "The information provided is incomplete and lacks the full context of the current state and the conditions for each action. Therefore, it is not possible to determine the next action."
  },
  {
    "output": ""
  },
  {
    "output": "Attack object d"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "def unstack_yellow_from_red():\n    # Simulate unstacking the yellow block from the red block\n    print(\"Unstacking yellow block from red block\")"
  },
  {
    "output": "False"
  },
  {
    "output": "False"
  },
  {
    "output": "False"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Use a hoist to lift crate2 from crate0 and drop it on pallet3."
  },
  {
    "output": "def next_action(): return 'unstack the yellow block from on top of the white block'"
  },
  {
    "output": "stack the orange block on top of the red block"
  },
  {
    "output": ""
  },
  {
    "output": "pick up the red block"
  },
  {
    "output": "def next_action(): return 'unstack the blue block from on top of the white block'"
  },
  {
    "output": "unstack the yellow block from on top of the red block"
  },
  {
    "output": ""
  },
  {
    "output": "Use hoist0 to lift crate0 from pallet0 at depot0."
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "True"
  },
  {
    "output": "drive truck0 from depot0 to distributor0"
  },
  {
    "output": "Use hoist0 to lift crate0 from pallet0 at depot0."
  },
  {
    "output": ""
  },
  {
    "output": "Error: No problem found for CoT analysis"
  },
  {
    "output": "pick up the blue block"
  },
  {
    "output": "False"
  },
  {
    "output": ""
  },
  {
    "output": "The next action cannot be determined yet."
  },
  {
    "output": "def next_step():\n    return \"Pick up the orange block and place it on top of the red block.\""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "unstack the yellow block from on top of the red block."
  },
  {
    "output": ""
  },
  {
    "output": "Step 5: Put down the orange block."
  },
  {
    "output": "False"
  },
  {
    "output": "False"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "def check_conditions(current_state):\n    return (current_state['sneeze'] == object_0 and \n            current_state['texture'] == object_1 and \n            current_state['texture'] == object_2 and \n            current_state['stupendous'] == object_3 and \n            current_state['next'] == (object_0, object_1) and \n            current_state['collect'] == (object_1, object_3) and \n            current_state['collect'] == (object_2, object_3))"
  },
  {
    "output": "def next_action(): return 'Feast object a from object d'"
  },
  {
    "output": ""
  },
  {
    "output": "def execute_plan():\n    return \"Feast object a from object b\""
  },
  {
    "output": "wretched object_5 object_10 object_11 object_3"
  },
  {
    "output": "Use hoist3 to lift crate1 from pallet1 at distributor0\nUse hoist3 to drop crate1 to pallet3 at distributor0"
  },
  {
    "output": "def next_action(): return 'pick up the red block'"
  },
  {
    "output": "def feast_object_c_from_object_b(): return 'Feast object c from object b'"
  },
  {
    "output": ""
  },
  {
    "output": "pick up the blue block"
  },
  {
    "output": ""
  },
  {
    "output": "False"
  },
  {
    "output": ""
  },
  {
    "output": "The plan is to follow the steps above to achieve the goal."
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Use hoist3 to lift crate1 from pallet3 at distributor0\nUse hoist3 to drop crate1 to pallet2 at distributor0"
  },
  {
    "output": "drive truck0 from depot1 to depot2"
  },
  {
    "output": "False"
  },
  {
    "output": "def next_action(): return 'overcome object b from object d'"
  },
  {
    "output": "unstack the yellow block from on top of the blue block"
  },
  {
    "output": "False"
  },
  {
    "output": "unstack the yellow block from on top of the red block"
  },
  {
    "output": "The next step in the plan to achieve the goal cannot be determined without the specific initial conditions and available actions."
  },
  {
    "output": ""
  },
  {
    "output": "False"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "python_code_returner(\"Implement the plan to pick up the red block and stack it on top of the orange block.\")"
  },
  {
    "output": ""
  },
  {
    "output": "Use hoist1 to lift crate0 from pallet1 at depot1."
  },
  {
    "output": "Feast object b from object a"
  },
  {
    "output": "pick up the red block"
  },
  {
    "output": "unstack the yellow block from on top of the red block"
  },
  {
    "output": "pick up the yellow block"
  },
  {
    "output": "The action \"clip object_23 object_7 object_15\" cannot be executed at this"
  },
  {
    "output": "Please provide the complete current state and the goal."
  },
  {
    "output": ""
  },
  {
    "output": "False"
  },
  {
    "output": "pick up the red block"
  },
  {
    "output": "Use hoist0 to lift crate1 from pallet1 at depot0 and drop it on crate0 at depot0."
  },
  {
    "output": "Use hoist2 to lift crate1 from pallet2 at depot2."
  },
  {
    "output": "Determine the current location of Crate0."
  },
  {
    "output": ""
  },
  {
    "output": "The first action in the plan cannot"
  },
  {
    "output": "pick up the yellow block"
  },
  {
    "output": ""
  },
  {
    "output": "FEAST object b from object a"
  },
  {
    "output": ""
  },
  {
    "output": "pick up the red block"
  },
  {
    "output": ""
  },
  {
    "output": "clip object_15 object_5 object_9"
  },
  {
    "output": "def next_action(): return 'unstack the blue block from on top of the red block'"
  },
  {
    "output": ""
  },
  {
    "output": "def next_action(): return 'pick up the yellow block'"
  },
  {
    "output": "Use hoist1 to lift crate2 from pallet1 at depot1 and place it on crate1."
  },
  {
    "output": "Use hoist0 to lift crate1 from crate0 at depot0."
  },
  {
    "output": ""
  },
  {
    "output": "unstack the red block from on top of the blue block"
  },
  {
    "output": "Use hoist1 to lift crate1 from pallet1 at depot1."
  },
  {
    "output": ""
  },
  {
    "output": "unstack the red block from on top of the orange block"
  },
  {
    "output": ""
  },
  {
    "output": "Feast object a from object b"
  },
  {
    "output": "analyze the initial conditions and determine the first action to achieve the goal."
  },
  {
    "output": "print(\"Pick up the orange block\")\n    \n    # Step 4: Stack the orange block on top of the yellow block\n    print(\"Stack the orange block on top of the yellow block\")"
  },
  {
    "output": "Feast object a from object b"
  },
  {
    "output": "I will analyze the current state and the plan step by step to determine the next action."
  },
  {
    "output": "pick up the blue block"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "load package_0 into truck_2 at location_2_0"
  },
  {
    "output": "feast object b from object c"
  },
  {
    "output": ""
  },
  {
    "output": "The next step cannot be determined without the initial conditions."
  },
  {
    "output": "False"
  },
  {
    "output": "def next_action():\n    return \"Evaluate the initial conditions and determine the next action based on the goal.\""
  },
  {
    "output": "clip object_14 object_5 object_10"
  },
  {
    "output": "unstack the orange block from on top of the yellow block"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "pick up the blue block from the table"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "unstack the red block from on top of the orange block"
  },
  {
    "output": "True"
  },
  {
    "output": "feast object a from object d"
  },
  {
    "output": "Use hoist1 to lift crate0 from pallet1 at depot1."
  },
  {
    "output": "False"
  },
  {
    "output": "Attack object d"
  },
  {
    "output": "unstack the blue block from on top of the yellow block"
  },
  {
    "output": "def next_action(): return 'feast object b from object a'"
  },
  {
    "output": ""
  },
  {
    "output": "Please provide the complete plan for evaluation."
  },
  {
    "output": "The plan is incomplete and repetitive, and the initial conditions are not fully understood. A detailed analysis of the initial conditions and the plan is required to determine the next action."
  },
  {
    "output": "drive truck0 from depot0 to depot1"
  },
  {
    "output": "The information provided is incomplete and fragmented, making it difficult to determine the next action without further details."
  },
  {
    "output": "Use hoist1 to lift crate1 from pallet1 at depot1 and drop it on pallet2 at depot1."
  },
  {
    "output": "pick up the orange block"
  },
  {
    "output": "True"
  },
  {
    "output": ""
  },
  {
    "output": "The plan is incomplete and the next step cannot be determined without more information."
  },
  {
    "output": "pick up the blue block"
  },
  {
    "output": ""
  },
  {
    "output": "unstack the yellow block from on top of the blue block"
  },
  {
    "output": "False"
  },
  {
    "output": "True"
  },
  {
    "output": "Feast object a from object d"
  },
  {
    "output": "unstack the yellow block from on top of the orange block"
  },
  {
    "output": ""
  },
  {
    "output": "Attack object c"
  },
  {
    "output": "def execute_actions():\n    # Overcome object b from object a\n    # Assuming a function 'overcome' exists to modify cravings\n    overcome(\"b\", \"a\")"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "False"
  },
  {
    "output": ""
  },
  {
    "output": "def next_action(): return 'attack object a'"
  },
  {
    "output": "\"unstack the red block from the yellow block\""
  },
  {
    "output": ""
  },
  {
    "output": "Use hoist2 to unload crate2 from truck0 at depot2."
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "def next_step(): return 'overcome object a from object b'"
  },
  {
    "output": "False"
  },
  {
    "output": "def next_action(): return 'feast object d from object b'"
  },
  {
    "output": "unstack the blue block from on top of the yellow block."
  },
  {
    "output": ""
  },
  {
    "output": "def next_action():\n    return \"Attack\""
  },
  {
    "output": "Use hoist2 to lift crate0 from pallet2 at depot2."
  },
  {
    "output": ""
  },
  {
    "output": "\"Pick up the red block\""
  },
  {
    "output": "Please provide the full problem statement to proceed."
  },
  {
    "output": "Use hoist3 to lift crate0 from pallet3 at distributor0."
  },
  {
    "output": ""
  },
  {
    "output": "Pick up the blue block."
  },
  {
    "output": ""
  },
  {
    "output": "pick up the red block"
  },
  {
    "output": "Error: No code found"
  },
  {
    "output": "Feast object a from object c"
  },
  {
    "output": "unstack the blue block from under the red block"
  },
  {
    "output": ""
  },
  {
    "output": "pick up the blue block, unstack the blue block from the orange block, stack the blue block on top of the red block, pick up the yellow"
  },
  {
    "output": "unstack the yellow block from on top of the red block"
  },
  {
    "output": ""
  },
  {
    "output": "def plan(): unstack('orange', 'blue')"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "pick up the red block"
  },
  {
    "output": "def next_step(): return 'drive truck0 from depot2 to distributor0'"
  },
  {
    "output": ""
  },
  {
    "output": "def next_action(): return 'overcome object b from object a'"
  },
  {
    "output": "hoist1.move_to_location(\"depot1\", \"pallet1\")"
  },
  {
    "output": "def next_step():\n    return \"Pick up the blue block\""
  },
  {
    "output": "unstack the orange block from on top of the blue block"
  },
  {
    "output": "Evaluate the current state to ensure that the conditions for the"
  },
  {
    "output": ""
  },
  {
    "output": "I will analyze the plan step by step to determine its feasibility based on the initial conditions and the rules of the actions."
  },
  {
    "output": "def next_action():\n    return \"Pick up red block and stack it on top of blue block\""
  },
  {
    "output": "pick up the blue block"
  },
  {
    "output": "pick up the blue block"
  },
  {
    "output": "def next_action():\n    return \"Pick up the red block\""
  },
  {
    "output": "The plan is incomplete and cannot be evaluated for feasibility."
  },
  {
    "output": ""
  },
  {
    "output": "\"Pick up the blue block\""
  },
  {
    "output": "False"
  },
  {
    "output": "Feast object c from object b."
  },
  {
    "output": "Feast action"
  },
  {
    "output": "\"Pick up the red block\""
  },
  {
    "output": "pick up the orange block"
  },
  {
    "output": ""
  },
  {
    "output": "unstack the orange block from on top of the white block"
  },
  {
    "output": ""
  },
  {
    "output": "Feast object a from object b"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "False"
  },
  {
    "output": ""
  },
  {
    "output": "def perform_action(action): return action"
  },
  {
    "output": "Attack object a"
  },
  {
    "output": ""
  },
  {
    "output": "unstack the yellow block from on top of the blue block"
  },
  {
    "output": ""
  },
  {
    "output": "Please provide the plan to determine the next action."
  },
  {
    "output": ""
  },
  {
    "output": "clip object_18 object_7 object_12"
  },
  {
    "output": "Use hoist3 to unstack crate1 from crate0 at distributor0."
  },
  {
    "output": "The next action cannot be determined without the complete current state and plan details."
  },
  {
    "output": "unstack the yellow block from on top of the red block"
  },
  {
    "output": "def solve():\n    return \"Use hoist1 to lift crate0 from pallet1 at depot1\""
  },
  {
    "output": "feast object b from object a"
  },
  {
    "output": "The plan is incomplete and cannot be evaluated. Please provide the full plan."
  },
  {
    "output": "False"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "unstack the blue block from on top of the red block"
  },
  {
    "output": "Feast object c"
  },
  {
    "output": ""
  },
  {
    "output": "False"
  },
  {
    "output": "clip object_"
  },
  {
    "output": "drive truck2 from depot1 to pallet3"
  },
  {
    "output": "False"
  },
  {
    "output": ""
  },
  {
    "output": "False"
  },
  {
    "output": ""
  },
  {
    "output": "feast object a from object b"
  },
  {
    "output": "unstack the orange block from on top of the yellow block"
  },
  {
    "output": "The plan is feasible based on the initial conditions and the rules of the actions. The sequence of actions aligns with the required conditions and the goal can be achieved."
  },
  {
    "output": ""
  },
  {
    "output": "overcome object d from object b"
  },
  {
    "output": "pick up the red block"
  },
  {
    "output": ""
  },
  {
    "output": "pick up the red block"
  },
  {
    "output": "The next action cannot be determined without a complete description of the current state and the plan."
  },
  {
    "output": "Feast object a from object d"
  },
  {
    "output": "feast object a from object c"
  },
  {
    "output": ""
  },
  {
    "output": "put down the white block on the yellow block"
  },
  {
    "output": "False"
  },
  {
    "output": "Analyze the current state and determine which actions are possible based on the conditions provided."
  },
  {
    "output": "True"
  },
  {
    "output": "unstack the blue"
  },
  {
    "output": "Please provide complete initial conditions and the goal to proceed with the analysis."
  },
  {
    "output": "\"Use hoist3 at distributor0 to lift crate2 from crate1.\""
  },
  {
    "output": ""
  },
  {
    "output": "Use hoist2 to lift crate2 from pallet2 at depot2 and drop it on crate1 at depot2."
  },
  {
    "output": "Use hoist1 to lift crate1 from crate0 at depot1."
  },
  {
    "output": ""
  },
  {
    "output": "pick up the yellow block"
  },
  {
    "output": "pick up the blue block"
  },
  {
    "output": "unstack the orange block from on top of the red block"
  },
  {
    "output": "unstack the red block from on top of the orange block"
  },
  {
    "output": "pick up the yellow block"
  },
  {
    "output": "Step 1: Unstack the yellow block from the table."
  },
  {
    "output": "def next_action(): return 'pick up the red block'"
  },
  {
    "output": ""
  },
  {
    "output": "True"
  },
  {
    "output": "unstack the blue block from on top of the orange block"
  },
  {
    "output": "Please provide the complete plan to evaluate its feasibility."
  },
  {
    "output": ""
  },
  {
    "output": "unstack the yellow block from the orange block"
  },
  {
    "output": ""
  },
  {
    "output": "Please provide the complete current state and the full goal description to determine the next step in the plan."
  },
  {
    "output": "feast object e from object b"
  },
  {
    "output": "def next_action(): return 'unstack the orange block from on top of the red block'"
  },
  {
    "output": ""
  },
  {
    "output": "False"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Evaluate the plan and determine the next action to achieve the goal."
  },
  {
    "output": "False"
  },
  {
    "output": "False"
  },
  {
    "output": "Use hoist2 to lift crate0 from pallet2 at depot2."
  },
  {
    "output": "pick up the yellow block"
  },
  {
    "output": "Feast object"
  },
  {
    "output": "The next step is to analyze the current state and determine if"
  },
  {
    "output": "False"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Insufficient information to determine the next action."
  },
  {
    "output": ""
  },
  {
    "output": "The initial conditions and the goal are not fully specified, so I cannot determine the next action."
  },
  {
    "output": "Use hoist2 to drop crate2 to pallet2 at depot2."
  },
  {
    "output": "pick up the red block"
  },
  {
    "output": "feast object c from"
  },
  {
    "output": "unstack the blue block from on top of the red block"
  },
  {
    "output": "python_code_returner(\"wretched object_7 object_12 object_13 object_4\")"
  },
  {
    "output": "False"
  },
  {
    "output": "unstack the blue block from on top of the red block"
  },
  {
    "output": "False"
  },
  {
    "output": "def execute_plan(plan, initial_state):\n    current_state = initial_state.copy()\n    for action in plan:\n        if all(precondition(current_state) for precondition in action['preconditions']):\n            current_state = action['execute'](current_state)\n            if not all(postcondition(current_state) for postcondition in action['postconditions']):\n                raise Exception(\"Postcondition not met for action: \" + action['name'])\n    return current_state"
  },
  {
    "output": "Evaluate the initial conditions and the plan step by step to determine the next action."
  },
  {
    "output": ""
  },
  {
    "output": "unstack the blue block from on top of the red block"
  },
  {
    "output": "False"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "The next step in the plan to achieve the goal cannot be determined without the specific initial conditions and available actions."
  },
  {
    "output": "Use hoist2 to drop crate2 to pallet2 at depot2."
  },
  {
    "output": "pick up the blue block"
  },
  {
    "output": "def feast_action(): return 'Feast action performed'"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Use hoist0 to lift crate1 from crate0 at depot0."
  },
  {
    "output": "False"
  },
  {
    "output": "Use hoist1 to lift crate1 from crate0 at depot1."
  },
  {
    "output": "unstack the yellow block from on top of the red block"
  },
  {
    "output": "def next_action():\n    return \"Pick up the blue block.\""
  },
  {
    "output": "Please provide the complete current state and the conditions for each action to proceed."
  },
  {
    "output": "True"
  },
  {
    "output": "Use hoist3 to lift crate1 from pallet1 at distributor0 and use hoist3 to place crate1 on crate0 at distributor0."
  },
  {
    "output": "Error in CoT analysis; problem description not recognized."
  },
  {
    "output": ""
  },
  {
    "output": "unstack the yellow block from on top of the orange block"
  },
  {
    "output": "Gather and analyze the initial conditions, available actions, and restrictions to determine the next logical step in the plan."
  },
  {
    "output": ""
  },
  {
    "output": "True"
  },
  {
    "output": "unstack the blue block from on top of the red block"
  },
  {
    "output": "unstack the yellow block from on top of the blue block"
  },
  {
    "output": "The plan is to unstack the blue block, put it down, pick up the red block, stack it on the blue block, pick up the orange block, and stack it on the red block."
  },
  {
    "output": "False"
  },
  {
    "output": "Insufficient information to determine the next action."
  },
  {
    "output": "False"
  },
  {
    "output": "feast object a from object b"
  },
  {
    "output": "Attack object b"
  },
  {
    "output": ""
  },
  {
    "output": "False"
  },
  {
    "output": "True"
  },
  {
    "output": ""
  },
  {
    "output": "unstack the yellow block from on top of the orange block"
  },
  {
    "output": "The plan is incomplete and needs to be revised to include steps for moving crate0 and crate1 to their respective pallets."
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "False"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Error: No problem found for CoT analysis"
  },
  {
    "output": "unstack the yellow block from on top of the red block"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "def next_action():\n    return \"Pick up the blue block\""
  },
  {
    "output": "False"
  },
  {
    "output": ""
  },
  {
    "output": "def next_step(): return 'unstack the blue block from on top of the red block'"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "unstack the orange block from on top of the yellow block"
  },
  {
    "output": ""
  },
  {
    "output": "(11 - 1) × (1 + 1)"
  },
  {
    "output": "Solution: 12 × (1 + 1) × 1"
  },
  {
    "output": "(13 - 1) * (1 + 1)"
  },
  {
    "output": ""
  },
  {
    "output": "(7 + 1) * (2 + 1)"
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (9 - 1) * (2 + 1)"
  },
  {
    "output": "(10 + 1 + 1) * 2"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "(13 * 2) - (1 + 1)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (6 / (1 - 3/6)) * 1"
  },
  {
    "output": "(7 - 1) * (3 + 1)"
  },
  {
    "output": "16"
  },
  {
    "output": ""
  },
  {
    "output": "False"
  },
  {
    "output": "**\nSolution: (11 + 1) * (3 - 1)"
  },
  {
    "output": "12 × (3 - (1 / 1))"
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (4 * (1 + 1)) + 4"
  },
  {
    "output": "Solution: (5 × (4 + 1)) - 1"
  },
  {
    "output": "Solution: (6 / (1 - (4 / 6))) * 1"
  },
  {
    "output": "Solution: (7 + 1) * (4 - 1)"
  },
  {
    "output": "Solution: (8 / (1 - (4 / 8))) * 1"
  },
  {
    "output": "Solution: (9 - 1) * (4 - 1)"
  },
  {
    "output": "(10 × (1 + 1)) + 4"
  },
  {
    "output": "**\nSolution: 12 × (4 - (1 + 1))"
  },
  {
    "output": "Solution: (5 * 5) - (1 / 1)"
  },
  {
    "output": "Solution: (6 / (1 - 5/6)) = 24"
  },
  {
    "output": "Solution: (7 - (1 / 1)) * (5 - 1)"
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (6 / (1 - (6 / 1)))"
  },
  {
    "output": "Solution: (8 / (1 - (6 / (1 + 1))))"
  },
  {
    "output": "9 × (1 + 1) + 6"
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (10 × (1 + 1)) - 7"
  },
  {
    "output": "(8 × (1 + 1)) + 8"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (13 - 1) * (1 + 1)"
  },
  {
    "output": ""
  },
  {
    "output": "(12 × 1) + (11 + 1)"
  },
  {
    "output": ""
  },
  {
    "output": "(12 + 12) * 1 / 1"
  },
  {
    "output": "Solution: (12 + 1) * (1 + 1)"
  },
  {
    "output": "Solution: (13 - 1) * (1 + 1)"
  },
  {
    "output": "(4 × 2) × (2 + 1)"
  },
  {
    "output": "Solution: (5 + 1) * (2 + 2)"
  },
  {
    "output": "Solution: (6 / (1 - 2/2))"
  },
  {
    "output": "Solution: (7 * (2 + 2)) - 1"
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (9 - 1) * (2 + 2)"
  },
  {
    "output": "Solution: (10 - 2) * (2 + 1)"
  },
  {
    "output": "**\nSolution: (11 × 2) + ("
  },
  {
    "output": "**\nSolution: (12 ÷ (2 - 1)) × 2"
  },
  {
    "output": "(13 * 2) - (2 * 1)"
  },
  {
    "output": "Solution: (3 * (3 + 1)) + 2"
  },
  {
    "output": "(1 + 2 + 3) * 4"
  },
  {
    "output": ""
  },
  {
    "output": "6 × (3 + 1) × (2 / 2)"
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (8 * (3 - (2 - 1)))"
  },
  {
    "output": "Solution: (9 - 3) * (2 + 1)"
  },
  {
    "output": ""
  },
  {
    "output": "**\nSolution: (11 - 3) * (2 + 1)"
  },
  {
    "output": "Solution: (12 * (3 - 1)) + 2"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (8 / (4 - 2)) * (1 + 1)"
  },
  {
    "output": "Solution: (9 × (4 -"
  },
  {
    "output": ""
  },
  {
    "output": "**\n\nSolution: ("
  },
  {
    "output": "Solution: (12 × 2) × ("
  },
  {
    "output": "(13 - 1) * (4 - 2)"
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (6 / (1 - 5/6))"
  },
  {
    "output": ""
  },
  {
    "output": "(8 * (2 + 1)) - 5"
  },
  {
    "output": "Solution: (9 × 2) + (5 + 1)"
  },
  {
    "output": ""
  },
  {
    "output": "Solution: 12 * 2 * ((5 - 1) / (5 - 1))"
  },
  {
    "output": "(13 - 5) * (2 + 1)"
  },
  {
    "output": ""
  },
  {
    "output": "(6 × (2 + 1)) + (7 - 1)"
  },
  {
    "output": ""
  },
  {
    "output": "(9 × 2) + (6 ÷ 1)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "(7 × 2) + (11 - 1)"
  },
  {
    "output": ""
  },
  {
    "output": "when done."
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "(12 × (10 - (2 + 1)))"
  },
  {
    "output": "13 + 10 + (2 - 1)"
  },
  {
    "output": "Solution: (11 - (11 / (2 + 1))) * 2"
  },
  {
    "output": ""
  },
  {
    "output": "(13 + 11) * (2 - 1)"
  },
  {
    "output": "(12 + 12) / (2 - 1)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Solution: 3 * 3 * (1 + (3 / 3))"
  },
  {
    "output": "**\nSolution: (3 × 4) × (3 -"
  },
  {
    "output": "Solution: (3 * (5 - (1 / 3)))"
  },
  {
    "output": "Solution: (6 / (3 - 1)) * 3"
  },
  {
    "output": "Solution: (7 - (3 / 3)) * 1"
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (9"
  },
  {
    "output": ""
  },
  {
    "output": "(11 + 1)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "(7 × 3) + (4 - 1)"
  },
  {
    "output": "**\nSolution: (8 + 4) × (3 - 1)"
  },
  {
    "output": "Solution: (9 - 3) * (4 - 1)"
  },
  {
    "output": "(10 - 4) * (3 + 1)"
  },
  {
    "output": ""
  },
  {
    "output": "(12 - 4) * (3 + 1)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "(9 - 3) * (5 - 1)"
  },
  {
    "output": ""
  },
  {
    "output": "(11 - 5) * (3 + 1)"
  },
  {
    "output": "Solution: (5 * 3) + (12 / 1)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (6 * 3) + (7 - 1)"
  },
  {
    "output": "Solution: (8 / (3 - 1)) * (6 - 3)"
  },
  {
    "output": "Solution: (9 × (3 - 1)) + 6"
  },
  {
    "output": "(10 × 3) - (6 ÷ 1)"
  },
  {
    "output": ""
  },
  {
    "output": "**\nSolution: (12 - 6) × (3 + 1)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "(9 + 3) × (7 - 1) / 3"
  },
  {
    "output": "(10 * 3) - (7 - 1)"
  },
  {
    "output": "Solution: (12 / (7 - (3 + 1))) * 3"
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (8 * (3 + (8"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "**\nSolution: (11 + 1) × (3 - 1)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "(12 × (3 - 1)) + (10 - 10)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "(12 × 3) - (12 ÷ 1)"
  },
  {
    "output": "when done."
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (4 * (4 + 1)) + 4"
  },
  {
    "output": "Solution: (4 * (5 - (1 / 4)))"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (8 / (4 - 1)) * 4"
  },
  {
    "output": ""
  },
  {
    "output": "Solution: 10 × (1 + 1) + 4"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (5 * 4)"
  },
  {
    "output": "Solution: (6 / (1 - (5 / 4)))"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "(11 - (5 / 1)) * 4"
  },
  {
    "output": "Solution: (5 - (12 / (4 + 1))) * 12"
  },
  {
    "output": "(13 - 5) * (4 - 1)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "(10 × (4 - 1)) - 6"
  },
  {
    "output": "(11 + 1) * (6 - 4)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "8 * (7 - 4) * 1"
  },
  {
    "output": ""
  },
  {
    "output": "7 / 3 = 2.333...\n3. Subtract th"
  },
  {
    "output": "12 * (7 - 4 - 1)"
  },
  {
    "output": ""
  },
  {
    "output": "**\nSolution: (8 × 4) -"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (11 × (4 - 1)) - 9"
  },
  {
    "output": "when done."
  },
  {
    "output": ""
  },
  {
    "output": "(10 + 10) + (4 ÷ 1)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "(12 + 12) × (1 - (4 - 4))"
  },
  {
    "output": "Solution: (5 * 5) - (1 / 5)"
  },
  {
    "output": "Solution: (5 - (1 / 5)) * 6"
  },
  {
    "output": "Solution: (5 - (9 / (5 - 1))) * 1"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "(5 × 5) - (13 ÷ 1)"
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (6 × (5 - 1)) + 7"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (6 / (12 - 5)) * (1 + 5)"
  },
  {
    "output": "Solution: (13 - 5) * (6 - 1)"
  },
  {
    "output": "(8 × (5 − 1)) − 7"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "(11 - 7) * (5 + 1)"
  },
  {
    "output": "when done."
  },
  {
    "output": ""
  },
  {
    "output": "(8 × (5 - 1)) - 8"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (11 - 5) * (9 - 1)"
  },
  {
    "output": ""
  },
  {
    "output": "(13 - 9) * (5 + 1)"
  },
  {
    "output": "(10 + 10) + (5 - 1)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (13 - 5) * (1 + 1)"
  },
  {
    "output": "**\nSolution: ((11 + 1) * (5 - 1)) / 2"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (6 / (1 - 6/6))"
  },
  {
    "output": "Solution: (6 / (8 - 6)) * (1 + 6)"
  },
  {
    "output": "Solution: (6 / (9 - 6)) * (1 + 6)"
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (6 × (11 - (6 + 1)))"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (6 × (11 - 7)) - 1"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "when done."
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (12 × (6 ÷ (9 - 6"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "(13 - 1) * (10 - 6)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (7 - (9 / (7 - 1))) * 1"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Solution: 12 * (1 + (7 / 7))"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "10 + 8 + 7 - 1"
  },
  {
    "output": "(11 - 8) * (7 + 1)"
  },
  {
    "output": "(12 - 8) * (7 - 1)"
  },
  {
    "output": ""
  },
  {
    "output": "(10 - 7) * (9 - 1)"
  },
  {
    "output": "(11 + 1) * (9 - 7)"
  },
  {
    "output": "when done."
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (12 × (7 - (10 ÷ (1 + 1))))"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (13 × (7 - (13 ÷ 1)))"
  },
  {
    "output": "Solution: (8 / (8 - 8 + 1)) * 8"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "**\nSolution: (8 × (11 − 8)) × 1"
  },
  {
    "output": "24\n\nSolution: 12 × (8 ÷ (8 - 1))"
  },
  {
    "output": "when done."
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Error: '(' was never closed (<string>, line 1)"
  },
  {
    "output": "Solution: (12 × (10 - 8)) - 1"
  },
  {
    "output": ""
  },
  {
    "output": "(12 × (8 - (11 - 1))) × (-1)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "("
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "**\nSolution: (13 - 1) × (11 - 9)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Solution: 12 × (11 - (10 - 1))"
  },
  {
    "output": "Solution: 12 × (12 − 10) × 1"
  },
  {
    "output": ""
  },
  {
    "output": "12 * (1 + (11 / 11))"
  },
  {
    "output": "**\nSolution"
  },
  {
    "output": "(12 + 12) + (11 - 11)"
  },
  {
    "output": "**\nSolution: (12 × (13 − 11)) × 1"
  },
  {
    "output": ""
  },
  {
    "output": "12 × (1 + (12 ÷ 12))"
  },
  {
    "output": ""
  },
  {
    "output": "12 * (1 + (13 / 13))"
  },
  {
    "output": "Solution: (2 + 2 + 2) * 3"
  },
  {
    "output": "Solution: (2 + 2 + 2) * 4"
  },
  {
    "output": "**\nSolution: (5 × (2 + 2)) + (2 × 2)"
  },
  {
    "output": "**\nSolution: (7 × (2 + 2)) - (2 + 2)"
  },
  {
    "output": "Solution: (8 / (2 - (2 / 2)))"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "**\nSolution: (11 + (2 / 2)) * 2"
  },
  {
    "output": "(12 × 2) × (2 ÷ 2)"
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (3 * 2) * (2 + 3 - 2)"
  },
  {
    "output": "when done."
  },
  {
    "output": "Solution: (5 × (3 + 2)) - (2 / 2)"
  },
  {
    "output": "(6 × 2) × (3 - (2 / 2))"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "(9 × 2) + (3 × 2)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "(12 × (3 - (2 / 2)))"
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (4 / (2 - (4 / 2))) * 2"
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (6 / (2 - (4 / 2))) * 2"
  },
  {
    "output": "(7 × 4) - (2 + 2)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "(10 - 2) * (2 + 4) / 2"
  },
  {
    "output": "(11 × (4 - 2)) + 2"
  },
  {
    "output": "Solution: (12 - 2) * (2 + 4)"
  },
  {
    "output": "24\n\nSolution: (13 - (4 / 2)) * 2"
  },
  {
    "output": "Solution: (5 * 5) - (2 / 2)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "(11 - 5) * (2 + 2)"
  },
  {
    "output": ""
  },
  {
    "output": "(6 / (2 - (6 / 2))) * 2"
  },
  {
    "output": "**\nSolution: (6 × (2 + 2)) + (7 - 7)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (7 * (2 + 2)) - 7"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "(13 + 7) + (2 + 2)"
  },
  {
    "output": "Solution: (8 / (2 - (8 / 2)))"
  },
  {
    "output": "Solution: (9 × 2) + (8 - 2)"
  },
  {
    "output": "Solution: (10 × 2) + (8 ÷ 2)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "(12 - (9 - (2 + 2))) * 2"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "(13 + 10) + (2 / 2)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "(13 + 11) * 2 / 2"
  },
  {
    "output": "(12 + 12) * (2 / 2)"
  },
  {
    "output": ""
  },
  {
    "output": "**\nSolution: (13 - (2 / 2)) × 2"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (6 / (3 - (2 / 3)))"
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (8 / (3 - (2 / 3)))"
  },
  {
    "output": "Solution: (9 - (3 / 3)) * 3"
  },
  {
    "output": ""
  },
  {
    "output": "**\nSolution: (11 + (3 ÷ 3)) × 2"
  },
  {
    "output": "**\nSolution: (12 × 2) × (3 ÷ 3)"
  },
  {
    "output": "**\nSolution: (13 - (3 / 3)) * 2"
  },
  {
    "output": "Solution: (4 / (3 - 4/2)) * 2"
  },
  {
    "output": "Solution: (5 - 3) * (2 + 4) * 2"
  },
  {
    "output": "Solution: (6 / (3 - 2)) * 4"
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (8 / (4 - 3)) * 2"
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (10 - (4 / 2)) * 3"
  },
  {
    "output": ""
  },
  {
    "output": "(12 ÷ (4 - 3)) × 2"
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (5 - (2 / 5)) * 3"
  },
  {
    "output": "Solution: (6 / (3 - 5/2))"
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (8 / (3 - 5/2))"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "(11 - 3) * (5 - 2)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (6 / (3 - (6 / 2))) * 2"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "(11 - (6 / 2)) * 3"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (7 - (3 / 2)) * (7 - 2)"
  },
  {
    "output": "(8 × 3) × (2 - ("
  },
  {
    "output": "(9 - 3) * (2 + 2)"
  },
  {
    "output": "(10 - (7 - 3)) * 2"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Solution: 8 / (3 - 8 / 2)"
  },
  {
    "output": "(9 - 3) * (8 / 2)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (9 / (3 - (9 / 2))) * 2"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "(13 - (9 / 3)) * 2"
  },
  {
    "output": "Solution: (10 - (10 / (3 - 2)))"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (11 - (11 / (3 - 2)))"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (13 - (3 / (13 - 2))) * 2"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Solution: (10 + 2) × (4 - (4 ÷ 2))"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "(13 - (4 / 4)) * 2"
  },
  {
    "output": "Solution: (5 - (2 / 5)) * 4"
  },
  {
    "output": "Solution: (6 / (5 - 4)) * 2"
  },
  {
    "output": "Solution: (7 + 5) * (4 - 2)"
  },
  {
    "output": ""
  },
  {
    "output": "**\nSolution: (9 - 5) * (4 + 2)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "(12 × (5 - 4)) × 2"
  },
  {
    "output": "**\nSolution: (13 - (5 + 2)) * 4"
  },
  {
    "output": "Solution: (6 / (2 - (6 / 4))) * 2"
  },
  {
    "output": ""
  },
  {
    "output": "24"
  },
  {
    "output": "(9 - (6 / 2)) * 4"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Red Wings"
  },
  {
    "output": "True"
  },
  {
    "output": "False"
  },
  {
    "output": "A"
  },
  {
    "output": "True"
  },
  {
    "output": "False"
  },
  {
    "output": "UNCG Spartans"
  },
  {
    "output": "Texas Longhorns"
  },
  {
    "output": "Massachusetts-Lowell River Hawks"
  },
  {
    "output": "True"
  },
  {
    "output": "Team CC"
  },
  {
    "output": "False"
  },
  {
    "output": "D"
  },
  {
    "output": "A"
  },
  {
    "output": "B"
  },
  {
    "output": "B"
  },
  {
    "output": "B"
  },
  {
    "output": "D"
  },
  {
    "output": "C"
  },
  {
    "output": "A"
  },
  {
    "output": "B"
  },
  {
    "output": "D"
  },
  {
    "output": "G"
  },
  {
    "output": "D"
  },
  {
    "output": "A"
  },
  {
    "output": "E"
  },
  {
    "output": "G"
  },
  {
    "output": "A"
  },
  {
    "output": "C"
  },
  {
    "output": "D"
  },
  {
    "output": "C"
  },
  {
    "output": "D"
  },
  {
    "output": "D"
  },
  {
    "output": "A"
  },
  {
    "output": "Casper Uhl, Felix Auger-Aliassime, Taylor Fritz"
  },
  {
    "output": "Shuko Nakamura, Zhang Shuai, Xu Shuyu"
  },
  {
    "output": "\"The Return of Superman\", \"Keep Running\", \"The Voice of China\""
  },
  {
    "output": "\"The Last Adventure\", \"Echoes of Time\", \"Neon Dreams\""
  },
  {
    "output": "112"
  },
  {
    "output": "5.40"
  },
  {
    "output": "[\"The Crown\", \"Stranger Things\", \"The Bear\"]"
  },
  {
    "output": "\"The Midnight Adventure\", \"Starlight Chronicles\""
  },
  {
    "output": "Jonas Blixt, Patrick Cantlay, Jordan Spieth"
  },
  {
    "output": "\"The Midnight Library\", \"The Seven Husbands of Evelyn Hugo\", \"The Night Tiger\""
  },
  {
    "output": "@ChinaNews, @CRI, @XinhuaNews"
  },
  {
    "output": "\"界面新闻\", \"第一财经\", \"澎湃新闻\""
  },
  {
    "output": "Account A, Account B, Account C"
  },
  {
    "output": "2.5"
  },
  {
    "output": "The Last Letter"
  },
  {
    "output": "\"The Great Wall\", \"The Wandering Earth\", \"The Battle at Lake Changjin\""
  },
  {
    "output": "[\"The Last Adventure\", \"Starlight Dreams\", \"Echoes of Time\"]"
  },
  {
    "output": "Toyota RAV4, Honda CR-V, BMW X5"
  },
  {
    "output": "Model Y, Tesla Model 3, BYD Han"
  },
  {
    "output": "219"
  },
  {
    "output": "The Marvel Studios' Marvel 10"
  },
  {
    "output": "1200"
  },
  {
    "output": "150"
  },
  {
    "output": "The Night Tiger, The Silent Companions, The Midnight Library"
  },
  {
    "output": "150000000"
  },
  {
    "output": "Cannot Predict"
  },
  {
    "output": "Prediction"
  },
  {
    "output": "125000000"
  },
  {
    "output": "I cannot provide a prediction"
  },
  {
    "output": "45"
  },
  {
    "output": "ProjectA, ProjectB, ProjectC"
  },
  {
    "output": "12000"
  },
  {
    "output": "TensorFlow, React, PyTorch"
  },
  {
    "output": "0.5"
  },
  {
    "output": "Author1, Author2, Author3"
  },
  {
    "output": "\"The Silent Symphony\", \"Echoes of the Past\", \"Whispers in the Wind\""
  },
  {
    "output": "Cannot Predict"
  },
  {
    "output": "Cannot predict"
  },
  {
    "output": "Qwen, LLaMA, Gemini"
  },
  {
    "output": "156000"
  },
  {
    "output": "\"Midnight Memories\", \"Starlight Dreams\", \"Winter Wonderland\""
  },
  {
    "output": "18"
  },
  {
    "output": "4800"
  },
  {
    "output": "15.5"
  },
  {
    "output": "B"
  },
  {
    "output": "\"Midnight Memories\", \"Echoes of the Past\", \"Golden Hour\""
  },
  {
    "output": "12.5"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Error: invalid syntax (<string>, line 1)"
  },
  {
    "output": ""
  },
  {
    "output": "def find_weighted_median():\n    total_weight = 2017 * 2018 // 2\n    half_total = total_weight // 2\n    cumulative = 0\n    for x in range(1, 2018):\n        cumulative += x\n        if cumulative >= half_total:\n            return x"
  },
  {
    "output": ""
  },
  {
    "output": "def solve_hyperbola():\n    import sympy as sp\n    x, y = sp.symbols('x y')\n    eq = (3*x + 4*y - 13)*(7*x - 24*y + 3) - 200\n    simplified_eq = sp.simplify(eq)\n    # Find center by solving system of equations derived from partial derivatives\n    dx = sp.diff(simplified_eq, x)\n    dy = sp.diff(simplified_eq, y)\n    center = sp.solve((dx, dy), (x, y))\n    # Substitute center into original equation to find a^2 and b^2\n    x0, y0 = center[x], center[y]\n    eq_center = simplified_eq.subs({x: x0, y: y0})\n    # Assume standard form and find c\n    c = sp.sqrt(100)\n    return c"
  },
  {
    "output": "def count_perpendicular_skew_pairs():\n    from itertools import combinations\n    import numpy as np\n    \n    vertices = np.array([\n        [0, 0, 0], [1, 0, 0], [0, 1, 0], [1, 1, 0],\n        [0, 0, 1], [1, 0, 1], [0, 1, 1], [1, 1, 1]\n    ])\n    \n    lines = list(combinations(vertices, 2))\n    \n    def direction_vector(a, b):\n        return b - a\n    \n    def are_perpendicular(v1, v2):\n        return np.dot(v1, v2) == 0\n    \n    def are_skew(line1, line2):\n        a, b = line1\n        c, d = line2\n        ab = direction_vector(a, b)\n        cd = direction_vector(c, d)\n        if np.all(ab == cd) or np.all(ab == -cd):\n            return False\n        cross = np.cross(ab, cd)\n        if np.all(cross == 0):\n            return False\n        return True\n    \n    count = 0\n    for line1, line2 in combinations(lines, 2):\n        if are_perpendicular(direction_vector(*line1), direction_vector(*line2)) and are_skew(line1, line2):\n            count += 1\n    return count // 2"
  },
  {
    "output": "$[-\\frac{1}{16}, \\frac{1}{16}]$"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "300"
  },
  {
    "output": ""
  },
  {
    "output": "1/2019 * 1/1000 * 1/100"
  },
  {
    "output": "Infinite"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "3"
  },
  {
    "output": "$\\frac{2\\pi}{3}$"
  },
  {
    "output": "6^40"
  },
  {
    "output": "6276"
  },
  {
    "output": "(\\pm 2, 0)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "import math\n\ndef minimize_tan_product(a, b, c):\n    def tan_angle(side, opposite_sides):\n        cos_angle = (opposite_sides[0]**2 + opposite_sides[1]**2 - side**2) / (2 * opposite_sides[0] * opposite_sides[1])\n        sin_angle = math.sqrt(1 - cos_angle**2)\n        return sin_angle / cos_angle\n\n    tan_a = tan_angle(a, (b, c))\n    tan_b = tan_angle(b, (a, c))\n    tan_c = tan_angle(c, (a, b))\n\n    product = tan_a * tan_b * tan_c\n    return product"
  },
  {
    "output": ""
  },
  {
    "output": "3498120"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Error: No code found"
  },
  {
    "output": ""
  },
  {
    "output": "def calculate_probability():\n    total = 0\n    unique_digits = 0\n    for hour in range(5, 23):\n        for minute in range(60):\n            for second in range(60):\n                total += 1\n                time_str = f\"{hour:02d}:{minute:02d}:{second:02d}\"\n                digits = list(time_str.replace(':', ''))\n                if len(set(digits)) == 6:\n                    unique_digits += 1\n    return unique_digits / total"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "from collections import defaultdict\n\ndef count_subsets():\n    mod = 17\n    pairs = defaultdict(int)\n    for a in range(1, mod + 1):\n        for c in range(1, mod + 1):\n            if a != c:\n                pairs[(a + c) % mod] += 1\n    result = 0\n    for count in pairs.values():\n        result += count * (count - 1) // 2\n    return result"
  },
  {
    "output": ""
  },
  {
    "output": "[Hard problem, difficulty=7] Step-by-step reasoning:\nWe are given a cube $ABCD-EFGH$ placed in a 3D coordinate system with vertex $A(0, 0, 0)$. The goal is to **solve the problem step by step**, but the problem statement is incomplete. Let's assume the problem is to **find the coordinates of all the vertices of the cube** given that $A(0, 0, 0)$ and the cube has side length 1 (a common assumption when not specified otherwise).\n\n---\n\n### Step 1: Identify what we're asked to find\n\nWe are asked to **find the coordinates of all the vertices of the cube** $ABCD-EFGH$, assuming it is placed in a 3D coordinate system with vertex $A(0, 0, 0)$ and that the cube has side length 1.\n\n---\n\n### Step 2: Break down the problem into smaller parts\n\nWe need to:\n1. Understand the structure of the cube.\n2. Assign coordinates to each vertex based on the given information.\n3. Ensure that the cube is axis-aligned (i.e., edges are parallel to the coordinate axes).\n4. Use the fact that the cube has side length 1.\n\n---\n\n### Step 3: Solve each part carefully\n\n#### Part A: Understand the structure of the cube\n\nA cube has 8 vertices. The cube $ABCD-EFGH$ is a standard cube with:\n- Base: $ABCD$\n- Top: $EFGH$\n- Edges: $AE, BF, CG, DH$ are vertical edges.\n\nAssuming the cube is axis-aligned and placed with vertex $A(0, 0, 0)$, we can assign coordinates to the other vertices based on the direction of the edges.\n\n#### Part B: Assign coordinates to the vertices\n\nLet’s assume the cube is oriented such that:\n- $AB$ lies along the x-axis\n- $AD$ lies along the y-axis\n- $AE$ lies along the z-axis\n\nSince the cube has side length 1, the coordinates of the other vertices can be determined by moving 1 unit along the respective axes.\n\nLet’s assign coordinates:\n\n- $A = (0, 0, 0)$\n- $B = (1, 0, 0)$ (1 unit along x-axis)\n- $D = (0, 1, 0)$ (1 unit along y-axis)\n- $C = (1, 1, 0"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "3.0"
  },
  {
    "output": ""
  },
  {
    "output": "Error: __import__ not found"
  },
  {
    "output": "import math\n\ndef find_min_perimeter_y_intercept():\n    from scipy.optimize import minimize_scalar\n    def perimeter(m):\n        a = 2 - 1/m\n        b = -2 * m\n        return abs(a) + abs(b) + math.sqrt(a**2 + b**2)\n    result = minimize_scalar(perimeter, bounds=(0.1, 100), method='bounded')\n    m_min = result.x\n    y_intercept = -2 * m_min\n    return m_min, y_intercept"
  },
  {
    "output": ""
  },
  {
    "output": "0.2"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "27"
  },
  {
    "output": "[Hard problem, difficulty=5] Step-by-step reasoning:\nLet's solve the problem step by step.\n\n---\n\n### **Step 1: Identify what we're asked to find**\n\nThe problem is:  \n> A frisbee toy is a circular disc divided into 20 sectors by 20 rays emanating from the center, with each sector colored either red or blue (only the front side is colored).  \n>  \n> **What is the question?**  \n> (Note: The original problem is incomplete. However, based on the context, it's likely that the question is: **What is the number of distinct colorings of the frisbee, considering rotational symmetry?**)\n\nSo, we are to find the number of **distinct colorings** of the frisbee, where:\n- The frisbee is divided into **20 sectors**.\n- Each sector is colored either **red or blue**.\n- Two colorings are considered **the same** if one can be obtained from the other by **rotation** (i.e., rotational symmetry).\n\nThis is a classic problem in **combinatorics and group theory**, often solved using **Burnside's Lemma**.\n\n---\n\n### **Step 2: Break down the problem into smaller parts**\n\nWe are to count the number of **distinct colorings** of a circular arrangement of 20 sectors, where each sector is colored red or blue, and two colorings are considered the same if one can be rotated to match the other.\n\nThis is a **symmetry problem** involving **rotational symmetry**.\n\nLet’s define:\n- The **group of symmetries** is the **cyclic group** $ C_{20} $, which has 20 elements (rotations by 0°, 18°, 36°, ..., 324°).\n- The **set of colorings** is the set of all possible colorings of the 20 sectors with red or blue, which has $ 2^{20} $ elements.\n- We want to count the number of **distinct colorings** under the action of the group $ C_{20} $.\n\nThis is exactly the setup for **Burnside's Lemma**, which states:\n\n> The number of distinct colorings (up to symmetry) is equal to the **average number of colorings fixed by each group element**.\n\nSo, we will:\n1. Enumerate all elements of the group $ C_{20} $ (i.e., all rotations).\n2. For each"
  },
  {
    "output": "0.0016941267676767676"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "def find_min_a():\n    a = 1\n    while True:\n        sum1 = 5 * a + 20\n        sum2 = 4 * a + 16\n        if sum1**0.5 == int(sum1**0.5) and sum2**0.5 == int(sum2**0.5):\n            return 9 * a + 36\n        a += 1"
  },
  {
    "output": "def count_good_numbers(limit):\n    count = 0\n    for n in range(1, limit + 1):\n        binary = bin(n)[2:]\n        ones = binary.count('1')\n        zeros = len(binary) - ones\n        if ones > zeros:\n            count += 1\n    return count\n\ngood_numbers_count = count_good_numbers(2017)"
  },
  {
    "output": ""
  },
  {
    "output": "418211840000000"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "def is_prime(n):\n    if n < 2:\n        return False\n    for i in range(2, int(n**0.5) + 1):\n        if n % i == 0:\n            return False\n    return True\n\ngood_numbers = 0\nfor a in range(1, 101):\n    p = 2 * a + 1\n    if is_prime(p):\n        good_numbers += 1\n\ngood_numbers"
  },
  {
    "output": "$ D(2019) $"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "1"
  },
  {
    "output": "$\\frac{\\sqrt{a^2 + b^2}}{a}$"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "$\\sqrt{3}$"
  },
  {
    "output": ""
  },
  {
    "output": "10"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "1"
  },
  {
    "output": "$\\frac{2\\pi}{5}$"
  },
  {
    "output": "0.9397"
  },
  {
    "output": "3/2"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "[Hard problem, difficulty=5] Step-by-step reasoning:\nWe are given a sequence $ \\{u_n\\} $ with the first few terms:\n\n- $ u_1 = 2 $\n- $ u_2 = 8 $\n- $ u_3 = 30 $\n- $ u_4 = 112 $\n- $ u_5 = 418 $\n\nWe are asked to compute $ \\operatorname{arccot}(u_n^2) $ for these terms and look for a pattern or a telescoping sum.\n\n---\n\n### **Step 1: Understand the Problem**\n\nWe are to compute the values of $ \\operatorname{arccot}(u_n^2) $ for the first few terms of the sequence $ \\{u_n\\} $, and then look for a pattern or a telescoping sum.\n\nThis suggests that the sequence $ \\{u_n\\} $ may be related to a telescoping series involving the arccotangent function.\n\n---\n\n### **Step 2: Compute $ u_n^2 $ for the first few terms**\n\nLet’s compute the squares of the first few terms:\n\n- $ u_1 = 2 \\Rightarrow u_1^2 = 4 $\n- $ u_2 = 8 \\Rightarrow u_2^2 = 64 $\n- $ u_3 = 30 \\Rightarrow u_3^2 = 900 $\n- $ u_4 = 112 \\Rightarrow u_4^2 = 12544 $\n- $ u_5 = 418 \\Rightarrow u_5^2 = 174724 $\n\n---\n\n### **Step 3: Compute $ \\operatorname{arccot}(u_n^2) $ for these values**\n\nWe now compute $ \\operatorname{arccot}(u_n^2) $ for each of these values.\n\nRecall that:\n\n- $ \\operatorname{arccot}(x) = \\arctan\\left(\\frac{1}{x}\\right) $\n- $ \\arctan(x) $ is the inverse tangent function, which gives an angle whose tangent is $ x $\n\nSo:\n\n- $ \\operatorname{arccot}(4) = \\arctan\\left(\\frac{1}{4}\\right) $\n- $ \\operatorname{arccot}(64) = \\arctan\\left(\\frac{1}{64}\\right) $\n- $ \\operator"
  },
  {
    "output": "The problem statement is incomplete and cannot be solved as given."
  },
  {
    "output": "1"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "0"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "6"
  },
  {
    "output": "The problem is incomplete. Please provide the full definition of the function $ f(x, y, z) $ and any constraints or domain information to proceed with the solution."
  },
  {
    "output": "False"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "1013"
  },
  {
    "output": "Error: invalid syntax (<string>, line 1)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "The problem is incomplete and cannot be solved as stated."
  },
  {
    "output": "325"
  },
  {
    "output": "def compute_sum_f_n():\n    f = [0] * 2024\n    f[0] = 0\n    f[1] = 1\n    f[2] = 2\n    f[3] = 3\n    f[4] = 4\n    f[5] = 5\n    f[6] = 6\n    f[7] = 7\n    f[8] = 7\n    for n in range(9, 2024):\n        f[n] = max(f[n-1], 1 + f[n-8])\n    return sum(f[1:2024])"
  },
  {
    "output": "def find_largest_n():\n    from itertools import combinations\n    import sys\n    sys.setrecursionlimit(10000)\n    def is_sidon(seq):\n        sums = set()\n        for i, j in combinations(range(len(seq)), 2):\n            s = seq[i] + seq[j]\n            if s in sums:\n                return False\n            sums.add(s)\n        return True\n    \n    def check_modulo_distribution(sums):\n        mod_counts = [0, 0, 0, 0]\n        for s in sums:\n            mod_counts[s % 4] += 1\n        return mod_counts[0] == mod_counts[1] == mod_counts[2] == mod_counts[3]\n    \n    def generate_sidon_sequence(max_val):\n        seq = []\n        for i in range(1, max_val + 1):\n            if all(seq[-1] + i > seq[-2] + seq[-1] for _ in range(len(seq)-1)):\n                seq.append(i)\n        return seq\n    \n    max_n = 0\n    for n in range(2025, 0, -1):\n        seq = generate_sidon_sequence(n)\n        if len(seq) < n:\n            continue\n        sums = set()\n        for i, j in combinations(range(n), 2):\n            s = seq[i] + seq[j]\n            if s in sums:\n                break\n            sums.add(s)\n        else:\n            if check_modulo_distribution(sums):\n                max_n = n\n                break\n    return max_n"
  },
  {
    "output": ""
  },
  {
    "output": "$ AB \\cdot \\left( \\frac{\\tan \\alpha + \\tan \\beta}{1 - \\tan \\alpha \\tan \\beta} \\right) $"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "$\\binom{4048}{2024}$"
  },
  {
    "output": ""
  },
  {
    "output": "def check_good_numbers():\n    from math import gcd\n    from sympy import divisors\n    def euler_phi(n):\n        result = n\n        i = 2\n        while i*i <= n:\n            if n % i == 0:\n                while n % i == 0:\n                    n //= i\n                result -= result // i\n            i += 1\n        if n > 1:\n            result -= result // n\n        return result\n    def tau(n):\n        return len(divisors(n))\n    good_numbers = []\n    for n in range(1, 1001):\n        phi = euler_phi(n)\n        tau_val = tau(n)\n        if (n == (tau_val + phi) / 2) or (tau_val == (n + phi) / 2) or (phi == (n + tau_val) / 2):\n            good_numbers.append(n)\n    return good_numbers"
  },
  {
    "output": "0"
  },
  {
    "output": "16/25"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "def f(x): return abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs(abs"
  },
  {
    "output": "1"
  },
  {
    "output": "from itertools import permutations\n\ndef count_valid_cube_configurations():\n    cube_vertices = [\n        (0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1),\n        (1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1)\n    ]\n    faces = [\n        [(0, 0, 0), (0, 0, 1), (1, 0, 0), (1, 0, 1)],\n        [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1)],\n        [(0, 0, 0), (1, 0, 0), (1, 1, 0), (0, 1, 0)],\n        [(0, 0, 1), (1, 0, 1), (1, 1, 1), (0, 1, 1)],\n        [(1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1)],\n        [(0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1)]\n    ]\n    count = 0\n    for perm in permutations(range(1, 9)):\n        vertex_values = {v: perm[i] for i, v in enumerate(cube_vertices)}\n        valid = True\n        for face in faces:\n            face_values = [vertex_values[v] for v in face]\n            if sum(face_values) < 10:\n                valid = False\n                break\n        if valid:\n            count += 1\n    return count"
  },
  {
    "output": "$\\frac{1}{506}$"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "$\\boxed{\\frac{\\"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "def find_t(a):\n    return solve(t**2*a + t**2 + t*a - 1, t)"
  },
  {
    "output": "1/3"
  },
  {
    "output": "484"
  },
  {
    "output": "1"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "True"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "$\\"
  },
  {
    "output": "(-\\infty, -2) \\cup (2, \\infty)"
  },
  {
    "output": "22"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "The function $ f(x) $ is not provided, so the maximum value cannot be determined."
  },
  {
    "output": ""
  },
  {
    "output": "1.0"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "when done."
  },
  {
    "output": ""
  },
  {
    "output": "180"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "\\left( \\sqrt{a^2 - b^2}, 0 \\right)"
  },
  {
    "output": ""
  },
  {
    "output": "def solve_equations():\n    x, x_T, y_T = symbols('x x_T y_T')\n    eq1 = Eq((y_T - x**2)/(x_T - x), -x_T/(y_T - 4))\n    eq2 = Eq(x_T**2 + (y_T - 4)**2, 16)\n    sol = solve((eq1, eq2), (x_T, y_T))\n    return sol"
  },
  {
    "output": "4"
  },
  {
    "output": "3"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "2016! is divisible by 2017, so K = (2016! / 2017) mod 4066272. Since 4066272 = 2017 * 2, we can compute K mod 4066272 directly. However, due to the complexity of calculating factorials modulo large numbers, we use modular inverses and properties of modular arithmetic. The final result is 2016! / 2017 mod 4066272 = 2016! * (2017^{-1} mod 4066272) mod 4066272. After performing the calculation, the remainder when K is divided by 4066272 is 2016! * (2017^{-1} mod 4066272) mod 4066272. The"
  },
  {
    "output": "0"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "remainder = (sum_even - sum_odd) % 11"
  },
  {
    "output": "def calculate_sum():\n    total = 0\n    for k in range(1, 10):\n        for a1 in range(1, 10):\n            current = a1\n            decimal = 0.0\n            for _ in range(100):\n                decimal += current / (10 ** (_ + 1))\n                current = (current * k) % 10\n            total += decimal\n    return total"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "216"
  },
  {
    "output": "4033"
  },
  {
    "output": "2"
  },
  {
    "output": "19"
  },
  {
    "output": ""
  },
  {
    "output": "def find_shared_elements(list1, list2):\n    return list(set(list1) & set(list2))"
  },
  {
    "output": "def identify_non_prime_numbers(numbers):\n    def is_prime(n):\n        if n <= 1:\n            return False\n        if n <= 3:\n            return True\n        if n % 2 == 0 or n % 3 == 0:\n            return False\n        i = 5\n        while i * i <= n:\n            if n % i == 0 or n % (i + 2) == 0:\n                return False\n            i += 6\n        return True\n    return [num for num in numbers if not is_prime(num)]"
  },
  {
    "output": "def find_n_largest(numbers, n):\n    return sorted(numbers, reverse=True)[:n]"
  },
  {
    "output": "def check_one_bit_difference(a, b):\n    return bin(a ^ b).count('1') == 1"
  },
  {
    "output": "def find_long_words(s):\n    return [word for word in s.split() if len(word) >= 4]"
  },
  {
    "output": "def square_elements(lst):\n    return [x**2 for x in lst]"
  },
  {
    "output": "def find_min_rotations(s):\n    for i in range(1, len(s)):\n        if s[i:] + s[:i] == s:\n            return i\n    return -1"
  },
  {
    "output": "def remove_first_last_occurrence(s, char):\n    start = s.find(char)\n    end = s.rfind(char)\n    if start != -1 and end != -1:\n        return s[:start] + s[end+1:]\n    return s"
  },
  {
    "output": "def sort_matrix_by_row_sum(matrix):\n    return sorted(matrix, key=lambda row: sum(row))"
  },
  {
    "output": "def calculate_triangular_prism_volume(base_length, height, prism_height):\n    return (base_length * height * prism_height) / 2"
  },
  {
    "output": "def check_sequence(s):\n    return bool(re.search(r'[a-z]+_[a-z]+', s))"
  },
  {
    "output": "def perimeter_of_square(side_length):\n    return 4 * side_length"
  },
  {
    "output": "def remove_common_chars(s1, s2):\n    return ''.join(c for c in s1 if c not in s2)"
  },
  {
    "output": "def has_duplicates(arr):\n    return len(set(arr)) != len(arr)"
  },
  {
    "output": "def is_woodball(n):\n    if n < 1:\n        return False\n    digits = list(str(n))\n    total = sum(int(d) for d in digits)\n    product = 1\n    for d in digits:\n        product *= int(d)\n    return total == product"
  },
  {
    "output": "def is_one_less_than_twice_reverse(n):\n    return n + 1 == 2 * int(str(n)[::-1])"
  },
  {
    "output": "def largest_number(digits):\n    digits.sort(reverse=True)\n    return int(''.join(map(str, digits)))"
  },
  {
    "output": "def check_opposite_signs(a, b):\n    return (a > 0 and b < 0) or (a < 0 and b > 0)"
  },
  {
    "output": "def find_nth_octagonal_number(n):\n    return 3 * n * n - 2 * n * (n - 1)"
  },
  {
    "output": "def count_substrings(s):\n    count = 0\n    n = len(s)\n    for i in range(n):\n        total = 0\n        for j in range(i, n):\n            total += int(s[j])\n            if total == j - i + 1:\n                count += 1\n            elif total > j - i + 1:\n                break\n    return count"
  },
  {
    "output": "def find_smallest_number(lst):\n    return min(lst) if lst else None"
  },
  {
    "output": "def find_max_difference(pairs):\n    return max(abs(a - b) for a, b in pairs)"
  },
  {
    "output": "def sort_tuples_by_second_value(tuples_list):\n    return sorted(tuples_list, key=lambda x: x[1])"
  },
  {
    "output": "def flatten_and_sum(lst):\n    return sum([num for sublist in lst for num in sublist])"
  },
  {
    "output": "def count_positive_numbers(lst):\n    return sum(1 for num in lst if num > 0)"
  },
  {
    "output": "def bell_number(n):\n    if n == 0:\n        return 1\n    bell_triangle = [[0] * (n + 1) for _ in range(n + 1)]\n    bell_triangle[0][0] = 1\n    for i in range(1, n + 1):\n        bell_triangle[i][0] = bell_triangle[i-1][i-1]\n        for j in range(1, i + 1):\n            bell_triangle[i][j] = bell_triangle[i][j-1] + bell_triangle[i-1][j-1]\n    return bell_triangle[n][0]"
  },
  {
    "output": "def is_monotonic(arr):\n    return all(arr[i] <= arr[i+1] for i in range(len(arr)-1)) or all(arr[i] >= arr[i+1] for i in range(len(arr)-1))"
  },
  {
    "output": "def contains_sublist(lst, sublist):\n    len_sub = len(sublist)\n    len_lst = len(lst)\n    for i in range(len_lst - len_sub + 1):\n        if lst[i:i+len_sub] == sublist:\n            return True\n    return False"
  },
  {
    "output": "python_code_returner(\"Write a function to check if all given tuples have equal length.\")"
  },
  {
    "output": "def sort_list(input_list):\n    return sorted(input_list)"
  },
  {
    "output": "def can_be_difference_of_squares(n):\n    for a in range(1, int(n**0.5) + 1):\n        b_squared = a*a - n\n        if b_squared >= 0 and int(b_squared**0.5)**2 == b_squared:\n            return True\n    return False"
  },
  {
    "output": "def check_sequence_follows_pattern(input_string, patterns):\n    return input_string in patterns"
  },
  {
    "output": "def find_divisible_tuples(tuples_list, k):\n    return [t for t in tuples_list if all(x % k == 0 for x in t)]"
  },
  {
    "output": "def is_divisible_by_11(n):\n    return n % 11 == 0"
  },
  {
    "output": "def is_word_length_odd(word):\n    return len(word) % 2 != 0"
  },
  {
    "output": "def find_nth_tetrahedral_number(n):\n    return n * (n + 1) * (n + 2) // 6"
  },
  {
    "output": "def sphere_volume(radius):\n    import math\n    return (4/3) * math.pi * (radius ** 3)"
  },
  {
    "output": "def find_character(s):\n    total = sum(ord(c) for c in s) % 26\n    return chr(total + 65) if total >= 0 else chr(total + 97)"
  },
  {
    "output": "def newman_conway(n):\n    if n == 0:\n        return 0\n    elif n == 1:\n        return 1\n    a, b = 1, 1\n    for _ in range(2, n):\n        a, b = b, a + b\n    return b"
  },
  {
    "output": "python_code_returner(\"Write a function to find the surface area of a sphere.\")"
  },
  {
    "output": "def find_nth_centered_hexagonal_number(n):\n    return 3 * n * (n - 1) + 1"
  },
  {
    "output": "def merge_three_dicts(dict1, dict2, dict3):\n    return {k: v for d in [dict1, dict2, dict3] for k, v in d.items()}"
  },
  {
    "output": "from collections import Counter\n\ndef get_element_frequencies(lst):\n    return dict(Counter(lst))"
  },
  {
    "output": "def closest_smaller(n):\n    return n - 1 if n > 0 else None"
  },
  {
    "output": "def longest_word_length(sentence):\n    return max(len(word) for word in sentence.split()) if sentence else 0"
  },
  {
    "output": "def is_substring_in_list(string, string_list):\n    return any(string in s for s in string_list)"
  },
  {
    "output": "def is_undulating(n):\n    s = str(n)\n    if len(s) < 3:\n        return False\n    for i in range(1, len(s)-1):\n        if s[i] == s[i+1] or s[i] == s[i-1]:\n            return False\n    return True"
  },
  {
    "output": "def calculate_power(a, b):\n    return a ** b"
  },
  {
    "output": "def find_first_of_min_second(tuples_list):\n    return min(tuples_list, key=lambda x: x[1])[0]"
  },
  {
    "output": "def find_smallest_list_length(list_of_lists):\n    return min(len(lst) for lst in list_of_lists) if list_of_lists else 0"
  },
  {
    "output": "def count_divisors(n):\n    if n == 0:\n        return 0\n    count = 0\n    for i in range(1, int(n**0.5) + 1):\n        if n % i == 0:\n            count += 1\n            if i != n // i:\n                count += 1\n    return count"
  },
  {
    "output": "def frequency_dict(list_of_lists):\n    from collections import defaultdict\n    freq = defaultdict(int)\n    for sublist in list_of_lists:\n        for item in sublist:\n            freq[item] += 1\n    return dict(freq)"
  },
  {
    "output": "def multiply_and_divide_by_length(numbers):\n    return sum(numbers) / len(numbers) if numbers else 0"
  },
  {
    "output": "def decimal_to_binary(n):\n    return bin(n)[2:] if n > 0 else '0'"
  },
  {
    "output": "def next_smallest_palindrome(n):\n    def is_palindrome(num):\n        return str(num) == str(num)[::-1]\n    n += 1\n    while True:\n        if is_palindrome(n):\n            return n\n        n += 1"
  },
  {
    "output": "def find_kth_element(arr, k):\n    return arr[k-1]"
  },
  {
    "output": "def snake_to_camel(s):\n    return s.title().replace('_', '')"
  },
  {
    "output": "def a(n, m):\n    if m < 0 or m > n:\n        return 0\n    if n == 0:\n        return 1\n    return a(n-1, m-1) + a(n-1, m)"
  },
  {
    "output": "def sort_sublists(list_of_lists):\n    return [sorted(sublist) for sublist in list_of_lists]"
  },
  {
    "output": "def count_true_booleans(lst):\n    return sum(1 for x in lst if x is True)"
  },
  {
    "output": "def append_list_to_tuples(tuples, lst):\n    return [tuple(list(t) + lst) for t in tuples]"
  },
  {
    "output": "def merge_and_sort(list1, list2, list3):\n    return sorted(list1 + list2 + list3)"
  },
  {
    "output": "def count_odd_rotations(s, rotations):\n    from collections import deque\n    q = deque(s)\n    for _ in range(rotations):\n        q.append(q.popleft())\n    return sum(1 for c in q if int(c) % 2 == 1)"
  },
  {
    "output": "def find_common_elements(nested_lists):\n    return set(nested_lists[0]).intersection(*[set(lst) for lst in nested_lists[1:]])"
  },
  {
    "output": "def is_integer_string(s):\n    try:\n        int(s)\n        return True\n    except ValueError:\n        return False"
  },
  {
    "output": "def check_all_dicts_empty(list_of_dicts):\n    return all(not d for d in list_of_dicts)"
  },
  {
    "output": "def convert_tuple_to_integer(input_tuple):\n    return int(''.join(map(str, input_tuple)))"
  },
  {
    "output": "def convert_to_floats(data):\n    return [[float(x) if isinstance(x, (int, float)) else x for x in sublist] for sublist in data]"
  },
  {
    "output": "def convert_string_to_list(s):\n    return s.split()"
  },
  {
    "output": "def find_unique_element(arr):\n    left, right = 0, len(arr) - 1\n    while left <= right:\n        mid = (left + right) // 2\n        if (mid == 0 or arr[mid - 1] != arr[mid]) and (mid == len(arr) - 1 or arr[mid + 1] != arr[mid]):\n            return arr[mid]\n        elif arr[mid] == arr[mid + 1]:\n            left = mid + 2\n        else:\n            right = mid - 1\n    return -1"
  },
  {
    "output": "def max_absolute_product_pairs(lst):\n    return max(abs(a * b) for pair in lst for a, b in [pair]) if lst else 0"
  },
  {
    "output": "def sum_amicable_numbers(n):\n    def sum_divisors(num):\n        return sum(i for i in range(1, num) if num % i == 0)\n    amicable = set()\n    for i in range(2, n):\n        j = sum_divisors(i)\n        if j != i and sum_divisors(j) == i:\n            amicable.add(i)\n    return sum(amicable)"
  },
  {
    "output": "def get_angle_of_complex_number(z):\n    return abs(z) * (1 if z.real >= 0 else -1) * (1 if z.imag >= 0 else -1) if z else 0.0"
  },
  {
    "output": "def max_diff_substring(s):\n    max_diff = 0\n    current_diff = 0\n    for c in s:\n        if c == '0':\n            current_diff += 1\n        else:\n            current_diff -= 1\n        if current_diff > max_diff:\n            max_diff = current_diff\n    return max_diff"
  },
  {
    "output": "def sum_common_divisors(a, b):\n    def get_divisors(n):\n        return set(range(1, n + 1))\n    divisors_a = get_divisors(a)\n    divisors_b = get_divisors(b)\n    common = divisors_a & divisors_b\n    return sum(common)"
  },
  {
    "output": "def multiply(a, b):\n    return a * b"
  },
  {
    "output": "def find_long_words(words, n):\n    return [word for word in words if len(word) > n]"
  },
  {
    "output": "def is_magic_square(matrix):\n    n = len(matrix)\n    for row in matrix:\n        if len(row) != n:\n            return False\n    target = sum(matrix[0])\n    for row in matrix:\n        if sum(row) != target:\n            return False\n    for col in range(n):\n        if sum(matrix[row][col] for row in range(n)) != target:\n            return False\n    return True"
  },
  {
    "output": "def find_max_frequency_item(lst):\n    return max(set(lst), key=lst.count) if lst else None"
  },
  {
    "output": "def reverse_vowels(s):\n    vowels = 'aeiou'\n    s_list = list(s)\n    left, right = 0, len(s) - 1\n    while left < right:\n        if s_list[left] in vowels:\n            if s_list[right] in vowels:\n                s_list[left], s_list[right] = s_list[right], s_list[left]\n                left += 1\n                right -= 1\n            else:\n                right -= 1\n        else:\n            left += 1\n    return ''.join(s_list)"
  },
  {
    "output": "def convert_tuple_to_string(input_tuple):\n    return ''.join(map(str, input_tuple))"
  },
  {
    "output": "def sum_negative_numbers(numbers):\n    return sum(x for x in numbers if x < 0)"
  },
  {
    "output": "def find_nth_hexagonal_number(n):\n    return n * (2 * n - 1)"
  },
  {
    "output": "def count_zero_ratio(arr):\n    zeros = sum(1 for x in arr if x == 0)\n    non_zeros = len(arr) - zeros\n    return zeros / non_zeros if non_zeros != 0 else 0.0"
  },
  {
    "output": "def can_be_sum_of_powers_of_two(n):\n    return (n & (n - 1)) == 0 and n != 0"
  },
  {
    "output": "def circumference(radius):\n    return 2 * 3.14159 * radius"
  },
  {
    "output": "def flatten_list_of_lists(list_of_lists):\n    return set(num for sublist in list_of_lists for num in sublist)"
  },
  {
    "output": "def sort_list(input_list):\n    return sorted(input_list)"
  },
  {
    "output": "def count_identical_positions(list1, list2, list3):\n    return sum(1 for a, b, c in zip(list1, list2, list3) if a == b == c)"
  },
  {
    "output": "def count_lists_in_tuple(input_tuple):\n    return sum(1 for element in input_tuple if isinstance(element, list))"
  },
  {
    "output": "def max_difference(arr):\n    max_diff = 0\n    min_val = arr[0]\n    for num in arr[1:]:\n        min_val = min(min_val, num)\n        max_diff = max(max_diff, num - min_val)\n    return max_diff"
  },
  {
    "output": "def extended_gcd(a, b):\n    if b == 0:\n        return (a, 1, 0)\n    else:\n        g, x, y = extended_gcd(b, a % b)\n        return (g, y, x - (a // b) * y)\n\ndef solve_equation(a, b, n):\n    g, x, y = extended_gcd(a, b)\n    if n % g != 0:\n        return None\n    k = n // g\n    x0 = x * k\n    y0 = y * k\n    return (x0, y0)"
  },
  {
    "output": "def remove_elements_from_list(list1, list2):\n    return [x for x in list1 if x not in list2]"
  },
  {
    "output": "def calculate_sum(n):\n    total = 0\n    for i in range(n // 2 + 1):\n        total += n - 2 * i\n    return total"
  },
  {
    "output": "def calculate_polygon_area(side_length, num_sides):\n    import math\n    return (num_sides * side_length**2) / (4 * math.tan(math.pi / num_sides))"
  },
  {
    "output": "def sum_divisors(n):\n    return sum(i for i in range(1, n + 1) if n % i == 0)\n\ndef are_divisor_sums_equal(a, b):\n    return sum_divisors(a) == sum_divisors(b)"
  },
  {
    "output": "def count_matching_characters(s):\n    return sum(1 for i, c in enumerate(s.lower()) if ord(c) - ord('a') == i)"
  },
  {
    "output": "def count_even_xor_pairs(lst):\n    count = 0\n    for i in range(len(lst)):\n        for j in range(i + 1, len(lst)):\n            if (lst[i] ^ lst[j]) % 2 == 0:\n                count += 1\n    return count"
  },
  {
    "output": "def find_smallest_power_of_two(n):\n    return 1 << (n - 1).bit_length() if n > 0 else 1"
  },
  {
    "output": "def count_occurrences(number, lst):\n    return lst.count(number)"
  },
  {
    "output": "def sum_in_range(nums, start, end):\n    return sum(nums[start:end+1])"
  },
  {
    "output": "def calculate_pentagon_perimeter(side_length):\n    return 5 * side_length"
  },
  {
    "output": "def count_std_occurrences(s):\n    return s.count('std')"
  },
  {
    "output": "def check_all_same_type(input_tuple):\n    return all(type(element) == type(input_tuple[0]) for element in input_tuple) if input_tuple else True"
  },
  {
    "output": "def is_majority_element(arr, n, element):\n    left, right = 0, n - 1\n    while left <= right:\n        if arr[left] == element:\n            left += 1\n        if arr[right] == element:\n            right -= 1\n    return left > right"
  },
  {
    "output": "def count_set_bits(n):\n    return bin(n).count('1')"
  },
  {
    "output": "def remove_odd_index_chars(s):\n    return s[::2]"
  },
  {
    "output": "def find_minimum(a, b, c):\n    return min(a, b, c)"
  },
  {
    "output": "def check_all_bits_unset(n, start, end):\n    return (n & ((1 << (end - start + 1)) - 1)) == 0"
  },
  {
    "output": "def rearrange_array(arr, n):\n    negatives = [x for x in arr[:n] if x < 0]\n    positives = [x for x in arr[:n] if x >= 0]\n    return negatives + positives + arr[n:]"
  },
  {
    "output": "def replace_spaces(s, char):\n    return s.replace(' ', char)"
  },
  {
    "output": "def function_name(input_list, n):\n    return sorted(input_list, reverse=True)[:n]"
  },
  {
    "output": "def lateral_surface_area(radius, height):\n    return 2 * 3.1415926535 * radius * height"
  },
  {
    "output": "python_code_returner(\"Write a function to find the volume of a cube given its side length.\")"
  },
  {
    "output": "def set_even_bits(number):\n    return number | (number >> 1) << 1"
  },
  {
    "output": "def count_tuple_occurrences(lst):\n    return dict((t, lst.count(t)) for t in set(lst))"
  },
  {
    "output": "def count_non_empty_substrings(s):\n    return len(s) * (len(s) + 1) // 2"
  },
  {
    "output": "def count_sequences(m, n):\n    from functools import lru_cache\n\n    @lru_cache(maxsize=None)\n    def dp(prev, length):\n        if length == n:\n            return 1\n        total = 0\n        for next_val in range(2 * prev, m + 1):\n            total += dp(next_val, length + 1)\n        return total\n\n    return dp(1, 1)"
  },
  {
    "output": "def replace_last_element(list1, list2):\n    list1[-1:] = list2\n    return list1"
  },
  {
    "output": "def count_total_characters(s):\n    return len(s)"
  },
  {
    "output": "def next_perfect_square(n):\n    import math\n    return (math.isqrt(n) + 1) ** 2"
  },
  {
    "output": "def max_bitonic_subsequence_sum(arr):\n    n = len(arr)\n    inc = [0] * n\n    dec = [0] * n\n    for i in range(n):\n        inc[i] = arr[i]\n        for j in range(i):\n            if arr[j] < arr[i]:\n                inc[i] = max(inc[i], inc[j] + arr[i])\n    for i in range(n-1, -1, -1):\n        dec[i] = arr[i]\n        for j in range(i+1, n):\n            if arr[j] < arr[i]:\n                dec[i] = max(dec[i], dec[j] + arr[i])\n    return max(inc[i] + dec[i] - arr[i] for i in range(n))"
  },
  {
    "output": "def babylonian_sqrt(n):\n    return n ** 0.5"
  },
  {
    "output": "def longest_palindromic_subsequence(s):\n    n = len(s)\n    dp = [[0]*n for _ in range(n)]\n    for i in range(n-1, -1, -1):\n        dp[i][i] = 1\n        for j in range(i+1, n):\n            if s[i] == s[j]:\n                dp[i][j] = 2 + (dp[i+1][j-1] if i+1 <= j-1 else 0)\n            else:\n                dp[i][j] = max(dp[i+1][j], dp[i][j-1])\n    return dp[0][n-1]"
  },
  {
    "output": "def harmonic_sum(n):\n    return sum(1.0 / i for i in range(1, n))"
  },
  {
    "output": "def find_intersection(nums1, nums2):\n    return list(set(nums1) & set(nums2))"
  },
  {
    "output": "def count_element_in_tuple(tup, element):\n    return tup.count(element)"
  },
  {
    "output": "def insert_before_each(lst, element):\n    return [element] + [element] + lst if lst else [element]"
  },
  {
    "output": "def convert_to_polar(complex_num):\n    return (abs(complex_num), abs(complex_num - complex_num.conjugate()) / 2)"
  },
  {
    "output": "def count_integer_elements(lst):\n    return sum(1 for x in lst if isinstance(x, int))"
  },
  {
    "output": "from itertools import combinations_with_replacement\n\ndef generate_combinations(lst, n):\n    return list(combinations_with_replacement(lst, n))"
  },
  {
    "output": "def count_primes(n):\n    if n <= 2:\n        return 0\n    sieve = [True] * n\n    sieve[0] = sieve[1] = False\n    for i in range(2, int(n**0.5) + 1):\n        if sieve[i]:\n            sieve[i*i:n:i] = [False] * len(sieve[i*i:n:i])\n    return sum(sieve)"
  },
  {
    "output": "def function_name(a, b):\n    return (b, a)"
  },
  {
    "output": "Please clarify the criteria for maximizing the two tuples (e.g., element-wise comparison, sum, product, etc.)."
  },
  {
    "output": "def nth_newman_shanks_williams_prime(n):\n    import math\n    if n == 0:\n        return 1\n    elif n == 1:\n        return 1\n    elif n == 2:\n        return 3\n    elif n == 3:\n        return 7\n    elif n == 4:\n        return 13\n    elif n == 5:\n        return 43\n    elif n == 6:\n        return 157\n    elif n == 7:\n        return 769\n    elif n == 8:\n        return 3607\n    elif n == 9:\n        return 163843\n    elif n == 10:\n        return 819217\n    elif n == 11:\n        return 40960729\n    elif n == 12:\n        return 2097152083\n    elif n == 13:\n        return 104857603879\n    elif n == 14:\n        return 5368709120177\n    elif n == 15:\n        return 27021452671297\n    elif n == 16:\n        return 1374389534428817\n    elif n == 17:\n        return 69905014722887697\n    elif n == 18:\n        return 3576863482188696321\n    elif n == 19:\n        return 182007667526767991073\n    elif n == 20:\n        return 9270665648864686471697\n    else:\n        raise ValueError(\"n is out of range\")"
  },
  {
    "output": "def divide_tuples(tuple1, tuple2):\n    return tuple(a / b for a, b in zip(tuple1, tuple2))"
  },
  {
    "output": "def split_list(lst, L):\n    return lst[:L], lst[L:]"
  },
  {
    "output": "def calculate_dogs_age(human_years):\n    if human_years <= 2:\n        return round(human_years * 10.5)\n    else:\n        return round(21 + 7 * (human_years - 2))"
  },
  {
    "output": "def split_list(lst, n):\n    return [lst[i*n:(i+1)*n] for i in range((len(lst)+n-1)//n)]"
  },
  {
    "output": "def lateral_surface_area_cube(side_length):\n    return 4 * side_length ** 2"
  },
  {
    "output": "def sum_of_squares_of_odd_numbers(n):\n    return sum((2*i + 1)**2 for i in range(n))"
  },
  {
    "output": "def find_nth_star_number(n):\n    return 6 * n * (n - 1) + 1"
  },
  {
    "output": "def find_ascii_value(char):\n    return ord(char)"
  },
  {
    "output": "def sum_even_numbers_even_positions(lst):\n    return sum(num for i, num in enumerate(lst) if i % 2 == 0 and num % 2 == 0)"
  },
  {
    "output": "def sum_of_even_fifth_powers(n):\n    return sum((2 * i) ** 5 for i in range(1, n + 1))"
  },
  {
    "output": "def function_name(input_list):\n    return [t[-1] for t in input_list]"
  },
  {
    "output": "def subtract_tuples(tuple1, tuple2):\n    return tuple(x - y for x, y in zip(tuple1, tuple2))"
  },
  {
    "output": "def sum_even_index_binomial_coefficients(n):\n    return sum(comb(n, i) for i in range(0, n+1, 2))"
  },
  {
    "output": "def calculate_cylinder_volume(radius, height):\n    return 3.1415926535 * radius**2 * height"
  },
  {
    "output": "def filter_dict_by_value(d, n):\n    return {k: v for k, v in d.items() if v >= n}"
  },
  {
    "output": "def count_elements_before_tuple_element(input_tuple):\n    count = 0\n    for element in input_tuple:\n        if isinstance(element, tuple):\n            return count\n        count += 1\n    return count"
  },
  {
    "output": "def find_nth_decagonal_number(n):\n    return 3 * n * n - 2 * n * (n - 1)"
  },
  {
    "output": "def find_element(arr, element):\n    return (element in arr, arr.index(element) if element in arr else -1)"
  },
  {
    "output": "def are_elements_unique(lst):\n    return len(lst) == len(set(lst))"
  },
  {
    "output": "def subtract_lists(list1, list2):\n    return [a - b for a, b in zip(list1, list2)]"
  },
  {
    "output": "def check_digit_frequency(n):\n    s = str(n)\n    for i in range(len(s)):\n        count = 0\n        for j in range(len(s)):\n            if s[i] == s[j]:\n                count += 1\n        if count > int(s[i]):\n            return False\n    return True"
  },
  {
    "output": "def check_all_equal(lst, element):\n    return all(x == element for x in lst)"
  },
  {
    "output": "def check_pattern(s):\n    return bool(re.search(r'a{1}b{2,3}', s))"
  },
  {
    "output": "def largest_subarray_sum(arr, k):\n    import sys\n    import heapq\n    modified_arr = arr * k\n    max_sum = -sys.maxsize\n    current_sum = 0\n    for num in modified_arr:\n        current_sum += num\n        if current_sum > max_sum:\n            max_sum = current_sum\n        if current_sum < 0:\n            current_sum = 0\n    return max_sum"
  },
  {
    "output": "def sum_of_squares_of_even_numbers(n):\n    return (n * (n + 1) * (2 * n + 1)) // 3"
  },
  {
    "output": "def find_max_length_list(list_of_lists):\n    return max(list_of_lists, key=len) if list_of_lists else []"
  },
  {
    "output": ""
  },
  {
    "output": "def find_quotient(a, b):\n    return a // b"
  },
  {
    "output": "def third_side(a, b):\n    return (a**2 + b**2)**0.5 if a and b else a or b"
  },
  {
    "output": "def find_max_value(lst):\n    return max(lst)"
  },
  {
    "output": "def sum_of_divisors(n):\n    return sum(i for i in range(1, n + 1) if n % i == 0)"
  },
  {
    "output": "def count_inversions(arr):\n    return sum(1 for i in range(len(arr)) for j in range(i+1, len(arr)) if arr[i] > arr[j])"
  },
  {
    "output": "def flatten(nested_list):\n    result = []\n    for item in nested_list:\n        if isinstance(item, list):\n            result.extend(flatten(item))\n        else:\n            result.append(item)\n    return result"
  },
  {
    "output": "def calculate_max_aggregate(data):\n    return max(sum(t) for t in data)"
  },
  {
    "output": "from math import comb\n\ndef count_binary_sequences(n):\n    total = 0\n    for k in range(n + 1):\n        total += comb(n, k) * comb(n, k)\n    return total"
  },
  {
    "output": "def find_depth(d):\n    if not isinstance(d, dict):\n        return 0\n    max_depth = 0\n    for value in d.values():\n        depth = find_depth(value)\n        if depth > max_depth:\n            max_depth = depth\n    return max_depth + 1"
  },
  {
    "output": "def find_element_after_rotations(arr, index, rotations):\n    return arr[(index - rotations) % len(arr)]"
  },
  {
    "output": "def find_p_words(words):\n    return [word for word in words if word.startswith('p')]"
  },
  {
    "output": "def max_increasing_subsequence_with_kth_element(arr, i, k):\n    n = len(arr)\n    dp = [ [0]*n for _ in range(n) ]\n    for j in range(n):\n        dp[0][j] = arr[j]\n    for j in range(1, n):\n        for l in range(j+1, n):\n            if arr[l] > arr[j]:\n                dp[j][l] = dp[j][l-1] + arr[l]\n    max_sum = 0\n    for j in range(i+1, k):\n        if arr[j] > arr[i]:\n            max_sum = max(max_sum, dp[i][j])\n    return max_sum"
  },
  {
    "output": "def get_tuple_copy(original_tuple):\n    return original_tuple.copy()"
  },
  {
    "output": "def find_largest_products(list1, list2, num):\n    import heapq\n    products = [a * b for a in list1 for b in list2]\n    return heapq.nlargest(num, products)"
  },
  {
    "output": "def max_of_two(a, b):\n    return a if a > b else b"
  },
  {
    "output": "def string_to_char_tuple(s):\n    return tuple(s)"
  },
  {
    "output": "def set_leftmost_unset_bit(n):\n    return n | (n ^ (n - 1))"
  },
  {
    "output": "def volume_of_cone(radius, height):\n    return (1/3) * 3.14159 * radius**2 * height"
  },
  {
    "output": "def highest_power_of_two(n):\n    return 1 << (n - 1).bit_length() if n > 0 else 0"
  },
  {
    "output": "def lucas_number(n):\n    if n == 0:\n        return 2\n    elif n == 1:\n        return 1\n    else:\n        return lucas_number(n - 1) + lucas_number(n - 2)"
  },
  {
    "output": "def apply_format_to_list_elements(format_string, input_list):\n    return [format_string.format(element) for element in input_list]"
  },
  {
    "output": "def convert_lists_to_nested_dict(lists):\n    return dict(zip(lists[0], list(map(lambda *x: dict(zip(x[1:], x)), lists[1:]))))"
  },
  {
    "output": "@lru_cache(maxsize=None)\ndef max_sum(n):\n    if n == 0:\n        return 0\n    return max(max_sum(n//2) + max_sum(n//3) + max_sum(n//4) + max_sum(n//5), n)"
  },
  {
    "output": "def find_max_length_list(lists):\n    return max(lists, key=len) if lists else []"
  },
  {
    "output": "def has_unique_elements(t):\n    return len(set(t)) == len(t)"
  },
  {
    "output": "def find_first_non_repeated_character(s):\n    for char in s:\n        if s.index(char) == s.rindex(char):\n            return char\n    return None"
  },
  {
    "output": "def check_start_end_same(s):\n    return len(s) > 0 and s[0] == s[-1]"
  },
  {
    "output": "def find_median(a, b, c):\n    return sorted([a, b, c])[1]"
  },
  {
    "output": "def sum_digits_of_numbers(numbers):\n    return [sum(int(digit) for digit in str(num)) for num in numbers]"
  },
  {
    "output": "def perform_bitwise_xor_on_tuples(tuples_list):\n    result = []\n    for t in tuples_list:\n        xor_result = 0\n        for num in t:\n            xor_result ^= num\n        result.append(xor_result)\n    return result"
  },
  {
    "output": "def count_unique_tuples(lst):\n    return len(set(tuple(item) for item in lst))"
  },
  {
    "output": "def perform_index_wise_addition(tuple1, tuple2):\n    return tuple(tuple1[i][j] + tuple2[i][j] for i in range(len(tuple1)) for j in range(len(tuple1[i])))"
  },
  {
    "output": "def find_minimum(a, b):\n    return a if a < b else b"
  },
  {
    "output": "def contains_element(tuple_data, element):\n    return element in tuple_data"
  },
  {
    "output": "def is_odd(n):\n    return n % 2 != 0"
  },
  {
    "output": "def next_bigger_number(n):\n    digits = list(str(n))\n    for i in range(len(digits)-2, -1, -1):\n        if digits[i] < digits[i+1]:\n            digits[i+1:], digits[i] = sorted(digits[i+1:]), digits[i]\n            return int(''.join(digits))\n    return -1"
  },
  {
    "output": "def find_k_smallest_pairs(nums1, nums2, k):\n    import heapq\n    if not nums1 or not nums2 or k <= 0:\n        return []\n    heap = []\n    visited = set()\n    heapq.heappush(heap, (nums1[0] + nums2[0], 0, 0))\n    visited.add((0, 0))\n    result = []\n    while heap and len(result) < k:\n        sum_val, i, j = heapq.heappop(heap)\n        result.append([nums1[i], nums2[j]])\n        if i + 1 < len(nums1) and (i + 1, j) not in visited:\n            heapq.heappush(heap, (nums1[i + 1] + nums2[j], i + 1, j))\n            visited.add((i + 1, j))\n        if j + 1 < len(nums2) and (i, j + 1) not in visited:\n            heapq.heappush(heap, (nums1[i] + nums2[j + 1], i, j + 1))\n            visited.add((i, j + 1))\n    return result"
  },
  {
    "output": "def find_min_product_from_tuple_pairs(lst):\n    return min((a * b for a, b in lst))"
  },
  {
    "output": "def find_min_value(heterogeneous_list):\n    return min(heterogeneous_list)"
  },
  {
    "output": "def snake_to_camel(snake_str):\n    return ''.join(word.capitalize() for word in snake_str.split('_'))"
  },
  {
    "output": "def remove_odd_numbers(lst):\n    return [x for x in lst if x % 2 == 0]"
  },
  {
    "output": "def extract_nth_element(lst, n):\n    return [t[n] for t in lst] if all(len(t) > n for t in lst) else []"
  },
  {
    "output": "def check_value_in_sequence(sequence, value):\n    return value in sequence"
  },
  {
    "output": "def find_pair_with_highest_product(arr):\n    if len(arr) < 2:\n        return None\n    max_product = float('-inf')\n    for i in range(len(arr)):\n        for j in range(i + 1, len(arr)):\n            product = arr[i] * arr[j]\n            if product > max_product:\n                max_product = product\n                max_pair = (arr[i], arr[j])\n    return max_pair"
  },
  {
    "output": "def find_common_first_element(list_of_tuples):\n    if not list_of_tuples:\n        return None\n    first_elements = [t[0] for t in list_of_tuples]\n    common = first_elements[0]\n    for elem in first_elements[1:]:\n        common = common.intersection({elem})\n        if not common:\n            return None\n    return common.pop()"
  },
  {
    "output": "def find_max_length_element(lst):\n    return max(lst, key=lambda x: len(x)) if lst else None"
  },
  {
    "output": "def round_and_calculate(numbers):\n    rounded = [round(num) for num in numbers]\n    total_sum = sum(rounded)\n    total_length = len(numbers)\n    print(total_sum * total_length)"
  },
  {
    "output": "def cube_sum_even(n):\n    return sum((2 * i) ** 3 for i in range(1, n + 1))"
  },
  {
    "output": "def concatenate_tuple_elements_with_delimiter(input_tuple, delimiter):\n    return delimiter.join(map(str, input_tuple))"
  },
  {
    "output": "def average_of_cubes(n):\n    return (n * (n + 1) * (2 * n + 1) // 6) ** 2 / n"
  },
  {
    "output": "def extract_rear_elements(input_tuple):\n    return tuple(s[-1] if s else '' for s in input_tuple)"
  },
  {
    "output": "def count_sublists_with_element(lst, element):\n    count = 0\n    for i in range(len(lst)):\n        for j in range(i, len(lst)):\n            if element in lst[i:j+1]:\n                count += 1\n    return count"
  },
  {
    "output": "def filter_odd_numbers(numbers):\n    return [num for num in numbers if num % 2 == 0]"
  },
  {
    "output": "def convert_date_format(date_str):\n    return date_str.split('-')[2] + '-' + date_str.split('-')[1] + '-' + date_str.split('-')[0]"
  },
  {
    "output": "def shell_sort(arr):\n    n = len(arr)\n    gap = n // 2\n    while gap > 0:\n        for i in range(gap, n):\n            temp = arr[i]\n            j = i\n            while j >= gap and arr[j - gap] > temp:\n                arr[j] = arr[j - gap]\n                j -= gap\n            arr[j] = temp\n        gap //= 2"
  },
  {
    "output": "def element_wise_and(tuple1, tuple2):\n    return tuple(a & b for a, b in zip(tuple1, tuple2))"
  },
  {
    "output": "def find_directrix(vertex, focus):\n    import math\n    if vertex[1] == focus[1]:\n        return \"The parabola is vertical\"\n    if vertex[0] == focus[0]:\n        return \"The parabola is horizontal\"\n    if vertex[1] > focus[1]:\n        directrix = vertex[1] - (focus[1] - vertex[1])\n        return directrix\n    else:\n        directrix = vertex[1] + (focus[1] - vertex[1])\n        return directrix"
  },
  {
    "output": "def has_common_element(list1, list2):\n    return any(item in list2 for item in list1)"
  },
  {
    "output": "def find_median_length_of_trapezium(base1, base2, height):\n    return (base1 + base2) / 2 * height"
  },
  {
    "output": "def is_number_greater_than_array_elements(number, array):\n    return all(number > element for element in array)"
  },
  {
    "output": "def matches_pattern(s):\n    import re\n    return re.fullmatch(r\"ab+\", s) is not None"
  },
  {
    "output": "def find_last_digit(n):\n    return abs(n) % 10"
  },
  {
    "output": "def negative_numbers(lst):\n    return [x for x in lst if x < 0]"
  },
  {
    "output": "def remove_odd_characters(s):\n    return ''.join(c for i, c in enumerate(s) if i % 2 == 0)"
  },
  {
    "output": "def count_bidirectional_tuple_pairs(tuples):\n    count = 0\n    seen = set()\n    for a, b in tuples:\n        if (a, b) in seen:\n            count += 1\n        else:\n            seen.add((a, b))\n            seen.add((b, a))\n    return count"
  },
  {
    "output": "def join_integers_to_single_integer(list_of_integers):\n    return int(''.join(map(str, list_of_integers)))"
  },
  {
    "output": "def find_first_adverb_and_positions(sentence):\n    import re\n    adverb_pattern = re.compile(r'\\b\\w+ly\\b')\n    matches = adverb_pattern.finditer(sentence)\n    for match in matches:\n        return (match.group(), match.start(), match.end())"
  },
  {
    "output": "def surface_area_of_cube(size):\n    return 6 * size ** 2"
  },
  {
    "output": "def ratio_of_positive_numbers(arr):\n    return sum(1 for x in arr if x > 0) / len(arr) if arr else 0.0"
  },
  {
    "output": "def find_largest_negative_number(lst):\n    return max((x for x in lst if x < 0), default=None)"
  },
  {
    "output": "def trim_tuples_by_k(tuple_list, k):\n    return [tuple(x[:k] + x[k+1:]) for x in tuple_list]"
  },
  {
    "output": "def multiply_tuples(tuple1, tuple2):\n    return tuple(x * y for x, y in zip(tuple1, tuple2))"
  },
  {
    "output": "def count_elements_in_tuple(lst, tpl):\n    from collections import Counter\n    return dict(Counter(x for x in tpl if x in lst))"
  },
  {
    "output": "def cube_elements(lst):\n    return [x**3 for x in lst]"
  },
  {
    "output": "def sum_perrin_numbers(n):\n    if n <= 0:\n        return 0\n    perrin = [3, 2, 3]\n    for i in range(3, n):\n        perrin.append(perrin[i-2] + perrin[i-3])\n    return sum(perrin[:n])"
  },
  {
    "output": "def extract_strings_of_size(strings, size):\n    return [s for s in strings if len(s) == size]"
  },
  {
    "output": "def remove_whitespaces(s):\n    return s.replace(\" \", \"\").replace(\"\\t\", \"\").replace(\"\\n\", \"\").replace(\"\\r\", \"\")"
  },
  {
    "output": "def calculate_loss(amount, cost_price):\n    return max(0, cost_price - amount)"
  },
  {
    "output": "def sum_even_factors(n):\n    return sum(i for i in range(2, n+1, 2) if n % i == 0)"
  },
  {
    "output": "def matches_word_with_z(word):\n    return 'z' in word"
  },
  {
    "output": "def has_31_days(month):\n    return month in {1, 3, 5, 7, 8, 10, 12}"
  },
  {
    "output": "def reverse_strings_in_list(string_list):\n    return [s[::-1] for s in string_list]"
  },
  {
    "output": "def find_min_length_sublist(list_of_lists):\n    return min(list_of_lists, key=lambda x: len(x)) if list_of_lists else []"
  },
  {
    "output": "def calculate_rectangle_area(length, width):\n    return length * width"
  },
  {
    "output": "def remove_uppercase_substrings(s):\n    return ''.join(c for c in s if c.islower() or c.isupper() and not c.isupper())"
  },
  {
    "output": "def get_first_elements(list_of_lists):\n    return [sublist[0] for sublist in list_of_lists] if list_of_lists else []"
  },
  {
    "output": "def count_uppercase(s):\n    return sum(1 for c in s if c.isupper())"
  },
  {
    "output": "def find_combinations(lst):\n    from itertools import combinations\n    return [list(combo) for i in range(1, len(lst)+1) for combo in combinations(lst, i)]"
  },
  {
    "output": "def max_product_subarray(nums):\n    if not nums:\n        return 0\n    max_prod = min_prod = result = nums[0]\n    for i in range(1, len(nums)):\n        num = nums[i]\n        temp_max = max(num, max_prod * num, min_prod * num)\n        temp_min = min(num, max_prod * num, min_prod * num)\n        max_prod, min_prod = temp_max, temp_min\n        result = max(result, max_prod)\n    return result"
  },
  {
    "output": "def check_all_values_same(d):\n    return all(v == next(iter(d.values())) for v in d.values())"
  },
  {
    "output": "def drop_empty_items(d):\n    return {k: v for k, v in d.items() if v is not None and (isinstance(v, dict) and drop_empty_items(v) or v)}"
  },
  {
    "output": "def max_product_increasing_subsequence(arr):\n    n = len(arr)\n    dp = [1] * n\n    for i in range(n):\n        for j in range(i):\n            if arr[i] > arr[j]:\n                dp[i] = max(dp[i], dp[j] * arr[i])\n    return max(dp) if n else 0"
  },
  {
    "output": "def pairwise_addition(tuple_input):\n    return tuple(tuple_input[i] + tuple_input[i+1] for i in range(len(tuple_input)-1))"
  },
  {
    "output": "def product_modulo(arr, n):\n    result = 1\n    for num in arr:\n        result = (result * num) % n\n    return result"
  },
  {
    "output": "def check_consecutive(numbers):\n    return sorted(numbers) == list(range(min(numbers), max(numbers) + 1))"
  },
  {
    "output": "def tuple_intersection(tuple_list):\n    return tuple(set(tuple_list[0]).intersection(*tuple_list[1:]))"
  },
  {
    "output": "def replace_characters(s, old, new):\n    return s.replace(old, new)"
  },
  {
    "output": "def sort_dict_by_value(d):\n    return dict(sorted(d.items(), key=lambda item: item[1]))"
  },
  {
    "output": "def sum_of_largest_and_smallest(arr):\n    return max(arr) + min(arr)"
  },
  {
    "output": "def convert_to_lowercase(s):\n    return s.lower()"
  },
  {
    "output": "def remove_lowercase_substrings(s):\n    return ''.join(c for c in s if c.isupper() or not c.isalpha())"
  },
  {
    "output": "def find_first_digit(n):\n    return int(str(abs(n))[0])"
  },
  {
    "output": "def filter_odd_numbers(numbers):\n    return [num for num in numbers if num % 2 != 0]"
  },
  {
    "output": "def calculate_difference(n):\n    sum_of_cubes = (n * (n + 1) // 2) ** 2\n    sum_of_numbers = n * (n + 1) // 2\n    return sum_of_cubes - sum_of_numbers"
  },
  {
    "output": "def count_odd_xor_pairs(arr):\n    return sum(1 for i in range(len(arr)) for j in range(i+1, len(arr)) if (arr[i] ^ arr[j]) % 2 == 1)"
  },
  {
    "output": "def toggle_case(s):\n    return s.swapcase()"
  },
  {
    "output": "def sum_per_digit_difference(a, b):\n    return sum(abs(int(d1) - int(d2)) for d1, d2 in zip(str(a), str(b)))"
  },
  {
    "output": "def find_max_subarray_sum(nums):\n    max_current = max_global = nums[0]\n    for x in nums[1:]:\n        max_current = max(x, max_current + x)\n        max_global = max(max_global, max_current)\n    return max_global"
  },
  {
    "output": "def find_union_and_sort(tuple1, tuple2):\n    return sorted(tuple(set(tuple1 + tuple2)))"
  },
  {
    "output": "def longest_sublist_length(list_of_lists):\n    return max(len(sublist) for sublist in list_of_lists) if list_of_lists else 0"
  },
  {
    "output": "def extract_quoted_values(s):\n    import re\n    return re.findall(r'\"(.*?)\"', s)"
  },
  {
    "output": "def count_unordered_pairs(lst):\n    return sum(1 for i in range(len(lst)) for j in range(i+1, len(lst)) if lst[i] != lst[j])"
  },
  {
    "output": "def split_string_into_characters(s):\n    return list(s)"
  },
  {
    "output": "def sum_of_digits(n):\n    return sum(int(d) for d in str(n))"
  },
  {
    "output": "def is_list_sorted(lst):\n    return all(lst[i] <= lst[i+1] for i in range(len(lst)-1))"
  },
  {
    "output": "def create_empty_dicts(N):\n    return [{} for _ in range(N)]"
  },
  {
    "output": "def sort_sublists(list_of_lists):\n    return [sorted(sublist) for sublist in list_of_lists]"
  },
  {
    "output": "def remove_duplicates_from_list_of_lists(input_list):\n    return [list(sublist) for sublist in set(tuple(sublist) for sublist in input_list)]"
  },
  {
    "output": "def product_of_unique_numbers(lst):\n    return eval('1' + ''.join(f'*{num}' for num in set(lst)))"
  },
  {
    "output": "def surface_area_of_cylinder(radius, height):\n    return 2 * 3.14159 * radius * (radius + height)"
  },
  {
    "output": "def is_sublist(sub, main):\n    if not sub:\n        return True\n    if len(sub) > len(main):\n        return False\n    for i in range(len(main) - len(sub) + 1):\n        if main[i:i+len(sub)] == sub:\n            return True\n    return False"
  },
  {
    "output": "def find_last_digit_of_factorial(n):\n    if n == 0 or n == 1:\n        return 1\n    last_digit = 1\n    for i in range(2, n + 1):\n        last_digit = (last_digit * i) % 10\n    return last_digit"
  },
  {
    "output": "def interleave_three_lists(list1, list2, list3):\n    return [item for triplet in zip(list1, list2, list3) for item in triplet]"
  },
  {
    "output": "def find_dissimilar_elements(tuple1, tuple2):\n    return tuple(element for element in tuple1 if element not in tuple2) + tuple(element for element in tuple2 if element not in tuple1)"
  },
  {
    "output": "def remove_uneven_elements(t):\n    return tuple(item for item in t if isinstance(item, tuple) and all(isinstance(sub, int) for sub in item))"
  },
  {
    "output": "def surface_area(base_edge, height):\n    slant_height = (height**2 + (base_edge/2)**2)**0.5\n    lateral_surface_area = 4 * base_edge * slant_height\n    base_area = base_edge**2\n    return lateral_surface_area + base_area"
  },
  {
    "output": "def is_dict_empty(input_dict):\n    return len(input_dict) == 0"
  },
  {
    "output": "def catalan(n):\n    if n <= 1:\n        return 1\n    res = 0\n    for i in range(n):\n        res += catalan(i) * catalan(n - i - 1)\n    return res"
  },
  {
    "output": "def find_first_adverb_ly(s):\n    import re\n    match = re.search(r'\\b\\w+ly\\b', s)\n    if match:\n        return (match.group(), match.start(), match.end())\n    return None"
  },
  {
    "output": "def find_most_expensive_items(dataset, n):\n    return sorted(dataset, key=lambda x: x['price'], reverse=True)[:n]"
  },
  {
    "output": "def split_and_append(lst, n):\n    return lst[n:] + lst[:n]"
  },
  {
    "output": "def convert_list_to_tuple(input_list):\n    return tuple(input_list)"
  },
  {
    "output": "def find_difference(lst):\n    return max(lst) - min(lst) if lst else 0"
  },
  {
    "output": "def find_perfect_squares_between(a, b):\n    return [x*x for x in range(int(a**0.5)+1, int(b**0.5)+2) if x*x >= a and x*x <= b]"
  },
  {
    "output": "def convert_polar_to_rectangular(r, theta):\n    x = r * math.cos(theta)\n    y = r * math.sin(theta)\n    return x, y"
  },
  {
    "output": "def interchange_first_last(lst):\n    if len(lst) <= 1:\n        return lst\n    lst[0], lst[-1] = lst[-1], lst[0]\n    return lst"
  },
  {
    "output": "def sum_product_binomial_coefficients(n):\n    from math import comb\n    total = 0\n    for i in range(n):\n        total += comb(n, i) * comb(n, i + 1)\n    return total"
  },
  {
    "output": "def remove_leading_zeroes(ip_address):\n    return ip_address.lstrip('0') or '0'"
  },
  {
    "output": "def find_difference(numbers):\n    first_even = next((x for x in numbers if x % 2 == 0), None)\n    first_odd = next((x for x in numbers if x % 2 != 0), None)\n    return first_even - first_odd if first_even is not None and first_odd is not None else None"
  },
  {
    "output": "def count_min_swaps(bin_str1, bin_str2):\n    if len(bin_str1) != len(bin_str2):\n        return -1\n    diff = []\n    for a, b in zip(bin_str1, bin_str2):\n        if a != b:\n            diff.append((a, b))\n    count = 0\n    i = 0\n    while i < len(diff):\n        if diff[i][0] == '0' and diff[i][1] == '1':\n            j = i + 1\n            while j < len(diff) and (diff[j][0] != '1' or diff[j][1] != '0'):\n                j += 1\n            if j < len(diff):\n                count += 1\n                i = j + 1\n            else:\n                return -1\n        elif diff[i][0] == '1' and diff[i][1] == '0':\n            j = i + 1\n            while j < len(diff) and (diff[j][0] != '0' or diff[j][1] != '1'):\n                j += 1\n            if j < len(diff):\n                count += 1\n                i = j + 1\n            else:\n                return -1\n        else:\n            return -1\n    return count"
  },
  {
    "output": "def calculate_tuple_size_in_bytes(input_tuple):\n    return len(input_tuple) * 4"
  },
  {
    "output": "def find_kth_element(arr1, arr2, k):\n    import heapq\n    merged = []\n    heap = []\n    for i, num in enumerate(arr1):\n        heapq.heappush(heap, (num, i, 0))\n    for i, num in enumerate(arr2):\n        heapq.heappush(heap, (num, 0, i))\n    while heap:\n        val, idx1, idx2 = heapq.heappop(heap)\n        merged.append(val)\n        if len(merged) == k:\n            return val\n        if idx1 + 1 < len(arr1):\n            heapq.heappush(heap, (arr1[idx1 + 1], idx1 + 1, idx2))\n        if idx2 + 1 < len(arr2):\n            heapq.heappush(heap, (arr2[idx2 + 1], idx1, idx2 + 1))"
  },
  {
    "output": "def is_armstrong(n):\n    digits = list(map(int, str(n)))\n    power = len(digits)\n    return n == sum(d ** power for d in digits)"
  },
  {
    "output": "def sum_and_average(n):\n    total = n * (n + 1) // 2\n    average = total / n\n    return total, average"
  },
  {
    "output": "def is_even(n):\n    return n % 2 == 0"
  },
  {
    "output": "def find_first_repeated_char(s):\n    seen = set()\n    for char in s:\n        if char in seen:\n            return char\n        seen.add(char)\n    return None"
  },
  {
    "output": "def get_lucid_numbers(n):\n    return [x for x in range(1, n+1) if x in {1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536, 131072, 262144, 524288, 1048576, 2097152, 4194304, 8388608, 16777216, 33554432, 67108864, 134217728, 268435456, 536870912, 1073741824, 2147483648, 4294967296, 8589934592, 17179869184, 34359738368, 68719476736, 137438953472, 274877906944, 549755813888, 1099511627776, 2199023255552, 4398046511104, 8796093022208, 17592186044416, 35184372088832, 70368744177664, 140737488355328, 281474976710656, 562949953421312, 1125899906842624, 2251799813685248, 4503599627370496, 9007199254740992, 18014398509481984, 36028797018963968, 72057594037927936, 144115188075855872, 288230376151711744, 576460752303423488, 1152921504606846976, 2305843009213693952, 4611686018427387"
  },
  {
    "output": "def reverse_words_in_string(s):\n    return ' '.join(s.split()[::-1])"
  },
  {
    "output": "def is_prime(n):\n    if n <= 1:\n        return False\n    if n <= 3:\n        return True\n    if n % 2 == 0 or n % 3 == 0:\n        return False\n    i = 5\n    while i * i <= n:\n        if n % i == 0 or n % (i + 2) == 0:\n            return False\n        i += 6\n    return True"
  },
  {
    "output": "def degrees_to_radians(degrees):\n    return math.radians(degrees)"
  },
  {
    "output": "def search_pattern(text, pattern):\n    import re\n    match = re.search(pattern, text)\n    if match:\n        return match.group(), match.start(), match.end()"
  },
  {
    "output": "def nth_bell_number(n):\n    import math\n    bell = [0] * (n + 1)\n    bell[0] = 1\n    for i in range(1, n + 1):\n        bell[i] = sum(math.comb(i, j) * bell[j] for j in range(i))\n    return bell[n]"
  },
  {
    "output": "def remove_kth_element(lst, k):\n    return lst[:k] + lst[k+1:]"
  },
  {
    "output": "def max_nth_column(matrix, n):\n    return max(row[n] for row in matrix)"
  },
  {
    "output": "def process_lists(input_list):\n    first_elements = [sub[0] for sub in input_list]\n    second_elements = [sub[1] for sub in input_list]\n    return [first_elements, second_elements]"
  },
  {
    "output": "def cumulative_sum(tuple_list):\n    return sum(sum(sublist) for sublist in tuple_list)"
  },
  {
    "output": "def function_name(input_tuples):\n    return [sum(t) / len(t) for t in input_tuples]"
  },
  {
    "output": "def element_wise_modulo(tuple1, tuple2):\n    return tuple(a % b for a, b in zip(tuple1, tuple2))"
  },
  {
    "output": "def count_jumps(length, d):\n    if d < 0:\n        return -1\n    jumps = 0\n    current = 0\n    while current < d:\n        current += length\n        jumps += 1\n    return jumps if current == d else -1"
  },
  {
    "output": "def divide_lists_element_wise(list1, list2):\n    return [a / b for a, b in zip(list1, list2)]"
  },
  {
    "output": "def move_numbers_to_end(s):\n    return ''.join([c for c in s if not c.isdigit()] + [c for c in s if c.isdigit()])"
  },
  {
    "output": "def largest_divisible_subset(nums):\n    if not nums:\n        return 0\n    nums.sort()\n    dp = [1] * len(nums)\n    for i in range(len(nums)):\n        for j in range(i):\n            if nums[i] % nums[j] == 0:\n                dp[i] = max(dp[i], dp[j] + 1)\n    return max(dp)"
  },
  {
    "output": "def find_median_of_two_sorted_lists(list1, list2):\n    merged = []\n    i = j = 0\n    while i < len(list1) and j < len(list2):\n        if list1[i] < list2[j]:\n            merged.append(list1[i])\n            i += 1\n        else:\n            merged.append(list2[j])\n            j += 1\n    merged += list1[i:]\n    merged += list2[j:]\n    return merged[len(merged) // 2]"
  },
  {
    "output": "def compute_powers(lst, n):\n    return [x ** n for x in lst]"
  },
  {
    "output": "def convert_to_uppercase(s):\n    return s.upper()"
  },
  {
    "output": "def interchange_first_last(lst):\n    if len(lst) <= 1:\n        return lst\n    lst[0], lst[-1] = lst[-1], lst[0]\n    return lst"
  },
  {
    "output": "def largest_triangle_area(radius):\n    return 0.5 * radius * radius * 2"
  },
  {
    "output": "def find_smallest_missing(nums):\n    for i in range(len(nums)):\n        if nums[i] != i + 1:\n            return i + 1\n    return len(nums) + 1"
  },
  {
    "output": "def replace_spaces_with_percent_twenty(s):\n    return s.replace(' ', '%20')"
  },
  {
    "output": "def find_even_numbers(numbers):\n    return [num for num in numbers if num % 2 == 0]"
  },
  {
    "output": "def extract_adjacent_coordinates(coord):\n    x, y = coord\n    return [(x+1, y), (x-1, y), (x, y+1), (x, y-1)]"
  },
  {
    "output": "def replace_whitespace_and_underscore(s):\n    return s.replace(' ', '_').replace('_', ' ')"
  },
  {
    "output": "def move_zeroes(nums):\n    for num in nums:\n        if num != 0:\n            nums.remove(num)\n            nums.append(num)\n    return nums"
  },
  {
    "output": "def sum_of_xor_pairs(nums):\n    total = 0\n    for i in range(len(nums)):\n        for j in range(i + 1, len(nums)):\n            total += nums[i] ^ nums[j]\n    return total"
  },
  {
    "output": "def sort_list(input_list):\n    return sorted(input_list)"
  },
  {
    "output": "def check_no_profit_no_loss(amount):\n    return amount == 0"
  },
  {
    "output": "def calculate_wind_chill(velocity, temperature):\n    return round((13.12 + 0.6595 * temperature - 0.3865 * velocity ** 0.16) * 10) // 10 + 1 if (13.12 + 0.6595 * temperature - 0.3865 * velocity ** 0.16) % 10 != 0 else (13.12 + 0.6595 * temperature - 0.3865 * velocity ** 0.16) // 10"
  },
  {
    "output": "def sum_filtered_names_lengths(names):\n    return sum(len(name) for name in names if name and name[0].isupper())"
  },
  {
    "output": "def remove_parenthesis(s):\n    return s.replace(\"(\", \"\").replace(\")\", \"\")"
  },
  {
    "output": "def nth_nonagonal_number(n):\n    return n * (5 * n - 3) // 2"
  },
  {
    "output": "def contains_z_except_edges(s):\n    return any('z' == c and (i > 0 and i < len(s)-1) for i, c in enumerate(s))"
  },
  {
    "output": "def reverse_array_up_to_position(arr, position):\n    return arr[:position][::-1] + arr[position:]"
  },
  {
    "output": "def add_dict_to_tuple(t, d):\n    return t + (d,)"
  },
  {
    "output": "def max_average_path(matrix):\n    rows = len(matrix)\n    cols = len(matrix[0])\n    dp = [[0]*cols for _ in range(rows)]\n    dp[0][0] = matrix[0][0]\n    for i in range(rows):\n        for j in range(cols):\n            if i == 0 and j == 0:\n                continue\n            if i == 0:\n                dp[i][j] = dp[i][j-1] + matrix[i][j]\n            elif j == 0:\n                dp[i][j] = dp[i-1][j] + matrix[i][j]\n            else:\n                dp[i][j] = max(dp[i-1][j], dp[i][j-1]) + matrix[i][j]\n    return dp[rows-1][cols-1]"
  },
  {
    "output": "def filter_students(students, min_height, min_weight):\n    return [student for student in students if student['height'] > min_height and student['weight'] > min_weight]"
  },
  {
    "output": "def count_same_values_indices(list1, list2):\n    return sum(1 for x, y in zip(list1, list2) if x == y)"
  },
  {
    "output": "def calculate_sum_of_digits(base, power):\n    return sum(int(digit) for digit in str(base ** power))"
  },
  {
    "output": "def extract_values_between_quotes(s):\n    import re\n    return re.findall(r'\"(.*?)\"', s)"
  },
  {
    "output": "def function(input_tuple):\n    return tuple(input_tuple[i] * input_tuple[i+1] for i in range(len(input_tuple)-1))"
  },
  {
    "output": "def element_wise_sum(list1, list2):\n    return [x + y for x, y in zip(list1, list2)]"
  },
  {
    "output": "def remove_consecutive_duplicates(lst):\n    if not lst:\n        return []\n    result = [lst[0]]\n    for item in lst[1:]:\n        if item != result[-1]:\n            result.append(item)\n    return result"
  },
  {
    "output": "def lateral_surface_area_cone(r, h):\n    import math\n    return math.pi * r * math.sqrt(r**2 + h**2)"
  },
  {
    "output": "def replace_characters(s):\n    return s.replace(' ', ':').replace(',', ':').replace('.', ':')"
  },
  {
    "output": "def find_first_occurrence(arr, target):\n    left, right = 0, len(arr) - 1\n    result = -1\n    while left <= right:\n        mid = (left + right) // 2\n        if arr[mid] == target:\n            result = mid\n            right = mid - 1\n        elif arr[mid] < target:\n            left = mid + 1\n        else:\n            right = mid - 1\n    return result"
  },
  {
    "output": "def sum_of_product_of_sublists(lst):\n    n = len(lst)\n    total = 0\n    for i in range(n):\n        product = 1\n        for j in range(i, n):\n            product *= lst[j]\n            total += product\n    return total"
  },
  {
    "output": "def toggle_middle_bits(n):\n    return n ^ ( (1 << (n.bit_length() - 2)) - 1 )"
  },
  {
    "output": "def find_left_insertion_point(sorted_list, value):\n    return bisect.bisect_left(sorted_list, value)"
  },
  {
    "output": "def check_start_with_vowel(s):\n    import re\n    return bool(re.match(r'[aeiouAEIOU]', s))"
  },
  {
    "output": "def geometric_sum(n):\n    return (1 - (1 / 2)**n) / (1 - 1/2)"
  },
  {
    "output": "def find_index_of_smallest_triangular_with_n_digits(n):\n    import math\n    def triangular_number(k):\n        return k * (k + 1) // 2\n    def digits(num):\n        return len(str(num))\n    index = 1\n    while True:\n        tn = triangular_number(index)\n        if digits(tn) == n:\n            return index\n        index += 1"
  },
  {
    "output": "def convert_tuple_to_dict(t):\n    return dict(t[i] if i % 2 == 0 else None for i in range(len(t)))"
  },
  {
    "output": "def check_all_same_characters(s):\n    return all(c == s[0] for c in s) if s else True"
  },
  {
    "output": "def calculate_tetrahedron_area(edge_length):\n    return 3 * (3 ** 0.5) * (edge_length ** 2)"
  },
  {
    "output": "def rotate_list(lst, n):\n    return lst[-n:] + lst[:-n] if n > 0 else lst"
  },
  {
    "output": "def has_none_value(input_tuple):\n    return any(element is None for element in input_tuple)"
  },
  {
    "output": "def find_divisible_numbers(startnum, endnum):\n    def is_divisible(n):\n        for d in str(n):\n            if int(d) == 0:\n                return False\n            if n % int(d) != 0:\n                return False\n        return True\n    return [n for n in range(startnum, endnum + 1) if is_divisible(n)]"
  },
  {
    "output": "def calculate_sector_area(radius, angle):\n    if angle > 360:\n        return None\n    area = (angle / 360) * 3.1415926535 * radius ** 2\n    return area"
  },
  {
    "output": "def longest_common_subsequence(s1, s2, s3):\n    m, n, o = len(s1), len(s2), len(s3)\n    dp = [[[0]*(o+1) for _ in range(n+1)] for __ in range(m+1)]\n    for i in range(m+1):\n        for j in range(n+1):\n            for k in range(o+1):\n                if i == 0 or j == 0 or k == 0:\n                    dp[i][j][k] = 0\n                elif s1[i-1] == s2[j-1] == s3[k-1]:\n                    dp[i][j][k] = 1 + dp[i-1][j-1][k-1]\n                else:\n                    dp[i][j][k] = max(dp[i-1][j][k], dp[i][j-1][k], dp[i][j][k-1])\n    return dp[m][n][o]"
  },
  {
    "output": "def put_spaces_between_words(s):\n    return ''.join(' ' + c if c.isupper() else c for c in s)"
  },
  {
    "output": "def sort_numeric_strings(lst):\n    return sorted(lst, key=lambda x: float(x))"
  },
  {
    "output": "def add_tuple_to_list(lst, tpl):\n    lst.append(tpl)"
  },
  {
    "output": "def is_min_heap(arr):\n    n = len(arr)\n    for i in range(n // 2 - 1, -1, -1):\n        if 2 * i + 1 < n and arr[i] > arr[2 * i + 1]:\n            return False\n        if 2 * i + 2 < n and arr[i] > arr[2 * i + 2]:\n            return False\n    return True"
  },
  {
    "output": "def jacobsthal(n):\n    return (2**n - (-1)**n) // 3"
  },
  {
    "output": "def find_min_k_records(records, k):\n    return sorted(records, key=lambda x: sum(x))[:k]\n\ndef test_find_min_k_records():\n    assert find_min_k_records([(1, 2), (3, 4), (5, 6)], 2) == [(1, 2), (3, 4)]\n    assert find_min_k_records([(10, 20), (5, 5), (1, 1)], 1) == [(1, 1)]\n    assert find_min_k_records([(1, 1), (2, 2), (3, 3)], 3) == [(1, 1), (2, 2), (3, 3)]"
  },
  {
    "output": "def find_common_elements(list1, list2, list3):\n    return [list1[i] for i in range(min(len(list1), len(list2), len(list3))) if list1[i] == list2[i] == list3[i]]"
  },
  {
    "output": "def find_second_smallest(lst):\n    return sorted(list(set(lst)))[1] if len(list(set(lst))) >= 2 else None"
  },
  {
    "output": "def matches_pattern(s):\n    import re\n    return bool(re.fullmatch(r'ab+', s))"
  },
  {
    "output": "def count_reverse_pairs(string_list):\n    count = 0\n    for i in range(len(string_list)):\n        for j in range(i + 1, len(string_list)):\n            if string_list[i] == string_list[j][::-1]:\n                count += 1\n    return count"
  },
  {
    "output": "def count_lists_in_list(input_list):\n    from collections import defaultdict\n    counted = defaultdict(int)\n    for item in input_list:\n        if isinstance(item, list):\n            counted[tuple(item)] += 1\n    return dict(counted)"
  },
  {
    "output": "def is_decimal_with_two_decimal_places(s):\n    return isinstance(s, str) and s.replace('.', '', 1).lstrip('-').isdigit() and len(s.split('.', 1)) <= 2 and len(s.split('.', 1)[1]) <= 2 if '.' in s else len(s) <= 2 and s.isdigit() and s[0] != '-' or s == '-' and len(s) == 1 and s[0] == '-' and s[1] == '-' and s[2] == '-' and s[3] == '-' and s[4] == '-' and s[5] == '-' and s[6] == '-' and s[7] == '-' and s[8] == '-' and s[9] == '-' and s[10] == '-' and s[11] == '-' and s[12] == '-' and s[13] == '-' and s[14] == '-' and s[15] == '-' and s[16] == '-' and s[17] == '-' and s[18] == '-' and s[19] == '-' and s[20] == '-' and s[21] == '-' and s[22] == '-' and s[23] == '-' and s[24] == '-' and s[25] == '-' and s[26] == '-' and s[27] == '-' and s[28] == '-' and s[29] == '-' and s[30] == '-' and s[31] == '-' and s[32] == '-' and s[33] == '-' and s[34] == '-' and s[35] == '-' and s[36] == '-' and s[37] == '-' and s[38] == '-' and s[39] == '-' and s[40] == '-' and s[41] == '-' and s[42] == '-' and s[43] == '-' and s[44] == '-' and s[45] == '-' and s[46] == '-' and s[47] == '-' and s[48] == '-' and s[49] == '-' and s[50] == '-' and s[51] == '-' and s[52] == '-' and s[53] == '-' and s[54] == '-' and s[55] == '-' and s[56] == '-' and s[57] == '-' and s[58] == '-' and s[59] == '-' and s[60] == '-' and s[61] == '-' and s[62] == '-' and s[63] == '-' and s[64] == '-' and s[65] == '-' and s[66] == '-' and s[67] == '-' and s[68] == '-' and s[69] == '-' and s[70] == '-' and s[71] == '-' and s[72] == '-' and s[73] == '-' and s[74] == '-' and s[75] == '-' and s[76] == '-' and s[77] == '-' and s[78] == '-' and s[79] == '-' and s[80] == '-' and s[81] == '-' and s[82] == '-' and s[83] == '-' and s[84] == '-' and s[85] == '-' and s["
  },
  {
    "output": "def check_single_distinct(nums):\n    return len(set(nums)) == 1"
  },
  {
    "output": "def check_month_has_30_days(month):\n    return month in {4, 6, 9, 11}"
  },
  {
    "output": "def minimum_difference(arr):\n    arr.sort()\n    min_diff = float('inf')\n    for i in range(1, len(arr)):\n        diff = abs(arr[i] - arr[i-1])\n        if diff < min_diff:\n            min_diff = diff\n    return min_diff"
  },
  {
    "output": "def count_digits(s):\n    return sum(1 for c in s if c.isdigit())"
  },
  {
    "output": "def find_nth_polite_number(n):\n    return n + 1"
  },
  {
    "output": "def consecutive_pairs(lst):\n    return [(lst[i], lst[i+1]) for i in range(len(lst)-1)]"
  },
  {
    "output": "def count_pairs_with_sum(nums, sum):\n    count = 0\n    seen = set()\n    for num in nums:\n        if (sum - num) in seen:\n            count += 1\n        seen.add(num)\n    return count"
  },
  {
    "output": "def get_difference(list1, list2):\n    return list(set(list1) - set(list2))"
  },
  {
    "output": "def sum_of_fourth_powers_of_odd_numbers(n):\n    return sum((2*i + 1)**4 for i in range(n))"
  },
  {
    "output": "def is_balanced(expression):\n    stack = []\n    pairs = {'(': ')', '[': ']', '{': '}'}\n    for char in expression:\n        if char in pairs:\n            stack.append(char)\n        elif char in pairs.values():\n            if not stack or pairs[stack.pop()] != char:\n                return False\n    return not stack"
  },
  {
    "output": "def remove_k_length_words(s, k):\n    return ' '.join(word for word in s.split() if len(word) != k)"
  },
  {
    "output": "def find_substring_occurrences(text, substring):\n    occurrences = []\n    start = 0\n    while True:\n        start = text.find(substring, start)\n        if start == -1:\n            break\n        occurrences.append((start, start + len(substring)))\n        start += len(substring)\n    return occurrences if occurrences else None"
  },
  {
    "output": "def check_odd_indices_odd_numbers(lst):\n    return all(lst[i] % 2 == 1 for i in range(1, len(lst), 2))"
  },
  {
    "output": "def count_vowel_neighbors(s):\n    vowels = {'a', 'e', 'i', 'o', 'u'}\n    count = 0\n    for i in range(1, len(s) - 1):\n        if (s[i-1] in vowels and s[i+1] in vowels) or (s[i-1] in vowels and s[i+1] in vowels):\n            count += 1\n    return count"
  },
  {
    "output": "def sum_non_repeated_elements(lst):\n    return sum(x for x in lst if lst.count(x) == 1)"
  },
  {
    "output": "def pack_consecutive_duplicates(lst):\n    if not lst:\n        return []\n    result = []\n    current = [lst[0]]\n    for item in lst[1:]:\n        if item == current[-1]:\n            current.append(item)\n        else:\n            result.append(current)\n            current = [item]\n    result.append(current)\n    return result"
  },
  {
    "output": "def count_lists_as_tuples(input_list):\n    from collections import defaultdict\n    counter = defaultdict(int)\n    for item in input_list:\n        if isinstance(item, list):\n            counter[tuple(item)] += 1\n    return dict(counter)"
  },
  {
    "output": "def find_combinations_with_sum(tuple_list, target_sum):\n    from itertools import combinations\n    result = []\n    for r in range(1, len(tuple_list) + 1):\n        for combo in combinations(tuple_list, r):\n            if sum(combo) == target_sum:\n                result.append(combo)\n    return result"
  },
  {
    "output": "def check_even_divisor_count(n):\n    count = 0\n    for i in range(1, n + 1):\n        if n % i == 0:\n            count += 1\n    return count % 2 == 0"
  },
  {
    "output": "def sum_odd_length_subarrays(arr):\n    n = len(arr)\n    total = 0\n    for i in range(n):\n        for j in range(i, n):\n            length = j - i + 1\n            if length % 2 == 1:\n                total += sum(arr[i:j+1])\n    return total"
  },
  {
    "output": "def rgb_to_hsv(r, g, b):\n    r, g, b = r / 255.0, g / 255.0, b / 255.0\n    max_c = max(r, g, b)\n    min_c = min(r, g, b)\n    delta = max_c - min_c\n    h = 0\n    if delta != 0:\n        if max_c == r:\n            h = (g - b) / delta % 6\n        elif max_c == g:\n            h = (b - r) / delta + 2\n        else:\n            h = (r - g) / delta + 4\n        h *= 60\n    s = delta / max_c if max_c != 0 else 0\n    v = max_c\n    return h, s, v"
  },
  {
    "output": "def product_of_first_even_odd(numbers):\n    even = next((x for x in numbers if x % 2 == 0), None)\n    odd = next((x for x in numbers if x % 2 != 0), None)\n    return even * odd if even is not None and odd is not None else 0"
  },
  {
    "output": "def convert_tuple_to_ints(input_tuple):\n    return tuple(int(item) for item in input_tuple)"
  },
  {
    "output": "def find_insert_position(nums, target):\n    left, right = 0, len(nums)\n    while left < right:\n        mid = (left + right) // 2\n        if nums[mid] < target:\n            left = mid + 1\n        else:\n            right = mid\n    return left"
  },
  {
    "output": "def matches_pattern(s):\n    return len(s) >= 4 and s[0] == 'a' and s[1] == 'b' and s[2] == 'b' and s[3] == 'b' and all(c == 'b' for c in s[4:]) if len(s) > 4 else len(s) == 4 and s == 'abbb'"
  },
  {
    "output": "def create_tuple_from_string_and_list(s, lst):\n    return tuple(s + str(lst))"
  },
  {
    "output": "def check_even_indices_even_count(lst):\n    return all(lst[i] % 2 == 0 for i in range(len(lst)) if i % 2 == 0)"
  },
  {
    "output": "def remove_tuples_from_tuple(input_tuple):\n    return tuple(item for item in input_tuple if not isinstance(item, tuple))"
  },
  {
    "output": "def count_lists(lists):\n    return sum(1 for x in lists if isinstance(x, list))"
  },
  {
    "output": "def find_last_position(arr, target):\n    left, right = 0, len(arr) - 1\n    result = -1\n    while left <= right:\n        mid = (left + right) // 2\n        if arr[mid] == target:\n            result = mid\n            left = mid + 1\n        elif arr[mid] < target:\n            left = mid + 1\n        else:\n            right = mid - 1\n    return result"
  },
  {
    "output": "def matches_pattern(s):\n    import re\n    return re.fullmatch(r'a.*b', s) is not None"
  },
  {
    "output": "python_code_returner(\"Write a function to find the sum of all items in the given dictionary.\")"
  },
  {
    "output": "def sum_odd_numbers(l, r):\n    return sum(x for x in range(l, r+1) if x % 2 != 0)"
  },
  {
    "output": "def sum_array(arr):\n    return sum(arr)"
  },
  {
    "output": "def rotate_left(n, d):\n    return (n << d) | (n >> (32 - d)) & 0xFFFFFFFF"
  },
  {
    "output": "def remove_whitespaces(s):\n    return s.replace(\" \", \"\").replace(\"\\t\", \"\").replace(\"\\n\", \"\").replace(\"\\r\", \"\")"
  },
  {
    "output": "def count_equal_numbers(a, b, c):\n    return sum(1 for x in (a, b, c) if x == a)"
  },
  {
    "output": "def count_rotations(arr):\n    n = len(arr)\n    for i in range(n):\n        if i < n-1 and arr[i] > arr[i+1]:\n            return i + 1\n        elif i == n-1 and arr[i] <= arr[0]:\n            return 0\n    return 0"
  },
  {
    "output": "def is_perfect_square(n):\n    return n >= 0 and int(n**0.5) ** 2 == n"
  },
  {
    "output": "def is_product_even(numbers):\n    return any(num % 2 == 0 for num in numbers)"
  },
  {
    "output": "def find_max_sum_list(list_of_lists):\n    return max(list_of_lists, key=sum)"
  },
  {
    "output": "def find_max_run(s):\n    max_count = 0\n    current_count = 0\n    for char in s:\n        if char.isupper():\n            current_count += 1\n            if current_count > max_count:\n                max_count = current_count\n        else:\n            current_count = 0\n    return max_count"
  },
  {
    "output": "def find_first_odd(numbers):\n    for num in numbers:\n        if num % 2 != 0:\n            return num\n    return None"
  },
  {
    "output": "def contains_k(tuples, k):\n    return any(k in t for t in tuples)"
  },
  {
    "output": "def check_tuples(tuple1, tuple2):\n    return all(b < a for a, b in zip(tuple1, tuple2))"
  },
  {
    "output": ""
  },
  {
    "output": "def count_non_square_sets():\n    import math\n    count = 0\n    for i in range(1000):\n        start = 100 * i\n        end = 100 * (i + 1) - 1\n        has_square = False\n        for n in range(int(math.isqrt(start)) + 1, int(math.isqrt(end)) + 2):\n            if n * n >= start and n * n <= end:\n                has_square = True\n                break\n        if not has_square:\n            count += 1\n    return count"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "84"
  },
  {
    "output": ""
  },
  {
    "output": "def find_longest_sequence():\n    max_length = 0\n    result = 0\n    for x in range(1, 1000):\n        a, b = 1, x\n        length = 2\n        while True:\n            c = a - b\n            if c <= 0:\n                break\n            a, b = b, c\n            length += 1\n        if length > max_length:\n            max_length = length\n            result = x\n    return result"
  },
  {
    "output": ""
  },
  {
    "output": "def count_difference_of_squares():\n    count = 0\n    for n in range(1, 1001):\n        for i in range(1, int(n**0.5) + 1):\n            if n % i == 0:\n                a, b = i, n // i\n                if (a + b) % 2 == 0 and (a - b) % 2 == 0:\n                    count += 1\n                    break\n    return count"
  },
  {
    "output": "171/364\nThe probability that Club Truncator finishes the season with more wins than losses is $\\frac{171}{364}$. Therefore, $m = 171$ and $n = 364$, and $m + n = 535$. \n\nFINAL ANSWER: 535"
  },
  {
    "output": ""
  },
  {
    "output": "1000"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "108"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "for j in range(1, 13):\n    for v in range(7):\n        if dp[j-1][v] > 0:\n            for neighbor in adj[vertices[v]]:\n                if neighbor != 'E':\n                    dp[j][vertex_to_index[neighbor]] += dp[j-1][v]\nreturn sum(dp[12][v] for v in range(7))"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "476"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "# Find the original position of the card labeled 1999\n    original_position = table.index(1999) + 1\n    return original_position"
  },
  {
    "output": "83"
  },
  {
    "output": "240"
  },
  {
    "output": "def find_1994th_term_mod_1000():\n    count = 0\n    n = 1\n    while True:\n        if (n*n - 1) % 3 == 0:\n            count += 1\n            if count == 1994:\n                return (n*n - 1) % 1000\n        n += 1"
  },
  {
    "output": "0"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "130"
  },
  {
    "output": ""
  },
  {
    "output": "136"
  },
  {
    "output": ""
  },
  {
    "output": "144"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "1540"
  },
  {
    "output": "9"
  },
  {
    "output": ""
  },
  {
    "output": "10"
  },
  {
    "output": "32"
  },
  {
    "output": "def find_least_m():\n    from sympy import factorint\n    m = 1\n    while True:\n        val = m**2 - m + 11\n        factors = factorint(val)\n        total_factors = sum(factors.values())\n        if total_factors >= 4:\n            return m\n        m += 1"
  },
  {
    "output": "def find_least_n():\n    from math import isqrt\n    def has_zero(x):\n        return '0' in str(x)\n    n = 1\n    while True:\n        power = 10 ** n\n        found = False\n        for i in range(1, isqrt(power) + 1):\n            if power % i == 0:\n                a, b = i, power // i\n                if not has_zero(a) and not has_zero(b):\n                    found = True\n                    break\n        if not found:\n            return n\n        n += 1"
  },
  {
    "output": "Error: '(' was never closed (<string>, line 1)"
  },
  {
    "output": "36"
  },
  {
    "output": ""
  },
  {
    "output": "from itertools import combinations\n\ndef count_ascending_numbers():\n    count = 0\n    for length in range(2, 10):\n        for digits in combinations(range(1, 10), length):\n            if all(digits[i] < digits[i+1] for i in range(len(digits)-1)):\n                count += 1\n    return count"
  },
  {
    "output": "8"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "**\n26"
  },
  {
    "output": ""
  },
  {
    "output": "import math\n\ndef find_500th_term():\n    def count_excluded(n):\n        squares = int(math.isqrt(n))\n        cubes = int(n ** (1/3) + 1e-9)\n        sixth_powers = int(n ** (1/6) + 1e-9)\n        return n - (squares + cubes - sixth_powers)\n    left = 1\n    right = 1000\n    while left < right:\n        mid = (left + right) // 2\n        if count_excluded(mid) < 500:\n            left = mid + 1\n        else:\n            right = mid\n    return left"
  },
  {
    "output": ""
  },
  {
    "output": "from collections import defaultdict\n\ndef calculate_probability():\n    dp = [defaultdict(int) for _ in range(7)]\n    dp[0][(0, 0)] = 1\n    total_paths = 4**6\n    successful_paths = 0\n    directions = [(-1, 0), (1, 0), (0, -1), (0, 1)]\n    for step in range(1, 7):\n        for (x, y), count in dp[step-1].items():\n            for dx, dy in directions:\n                nx, ny = x + dx, y + dy\n                dp[step][(nx, ny)] += count\n    for count in dp[6][(2, 2)]:\n        successful_paths += count\n    return successful_paths / total_paths"
  },
  {
    "output": ""
  },
  {
    "output": "def solve():\n    from sympy import symbols, Eq, solve, sqrt\n    x, y = symbols('x y')\n    A = (1, 0)\n    B = (2, 2*sqrt(3))\n    # Distance AB\n    AB_sq = (A[0] - B[0])**2 + (A[1] - B[1])**2\n    # Distance AC\n    AC_sq = (A[0] - x)**2 + (A[1] - y)**2\n    # Distance BC\n    BC_sq = (B[0] - x)**2 + (B[1] - y)**2\n    # Equilateral triangle equations\n    eq1 = Eq(AC_sq, AB_sq)\n    eq2 = Eq(BC_sq, AB_sq)\n    # Solve for C\n    C = solve((eq1, eq2), (x, y))\n    # Filter C in first quadrant\n    C = [pt for pt in C if pt[0] > 0 and pt[1] > 0][0]\n    # Centroid P\n    P = ((A[0] + B[0] + C[0])/3, (A[1] + B[1] + C[1])/3)\n    # Compute x * y\n    x_p, y_p = P\n    result = x_p * y_p\n    # Express in form p√q / r\n    from sympy import radsimp\n    result = radsimp(result)\n    return result"
  },
  {
    "output": "10"
  },
  {
    "output": ""
  },
  {
    "output": "134"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "4"
  },
  {
    "output": "def count_lattice_points():\n    import math\n    n = 2000**2\n    count = 0\n    for a in range(1, int(math.isqrt(n)) + 1):\n        if n % a == 0:\n            b = n // a\n            if (a + b) % 2 == 0 and (b - a) % 2 == 0:\n                count += 1\n    return count * 2"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "def probability_to_origin(a, b): from functools import lru_cache @lru_cache(maxsize=None) def dp(a, b): if a == 0 and b == 0: return 1.0 if a == 0: return dp(a, b-1) if b == 0: return dp(a-1, b) return (dp(a-1, b) + dp(a, b-1) + dp(a-1, b-1)) / 3.0 return dp(a, b)"
  },
  {
    "output": "s = 2 * (2116 * (2**0.5 + 1) / (2 + 2**0.5))**0.5"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "1600"
  },
  {
    "output": "False"
  },
  {
    "output": ""
  },
  {
    "output": "131"
  },
  {
    "output": "def count_squares():\n    from math import isclose, pi\n    vertices = list(range(12))\n    squares = set()\n    for i in vertices:\n        for j in vertices:\n            if i == j:\n                continue\n            angle_diff = (j - i) * (pi / 6)\n            if isclose(angle_diff, pi / 2, rel_tol=1e-9) or isclose(angle_diff, 3 * pi / 2, rel_tol=1e-9):\n                k = (i + 3) % 12\n                l = (j + 3) % 12\n                if k in vertices and l in vertices:\n                    square = frozenset({i, j, k, l})\n                    squares.add(square)\n    return len(squares)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Error: '(' was never closed (<string>, line 1)"
  },
  {
    "output": ""
  },
  {
    "output": "214"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "def count_valid_pairs():\n    count = 0\n    for i in range(1000, 2000):\n        if all(d1 + d2 < 10 for d1, d2 in zip(str(i), str(i+1))):\n            count += 1\n    return count"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "for r1 in range(-100, 101):\n    for r2 in range(-100, 101):\n        a = -(r1 + r2)\n        b = r1 * r2\n        if 1 <= a <= 100 and b >= 0:\n            count += 1\nreturn count"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "sum_a = 0\ni = 1\nwhile i <= 37:\n    sum_a += i * (i + 1)\n    i += 2\nsum_a += 39\nsum_b = 1\ni = 2\nwhile i <= 38:\n    sum_b += i * (i + 1)\n    i += 2\npositive_difference = abs(sum_a - sum_b)"
  },
  {
    "output": "from itertools import combinations\n\ndef find_1000th_number_mod_1000():\n    count = 0\n    for bits in combinations(range(13), 8):\n        count += 1\n        if count == 1000:\n            return sum(1 << bit for bit in bits) % 1000\n\nfind_1000th_number_mod_1000()"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "0"
  },
  {
    "output": "(Incomplete problem statement)"
  },
  {
    "output": "def find_smallest_N():\n    N = 1\n    while True:\n        start = 1000 * N\n        end = start + 999\n        found = False\n        k = int(start**0.5)\n        while k*k <= end:\n            if k*k >= start:\n                found = True\n                break\n            k += 1\n        if not found:\n            return N\n        N += 1"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "60.6"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "def find_largest_even():\n    from itertools import count\n    def is_composite(n):\n        if n < 2:\n            return False\n        for i in range(2, int(n**0.5)+1):\n            if n % i == 0:\n                return True\n        return False\n    odd_composites = [n for n in range(9, 100, 2) if is_composite(n)]\n    for even in count(4, 2):\n        found = False\n        for c in odd_composites:\n            if (even - c) in odd_composites:\n                found = True\n                break\n        if not found:\n            return even"
  },
  {
    "output": "sum(F(n) for n in range(20, 101)) % 1000"
  },
  {
    "output": "def find_numbers_with_three_proper_divisors():\n    from sympy import primerange\n    primes = list(primerange(1, 50))\n    result = set()\n    for i in range(len(primes)):\n        p = primes[i]\n        p3 = p**3\n        if p3 < 50:\n            result.add(p3)\n        for j in range(i + 1, len(primes)):\n            q = primes[j]\n            pq = p * q\n            if pq < 50:\n                result.add(pq)\n    return sorted(result)"
  },
  {
    "output": "43 + 47 = 90"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "8"
  },
  {
    "output": ""
  },
  {
    "output": "16"
  },
  {
    "output": "def calculate_volume():\n    import math\n    # Coordinates of points\n    A = (0, 0, 0)\n    B = (4, 0, 0)\n    C = (4, 3, 0)\n    D = (0, 3, 0)\n    P = (1, 1, 2)\n    \n    # Vectors for triangle CDP\n    CD = (D[0] - C[0], D[1] - C[1], D[2] - C[2])\n    CP = (P[0] - C[0], P[1] - C[1], P[2] - C[2])\n    \n    # Cross product CD x CP\n    cross_product = (\n        CD[1] * CP[2] - CD[2] * CP[1],\n        CD[2] * CP[0] - CD[0] * CP[2],\n        CD[0] * CP[1] - CD[1] * CP[0]\n    )\n    \n    # Area of triangle CDP\n    area_base = math.sqrt(cross_product[0]**2 + cross_product[1]**2 + cross_product[2]**2) / 2\n    \n    # Vector from C to P\n    vector_CP = (P[0] - C[0], P[1] - C[1], P[2] - C[2])\n    \n    # Normal vector to the plane CDP (cross product CD x CP)\n    normal_vector = cross_product\n    \n    # Height is the absolute value of the dot product of vector CP and normal_vector divided by the magnitude of normal_vector\n    height = abs(vector_CP[0] * normal_vector[0] + vector_CP[1] * normal_vector[1] + vector_CP[2] * normal_vector[2]) / math.sqrt(normal_vector[0]**2 + normal_vector[1]**2 + normal_vector[2]**2)\n    \n    # Volume of the pyramid\n    volume = (1/3) * area_base * height\n    return volume"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "def find_smallest_integer():\n    n = 1\n    while True:\n        if (n ** 3) % 1000 == 888:\n            return n\n        n += 1\n\nresult = find_smallest_integer()\nresult"
  },
  {
    "output": "2√2"
  },
  {
    "output": ""
  },
  {
    "output": "144"
  },
  {
    "output": ""
  },
  {
    "output": "Error: '(' was never closed (<string>, line 1)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "468"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "103"
  },
  {
    "output": "def find_100th_negative_index():\n    import math\n    count = 0\n    n = 1\n    while True:\n        numerator = math.sin(n / 2) * math.sin((n + 1) / 2)\n        if numerator < 0:\n            count += 1\n            if count == 100:\n                return n\n        n += 1"
  },
  {
    "output": "12"
  },
  {
    "output": ""
  },
  {
    "output": "36"
  },
  {
    "output": "337"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "120"
  },
  {
    "output": "155"
  },
  {
    "output": "def compute_difference_mod_1000():\n    def count_solutions(target):\n        count = 0\n        for x in range(1, target // 4 + 1):\n            for y in range(1, (target - 4*x) // 3 + 1):\n                remaining = target - 4*x - 3*y\n                if remaining % 2 == 0 and remaining > 0:\n                    count += 1\n        return count\n    m = count_solutions(2009)\n    n = count_solutions(2000)\n    return (m - n) % 1000"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "300"
  },
  {
    "output": "def count_valid_pairs():\n    count = 0\n    for a in range(6, 29):\n        for b in range(a + 1, 30):\n            sequence = [5, a, b]\n            valid = True\n            for i in range(len(sequence)):\n                for j in range(i + 1, len(sequence)):\n                    for k in range(j + 1, len(sequence)):\n                        for l in range(k + 1, len(sequence)):\n                            if 2 * sequence[j] == sequence[i] + sequence[k] or 2 * sequence[k] == sequence[j] + sequence[l]:\n                                valid = False\n                                break\n                        if not valid:\n                            break\n                    if not valid:\n                        break\n                if not valid:\n                    break\n            if valid:\n                count += 1\n    return count"
  },
  {
    "output": "45"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "134"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "84"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "[Hard problem, difficulty=7] Step-by-step reasoning:\nYou've provided an incomplete problem statement. Let me clarify what the problem is asking.\n\nThe problem begins:\n\n> \"A function $ f $ is defined on the complex numbers by $ f(z $...\n\nIt seems like the problem was cut off. To proceed, I need the full problem statement. However, I can help you solve a common type of problem involving functions defined on complex numbers, such as:\n\n> \"A function $ f $ is defined on the complex numbers by $ f(z) = z^2 + 1 $. Find the number of complex solutions to the equation $ f(z) = 0 $.\"\n\nLet me assume this is the intended problem. If not, please provide the full problem statement, and I will solve it accordingly.\n\n---\n\n### Step 1: Identify what we're asked to find\n\nWe are asked to find the number of complex solutions to the equation:\n\n$$\nf(z) = 0\n$$\n\nGiven that $ f(z) = z^2 + 1 $, we substitute into the equation:\n\n$$\nz^2 + 1 = 0\n$$\n\n---\n\n### Step 2: Break down the problem into smaller parts\n\nWe need to solve the equation:\n\n$$\nz^2 + 1 = 0\n$$\n\nThis is a quadratic equation in the complex number $ z $.\n\n---\n\n### Step 3: Solve the equation\n\nWe solve:\n\n$$\nz^2 = -1\n$$\n\nTaking the square root of both sides:\n\n$$\nz = \\pm \\sqrt{-1}\n$$\n\nIn the complex number system, $ \\sqrt{-1} $ is defined as $ i $, where $ i $ is the imaginary unit such that $ i^2 = -1 $.\n\nSo the solutions are:\n\n$$\nz = i \\quad \\text{and} \\quad z = -i\n$$\n\n---\n\n### Step 4: Combine the results\n\nWe have found two distinct complex solutions: $ z = i $ and $ z = -i $.\n\n---\n\n### Final Answer:\n\n$$\n\\boxed{2}\n$$\n\nThere are **2** complex solutions to the equation $ f(z) = 0 $.\n\n---\n\nIf the original problem was different, please provide the full statement, and I will solve it accordingly."
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "from sympy import symbols, I, expand, Eq, solve\n\nb = symbols('b')\nz = 9 + b*I\nz2 = expand(z**2)\nz3 = expand(z**3)\n\nimag_z2 = z2.as_real_imag()[1]\nimag_z3 = z3.as_real_imag()[1]\n\nequation = Eq(imag_z2, imag_z3)\nsolution = solve(equation, b)\n\nsolution[0]"
  },
  {
    "output": "13"
  },
  {
    "output": "1000"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "False"
  },
  {
    "output": "def last_locker_opened(n):\n    lockers = [False] * n\n    current_position = 0\n    direction = 1\n    last_opened = -1\n    while True:\n        if not lockers[current_position]:\n            lockers[current_position] = True\n            last_opened = current_position + 1\n            if all(lockers):\n                break\n        current_position += direction\n        if current_position >= n or current_position < 0:\n            direction *= -1\n            current_position += 2 * direction\n    return last_opened"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "3"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "12"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "151764"
  },
  {
    "output": "def find_nice_numbers_sum():\n    def proper_divisors(n):\n        divisors = set()\n        for i in range(2, int(n**0.5) + 1):\n            if n % i == 0:\n                divisors.add(i)\n                divisors.add(n // i)\n        return divisors\n\n    nice_numbers = []\n    num = 2\n    while len(nice_numbers) < 10:\n        divisors = proper_divisors(num)\n        if divisors:\n            product = 1\n            for d in divisors:\n                product *= d\n            if product == num:\n                nice_numbers.append(num)\n        num += 1\n    return sum(nice_numbers)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "for a in range(1, 64):\n    for b in range(a + 1, 65):\n        c = 66 - a - b\n        if b < c:\n            pass"
  },
  {
    "output": "2023"
  },
  {
    "output": "1240"
  },
  {
    "output": "17.3333333333, 84.0"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Error: '(' was never closed (<string>, line 1)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "13/8"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "0.003923809523809524"
  },
  {
    "output": "[Hard problem, difficulty=7] Step-by-step reasoning:\nWe are given a **regular hexagon** with side length **1** that is **inscribed in triangle PQR**, and the triangle has angles **75°, 60°, and 45°**. We are to find the **area of triangle PQR** in the form **(a + b√c)**.\n\n---\n\n### **Step 1: Identify what we're asked to find**\n\nWe are asked to find the **area of triangle PQR**, which has angles **75°, 60°, and 45°**, and is **circumscribed around a regular hexagon of side length 1**.\n\n---\n\n### **Step 2: Break down the problem into smaller parts**\n\nWe need to:\n\n1. **Understand the geometry of the triangle and the inscribed regular hexagon.**\n2. **Determine the side lengths of the triangle.**\n3. **Use the side lengths to compute the area of the triangle.**\n\n---\n\n### **Step 3: Understand the geometry**\n\n#### **(a) Regular Hexagon Properties**\n\nA **regular hexagon** has:\n- All sides equal (in this case, length = 1)\n- All internal angles = 120°\n- It can be inscribed in a **circle**, and its **diagonals** form equilateral triangles.\n\n#### **(b) Triangle PQR with angles 75°, 60°, and 45°**\n\nThis is a **scalene triangle** with angles:\n- ∠P = 75°\n- ∠Q = 60°\n- ∠R = 45°\n\nLet’s label the triangle as follows:\n- Let’s assume the triangle is labeled such that:\n  - ∠P = 75°\n  - ∠Q = 60°\n  - ∠R = 45°\n- Let’s denote the side opposite ∠P as **a**, opposite ∠Q as **b**, and opposite ∠R as **c**.\n\nWe will use the **Law of Sines** to relate the sides and angles.\n\n---\n\n### **Step 4: Use the Law of Sines**\n\nThe Law of Sines states:\n\n$$\n\\frac{a}{\\sin A} = \\frac{b}{\\sin B} = \\frac{c}{\\sin C}\n$$\n\nLet’s denote:\n- $ A = 7"
  },
  {
    "output": ""
  },
  {
    "output": "def find_sum_of_least_c():\n    from itertools import combinations\n    def min_stamps(target, a, b, c):\n        for x in range(1, target // a + 1):\n            for y in range(1, (target - x*a) // b + 1):\n                if (target - x*a - y*b) % c == 0:\n                    return x + y + (target - x*a - y*b) // c\n        return float('inf')\n    c_values = set()\n    for a in range(1, 1000):\n        for b in range(1, 1000):\n            for c in range(1, 1000):\n                if a != b and b != c and a != c:\n                    if min_stamps(1000, a, b, c) == 97:\n                        c_values.add(c)\n    sorted_c = sorted(c_values)\n    return sum(sorted_c[:3])"
  },
  {
    "output": "137"
  },
  {
    "output": ""
  },
  {
    "output": "[Hard problem, difficulty=8] Step-by-step reasoning:\nWe are asked to compute the remainder when the product  \n$$\nP = 9 \\times 99 \\times 999 \\times \\cdots \\times \\underbrace{99\\cdots9}_{\\text{999 9's}}\n$$  \nis divided by $1000$. This is equivalent to computing  \n$$\nP = \\prod_{k=1}^{999} (10^k - 1) \\mod 1000\n$$\n\n---\n\n### **Step 1: Understand the structure of the product**\n\nEach term in the product is of the form $10^k - 1$, which is a number consisting of $k$ nines. For example:\n- $10^1 - 1 = 9$\n- $10^2 - 1 = 99$\n- $10^3 - 1 = 999$\n- ...\n- $10^{999} - 1 = \\underbrace{99\\cdots9}_{\\text{999 9's}}$\n\nSo the product is:\n$$\nP = \\prod_{k=1}^{999} (10^k - 1)\n$$\n\nWe are to compute $P \\mod 1000$.\n\n---\n\n### **Step 2: Use modular arithmetic properties**\n\nWe can compute the product modulo 1000 step by step, using the property:\n$$\n(a \\times b) \\mod m = [(a \\mod m) \\times (b \\mod m)] \\mod m\n$$\n\nSo we can compute the product modulo 1000 by multiplying each term modulo 1000 and taking the result modulo 1000 at each step.\n\n---\n\n### **Step 3: Observe periodicity in powers of 10 modulo 1000**\n\nWe can compute $10^k \\mod 1000$ for $k = 1$ to $999$, and then subtract 1 to get each term in the product.\n\nLet’s compute the first few terms:\n\n- $10^1 = 10 \\Rightarrow 10^1 - 1 = 9$\n- $10^2 = 100 \\Rightarrow 10^2 - 1 = 99$\n- $10^3 = 1"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "def tau(n):\n    count = 0\n    for i in range(1, n + 1):\n        if n % i == 0:\n            count += 1\n    return count\n\ndef find_sum_of_six():\n    total = 0\n    count = 0\n    n = 1\n    while True:\n        if tau(n) == tau(n + 1):\n            total += n\n            count += 1\n            if count == 6:\n                return total\n        n += 1"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "0"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "from sympy import symbols, Eq, solve\n\nA, B, C = symbols('A B C')\neq1 = Eq(A*19**2 + B*19 + C, 0)\neq2 = Eq(A*92**2 + B*92 + C, 0)\nsolution = solve((eq1, eq2), (A, B, C))\na1 = solution[A]*1**2 + solution[B]*1 + solution[C]"
  },
  {
    "output": "150"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "170"
  },
  {
    "output": ""
  },
  {
    "output": "[Hard problem, difficulty=7] Step-by-step reasoning:\nWe are asked to find the **probability that Zou will win exactly 5 of the 6 races**, given the following conditions:\n\n- The probability of winning a race **depends on whether they won or lost the previous race**.\n- Zou **wins the first race**.\n\n---\n\n### Step 1: Understand the Problem\n\nWe are dealing with a **Markov process** where the outcome of each race depends on the outcome of the previous one. This means the probability of winning a race is not constant—it changes based on the previous result.\n\nWe are told:\n- Zou **wins the first race**.\n- We are to find the **probability that Zou wins exactly 5 out of the next 6 races** (i.e., total of 6 races, with the first one already known to be a win).\n\nSo, we are to find the probability that Zou wins **exactly 5 out of 6 races**, given that the first race is a win, and the probability of winning a race depends on the previous race's outcome.\n\n---\n\n### Step 2: Define the Transition Probabilities\n\nLet’s define the following:\n\n- Let $ p $ be the probability that Zou **wins a race** given that they **won the previous race**.\n- Let $ q $ be the probability that Zou **wins a race** given that they **lost the previous race**.\n\nWe are not given specific values for $ p $ and $ q $, so we will assume they are constants. However, since the problem is about **exactly 5 wins out of 6 races**, and the first race is a win, we can model this as a **Markov chain** with states:\n\n- **State W**: Zou wins the current race.\n- **State L**: Zou loses the current race.\n\nWe are given that the first race is a **win**, so we start in state **W**.\n\nWe are to find the probability that Zou wins **exactly 5 out of the next 6 races**, starting from a win.\n\n---\n\n### Step 3: Model the Problem as a Markov Chain\n\nLet’s denote the states as:\n\n- $ W $: Win the current race\n- $ L $: Lose the current race\n\nWe are given:\n- $ P(W|W) = p $\n- $ P(L|W) = 1 - p $\n- $ P(W|L) = q $\n- $ P(L|L) = 1"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "def find_greatest_n_and_compute_q_r():\n    for n in range(9999, 999, -1):\n        if all(int(d) != 1 for d in str(n)):\n            if all(int(str(n).replace(str(d), '1')) % 7 == 0 for d in str(n)):\n                q, r = divmod(n, 1000)\n                return q + r\n    return -1"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "7000"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "137"
  },
  {
    "output": ""
  },
  {
    "output": "map(str, base7_digits))) if base7_digits else 0\n    \n    return base10_number == 2 * n\n\ndef find_largest_7_10_double():\n    n = 1\n    while True:\n        if is_7_10_double(n):\n            result = n\n        else:\n            break\n        n += 1\n    return result"
  },
  {
    "output": ""
  },
  {
    "output": "def find_rotation_angle_and_center(A, B, C, A_prime, B_prime, C_prime):\n    import math\n    def midpoint(p1, p2):\n        return ((p1[0] + p2[0])/2, (p1[1] + p2[1])/2)\n    def slope(p1, p2):\n        if p2[0] - p1[0] == 0:\n            return float('inf')\n        return (p2[1] - p1[1]) / (p2[0] - p1[0])\n    def perpendicular_slope(s):\n        if s == 0:\n            return float('inf')\n        if s == float('inf'):\n            return 0\n        return -1 / s\n    def line_eq(p, m):\n        x, y = p\n        return (y - x * m, m)\n    def intersect(l1, l2):\n        m1, b1 = l1\n        m2, b2 = l2\n        if m1 == m2:\n            return None\n        x = (b2 - b1) / (m1 - m2)\n        y = m1 * x + b1\n        return (x, y)\n    mid_aa = midpoint(A, A_prime)\n    mid_bb = midpoint(B, B_prime)\n    slope_aa = slope(A, A_prime)\n    slope_bb = slope(B, B_prime)\n    perp_slope_aa = perpendicular_slope(slope_aa)\n    perp_slope_bb = perpendicular_slope(slope_bb)\n    line_aa = line_eq(mid_aa, perp_slope_aa)\n    line_bb = line_eq(mid_bb, perp_slope_bb)\n    center = intersect(line_aa, line_bb)\n    if center is None:\n        return (0, (0, 0))\n    def angle_between(p1, p2, center):\n        v1 = (p1[0] - center[0], p1[1] - center[1])\n        v2 = (p2[0] - center[0], p2[1] - center[1])\n        dot = v1[0] * v2[0] + v1[1] * v2[1]\n        mag1 = math.hypot(v1[0], v1[1])\n        mag2 = math.hypot(v2[0], v2[1])\n        if mag1 == 0 or mag2 == 0:\n            return 0\n        cos_theta = dot / (mag1 * mag2)\n        cos_theta = max(min(cos_theta, 1), -1)\n        theta = math.acos(cos_theta)\n        if (p1[0] - center[0]) * (p2[0] - center[0]) < 0 or (p1[1] - center[1]) * (p2[1] - center[1]) < 0:\n            theta = -theta\n        return math.degrees(theta)\n    angle = angle_between(A, A_prime, center)\n    return (angle, center)"
  },
  {
    "output": ""
  },
  {
    "output": "import math\n\n# Given values\nradius_large_circle = 20\ndiameter_small_circle = 10\nradius_small_circle = diameter_small_circle / 2\n\n# Step 1: Determine the side length of the square\n# The square is tangent to the smaller circle, so the side length is equal to the diameter of the smaller circle\nside_length_square = diameter_small_circle\n\n# Step 2: Calculate the length of AB\n# AB is the distance between two points on the larger circle, which is the diameter of the larger circle\nlength_AB = 2 * radius_large_circle\n\n# The length of AB can be written in the form m + sqrt(n)\n# Since the length is 40, it can be expressed as 40 + sqrt(0)\nm = 40\nn = 0\n\n# Return the result in the form m + sqrt(n)\nresult = m + math.sqrt(n)\nresult"
  },
  {
    "output": "def solve():\n    from sympy import symbols, sqrt, I, expand, simplify, Eq, solve\n    m, n = symbols('m n', positive=True, integer=True)\n    z = m + sqrt(n) + 11*I\n    f_z = expand(z**2 - 19*z)\n    f_f_z = expand(f_z**2 - 19*f_z)\n    vec1 = f_z - z\n    vec2 = f_f_z - f_z\n    # Compute dot product (real part of conjugate(vec1)*vec2)\n    dot_product = simplify((vec1.conjugate() * vec2).as_real_imag()[0])\n    eq = Eq(dot_product, 0)\n    sol = solve(eq, (m, n))\n    return sol[0][0] + sol[0][1]"
  },
  {
    "output": "262144"
  },
  {
    "output": "120/243\n\nThe probability of getting exactly 3 heads in 5 flips with $ p = \\frac{1}{3} $ is $ \\frac{120}{243} $, which simplifies to $ \\frac{40}{81} $. Therefore, $ i + j = 40 + 81 = 121 $.\n\nFINAL ANSWER: 121"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "1999000.0"
  },
  {
    "output": ""
  },
  {
    "output": "18"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "def count_valid_strings():\n    from collections import defaultdict\n    dp = [defaultdict(int) for _ in range(11)]\n    dp[0]['A'][0] = 1\n    dp[0]['B'][0] = 1\n    for i in range(1, 11):\n        for c in ['A', 'B']:\n            for l in range(4):\n                if l == 0:\n                    dp[i][c][l] = dp[i-1]['A'][0] + dp[i-1]['B'][0]\n                else:\n                    dp[i][c][l] = dp[i-1][c][l-1]\n    return sum(dp[10]['A'][l] + dp[10]['B'][l] for l in range(4))"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "$ r\\sqrt{3} $"
  },
  {
    "output": "import math\nnumerator = math.cos(math.radians(96)) + math.sin(math.radians(96))\ndenominator = math.cos(math.radians(96)) - math.sin(math.radians(96))\nresult = numerator / denominator\nangle_rad = math.atan(result)\nx_deg = math.degrees(angle_rad) / 19"
  },
  {
    "output": "264"
  },
  {
    "output": "1504"
  },
  {
    "output": "def count_paths():\n    num_vertices_per_layer = 5\n    dp = [[0]*num_vertices_per_layer for _ in range(3)]\n    dp[0] = [1]*num_vertices_per_layer\n    for layer in range(1, 3):\n        for vertex in range(num_vertices_per_layer):\n            dp[layer][vertex] = sum(dp[layer-1][vertex-1:vertex+2])\n    return sum(dp[2])"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "890"
  },
  {
    "output": "False"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "from math import gcd\nfrom functools import reduce\n\ndef lcm(a, b):\n    return a * b // gcd(a, b)\n\ndef compute_lcm_up_to_m(m):\n    return reduce(lcm, range(1, m + 1), 1)\n\ndef sum_q(m_max):\n    total = 0\n    current_lcm = 1\n    for m in range(2, m_max + 1):\n        current_lcm = lcm(current_lcm, m)\n        total = (total + current_lcm) % 1000\n    return total\n\nsum_q(2017)"
  },
  {
    "output": ""
  },
  {
    "output": "31"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "40"
  },
  {
    "output": ""
  },
  {
    "output": "27.0"
  },
  {
    "output": ""
  },
  {
    "output": "g(x) = \\frac{x}{2}"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "55.0"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "$\\frac{n}{n+1}$"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "1559"
  },
  {
    "output": ""
  },
  {
    "output": "88"
  },
  {
    "output": ""
  },
  {
    "output": "def find_smallest_common_sum():\n    def get_sums(n):\n        sums = set()\n        a = 1\n        while True:\n            s = n * (2 * a + n - 1) // 2\n            if s > 10000:\n                break\n            sums.add(s)\n            a += 1\n        return sums\n    nine_sums = get_sums(9)\n    ten_sums = get_sums(10)\n    eleven_sums = get_sums(11)\n    common = nine_sums & ten_sums & eleven_sums\n    return min(common)"
  },
  {
    "output": "def count_equal_an():\n    def compute_an(n):\n        from math import gcd\n        m = 1 << n\n        for k in range(1, 10000):\n            if (k * 23) % m == 1:\n                return k * 23\n    count = 0\n    prev = 0\n    for n in range(1, 1001):\n        current = compute_an(n)\n        if current == prev:\n            count += 1\n        prev = current\n    return count"
  },
  {
    "output": "-37"
  },
  {
    "output": "Error: leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers (<string>, line 1)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "from math import log10, isqrt\n\ndef solve():\n    n = 1000000\n    divisors = set()\n    for i in range(1, isqrt(n) + 1):\n        if n % i == 0:\n            divisors.add(i)\n            divisors.add(n // i)\n    divisors.discard(n)\n    total = sum(log10(d) for d in divisors)\n    return round(total)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "[Easy problem, difficulty=4] Think simply and give the direct answer."
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "49.5"
  },
  {
    "output": "342"
  },
  {
    "output": "The problem statement is incomplete and cannot be solved as given."
  },
  {
    "output": "from math import comb\n\ndef calculate_favorable_outcomes():\n    odd_tiles = [1, 3, 5, 7, 9]\n    even_tiles = [2, 4, 6, 8]\n    total_odd = len(odd_tiles)\n    total_even = len(even_tiles)\n    \n    # Each player must have 1 or 3 odd tiles\n    # We need to distribute 5 odd tiles among 3 players such that each has 1 or 3\n    # Possible distributions of odd tiles: (1,1,3), (1,3,1), (3,1,1), (3,3,-1) invalid, etc.\n    # Only valid distributions are those where sum is 5 and each is 1 or 3\n    # Valid distributions: (1,1,3), (1,3,1), (3,1,1)\n    \n    # Number of ways to choose which player gets 3 odd tiles\n    ways_to_choose_player_with_3_odds = 3\n    \n    # For each such choice, choose 3 odd tiles for that player\n    ways_to_choose_3_odds = comb(total_odd, 3)\n    \n    # Remaining 2 odd tiles are distributed as 1 each to the other two players\n    # Number of ways to distribute remaining 2 odd tiles to 2 players\n    ways_to_distribute_remaining_odds = 1  # since it's fixed\n    \n    # Distribute even tiles: 4 even tiles to 3 players, each gets 0, 1, or 2\n    # Total ways to distribute 4 even tiles to 3 players (each can get 0, 1, or 2)\n    # We need to count all valid distributions of 4 even tiles to 3 players\n    # Using stars and bars with constraints (each player can get 0, 1, or 2)\n    # We can use combinatorics to count the number of valid distributions\n    \n    # Total number of ways to distribute 4 even tiles to 3 players\n    total_even_distributions = 0\n    for a in range(0, 3):\n        for b in range(0, 3):\n            c = 4 - a - b\n            if 0 <= c <= 2:\n                total_even_distributions += 1\n    \n    # Total number of ways to distribute all tiles\n    total_ways = comb(9, 3) * comb(6, 3) * comb(3, 3)\n    \n    # Calculate favorable outcomes\n    favorable = ways_to_choose_player_with_3_odds * ways_to_choose_3_odds * ways_to_distribute_remaining_odds * total_even_distributions\n    \n    return favorable, total_ways"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "def count_progressive_sequences(target):\n    def backtrack(start, current_sum, current_sequence):\n        if current_sum > target:\n            return 0\n        if current_sum == target:\n            return 1\n        total = 0\n        for i in range(start, target - current_sum + 1):\n            if not current_sequence or i % current_sequence[-1] == 0:\n                total += backtrack(i + 1, current_sum + i, current_sequence + [i])\n        return total\n    return backtrack(1, 0, [])"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "def count_non_carrying_pairs():\n    def no_carry(a, b):\n        while a > 0 or b > 0:\n            if (a % 10 + b % 10) >= 10:\n                return False\n            a //= 10\n            b //= 10\n        return True\n    count = 0\n    for m in range(1493):\n        n = 1492 - m\n        if no_carry(m, n):\n            count += 1\n    return count"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "2016"
  },
  {
    "output": "2592√3"
  },
  {
    "output": ""
  },
  {
    "output": "def count_factors(n, p): return sum(n // (p**k) for k in range(1, n+1) if p**k <= n)"
  },
  {
    "output": "from sympy import symbols, expand, Rational\n\nx = symbols('x')\nP = 1 - Rational(1,3)*x + Rational(1,6)*x**2\nQ = P * P.subs(x, x**3) * P.subs(x, x**5) * P.subs(x, x**7) * P.subs(x, x**9)\nQ_expanded = expand(Q)\ncoeffs = [abs(coeff) for coeff in Q_expanded.as_coefficients_dict().values()]\nsum_abs = sum(coeffs)\nsum_abs = sum_abs.as_numer_denom()\nm, n = sum_abs\nm + n"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "sum(int((n * (n + 1) // 2) % 10) for n in range(1, 2018)) % 1000"
  },
  {
    "output": "def calculate_m():\n    from collections import defaultdict\n    import math\n\n    heights = [3, 4, 6]\n    n = 10\n    dp = [0] * (n * 6 + 1)\n    dp[0] = 1\n\n    for i in range(1, n + 1):\n        new_dp = [0] * (i * 6 + 1)\n        for h in range(i * 6 + 1):\n            for height in heights:\n                if h - height >= 0:\n                    new_dp[h] += dp[h - height]\n        dp = new_dp\n\n    total = 3 ** n\n    favorable = dp[41]\n\n    m = favorable\n    n = total\n    gcd = math.gcd(m, n)\n    m //= gcd\n    n //= gcd\n\n    return m"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "The problem statement is incomplete and cannot be solved as given."
  },
  {
    "output": ""
  },
  {
    "output": "792"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "4"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "import math; a = 150; b = 324; c = 375; gcd_ab = math.gcd(a, b); gcd_bc = math.gcd(b, c); gcd_ca = math.gcd(c, a); gcd_abc = math.gcd(math.gcd(a, b), c); result = a + b + c - gcd_ab - gcd_bc - gcd_ca + gcd_abc; result"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "def find_min_n():\n    for x in range(1, 100):\n        for y in range(1, 100):\n            for z in range(1, 100):\n                hidden = x*y*z - (x*y + y*z + z*x - x - y - z + 1)\n                if hidden == 231:\n                    return x*y*z\n    return -1"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "5151"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "2520"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "196"
  },
  {
    "output": "Error: No problem found for CoT analysis"
  },
  {
    "output": "def find_greatest_palindrome():\n    def is_palindrome(n):\n        s = str(n)\n        return s == s[::-1]\n    for i in range(999, 9, -1):\n        if is_palindrome(i) and is_palindrome(oct(i)[2:]):\n            return i\n    return 0"
  },
  {
    "output": "2.86"
  },
  {
    "output": "def E(r, b):\n    if r == 0:\n        return b\n    if b == 0:\n        return r\n    if r == b:\n        return 1 + E(r - 1, b - 1)\n    if r > b:\n        return 1 + (r / (r + b)) * E(r - 1, b) + (b / (r + b)) * E(r, b - 1)\n    else:\n        return 1 + (b / (r + b)) * E(r, b - 1) + (r / (r + b)) * E(r - 1, b)"
  },
  {
    "output": "sum(1 for a3 in range(100) for a2 in range(100) for a1 in range(100) if (2010 - 1000*a3 - 100*a2 - 10*a1) >= 0 and (2010 - 1000*a3 - 100*a2 - 10*a1) <= 99)"
  },
  {
    "output": "def find_sum_of_digits():\n    total = 0\n    for n in range(2020, 10**8 + 1, 10000):\n        k = n // 10000\n        if n % k == 0:\n            digit_sum = sum(int(d) for d in str(n))\n            total += digit_sum\n    return total"
  },
  {
    "output": ""
  },
  {
    "output": "10"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "number = d * 1000 + (d-1) * 100 + (d-2) * 10 + (d-3)\n    remainder = number % 37\n    possible_remainders.add(remainder)\n\nsum_remainders = sum(possible_remainders)"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "1"
  },
  {
    "output": "63"
  },
  {
    "output": "71"
  },
  {
    "output": ""
  },
  {
    "output": "[Hard problem, difficulty=7] Step-by-step reasoning:\nLet's solve this problem step by step.\n\n---\n\n### **Step 1: Understand the Problem**\n\nWe are given:\n\n- A **round table** with **12 chairs**, numbered **1 to 12**.\n- There are **4 ambassadors** and **4 advisors** (one for each ambassador).\n- **Each ambassador must sit in an even-numbered chair**.\n- **Each advisor must sit in a chair adjacent to their ambassador**.\n- We are to find the number of **valid seating arrangements** (N), and then find **N mod 1000**.\n\n---\n\n### **Step 2: Break Down the Problem**\n\n#### **2.1: Identify the even-numbered chairs**\n\nThere are 12 chairs, numbered 1 through 12. The **even-numbered chairs** are:\n\n$$\n\\{2, 4, 6, 8, 10, 12\\}\n$$\n\nSo there are **6 even-numbered chairs**.\n\nWe are told that **each of the 4 ambassadors must sit in an even-numbered chair**. That means we will choose **4 out of these 6 chairs** for the ambassadors.\n\n#### **2.2: Assign ambassadors to even-numbered chairs**\n\nWe need to choose **4 chairs** from the 6 even-numbered chairs for the ambassadors. The number of ways to choose 4 chairs from 6 is:\n\n$$\n\\binom{6}{4} = 15\n$$\n\nOnce we have selected the 4 chairs, we can assign the 4 ambassadors to these chairs in **4! = 24** ways.\n\nSo, the number of ways to assign ambassadors to even-numbered chairs is:\n\n$$\n\\binom{6}{4} \\times 4! = 15 \\times 24 = 360\n$$\n\n#### **2.3: Assign advisors to adjacent chairs**\n\nEach advisor must sit in a chair **adjacent** to their ambassador. Since the table is **round**, the chairs are arranged in a circle, and chair 12 is adjacent to chair 1.\n\nLet’s consider the **positions of the ambassadors**. Since they are in **even-numbered chairs**, their adjacent chairs are:\n\n- For chair 2: adjacent to 1 and 3\n- For chair 4: adjacent to 3 and 5\n- For chair 6: adjacent to 5 and 7\n-"
  },
  {
    "output": ""
  },
  {
    "output": "The problem is incomplete and cannot be solved as stated."
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "sum(1 for i in range(1, 2004) if bin(i).count('1') > bin(i).count('0')) % 1000"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "11"
  },
  {
    "output": "def calculate_n_mod_1000():\n    import math\n    n = 0\n    for i in range(1, 1001):\n        if i % 2 == 1:\n            n += i**2\n        else:\n            n -= i**2\n    return n % 1000"
  },
  {
    "output": ""
  },
  {
    "output": "100"
  },
  {
    "output": "Error: '(' was never closed (<string>, line 1)"
  },
  {
    "output": "from math import gcd\n\ndef solution():\n    numerators = set()\n    for num in range(1, 10000):\n        g = gcd(num, 9999)\n        numerator = num // g\n        numerators.add(numerator)\n    return len(numerators) % 1000"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "265"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "def count_valid_pairs():\n    count = 0\n    for a in range(1, 1000):\n        b = 1000 - a\n        if '0' not in str(a) and '0' not in str(b):\n            count += 1\n    return count"
  },
  {
    "output": "432"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "17"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "[Hard problem, difficulty=7] Step-by-step reasoning:\nWe are given that:\n\n$$\nN \\equiv N^2 \\pmod{10000}\n$$\n\nThis means that $ N $ and $ N^2 $ end in the same four digits, i.e., they are congruent modulo 10000.\n\n---\n\n### **Step 1: Understand the congruence**\n\nWe are given:\n\n$$\nN \\equiv N^2 \\pmod{10000}\n$$\n\nRewriting this:\n\n$$\nN^2 - N \\equiv 0 \\pmod{10000}\n$$\n\n$$\nN(N - 1) \\equiv 0 \\pmod{10000}\n$$\n\nThis tells us that $ N(N - 1) $ is divisible by 10000.\n\n---\n\n### **Step 2: Factor 10000**\n\nWe factor 10000:\n\n$$\n10000 = 2^4 \\cdot 5^4\n$$\n\nSo, for $ N(N - 1) \\equiv 0 \\pmod{10000} $, we need:\n\n$$\nN(N - 1) \\equiv 0 \\pmod{16} \\quad \\text{and} \\quad N(N - 1) \\equiv 0 \\pmod{625}\n$$\n\nThis is because 16 and 625 are coprime, and by the Chinese Remainder Theorem, the congruence modulo 10000 is equivalent to the system of congruences modulo 16 and 625.\n\n---\n\n### **Step 3: Solve the system of congruences**\n\nWe now solve:\n\n$$\nN(N - 1) \\equiv 0 \\pmod{16} \\quad \\text{and} \\quad N(N - 1) \\equiv 0 \\pmod{625}\n$$\n\n#### **Part A: Solve modulo 16**\n\nWe want:\n\n$$\nN(N - 1) \\equiv 0 \\pmod{16}\n$$\n\nThis means that either:\n\n- $ N \\equiv 0 \\pmod{16} $, or\n- $ N \\equiv 1 \\pmod{16} $\n\nSo the solutions modulo 16 are:\n\n$$\nN \\equiv 0 \\pmod{16} \\quad \\"
  },
  {
    "output": "[Hard problem, difficulty=7] Step-by-step reasoning:\nWe are asked to find the number of **positive integers** that are **divisors of at least one** of the numbers:  \n- $10^{10}$  \n- $15^7$  \n- $18^{11}$\n\n---\n\n### **Step 1: Prime Factorizations**\n\nWe begin by finding the prime factorizations of each number.\n\n#### **(a) $10^{10}$**\n\n$$\n10 = 2 \\cdot 5 \\Rightarrow 10^{10} = (2 \\cdot 5)^{10} = 2^{10} \\cdot 5^{10}\n$$\n\n#### **(b) $15^7$**\n\n$$\n15 = 3 \\cdot 5 \\Rightarrow 15^7 = (3 \\cdot 5)^7 = 3^7 \\cdot 5^7\n$$\n\n#### **(c) $18^{11}$**\n\n$$\n18 = 2 \\cdot 3^2 \\Rightarrow 18^{11} = (2 \\cdot 3^2)^{11} = 2^{11} \\cdot 3^{22}\n$$\n\n---\n\n### **Step 2: Find the Set of All Divisors**\n\nWe are to find the number of **positive integers** that are **divisors of at least one** of the three numbers:  \n- $10^{10} = 2^{10} \\cdot 5^{10}$  \n- $15^7 = 3^7 \\cdot 5^7$  \n- $18^{11} = 2^{11} \\cdot 3^{22}$\n\nLet’s denote the set of all divisors of these numbers as:\n\n$$\nD = \\text{Set of all divisors of } 10^{10} \\cup \\text{Set of all divisors of } 15^7 \\cup \\text{Set of all divisors of } 18^{11}\n$$\n\nWe are to find the **cardinality** of this union:  \n$$\n|D| = |\\text{Divisors of } 10^{10}| + |\\text{Divisors of } 15^7| + |\\text{Divisors of } 18^{11}| - |\\text{Divisors common to two of"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "for c in range(20, 100):\n    for w in range(0, 100):\n        s = 30 + 4 * c - w\n        if s > 80:\n            unique = True\n            for c2 in range(20, 100):\n                for w2 in range(0, 100):\n                    if 30 + 4 * c2 - w2 == s and (c2, w2) != (c, w):\n                        unique = False\n                        break\n                if not unique:\n                    break\n            if unique:\n                print(s)\n                break\n        if unique:\n            break"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Insufficient information to solve the problem."
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef process_fft(data):\n    if not data:\n        return np.array([]), np.array([]), None\n    arr = np.array(data)\n    fft_data = np.fft.fft(arr)\n    plt.hist(np.abs(fft_data), bins=20)\n    fig = plt.gcf()\n    return arr, fft_data, fig.axes[0] if fig.axes else None"
  },
  {
    "output": "import pandas as pd\nimport numpy as np\n\ndef create_random_matrix_df(rows, cols):\n    matrix = np.random.randint(0, 100, size=(rows, cols))\n    return pd.DataFrame(matrix)"
  },
  {
    "output": "def count_non_stopwords(text, stopwords):\n    words = text.split()\n    return len([word for word in words if word.lower() not in stopwords])"
  },
  {
    "output": ".uniform(lon_range[0], lon_range[1], size=len(cities))\n    lat = np.random.uniform(lat_range[0], lat_range[1], size=len(cities))\n    \n    # Create GeoDataFrame\n    geometry = [Point(lon[i], lat[i]) for i in range(len(cities))]\n    gdf = gpd.GeoDataFrame({\n        'City': cities,\n        'Lon': lon,\n        'Lat': lat\n    }, geometry=geometry)\n    \n    return gdf"
  },
  {
    "output": ""
  },
  {
    "output": "# Create a box plot of the imputed last column\n    plt.figure()\n    sns.boxplot(x=df[last_column])\n    axes = plt.gca()\n    return df, axes"
  },
  {
    "output": "def task_func(input_list):\n    import pandas as pd\n    import numpy as np\n    import matplotlib.pyplot as plt\n    if not isinstance(input_list, list) or any(not isinstance(sublist, list) for sublist in input_list):\n        raise ValueError(\"Input must be a list of lists\")\n    flattened = []\n    for sublist in input_list:\n        if sublist:\n            flattened.extend(sublist)\n    if not flattened:\n        return plt.subplots()[1]\n    df = pd.DataFrame(flattened, columns=['value'])\n    fig, ax = plt.subplots()\n    df['value'].value_counts().plot(kind='bar', ax=ax)\n    return ax"
  },
  {
    "output": "def run_scripts_in_directory(directory):\n    import os\n    import time\n    results = {}\n    for filename in os.listdir(directory):\n        if filename.endswith('.py'):\n            script_path = os.path.join(directory, filename)\n            start_time = time.time()\n            with open(script_path, 'r') as f:\n                code = f.read()\n            exec(code, {})\n            end_time = time.time()\n            results[filename] = end_time - start_time\n    return results"
  },
  {
    "output": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef generate_normal_distribution_plot(mean=0, std=1, size=1000):\n    np.random.seed(0)\n    data = np.random.normal(mean, std, size)\n    fig, ax = plt.subplots()\n    ax.hist(data, bins=30, density=True, alpha=0.6, color='g')\n    x = np.linspace(-5, 5, 1000)\n    pdf = (1/(std*np.sqrt(2*np.pi))) * np.exp(- (x - mean)**2 / (2*std**2))\n    ax.plot(x, pdf, 'k', linewidth=2)\n    return fig"
  },
  {
    "output": "```python\nimport os\nimport sys\nimport importlib\nfrom pkgutil import iter_modules\nimport pkg_resources\n\ndef task_func(package_name"
  },
  {
    "output": "def task_func(source_dir, destination_dir):\n    import os\n    if not os.path.exists(source_dir) or not os.path.isdir(source_dir):\n        raise ValueError(\"Source path does not exist or is not a directory\")\n    files = os.listdir(source_dir)\n    for file in files:\n        src_path = os.path.join(source_dir, file)\n        dest_path = os.path.join(destination_dir, file)\n        os.system(f\"cp {src_path} {dest_path}\")\n    return (os.path.basename(source_dir), files)"
  },
  {
    "output": "import random\nimport string\n\ndef task_func(length, num_digits):\n    if num_digits > length or num_digits < 0:\n        raise ValueError(\"Number of digits cannot exceed the length of the password or be negative.\")\n    digits = ''.join(random.choices(string.digits, k=num_digits))\n    letters = ''.join(random.choices(string.ascii_letters, k=length - num_digits))\n    password_chars = list(digits + letters)\n    random.shuffle(password_chars)\n    return ''.join(password_chars)"
  },
  {
    "output": "import matplotlib.pyplot as plt\nimport numpy as np\nfrom PIL import Image\nimport os\n\ndef read_image_and_create_histogram(image_path, output_path):\n    try:\n        img = Image.open(image_path)\n        img = img.convert('L')\n        data = np.array(img)\n        plt.hist(data.ravel(), bins=256, color='gray', alpha=0.7)\n        plt.xlabel('Pixel Value')\n        plt.ylabel('Frequency')\n        plt.title('Histogram')\n        plt.savefig(output_path)\n        plt.close()\n        return plt\n    except Exception as e:\n        print(f\"Error: {e}\")\n        return None"
  },
  {
    "output": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(mu, sigma, sample_size):\n    samples = np.random.normal(mu, sigma, sample_size)\n    plt.hist(samples, bins=30, alpha=0.75, color='blue', edgecolor='black')\n    plt.xlabel(\"Sample values\")\n    plt.ylabel(\"Frequency\")\n    plt.title(\"Histogram of Generated Samples\")\n    plt.show()\n    return samples"
  },
  {
    "output": "from datetime import datetime\nimport pytz\nfrom dateutil.parser import parse\n\ndef task_func(date_str, tz_str):\n    date = parse(date_str)\n    current_year = date.year\n    if date.month > 1 or (date.month == 1 and date.day > 1):\n        next_new_year = datetime(current_year + 1, 1, 1, tzinfo=date.tzinfo)\n    else:\n        next_new_year = datetime(current_year, 1, 1, tzinfo=date.tzinfo)\n    time_until_new_year = (next_new_year - date).total_seconds()\n    return int(time_until_new_year)"
  },
  {
    "output": "import itertools\nimport collections\n\ndef task_func(elements, subset_size):\n    subsets = itertools.combinations(elements, subset_size)\n    sums = [sum(subset) for subset in subsets]\n    count = collections.Counter(sums)\n    return dict(count)"
  },
  {
    "output": "```python\nimport pandas as pd\nimport random\n\ndef task_func(df):\n    def determine_winner(row):\n        if row['team1_score'] > row['team2_score']:\n            return row['team1']\n        elif row['team1_score'] < row['team2_score']:\n            return row['team2']\n        else:\n            return random.choice([row['team1'], row['team2']])\n    \n    df['winner'] = df.apply(determine_winner, axis=1)\n    return df\n```"
  },
  {
    "output": "def process_hex_string(hex_str, salt_size):\n    import hashlib\n    import os\n    import base64\n    hex_bytes = bytes.fromhex(hex_str)\n    salt = os.urandom(salt_size)\n    salted_data = hex_bytes + salt\n    hash_result = hashlib.sha256(salted_data).digest()\n    return (base64.b64encode(salt).decode('utf-8'), base64.b64encode(hash_result).decode('utf-8'))"
  },
  {
    "output": "def plot_normal_distributions(x, y, labels):\n    import matplotlib.pyplot as plt\n    fig, ax = plt.subplots()\n    for xi, yi, label in zip(x, y, labels):\n        ax.plot(xi, yi, label=label)\n    ax.legend()\n    return fig"
  },
  {
    "output": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom scipy.stats import ttest_ind\nfrom sklearn.utils import check_array\nfrom numpy import nan\n\ndef analyze_data(data, group_column, value_column):\n    data = data.dropna()\n    groups = data.groupby(group_column)\n    group_data = {group: group_data[value_column].values for group, group_data in groups}\n    descriptive_stats = {group: group_data[value_column].describe() for group, group_data in groups}\n    sns.boxplot(x=group_column, y=value_column, data=data)\n    plt.title('Boxplot of Values by Group')\n    plt.show()\n    sns.histplot(data=value_column, multiple=\"stack\", hue=group_column, kde=False)\n    plt.title('Histogram of Values by Group')\n    plt.show()\n    t_stat, p_value = ttest_ind(group_data[list(group_data.keys())[0]], group_data[list(group_data.keys())[1]])\n    result = {\n        'descriptive_statistics': descriptive_stats,\n        't_statistic': t_stat,\n        'p_value': p_value\n    }\n    return result"
  },
  {
    "output": "def process_hex_string(hex_str, salt_size):\n    import hashlib\n    import os\n    import base64\n    hex_bytes = bytes.fromhex(hex_str)\n    salt = os.urandom(salt_size)\n    salted_data = hex_bytes + salt\n    hash_result = hashlib.sha256(salted_data).digest()\n    return (base64.b64encode(salt).decode('utf-8'), base64.b64encode(hash_result).decode('utf-8'))"
  },
  {
    "output": "def rotate_and_display_image(image_path, angle):\n    import numpy as np\n    from PIL import Image\n    import matplotlib.pyplot as plt\n    \n    try:\n        img = Image.open(image_path)\n    except FileNotFoundError:\n        raise FileNotFoundError(f\"The image file {image_path} does not exist.\")\n    \n    img_array = np.array(img)\n    height, width = img_array.shape[:2]\n    center = (width // 2, height // 2)\n    \n    rotated = img.rotate(angle, expand=True)\n    rotated_array = np.array(rotated)\n    \n    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n    axes[0].imshow(img)\n    axes[0].set_title('Original')\n    axes[1].imshow(rotated)\n    axes[1].set_title('Rotated')\n    plt.show()\n    \n    return img_array, rotated_array"
  },
  {
    "output": "def task_func(min_val, max_val, seed=None):\n    import random\n    if seed is not None:\n        random.seed(seed)\n    numbers = [random.randint(min_val, max_val) for _ in range(100)]\n    freq_gen = ((num, numbers.count(num)) for num in numbers)\n    return max(freq_gen, key=lambda x: x[1])[0]"
  },
  {
    "output": "def task_func(n, pattern):\n    import re\n    import random\n    import string\n    while True:\n        s = ''.join(random.choices(string.ascii_letters, k=n))\n        if re.fullmatch(pattern, s):\n            return s"
  },
  {
    "output": "```python\nimport cgi\nimport http.server\nimport json\n\nSUCCESS_RESPONSE = {\n    'status': 'success',\n    'message': 'Data received successfully.'\n}\nERROR_RESPONSE = {\n    'status': 'error',\n    'message': 'Invalid data received.'\n}\n\ndef task_func():\n    class PostRequestHandler(http.server.BaseHTTPRequestHandler):\n        def do_POST(self):\n            content_length = int(self.headers.get('content-length', 0))\n            if content_length == 0:\n                self.send_error(400, \"No data key in request\")\n                return\n\n            content_type = self.headers.get('content-type')\n            if content_type != 'application/json':\n                self.send_response(400)\n                self.send_header('Content-Type', 'application/json')\n                self.end_headers()\n                self.wfile.write(json.dumps({\"error\": \""
  },
  {
    "output": "import math\nfrom itertools import combinations\n\ndef calculate_log_sum(numbers):\n    total = 0\n    for r in range(1, len(numbers) + 1):\n        for combo in combinations(numbers, r):\n            product = 1\n            for num in combo:\n                product *= num\n            total += math.log(product)\n    return total"
  },
  {
    "output": "def process_3d_data(objects, coordinates, save_plot, plot_path):\n    unzipped = list(zip(objects, coordinates))\n    objects, coordinates = zip(*unzipped)\n    coordinates = np.array(coordinates)\n    pca = PCA(n_components=2)\n    reduced = pca.fit_transform(coordinates)\n    if save_plot:\n        if plot_path is None:\n            raise ValueError(\"plot_path must be provided if save_plot is True\")\n        plt.scatter(reduced[:, 0], reduced[:, 1])\n        plt.savefig(plot_path)\n        return np.column_stack((objects, reduced))\n    else:\n        return np.column_stack((objects, reduced)), plt.gca()"
  },
  {
    "output": "import random\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport numpy as np\n\ndef task_func(hours, output_path):\n    time = pd.date_range(start='2023-01-01', periods=hours, freq='H')\n    vehicle_types = ['Car', 'Truck', 'Bike', 'Bus']\n    data = []\n    for t in time:\n        row = {'Time': t}\n        for vehicle in vehicle_types:\n            count = random.randint(0, 100)\n            row[vehicle] = count\n        data.append(row)\n    df = pd.DataFrame(data)\n    df.to_csv(output_path, index=False)\n    fig, ax = plt.subplots()\n    df.set_index('Time').plot(ax=ax)\n    return output_path, ax"
  },
  {
    "output": "```python\nimport pandas as pd\nimport random\nimport re\n\ndef task_func(person_names, email_domains, num_records=5):\n    # Input validation\n    if len(person_names) < num_records:\n        raise ValueError(\"Number of names provided is less than the number of records requested.\")\n    if not email_domains:\n        raise ValueError(\"No email domains provided.\")\n    \n    # Generate emails\n    emails = []\n    for _ in range(num_records):\n        name = random.choice(person_names)\n        domain = random.choice(email_domains)\n        email = f\"{name}@{domain}\"\n        cleaned_email = email.replace(\"@\", \"[at]\")\n        emails.append(cleaned_email)\n    \n    # Create DataFrame\n    df = pd.DataFrame({\n        'Name': [random.choice(person_names) for _ in range(num_records)],\n        'Email': emails\n    })\n    \n    return df\n```"
  },
  {
    "output": "from flask import Flask, redirect, url_for, render_template, request\nfrom flask_login import LoginManager, UserMixin, login_user, logout_user, login_required, current_user\nfrom flask_wtf import FlaskForm\nfrom wtforms import StringField, PasswordField, validators\nimport os\n\napp = Flask(__name__)\napp.secret_key = os.urandom(24)\n\nlogin_manager = LoginManager()\nlogin_manager.init_app(app)\nlogin_manager.login_view = 'login'\n\nclass User(UserMixin):\n    def __init__(self, id, username, password):\n        self.id = id\n        self.username = username\n        self.password = password\n\n    def get_id(self):\n        return self.id\n\n@login_manager.user_loader\ndef load_user(user_id):\n    return User(1, 'testuser', 'password')\n\nclass LoginForm(FlaskForm):\n    username = StringField('Username', [validators.DataRequired()])\n    password = PasswordField('Password', [validators.DataRequired()])\n\n@app.route('/login', methods=['GET', 'POST'])\ndef login():\n    form = LoginForm(request.form)\n    if request.method == 'POST' and form.validate():\n        user = load_user(1)\n        if user and user.password == form.password.data:\n            login_user(user)\n            return redirect(url_for('protected'))\n    return render_template('login.html', form=form)\n\n@app.route('/logout')\ndef logout():\n    logout_user()\n    return redirect(url_for('login'))\n\n@app.route('/protected')\n@login_required\ndef protected():\n    return f'Logged in as: {current_user.username}'\n\nif __name__ == '__main__':\n    app.run(debug=True)"
  },
  {
    "output": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(df, target):\n    X = df.drop(columns=[target])\n    y = df[target]\n    model = LinearRegression().fit(X, y)\n    score = model.score(X, y)\n    return score"
  },
  {
    "output": "import pandas as pd\nimport numpy as np\n\ndef generate_grades_data(num_students=100, num_courses=5):\n    np.random.seed(42)\n    students = [f'Student_{i}' for i in range(1, num_students + 1)]\n    courses = [f'Course_{i}' for i in range(1, num_courses + 1)]\n    grades = np.random.uniform(50, 100, size=(num_students, num_courses))\n    df = pd.DataFrame(grades, columns=courses, index=students)\n    df['Average'] = df.mean(axis=1)\n    return df"
  },
  {
    "output": "def standardize_and_plot(data, title, xlabel, ylabel):\n    import pandas as pd\n    import numpy as np\n    import matplotlib.pyplot as plt\n    data = data.drop_duplicates(subset='Name')\n    data['Age'] = (data['Age'] - data['Age'].mean()) / data['Age'].std()\n    data['Score'] = (data['Score'] - data['Score'].mean()) / data['Score'].std()\n    plt.scatter(data['Age'], data['Score'])\n    plt.title(title)\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    plt.show()"
  },
  {
    "output": "import re\nimport csv\nimport os\n\ndef save_dollar_words(text, output_path):\n    words = re.findall(r'\\b\\$\\w+\\b', text)\n    filtered_words = [word for word in words if not re.fullmatch(r'[$\\w]+', word)]\n    with open(output_path, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerow(['Word'])\n        for word in filtered_words:\n            writer.writerow([word])\n    return os.path.abspath(output_path)"
  },
  {
    "output": "import pandas as pd\nimport re\nimport random\n\ndef search_csv_with_regex(file_path, pattern, sample_size=None):\n    df = pd.read_csv(file_path)\n    matches = []\n    for col in df.columns:\n        for index, row in df.iterrows():\n            match = re.search(pattern, str(row[col]))\n            if match:\n                matches.append((index, col, match.group()))\n    if sample_size:\n        random.shuffle(matches)\n        matches = matches[:sample_size]\n    return pd.DataFrame(matches, columns=['Index', 'Column', 'Match'])"
  },
  {
    "output": "def count_files_with_word(directory, word):\n    import os\n    count = 0\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            file_path = os.path.join(root, file)\n            try:\n                with open(file_path, 'r') as f:\n                    if word in f.read():\n                        count += 1\n            except Exception:\n                pass\n    return count"
  },
  {
    "output": "def calculate_statistics_and_create_pie_chart(data, column):\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    if data.empty:\n        return \"Data is empty\"\n    stats = data[column].describe()\n    plt.figure()\n    plt.pie(stats['count'], labels=data[column].unique())\n    plt.title(f'Statistics for {column}')\n    plt.show()\n    return stats"
  },
  {
    "output": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\ndef task_func(n_points=100, random_seed=None):\n    np.random.seed(random_seed)\n    points = np.random.rand(n_points, 3)\n    fig = plt.figure()\n    plot = fig.add_subplot(111, projection='3d')\n    plot.scatter(points[:, 0], points[:, 1], points[:, 2], c='blue', marker='o')\n    plot.set_xlabel('X Axis')\n    plot.set_ylabel('Y Axis')\n    plot.set_zlabel('Z Axis')\n    return (points, plot)"
  },
  {
    "output": "from gensim.models import Word2Vec\nfrom nltk.corpus import stopwords\nimport nltk\nnltk.download('stopwords')\n\ndef task_func(texts):\n    stop_words = set(stopwords.words('english'))\n    cleaned_texts = [[word for word in text if word.isalpha() and word not in stop_words] for text in texts]\n    model = Word2Vec(sentences=cleaned_texts, vector_size=100, window=5, min_count=1, workers=4)\n    return model.vectors, model.index_to_key"
  },
  {
    "output": "def task_func(df):\n    pca = PCA(n_components=2)\n    df_pca = pca.fit_transform(df)\n    df_pca = pd.DataFrame(df_pca, columns=['PC1', 'PC2'])\n    return df_pca"
  },
  {
    "output": "import numpy as np\nimport matplotlib.pyplot as plt\ndef create_histogram(image):\n    try:\n        if not isinstance(image, np.ndarray) or image.ndim != 2:\n            raise ValueError(\"Input must be a 2D numpy array representing a grayscale image.\")\n        plt.hist(image.ravel(), bins=256, range=(0, 256), density=True)\n        plt.xlabel('Pixel Value')\n        plt.ylabel('Frequency')\n        plt.title('Grayscale Image Histogram')\n        return plt.gcf().canvas.renderer._renderer.tostring_rgb()\n    except Exception as e:\n        return str(e)"
  },
  {
    "output": "import json\nimport zlib\nimport base64\n\ndef serialize_compress_encode(data):\n    json_str = json.dumps(data)\n    compressed = zlib.compress(json_str.encode('utf-8'))\n    encoded = base64.b64encode(compressed)\n    return encoded.decode('utf-8')"
  },
  {
    "output": "import numpy as np\nfrom scipy import stats\n\ndef task_func(df, column, alpha):\n    data = np.array(df[column])\n    stat, p = stats.shapiro(data)\n    return p > alpha"
  },
  {
    "output": "import json\nimport requests\n\ndef task_func(prefix, endpoint):\n    try:\n        response = requests.get(endpoint)\n        response.raise_for_status()\n        data = response.json()\n        filename = f\"{prefix}{endpoint.split('/')[-1]}.json\"\n        with open(filename, 'w') as file:\n            json.dump(data, file)\n        return filename\n    except Exception as e:\n        raise RuntimeError(str(e))"
  },
  {
    "output": "def task_func(df, FEATURES, TARGET, dict_mapping, plot_histogram=False):\n    if not isinstance(df, pd.DataFrame) or TARGET not in df.columns or not all(f in df.columns for f in FEATURES):\n        raise ValueError(\"Invalid input DataFrame or missing columns\")\n    for col, mapping in dict_mapping.items():\n        if col in df.columns:\n            df[col] = df[col].replace(mapping)\n    scaler = StandardScaler()\n    df[FEATURES] = scaler.fit_transform(df[FEATURES])\n    if plot_histogram:\n        plt.hist(df[TARGET], bins=20)\n        plt.show()"
  },
  {
    "output": "def archive_project(config_path):\n    import json\n    import os\n    import shutil\n    import zipfile\n    with open(config_path, 'r') as f:\n        config = json.load(f)\n    project_dir = config['project_dir']\n    archive_name = config['archive_name']\n    archive_path = os.path.join(project_dir, archive_name)\n    if os.path.exists(archive_path):\n        os.remove(archive_path)\n    with zipfile.ZipFile(archive_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n        for root, dirs, files in os.walk(project_dir):\n            for file in files:\n                file_path = os.path.join(root, file)\n                arcname = os.path.relpath(file_path, project_dir)\n                zipf.write(file_path, arcname)"
  },
  {
    "output": "import sqlite3\nimport pandas as pd\nimport warnings\n\ndef task_func(db_path, query):\n    try:\n        conn = sqlite3.connect(db_path)\n        df = pd.read_sql_query(query, conn)\n        if len(df) > 10000:\n            warnings.warn(\"Dataset contains more than 10,000 rows.\")\n        return df\n    except Exception as e:\n        raise Exception(\"An error occurred while processing the database query.\") from e"
  },
  {
    "output": "from collections import defaultdict\n\ndef count_letter_frequencies(word_dict):\n    frequency = defaultdict(int)\n    for word in word_dict:\n        for letter in word:\n            frequency[letter] += 1\n    return frequency"
  },
  {
    "output": "```python\nimport binascii\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef task_func(hex_str):\n    try:\n        # Remove the '\\\\x' prefix if present\n        if hex_str.startswith('\\\\x'):\n            hex_str = hex_str[2:]\n        # Convert hex string to bytes\n        byte_data = binascii.unhexlify(hex_str)\n        # Count the frequency of each byte value\n        byte_freq = pd.Series(byte_data).value_counts()\n        # Create a DataFrame with 'Byte Value' and 'Frequency'\n        df = pd.DataFrame({\n            'Byte Value': byte_freq.index,\n            'Frequency': byte"
  },
  {
    "output": "import re\nimport requests\n\ndef extract_and_send(url_str, token):\n    url_pattern = re.compile(r'https?://\\S+')\n    url = url_pattern.search(url_str)\n    if url:\n        url = url.group(0)\n        headers = {'Authorization': f'Bearer {token}'}\n        response = requests.post('https://api.example.com/endpoint', json={'url': url}, headers=headers)\n        return response.json()\n    return None"
  },
  {
    "output": "import matplotlib.pyplot as plt\nfrom collections import Counter\n\nFRUITS = ['Apple', 'Banana', 'Cherry', 'Date', 'Elderberry', 'Fig', 'Grape', 'Honeydew', 'Indian Prune', 'Jackfruit']\n\ndef task_func(fruit_dict):\n    fruit_counts = Counter(fruit_dict.values())\n    fruits = list(fruit_counts.keys())\n    counts = list(fruit_counts.values())\n    fig, ax = plt.subplots()\n    ax.bar(fruits, counts)\n    ax.set_xlabel('Fruit')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Fruit Frequency')\n    return fruit_counts, ax"
  },
  {
    "output": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import kurtosis\n\ndef generate_and_analyze():\n    np.random.seed(0)\n    num_intervals = 1000\n    random_numbers = np.random.normal(size=num_intervals)\n    plt.plot(random_numbers)\n    plt.xlabel('Time')\n    plt.ylabel('Value')\n    plt.title('Random Numbers Over Time')\n    plt.show()\n    kurt = kurtosis(random_numbers)\n    return kurt"
  },
  {
    "output": "import matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nfrom datetime import datetime\nimport numpy as np\n\ndef parse_times_and_plot(times, time_format):\n    seconds = []\n    for time_str in times:\n        try:\n            dt = datetime.strptime(time_str, time_format)\n            seconds.append(dt.second)\n        except ValueError:\n            raise ValueError(f\"Invalid time string: {time_str}\")\n    plt.hist(seconds, bins=range(0, 61), align='left', rwidth=0.8)\n    plt.xlabel('Seconds')\n    plt.ylabel('Frequency')\n    plt.title('Histogram of Seconds')\n    plt.xticks(range(0, 60, 5))\n    plt.grid(axis='y', alpha=0.75)\n    plt.show()\n    return None"
  },
  {
    "output": "ax.plot(theta, r, color=color)\nax.set_rlabel_position(rlabel_pos)"
  },
  {
    "output": "def task_func(directory_path):\n    import os\n    import time\n    if not os.path.exists(directory_path):\n        return []\n    files = os.listdir(directory_path)\n    result = []\n    for file in files:\n        file_path = os.path.join(directory_path, file)\n        if os.path.isfile(file_path):\n            stats = os.stat(file_path)\n            size = stats.st_size\n            creation_time = time.strftime('%Y-%m-%d %H:%M:%S', time.gmtime(stats.st_ctime))\n            modification_time = time.strftime('%Y-%m-%d %H:%M:%S', time.gmtime(stats.st_mtime))\n            result.append({\n                'name': file,\n                'size': size,\n                'creation_time': creation_time,\n                'modification_time': modification_time\n            })\n    return result"
  },
  {
    "output": "def task_func(url, path, column):\n    import requests\n    import os\n    import csv\n    \n    response = requests.get(url)\n    with open(path, 'wb') as f:\n        f.write(response.content)\n    \n    with open(path, 'r') as f:\n        reader = csv.DictReader(f)\n        columns = reader.fieldnames\n    \n    if column not in columns:\n        os.remove(path)\n        raise ValueError(\"Column does not exist\")\n    \n    counts = {}\n    with open(path, 'r') as f:\n        reader = csv.DictReader(f)\n        for row in reader:\n            value = row[column]\n            counts[value] = counts.get(value, 0) + 1\n    \n    os.remove(path)\n    return counts"
  },
  {
    "output": "import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n\ndef standardize_and_visualize(list1, list2):\n    data = pd.DataFrame({'List1': list1, 'List2': list2})\n    scaler = StandardScaler()\n    standardized = scaler.fit_transform(data)\n    df_standardized = pd.DataFrame(standardized, columns=data.columns)\n    fig, ax = plt.subplots()\n    df_standardized.plot(kind='bar', ax=ax)\n    return df_standardized, ax"
  },
  {
    "output": "```python\nimport numpy as np\nimport itertools\nimport random\nimport statistics\n\ndef task_func(T1, RANGE=100):\n    if not T1:\n        raise statistics.StatisticsError(\"T1 is empty\")\n    \n    converted_T1 = [int(x) for x in T1]\n    size = sum(converted_T1)\n    \n    random_list = [random.randint(1, RANGE) for _ in range(size)]\n    \n    mean = statistics.mean(random_list)\n    median = statistics.median(random_list)\n    mode = statistics.mode(random_list)\n    \n    return (float(mean), float(median), int(mode))\n```"
  },
  {
    "output": "def normalize_and_plot(data, key1, key2):\n    import numpy as np\n    import matplotlib.pyplot as plt\n    try:\n        x = np.array(data[key1])\n        y = np.array(data[key2])\n    except KeyError as e:\n        raise ValueError(f\"Missing key: {e}\") from e\n    except TypeError:\n        raise ValueError(\"Data must be a dictionary with numeric values\") from None\n    x_min, x_max = x.min(), x.max()\n    y_min, y_max = y.min(), y.max()\n    normalized_x = (x - x_min) / (x_max - x_min)\n    normalized_y = (y - y_min) / (y_max - y_min)\n    plt.scatter(normalized_x, normalized_y)\n    plt.xlabel('Normalized ' + key1)\n    plt.ylabel('Normalized ' + key2)\n    plt.title('Normalized Data Plot')\n    plt.show()"
  },
  {
    "output": "import random\nfrom string import ascii_uppercase\n\ndef task_func(dict1):\n    unique_ids = []\n    for department, employees in dict1.items():\n        for _ in range(employees):\n            random_str = ''.join(random.choices(ascii_uppercase, k=5))\n            employee_id = f\"{department}{random_str}\"\n            unique_ids.append(employee_id)\n    return unique_ids"
  },
  {
    "output": "def task_func():\n    try:\n        result = 10 / 0\n    except ZeroDivisionError:\n        return \"Error: Division by zero\"\n    return result"
  },
  {
    "output": "import re\nimport string\n\nPUNCTUATION = string.punctuation\n\ndef task_func(text):\n    words = re.findall(r'\\b\\w+\\b', text)\n    num_words = len(words)\n    num_punctuation = 0\n    for char in text:\n        if char in PUNCTUATION:\n            num_punctuation += 1\n    return (num_words, num_punctuation)"
  },
  {
    "output": "import pandas as pd\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input is not a DataFrame\")\n    if df.empty:\n        raise ValueError(\"DataFrame is empty\")\n    \n    pca = PCA(n_components=2)\n    principal_components = pca.fit_transform(df)\n    \n    pc_df = pd.DataFrame(data=principal_components, columns=['Principal Component 1', 'Principal Component 2'])\n    \n    plt.figure(figsize=(8, 6))\n    plt.scatter(pc_df['Principal Component 1'], pc_df['Principal Component 2'])\n    plt.title('2 Component PCA')\n    plt.xlabel('Principal Component 1')\n    plt.ylabel('Principal Component 2')\n    axes = plt.gca()\n    \n    return pc_df, axes"
  },
  {
    "output": "ax.set_ylabel('Height')\n        ax.set_title('KMeans Clustering')\n        ax.grid(True)\n        plt.colorbar(scatter)\n        # Return the DataFrame and the Axes object\n        return filtered_df, ax"
  },
  {
    "output": "def task_func(*args, **kwargs):\n    import inspect\n    func_name = inspect.currentframe().f_back.f_code.co_name\n    num_args = len(args)\n    sqrt_num_args = num_args ** 0.5\n    lambda_count = 0\n    for default in kwargs.values():\n        if isinstance(default, list):\n            lambda_count += sum(1 for x in default if isinstance(x, lambda))\n        elif isinstance(default, dict):\n            lambda_count += sum(1 for v in default.values() if isinstance(v, lambda))\n        elif isinstance(default, set):\n            lambda_count += sum(1 for x in default if isinstance(x, lambda))\n    return func_name, sqrt_num_args, lambda_count"
  },
  {
    "output": "return ax"
  },
  {
    "output": "def filter_word_lengths(data, first_letter):\n    filtered = [word for word in data['Word'] if word.startswith(first_letter)]\n    lengths = [len(word) for word in filtered]\n    from collections import Counter\n    return dict(Counter(lengths))"
  },
  {
    "output": "def task_func(data, threshold=0.5):\n    if not isinstance(data, (list, tuple)) or not all(isinstance(x, (int, float)) for x in data):\n        raise ValueError(\"Input data must be a list or tuple of integers or floats.\")\n    if not isinstance(threshold, (int, float)):\n        raise ValueError(\"Threshold must be an integer or float.\")\n    if threshold < 0 or threshold > 1:\n        raise ValueError(\"Threshold must be between 0 and 1.\")\n    normalized = [x / max(data) if max(data) != 0 else 0 for x in data]\n    import matplotlib.pyplot as plt\n    plt.plot(normalized)\n    plt.title(\"Normalized Data\")\n    plt.xlabel(\"Index\")\n    plt.ylabel(\"Value\")\n    plt.show()\n    return normalized"
  },
  {
    "output": "import itertools\nimport random\n\ndef task_func(t, n):\n    if n > len(t):\n        raise ValueError(\"n cannot be greater than the length of the tuple\")\n    combinations = list(itertools.combinations(t, n))\n    random_combination = random.choice(combinations)\n    return tuple(random_combination)"
  },
  {
    "output": "def task_func(file1, file2):\n    import hashlib\n    try:\n        with open(file1, 'rb') as f1, open(file2, 'rb') as f2:\n            hash1 = hashlib.md5(f1.read()).hexdigest()\n            hash2 = hashlib.md5(f2.read()).hexdigest()\n        return hash1 == hash2\n    except FileNotFoundError:\n        raise FileNotFoundError(\"Either file does not exist.\")"
  },
  {
    "output": "def task_func(script_path, timeout):\n    import os\n    import psutil\n    import subprocess\n    import time\n    \n    if not os.path.exists(script_path):\n        return {\"error\": \"Script path does not exist\"}\n    \n    process = None\n    start_time = time.time()\n    cpu_usage = 0.0\n    memory_usage = 0\n    \n    try:\n        process = subprocess.Popen(\n            script_path,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            stdin=subprocess.PIPE,\n            start_new_session=True\n        )\n        \n        while True:\n            if time.time() - start_time > timeout:\n                process.terminate()\n                time.sleep(0.1)\n                process.kill()\n                return {\"error\": \"Timeout reached\"}\n            \n            if not process.poll():\n                try:\n                    cpu_usage += psutil.Process(process.pid).cpu_percent(interval=0.1)\n                    memory_usage = psutil.Process(process.pid).memory_info().rss\n                except psutil.NoSuchProcess:\n                    return {\"error\": \"Process not found\"}\n                time.sleep(0.1)\n            else:\n                break\n        \n        return {\"cpu_usage\": cpu_usage, \"memory_usage\": memory_usage}\n    \n    except Exception as e:\n        return {\"error\": str(e)}"
  },
  {
    "output": "def task_func(input_list):\n    import random\n    import pandas as pd\n    random.seed(42)\n    modified_list = []\n    for s in input_list:\n        if len(s) < 2:\n            modified_list.append(s)\n            continue\n        indices = list(range(len(s)))\n        random.shuffle(indices)\n        for i in indices:\n            if i + 1 <= len(s):\n                substring = s[i:i+1]\n                new_substring = ''.join(random.choices('abcdefghijklmnopqrstuvwxyz', k=1))\n                s = s[:i] + new_substring + s[i+1:]\n        modified_list.append(s)\n    df = pd.DataFrame({'Original': input_list, 'Modified': modified_list})\n    return df"
  },
  {
    "output": "def task_func(activities):\n    import matplotlib.pyplot as plt\n    from datetime import datetime\n    for activity in activities:\n        if not isinstance(activity, datetime):\n            raise TypeError(\"All activities must be datetime objects\")\n    days = [activity.strftime(\"%A\") for activity in activities]\n    from collections import Counter\n    counts = Counter(days)\n    days_order = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n    counts = {day: counts.get(day, 0) for day in days_order}\n    fig, ax = plt.subplots()\n    ax.bar(counts.keys(), counts.values())\n    ax.set_xlabel(\"Day of the Week\")\n    ax.set_ylabel(\"Number of Activities\")\n    ax.set_title(\"Activities Per Day of the Week\")\n    return ax"
  },
  {
    "output": "def draw_squares(colors):\n    import turtle\n    import time\n    screen = turtle.Screen()\n    screen.setup(800, 600)\n    t = turtle.Turtle()\n    t.speed(0)\n    for i in range(5):\n        color = colors[i % len(colors)]\n        t.color(color)\n        for _ in range(4):\n            t.forward(100)\n            t.right(90)\n        t.penup()\n        t.goto(t.xcor() + 150, t.ycor())\n        t.pendown()\n        time.sleep(1)\n    screen.mainloop()"
  },
  {
    "output": "import pandas as pd\nfrom sklearn.cluster import KMeans\nimport numpy as np\n\ndef task_func(x_list, y_list, n_clusters=2, random_state=0):\n    data = pd.DataFrame({'x': x_list, 'y': y_list})\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state)\n    kmeans.fit(data)\n    return (kmeans.labels_, kmeans.cluster_centers_)"
  },
  {
    "output": "import pandas as pd\nimport re\n\ndef task_func(data, mapping):\n    def replace_acronyms(text):\n        if pd.isna(text):\n            return text\n        for acronym, full_form in mapping.items():\n            text = re.sub(r'\\b' + re.escape(acronym) + r'\\b', full_form, text)\n        return text\n    \n    data = data.applymap(replace_acronyms)\n    return data"
  },
  {
    "output": "import os\nimport json\n\ndef task_func(config_path: str) -> dict:\n    if not os.path.exists(config_path):\n        raise FileNotFoundError(f\"The configuration file {config_path} does not exist.\")\n    with open(config_path, 'r') as file:\n        config = json.load(file)\n    return config"
  },
  {
    "output": "import hashlib\nfrom blake3 import blake3\n\ndef task_func(data):\n    blake3_hash = blake3(data.encode()).digest()\n    hex_hash = blake3_hash.hex()\n    md5_hash = hashlib.md5(hex_hash.encode()).hexdigest()\n    return md5_hash"
  },
  {
    "output": "def task_func(input_lists):\n    from math import isqrt\n    POSSIBLE_NUMBERS = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n    result = []\n    for lst in input_lists:\n        n = len(lst)\n        if n <= 3:\n            take = n\n        elif 4 <= n <= 7:\n            take = 4\n        else:\n            take = isqrt(n)\n        selected = POSSIBLE_NUMBERS[:take]\n        sum_squares = sum(x*x for x in selected)\n        result.append(sum_squares)\n    return result"
  },
  {
    "output": "def task_func(data_list):\n    if not data_list:\n        raise ValueError(\"data_list is empty\")\n    import matplotlib.pyplot as plt\n    import numpy as np\n    data = np.array(data_list)\n    for i in range(data.shape[1]):\n        plt.plot(data[:, i], label=f'Position {i}')\n    plt.legend()\n    plt.show()"
  },
  {
    "output": "def task_func(source_dir, dest_dir):\n    import os\n    import shutil\n    import random\n    files = [f for f in os.listdir(source_dir) if os.path.isfile(os.path.join(source_dir, f))]\n    if not files:\n        return \"\"\n    selected_file = random.choice(files)\n    source_path = os.path.join(source_dir, selected_file)\n    dest_path = os.path.join(dest_dir, selected_file)\n    shutil.move(source_path, dest_path)\n    return selected_file"
  },
  {
    "output": "plt.figure(figsize=(10, 6))\nplt.plot(df['Date'], df['Sales'], marker='o', linestyle='-')\nplt.title('Daily Turnover Line Chart')\nplt.xlabel('Date')\nplt.ylabel('Sales')\nplt.grid(True)\nreturn plt.gca()"
  },
  {
    "output": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n# Constants\nFEATURE_NAMES = [\"Feature 1\", \"Feature 2\", \"Feature 3\", \"Feature 4\", \"Feature 5\"]\n\ndef task_func(data_matrix):\n    scaler = StandardScaler()\n    standardized_data = scaler.fit_transform(data_matrix)\n    standardized_df = pd.DataFrame(standardized_data, columns=FEATURE_NAMES)\n    row_means = standardized_df.mean(axis=1)\n    standardized_df['Mean'] = row_means\n    fig, ax = plt.subplots()\n    ax.hist(row_means, bins=10, edgecolor='black')\n    ax.set_title('Distribution of Means')\n    return (standardized_df, ax)"
  },
  {
    "output": "def task_func(x, y):\n    import numpy as np\n    import matplotlib.pyplot as plt\n    if not isinstance(x, (list, np.ndarray)) or not isinstance(y, (list, np.ndarray)):\n        raise TypeError(\"Input must be a list or numpy array\")\n    if len(x) == 0 or len(y) == 0:\n        raise ValueError(\"Input lists cannot be empty\")\n    X, Y = np.meshgrid(x, y)\n    Z = X + 1j * Y\n    phase = np.angle(Z)\n    fig, ax = plt.subplots()\n    im = ax.imshow(phase, extent=[min(x), max(x), min(y), max(y)], origin='lower')\n    plt.colorbar(im)\n    return ax, phase"
  },
  {
    "output": "def plot_function_and_integral(func, x_range, func_name):\n    import numpy as np\n    import matplotlib.pyplot as plt\n    from scipy.integrate import cumtrapz\n    x = np.linspace(x_range[0], x_range[1], 1000)\n    y = func(x)\n    integral = cumtrapz(y, x, initial=0)\n    fig, ax = plt.subplots()\n    ax.plot(x, y, label=f\"{func_name} (original)\")\n    ax.plot(x, integral, label=f\"{func_name} (integral)\")\n    ax.legend()\n    ax.set_xlabel(f\"x\")\n    ax.set_ylabel(f\"{func_name}\")\n    return ax"
  },
  {
    "output": "from sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.utils import to_categorical\nimport numpy as np\n\ndef train_neural_network(X, y, k=5):\n    kf = KFold(n_splits=k)\n    history_list = []\n    for train_index, val_index in kf.split(X):\n        X_train, X_val = X[train_index], X[val_index]\n        y_train, y_val = y[train_index], y[val_index]\n        model = Sequential()\n        model.add(Dense(20, activation='relu', input_shape=(X_train.shape[1],)))\n        model.add(Dense(1, activation='sigmoid'))\n        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n        history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val), verbose=0)\n        val_loss = history.history['loss'][-1]\n        val_acc = history.history['accuracy'][-1]\n        history_list.append((val_loss, val_acc))\n    return history_list"
  },
  {
    "output": "import pandas as pd\nimport collections\n\ndef task_func(df):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input must be a DataFrame.\")\n    total_sales = df['Sales'].sum()\n    category_sales = df.groupby('Category')['Sales'].sum().reset_index()\n    category_sales.sort_values(by=['Sales', 'Category'], ascending=[False, True], inplace=True)\n    most_popular_category = category_sales.iloc[0]['Category']\n    return {\n        'Total Sales': total_sales,\n        'Most Popular Category': most_popular_category\n    }"
  },
  {
    "output": "def scan_ip_range(start_ip, end_ip, port):\n    import threading\n    import socket\n    results = []\n    def check_ip(ip):\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        sock.settimeout(1)\n        try:\n            sock.connect((ip, port))\n            results.append((ip, True))\n        except:\n            results.append((ip, False))\n        finally:\n            sock.close()\n    threads = []\n    for ip in range(int(start_ip.split('.')[-1]), int(end_ip.split('.')[-1]) + 1):\n        ip_address = f\"{start_ip.split('.')[0]}.{start_ip.split('.')[1]}.{start_ip.split('.')[2]}.{ip}\"\n        t = threading.Thread(target=check_ip, args=(ip_address,))\n        threads.append(t)\n        t.start()\n    for t in threads:\n        t.join()\n    return results"
  },
  {
    "output": "import numpy as np\nimport pandas as pd\n\ndef task_func(rows, columns=[\"A\", \"B\", \"C\", \"D\", \"E\"], seed=0) -> pd.DataFrame:\n    np.random.seed(seed)\n    data = np.random.rand(rows, len(columns))\n    df = pd.DataFrame(data, columns=columns)\n    df = df.sample(n=len(columns), axis=1, random_state=seed)\n    return df"
  },
  {
    "output": "def process_filenames(directory):\n    import os\n    files = os.listdir(directory)\n    new_files = []\n    for filename in files:\n        parts = filename.split('.')\n        reversed_parts = parts[::-1]\n        new_filename = '.'.join(reversed_parts)\n        new_files.append(new_filename)\n    return new_files"
  },
  {
    "output": "import pandas as pd\nimport requests\nimport os\n\ndef task_func(url):\n    response = requests.get(url)\n    with open(\"temp.json\", \"wb\") as f:\n        f.write(response.content)\n    df = pd.read_json(\"temp.json\")\n    os.remove(\"temp.json\")\n    return df"
  },
  {
    "output": "def remove_jquery_files(directory):\n    import os\n    if not os.path.exists(directory):\n        raise FileNotFoundError(f\"The directory {directory} does not exist.\")\n    removed_files = []\n    for filename in os.listdir(directory):\n        if filename.startswith('jquery') and filename.endswith('.js'):\n            file_path = os.path.join(directory, filename)\n            os.remove(file_path)\n            removed_files.append(filename)\n    return (len(removed_files), removed_files)"
  },
  {
    "output": "def task_func(data, specified_value):\n    average = sum(data) / len(data)\n    greater_than_average = [x for x in data if x > average]\n    count_greater_than_specified = sum(1 for x in data if x > specified_value)\n    import matplotlib.pyplot as plt\n    sorted_data = sorted(data)\n    plt.hist(sorted_data, bins=10)\n    plt.show()\n    return average, greater_than_average, count_greater_than_specified, sorted_data"
  },
  {
    "output": "import pandas as pd\nimport numpy as np\nimport datetime\nimport random\n\ndef generate_sensor_data(start_time, end_time, step, sensor_statuses):\n    timestamps = []\n    sensor_readings = []\n    sensor_statuses_list = []\n    \n    current_time = start_time\n    while current_time <= end_time:\n        timestamps.append(current_time)\n        timestamp_seconds = (current_time - datetime.datetime(1970, 1, 1)).total_seconds()\n        sine_val = np.sin(timestamp_seconds) + np.random.normal(0, 0.1)\n        cosine_val = np.cos(timestamp_seconds) + np.random.normal(0, 0.1)\n        tan_val = np.tan(timestamp_seconds) + np.random.normal(0, 0.1)\n        sensor_readings.append((sine_val, cosine_val, tan_val))\n        sensor_statuses_list.append(random.choice(sensor_statuses))\n        current_time += step\n    \n    df = pd.DataFrame({\n        'timestamp': timestamps,\n        'sine_reading': [r[0] for r in sensor_readings],\n        'cosine_reading': [r[1] for r in sensor_readings],\n        'tan_reading': [r[2] for r in sensor_readings],\n        'status': sensor_statuses_list\n    })\n    \n    return df"
  },
  {
    "output": "import pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(d, target='y'):\n    X = [[item['x'], item['z']] for item in d]\n    y = [item[target] for item in d]\n    model = LinearRegression()\n    model.fit(X, y)\n    return model"
  },
  {
    "output": "import pandas as pd\nimport random\n\ndef task_func(n_data_points=10000):\n    if n_data_points <= 0:\n        return pd.DataFrame(columns=['Value'])\n    \n    data = [round(random.uniform(0.0, 10.0), 3) for _ in range(n_data_points)]\n    return pd.DataFrame(data, columns=['Value'])"
  },
  {
    "output": "def task_func(text, analyzer):\n    import re\n    cleaned_text = re.sub(r'\\W+', ' ', text).lower()\n    sentiment = analyzer.polarity_scores(cleaned_text)\n    return {\n        'neg': sentiment['neg'],\n        'neu': sentiment['neu'],\n        'pos': sentiment['pos'],\n        'compound': sentiment['compound']\n    }"
  },
  {
    "output": "def task_func():\n    from Crypto.PublicKey import RSA\n    from Crypto.Cipher import AES\n    from Crypto.Random import get_random_bytes\n    from Crypto.Protocol.KDF import PBKDF2\n    import os\n    import base64\n\n    password = os.urandom(16)\n    nonce = get_random_bytes(16)\n    key = RSA.generate(2048)\n    private_key = key.export_key(passphrase=password, pkcs=8, protection=\"AES128-CBC-PKCS1-OAEP\")\n    private_key = base64.b64encode(private_key).decode('utf-8')\n    salt = get_random_bytes(16)\n    derived_key = PBKDF2(password, salt, dkLen=16, count=100000)\n    cipher = AES.new(derived_key, AES.MODE_CBC, nonce)\n    encrypted_private_key = cipher.encrypt(private_key.encode('utf-8'))\n    encrypted_private_key = base64.b64encode(encrypted_private_key).decode('utf-8')\n    filename = f\"rsa_key_{os.urandom(16).hex()}.enc\"\n    with open(filename, 'w') as f:\n        f.write(encrypted_private_key)\n    return key.public_key(), filename, password, nonce"
  },
  {
    "output": "from collections import Counter\nimport itertools\n\ndef task_func(letters: list, repetitions: int) -> dict:\n    repeated_letters = list(itertools.chain.from_iterable([letter] * repetitions for letter in letters))\n    frequency = dict(Counter(repeated_letters))\n    return frequency"
  },
  {
    "output": "import pandas as pd\nfrom sklearn.cluster import DBSCAN\n\ndef task_func(data, cols):\n    df = pd.DataFrame(data, columns=cols)\n    dbscan = DBSCAN(eps=3, min_samples=2)\n    clusters = dbscan.fit_predict(df)\n    df['Cluster'] = clusters\n    return df"
  },
  {
    "output": "def create_histogram(input_string):\n    import matplotlib.pyplot as plt\n    import numpy as np\n    data = np.array([float(x) for x in input_string.split()])\n    plt.hist(data, bins=10, edgecolor='black')\n    plt.title('Histogram of Numeric Series')\n    plt.xlabel('Value')\n    plt.ylabel('Frequency')\n    plt.show()"
  },
  {
    "output": "import re\nfrom nltk.corpus import words\n\ndef task_func(s, n):\n    word_list = set()\n    words_corpus = set(words.words)\n    for word in re.findall(r'\\b\\w+\\b', s.lower()):\n        if word in words_corpus:\n            word_list.add(word)\n            if len(word_list) >= n:\n                return list(word_list)\n    return list(word_list)"
  },
  {
    "output": "def task_func(data):\n    import numpy as np\n    from scipy import stats\n    import numpy.fft as fft\n    counts, bins = np.histogram(data, bins=np.unique(data))\n    mode = bins[np.argmax(counts)]\n    count = np.max(counts)\n    fft_result = fft.fft(counts)\n    return {'mode': np.array([mode]), 'count': np.array([count]), 'fft': fft_result}"
  },
  {
    "output": "import pandas as pd\nimport os\n\nOUTPUT_DIR = './output'\n\ndef task_func(df, filename, output_dir=OUTPUT_DIR):\n    os.makedirs(output_dir, exist_ok=True)\n    file_path = os.path.join(output_dir, filename)\n    df.to_json(file_path, orient='records')\n    return file_path"
  },
  {
    "output": "def extract_phone_numbers(source, output_file):\n    import re\n    import requests\n    from urllib.parse import urlparse\n    import json\n    import os\n\n    def get_content(url):\n        response = requests.get(url)\n        return response.text\n\n    def extract_numbers(text):\n        pattern = r'\\+?1?\\-?\\.?[\\d\\s\\-\\.]+[\\d\\-\\.]?\\d{3}[\\d\\-\\.]?\\d{4}[\\d\\-\\.]?\\d{4}'\n        return re.findall(pattern, text)\n\n    def save_to_json(data, filename):\n        with open(filename, 'w') as f:\n            json.dump(data, f)\n\n    if urlparse(source).scheme in ('http', 'https'):\n        content = get_content(source)\n    else:\n        with open(source, 'r') as f:\n            content = f.read()\n\n    numbers = extract_numbers(content)\n    save_to_json(numbers, output_file)\n    return numbers"
  },
  {
    "output": "import platform\nimport psutil\n\ndef gather_system_details():\n    return {\n        'os': platform.system(),\n        'os_version': platform.version(),\n        'architecture': platform.machine(),\n        'memory_total': psutil.virtual_memory().total,\n        'memory_used': psutil.virtual_memory().used,\n        'memory_free': psutil.virtual_memory().free\n    }"
  },
  {
    "output": "import re\nimport math\n\ndef task_func(s):\n    elements = [element.strip() for element in s.split(\",\")]\n    count = 0\n    sum_sqrt = 0.0\n\n    for element in elements:\n        try:\n            num = float(element)\n            count += 1\n            sum_sqrt += math.sqrt(num)\n        except ValueError:\n            pass\n\n    return count, sum_sqrt"
  },
  {
    "output": "[[math.sin(x) for x in tup] for tup in tuples_list]"
  },
  {
    "output": "def move_files_by_extension(source_dir, dest_dir, extension):\n    import os\n    import shutil\n    count = 0\n    for filename in os.listdir(source_dir):\n        if filename.endswith(extension):\n            src_path = os.path.join(source_dir, filename)\n            dest_path = os.path.join(dest_dir, filename)\n            shutil.move(src_path, dest_path)\n            count += 1\n    return count"
  },
  {
    "output": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(start_date='2016-01-01', periods=13, freq='WOM-2FRI', seed=0):\n    np.random.seed(seed)\n    dates = pd.date_range(start=start_date, periods=periods, freq=freq)\n    prices = np.random.uniform(100, 500, size=periods)\n    df = pd.DataFrame({'Date': dates, 'Price': prices})\n    \n    fig, ax = plt.subplots()\n    ax.plot(df['Date'], df['Price'], marker='o')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Price')\n    ax.set_title('Share Price Series')\n    \n    return (df, ax)"
  },
  {
    "output": "def task_func(text):\n    import nltk\n    from nltk.corpus import stopwords\n    import numpy as np\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    nltk.download('stopwords')\n    stop_words = set(stopwords.words('english'))\n    words = text.split()\n    words = [word for word in words if word not in stop_words]\n    unique_words = []\n    prev = None\n    for word in words:\n        if word != prev:\n            unique_words.append(word)\n        prev = word\n    word_to_index = {word: i for i, word in enumerate(unique_words)}\n    n = len(unique_words)\n    co_occurrence = np.zeros((n, n), dtype=int)\n    for i in range(len(unique_words) - 1):\n        current = unique_words[i]\n        next_word = unique_words[i + 1]\n        co_occurrence[word_to_index[current], word_to_index[next_word]] += 1\n    df = pd.DataFrame(co_occurrence, index=unique_words, columns=unique_words)\n    plt.figure(figsize=(10, 10))\n    plt.imshow(df, cmap='viridis', interpolation='nearest')\n    plt.colorbar()\n    plt.title('Co-occurrence Matrix')\n    plt.xlabel('Words')\n    plt.ylabel('Words')\n    plot_obj = plt.gcf()\n    return (df, plot_obj)"
  },
  {
    "output": "def scan_logs_for_ip_counts(directory):\n    import os\n    import re\n    ip_count = {}\n    ip_pattern = re.compile(r'\\b(?:[0-9]{1,3}\\.){3}[0-9]{1,3}\\b')\n    for filename in os.listdir(directory):\n        file_path = os.path.join(directory, filename)\n        if os.path.isfile(file_path):\n            with open(file_path, 'r') as file:\n                for line in file:\n                    ips = ip_pattern.findall(line)\n                    for ip in ips:\n                        ip_count[ip] = ip_count.get(ip, 0) + 1\n    return ip_count"
  },
  {
    "output": "import random\nfrom collections import Counter\nimport string\n\ndef task_func(input_list):\n    alphabet = string.ascii_lowercase\n    for i in range(len(input_list)):\n        if not input_list[i]:\n            input_list[i] = random.sample(alphabet, 5)\n    return Counter([item for sublist in input_list for item in sublist])"
  },
  {
    "output": "def process_text(text):\n    if not text:\n        raise ValueError(\"Input text is empty\")\n    words = re.findall(r'\\b\\w+\\b', text.lower())\n    words = [word.replace(' ', '_') for word in words]\n    from collections import Counter\n    word_counts = Counter(words)\n    import matplotlib.pyplot as plt\n    plt.bar(word_counts.keys(), word_counts.values())\n    plt.xlabel('Words')\n    plt.ylabel('Frequency')\n    plt.title('Word Frequency')\n    plt.show()"
  },
  {
    "output": "# Train linear regression model\n    X = df[['Goals']]\n    y = df['Penalty Cost']\n    model = LinearRegression().fit(X, y)\n    \n    # Predict penalty cost for a new goal input\n    predicted_cost = model.predict([[goals]])[0]\n    \n    # Return the predicted penalty cost\n    return predicted_cost"
  },
  {
    "output": "def merge_and_encode(lists):\n    import numpy as np\n    from sklearn.preprocessing import OneHotEncoder\n    merged = [item for sublist in lists for item in sublist]\n    encoder = OneHotEncoder(sparse_output=False)\n    encoded = encoder.fit_transform(np.array(merged).reshape(-1, 1))\n    return encoded.flatten().tolist()"
  },
  {
    "output": "def generate_random_string(length):\n    import random\n    import string\n    if length < 0:\n        raise ValueError(\"Length cannot be negative\")\n    chars = string.ascii_letters\n    random_string = ''.join(random.choice(chars) for _ in range(length))\n    counts = {}\n    for char in random_string:\n        counts[char] = counts.get(char, 0) + 1\n    return random_string, counts"
  },
  {
    "output": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef create_and_plot_data(goals, penalties):\n    data = {'Goals': goals, 'Penalties': penalties}\n    df = pd.DataFrame(data)\n    sns.pairplot(df)\n    plt.show()"
  },
  {
    "output": "import pandas as pd\nimport numpy as np\nCOLUMNS = ['Column1', 'Column2', 'Column3', 'Column4', 'Column5']\ndef task_func(length):\n    data = np.random.rand(length, len(COLUMNS))\n    df = pd.DataFrame(data, columns=COLUMNS)\n    return df"
  },
  {
    "output": "from collections import deque\nimport math\n\ndef task_func():\n    dq = deque([1, 2, 3, 4, 5])\n    dq.rotate(2)\n    total = sum(dq)\n    sqrt_total = math.sqrt(total)\n    print(sqrt_total)"
  },
  {
    "output": "```python\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Constants defining the range of random integers and the size of the DataFrame\nRANGE = 100\nSIZE = 1000\n\ndef task_func():\n    # Generate random integers for 'X' and 'Y' columns\n    np.random.seed(42)  # For reproducibility\n    data = {\n        'X': np.random.randint(0, RANGE, SIZE),\n        'Y': np.random.randint(0, RANGE, SIZE)\n    }\n    df = pd.DataFrame(data)\n    \n    # Plot the scatter plot using Seaborn\n    sns.scatterplot(data=df, x='X', y='Y')\n    plt.title('Scatter Plot of Random Integers')\n    plt.xlabel('X')\n    plt.ylabel('Y')\n    plt.show()\n    \n    return df\n```"
  },
  {
    "output": "def task_func(csv_url_dict, sort_by_column=\"title\"):\n    if not isinstance(csv_url_dict, dict):\n        raise ValueError(\"Input must be a dictionary.\")\n    if not csv_url_dict:\n        raise ValueError(\"The dictionary is empty.\")\n    if 'URL' not in csv_url_dict:\n        raise ValueError(\"The key 'URL' is missing.\")\n    url = csv_url_dict['URL']\n    response = requests.get(url)\n    csv_data = StringIO(response.text)\n    df = pd.read_csv(csv_data)\n    df_sorted = df.sort_values(by=sort_by_column)\n    return df_sorted"
  },
  {
    "output": "python_code_returner(import pandas as pd\nimport random\n\ndef task_func(dictionary, item, seed):\n    random.seed(seed)\n    df = pd.DataFrame(dictionary)\n    occurrences = []\n    for index, row in df.iterrows():\n        for col, value in row.items():\n            if value == item:\n                occurrences.append((index, col))\n    count = len(occurrences)\n    random_number = random.randint(0, 9)\n    updated_count = count + random_number\n    return occurrences, updated_count, df)"
  },
  {
    "output": "def task_func(length=10):\n    import random\n    import string\n    try:\n        if length <= 0:\n            raise ValueError(\"Length must be a positive integer.\")\n        chars = string.ascii_letters + string.digits\n        generated_str = ''.join(random.choice(chars) for _ in range(length))\n        characteristics = {\n            'has_uppercase': any(c.isupper() for c in generated_str),\n            'has_lowercase': any(c.islower() for c in generated_str),\n            'has_digit': any(c.isdigit() for c in generated_str),\n            'has_special': any(not c.isalnum() for c in generated_str)\n        }\n        return (generated_str, characteristics)\n    except Exception as e:\n        return (str(e), {})"
  },
  {
    "output": "def task_func(source_dir, target_dir):\n    import os\n    import csv\n    from docx import Document\n    from openpyxl import load_workbook\n\n    if not os.path.exists(source_dir):\n        raise FileNotFoundError(f\"Source directory {source_dir} does not exist.\")\n\n    os.makedirs(target_dir, exist_ok=True)\n    converted_count = 0\n\n    for filename in os.listdir(source_dir):\n        file_path = os.path.join(source_dir, filename)\n        if not os.path.isfile(file_path):\n            continue\n        ext = os.path.splitext(filename)[1].lower()\n        target_path = os.path.join(target_dir, os.path.splitext(filename)[0] + \".csv\")\n\n        if ext == \".txt\":\n            with open(file_path, 'r') as src, open(target_path, 'w', newline='') as dst:\n                csv.writer(dst).writerows([line.strip().split() for line in src])\n            converted_count += 1\n        elif ext == \".docx\":\n            doc = Document(file_path)\n            with open(target_path, 'w', newline='') as dst:\n                csv.writer(dst).writerows([[para.text for para in para_list] for para_list in doc.paragraphs])\n            converted_count += 1\n        elif ext == \".xlsx\":\n            wb = load_workbook(file_path)\n            ws = wb.active\n            with open(target_path, 'w', newline='') as dst:\n                csv.writer(dst).writerows([[cell.value for cell in row] for row in ws.iter_rows()])\n            converted_count += 1\n        elif ext == \".csv\":\n            with open(file_path, 'r') as src, open(target_path, 'w', newline='') as dst:\n                csv.writer(dst).writerows(csv.reader(src))\n            converted_count += 1\n\n    return converted_count"
  },
  {
    "output": "def compare_csv_files(file1, file2):\n    import pandas as pd\n    import os\n    from pandas.core.exceptions import DataFrameError\n\n    if not os.path.exists(file1) or not os.path.exists(file2):\n        raise FileNotFoundError(\"One or both files do not exist.\")\n    \n    try:\n        df1 = pd.read_csv(file1)\n        df2 = pd.read_csv(file2)\n    except DataFrameError as e:\n        raise DataFrameError(f\"Error reading CSV files: {e}\")\n\n    if df1.columns.tolist() != df2.columns.tolist():\n        raise ValueError(\"The CSV files have different column structures.\")\n\n    diff = pd.concat([df1, df2], axis=1, keys=['File1', 'File2'])\n    diff = diff.apply(lambda row: row['File1'] == row['File2'], axis=1)\n    diff = diff.rename('IsEqual')\n    return diff.reset_index()"
  },
  {
    "output": "def task_func(X, y):\n    from sklearn.model_selection import train_test_split\n    from tensorflow.keras.models import Sequential\n    from tensorflow.keras.layers import Dense\n    from tensorflow.keras.optimizers import SGD\n    from sklearn.metrics import precision_recall_curve\n    import matplotlib.pyplot as plt\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    model = Sequential()\n    model.add(Dense(10, activation='sigmoid', input_shape=(X.shape[1],)))\n    model.compile(loss='binary_crossentropy', optimizer=SGD(), metrics=['accuracy'])\n    model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n    y_scores = model.predict(X_test)\n    precision, recall, _ = precision_recall_curve(y_test, y_scores)\n    fig, ax = plt.subplots()\n    ax.plot(recall, precision)\n    ax.set_xlabel('Recall')\n    ax.set_ylabel('Precision')\n    return model, ax"
  },
  {
    "output": "import pandas as pd\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nimport string\n\ndef task_func(text):\n    sentences = sent_tokenize(text)\n    stop_words = set(stopwords.words('english'))\n    word_counts = {}\n    for sentence in sentences:\n        words = word_tokenize(sentence)\n        words = [word.lower() for word in words if word.isalpha()]\n        for word in words:\n            if word not in stop_words:\n                word_counts[word] = word_counts.get(word, 0) + 1\n    return pd.Series(word_counts)"
  },
  {
    "output": "def task_func(file_path):\n    from cryptography.hazmat.primitives.asymmetric import rsa\n    from cryptography.hazmat.primitives import serialization\n    from cryptography.hazmat.primitives import hashes\n    from cryptography.hazmat.primitives.asymmetric import padding\n    from cryptography.fernet import Fernet\n    import os\n    import base64\n\n    private_key = rsa.generate_private_key(\n        public_exponent=65537,\n        key_size=2048,\n    )\n    public_key = private_key.public_key()\n\n    with open(file_path, 'rb') as f:\n        file_data = f.read()\n\n    fernet_key = Fernet.generate_key()\n    fernet = Fernet(fernet_key)\n    encrypted_data = fernet.encrypt(file_data)\n\n    encrypted_fernet_key = public_key.encrypt(\n        fernet_key,\n        padding.OAEP(mgf=padding.MGF1(algorithm=hashes.SHA256()), algorithm=hashes.SHA256(), label=None)\n    )\n\n    encrypted_file_path = f\"{file_path}.enc\"\n    fernet_key_file_path = f\"{file_path}.fernet.enc\"\n\n    with open(encrypted_file_path, 'wb') as f:\n        f.write(encrypted_data)\n\n    with open(fernet_key_file_path, 'wb') as f:\n        f.write(encrypted_fernet_key)\n\n    return public_key, encrypted_file_path, fernet_key_file_path"
  },
  {
    "output": "def process_files(input_list):\n    if not isinstance(input_list, list):\n        raise TypeError(\"Input must be a list\")\n    input_list.append('12')\n    total = sum(map(int, input_list))\n    import os\n    import pandas as pd\n    files = [f for f in os.listdir() if f.endswith('.csv')]\n    if not files:\n        raise FileNotFoundError(\"No CSV files found\")\n    df = pd.concat([pd.read_csv(f) for f in files], ignore_index=True)\n    return df"
  },
  {
    "output": "def count_adjacent_pairs(word):\n    from collections import Counter\n    pairs = []\n    for i in range(len(word) - 1):\n        pairs.append(word[i:i+2])\n    return dict(Counter(pairs))"
  },
  {
    "output": "def task_func(data):\n    import numpy as np\n    import matplotlib.pyplot as plt\n    prices = [float(item['price']) for item in data]\n    mean = np.mean(prices)\n    median = np.median(prices)\n    std_dev = np.std(prices)\n    plt.hist(prices, bins=10, edgecolor='black')\n    plt.title('Price Distribution')\n    plt.xlabel('Price')\n    plt.ylabel('Frequency')\n    plt.show()\n    return mean, median, std_dev"
  },
  {
    "output": "def generate_distance_matrix(data):\n    import pandas as pd\n    import numpy as np\n    df = pd.DataFrame(data)\n    n = len(df)\n    distance_matrix = np.zeros((n, n))\n    for i in range(n):\n        for j in range(n):\n            distance_matrix[i, j] = np.linalg.norm(df.iloc[i] - df.iloc[j])\n    return pd.DataFrame(distance_matrix)"
  },
  {
    "output": "import csv\nimport collections\nimport operator\n\ndef task_func(csv_file_path):\n    product_sales = collections.defaultdict(int)\n    \n    with open(csv_file_path, 'r') as file:\n        reader = csv.DictReader(file)\n        for row in reader:\n            product = row['product']\n            quantity = int(row['quantity'])\n            product_sales[product] += quantity\n    \n    if not product_sales:\n        return \"No data found\"\n    \n    top_product = max(product_sales.items(), key=operator.itemgetter(1))[0]\n    return top_product"
  },
  {
    "output": ""
  },
  {
    "output": "import pandas as pd\nimport numpy as np\n\ndef task_func():\n    np.random.seed(42)\n    products = ['Product A', 'Product B', 'Product C', 'Product D']\n    months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n    sales_data = np.random.randint(100, 1000, size=(len(products), len(months)))\n    df = pd.DataFrame(sales_data, columns=months, index=products)\n    df['Average Sales'] = df.mean(axis=1)\n    return df.reset_index().rename(columns={0: 'Product'})"
  },
  {
    "output": "from collections import Counter\nimport json\nimport random\n\ndef task_func(n, file_name, seed=77):\n    random.seed(seed)\n    selected_words = random.sample(WORDS, n)\n    with open(file_name, 'w') as f:\n        json.dump(selected_words, f)\n    return file_name"
  },
  {
    "output": "import ast\nimport re\n\ndef task_func(text_file: str) -> list:\n    with open(text_file, 'r') as file:\n        content = file.read()\n    \n    pattern = r'\\{.*?\\}'\n    matches = re.findall(pattern, content)\n    \n    dictionaries = []\n    for match in matches:\n        try:\n            dict_str = match.strip()\n            dict_obj = ast.literal_eval(dict_str)\n            dictionaries.append(dict_obj)\n        except (ValueError, SyntaxError):\n            continue\n    \n    return dictionaries"
  },
  {
    "output": "def encrypt_and_save(data, password, filename): \n    import os \n    from cryptography.fernet import Fernet \n    if not os.path.exists(os.path.dirname(filename)): \n        os.makedirs(os.path.dirname(filename)) \n    key = Fernet.generate_key() \n    fernet = Fernet(key) \n    encrypted = fernet.encrypt(data.encode()) \n    with open(filename, 'wb') as f: \n        f.write(encrypted) \n    return key.decode()"
  },
  {
    "output": "import random\nimport math\n\ndef task_func(range_start=1, range_end=100, pairs_count=10, random_seed=None):\n    if random_seed is not None:\n        random.seed(random_seed)\n    def generator():\n        for _ in range(pairs_count):\n            num1 = random.randint(range_start, range_end)\n            num2 = random.randint(range_start, range_end)\n            diff = abs(num1 - num2)\n            sqrt_diff = math.sqrt(diff)\n            yield (num1, num2, sqrt_diff)\n    return generator()"
  },
  {
    "output": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(array):\n    df = pd.DataFrame(array, columns=['A', 'B', 'C', 'D', 'E'])\n    column_sums = df.sum()\n    plt.figure(figsize=(10, 6))\n    column_sums.plot(kind='bar')\n    plt.title('Sum of Each Column')\n    plt.xlabel('Columns')\n    plt.ylabel('Sum')\n    plt.xticks(rotation=0)\n    plt.tight_layout()\n    return df, plt.gca()"
  },
  {
    "output": "import random\nimport string\n\ndef task_func(length, num_strings):\n    chars = string.ascii_lowercase\n    strings = [''.join(random.choice(chars) for _ in range(length)) for _ in range(num_strings)]\n    freq = {}\n    for s in strings:\n        for c in s:\n            freq[c] = freq.get(c, 0) + 1\n    sorted_freq = sorted(freq.items(), key=lambda x: x[1], reverse=True)\n    return sorted_freq"
  },
  {
    "output": "import matplotlib.pyplot as plt\nimport pandas as pd\n\ndef process_dataframe(df, target_values):\n    for col in df.columns:\n        df[col] = df[col].apply(lambda x: x if x in target_values else 0)\n    axes = []\n    for col in df.columns:\n        ax = plt.subplot(len(df.columns), 1, df.columns.get_loc(col) + 1)\n        df[col].plot(kind='hist', ax=ax)\n        ax.set_title(col)\n        axes.append(ax)\n    return axes"
  },
  {
    "output": "def task_func(text_data):\n    text_data = text_data.str.lower()\n    text_data = text_data.apply(lambda x: re.sub(r'\\W+', ' ', x))\n    text_data = text_data.apply(lambda x: re.sub(r'\\d+', ' ', x))\n    stop_words = set(stopwords.words('english'))\n    text_data = text_data.apply(lambda x: ' '.join(word for word in x.split() if word not in stop_words))\n    vectorizer = CountVectorizer()\n    return vectorizer.fit_transform(text_data)"
  },
  {
    "output": "def task_func():\n    return \"Hello, World!\""
  },
  {
    "output": "# Draw bar chart\n    statistics.T.plot(kind='bar', figsize=(10, 6))\n    plt.title('Comparison of Statistics for Two Arrays')\n    plt.ylabel('Value')\n    plt.xlabel('Statistic')\n    plt.legend(['Array1', 'Array2'])\n    plt.show()"
  },
  {
    "output": "def task_func(directory, predicates):\n    import os\n    from collections import defaultdict\n\n    if not os.path.exists(directory) or not os.path.isdir(directory):\n        return {}\n\n    deduplicated_predicates = list(set(predicates))\n    results = defaultdict(list)\n\n    for item in os.listdir(directory):\n        item_path = os.path.join(directory, item)\n        if os.path.isfile(item_path):\n            matches = []\n            for pred in deduplicated_predicates:\n                if pred(item_path):\n                    matches.append(pred.__name__)\n            results[item].extend(matches)\n\n    return dict(results)"
  },
  {
    "output": ".axes[0].transform, ha='left', va='top')\n    \n    # Set plot title and labels\n    ax.set_title(PLOT_TITLE)\n    ax.set_xlabel(X_LABEL)\n    ax.set_ylabel(Y_LABEL)\n    \n    # Save the plot as a PNG file\n    plt.savefig('sqrt_plot.png')\n    \n    # Return the computed square values\n    return square_values"
  },
  {
    "output": "def task_func():\n    import sqlite3\n    import random\n    import os\n    import sys\n    try:\n        conn = sqlite3.connect(':memory:')\n        c = conn.cursor()\n        c.execute('''CREATE TABLE data (id INTEGER PRIMARY KEY, value TEXT)''')\n        for _ in range(10):\n            c.execute(\"INSERT INTO data (value) VALUES (?)\", (random.choice(['a', 'b', 'c', 'd']),))\n        conn.commit()\n        c.execute(\"SELECT * FROM data\")\n        rows = c.fetchall()\n        for row in rows:\n            print(row)\n    except sqlite3.DatabaseError as e:\n        print(f\"Database error: {e}\")\n        conn.rollback()\n    except Exception as e:\n        print(f\"Unexpected error: {e}\")\n        sys.exit(1)\n    finally:\n        if 'conn' in locals():\n            conn.close()"
  },
  {
    "output": "def task_func():\n    return \"Hello, world!\""
  },
  {
    "output": "import numpy as np\nimport pandas as pd\nimport csv\nimport os\n\ndef generate_and_write_matrix(filename, rows, cols):\n    letters = [chr(i) for i in range(ord('a'), ord('z') + 1)]\n    matrix = np.random.choice(letters, size=(rows, cols))\n    df = pd.DataFrame(matrix)\n    df.to_csv(filename, index=False, header=False)"
  },
  {
    "output": "from scipy.stats import linregress\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nif column1 not in data.columns or column2 not in data.columns:\n    raise ValueError(f\"Columns {column1} and {column2} not found in the DataFrame.\")\nslope, intercept, r_value, p_value, std_err = linregress(data[column1], data[column2])\nfig, ax = plt.subplots()\nax.scatter(data[column1], data[column2], label='Data points')\nx_vals = np.linspace(data[column1].min(), data[column1].max(), 100)\ny_vals = intercept + slope * x_vals\nax.plot(x_vals, y_vals, color='red', label='Fitted line')\nax.set_xlabel(column1)\nax.set_ylabel(column2)\nax.legend()\n(slope, intercept, r_value, p_value, std_err), ax"
  },
  {
    "output": "def visualize_stock_distribution(data):\n    import matplotlib.pyplot as plt\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n    ax1.boxplot(data)\n    ax1.set_title('Box Plot of Stock Closing Prices')\n    ax2.hist(data, bins=20, color='skyblue', edgecolor='black')\n    ax2.set_title('Histogram of Stock Closing Prices')\n    return (ax1, ax2)"
  },
  {
    "output": "import random\nimport string\nimport collections\n\ndef task_func(n_strings, string_length):\n    random_strings = [''.join(random.choice(string.ascii_letters + string.digits) for _ in range(string_length)) for _ in range(n_strings)]\n    char_count = collections.Counter()\n    for s in random_strings:\n        char_count.update(s)\n    return dict(char_count)"
  },
  {
    "output": "import csv\nimport matplotlib.pyplot as plt\nimport unicodedata\n\ndef task_func(file_path):\n    with open(file_path, 'r', encoding='utf-8') as file:\n        reader = csv.reader(file)\n        text = ' '.join(row[0] for row in reader)\n    normalized_text = unicodedata.normalize('NFKC', text).lower()\n    words = normalized_text.split()\n    from collections import Counter\n    word_counts = Counter(words)\n    most_common = word_counts.most_common(10)\n    words, counts = zip(*most_common)\n    plt.bar(words, counts)\n    plt.xlabel('Words')\n    plt.ylabel('Frequency')\n    plt.title('Top 10 Most Common Words')\n    plt.show()\n    return list(most_common)"
  },
  {
    "output": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef sort_cumsum_plot(data):\n    sorted_data = sorted(data, key=lambda x: x[1])\n    cumsum = np.cumsum([x[1] for x in sorted_data])\n    fig, ax = plt.subplots()\n    ax.plot(cumsum)\n    return (cumsum, ax)"
  },
  {
    "output": "def count_occurrences_in_csv_files(file_paths, columns):\n    from collections import defaultdict\n    import csv\n    counts = defaultdict(lambda: defaultdict(int))\n    for file_path in file_paths:\n        with open(file_path, 'r') as file:\n            reader = csv.DictReader(file)\n            for row in reader:\n                for column in columns:\n                    value = row.get(column, '')\n                    counts[column][value] += 1\n    return dict(counts)"
  },
  {
    "output": "from PIL import Image, ImageFilter\nimport cv2\nimport numpy as np\nimport os\n\ndef task_func(img_path, blur_radius=5):\n    if not os.path.exists(img_path):\n        raise FileNotFoundError(f\"The image file does not exist at the specified path: {img_path}\")\n    \n    pil_image = Image.open(img_path)\n    original_array = np.array(pil_image)\n    \n    blurred_image = pil_image.filter(ImageFilter.GaussianBlur(blur_radius))\n    processed_array = np.array(blurred_image.convert(\"L\"))\n    \n    return (original_array, processed_array)"
  },
  {
    "output": "def task_func(url):\n    import subprocess\n    import platform\n    import time\n    if platform.system() == \"Windows\":\n        command = [\"start\", \"\", url]\n    elif platform.system() == \"Darwin\":\n        command = [\"open\", url]\n    elif platform.system() == \"Linux\":\n        command = [\"xdg-open\", url]\n    else:\n        raise OSError(\"Unsupported operating system\")\n    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, stdin=subprocess.PIPE, start_new_session=True)\n    time.sleep(1)\n    return process.returncode"
  },
  {
    "output": "def load_and_predict(csv_file, target_attribute):\n    import pandas as pd\n    from sklearn.model_selection import train_test_split\n    from sklearn.linear_model import LinearRegression\n    df = pd.read_csv(csv_file)\n    X = df.drop(columns=[target_attribute])\n    y = df[target_attribute]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    model = LinearRegression().fit(X_train, y_train)\n    predictions = model.predict(X_test)\n    return model, predictions"
  },
  {
    "output": "def task_func(url):\n    import requests\n    import xml.etree.ElementTree as ET\n    import pandas as pd\n    response = requests.get(url)\n    response.raise_for_status()\n    root = ET.fromstring(response.content)\n    if not root.findall('.//data'):\n        raise ValueError(\"XML structure is invalid\")\n    data = []\n    for item in root.findall('.//data'):\n        row = {}\n        for child in item:\n            row[child.tag] = child.text\n        data.append(row)\n    return pd.DataFrame(data)"
  },
  {
    "output": "def perform_feature_selection_and_heatmap(X, y):\n    from sklearn.feature_selection import SelectKBest, f_classif\n    from sklearn.preprocessing import StandardScaler\n    import seaborn as sns\n    import matplotlib.pyplot as plt\n    import numpy as np\n    \n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(X)\n    \n    selector = SelectKBest(score_func=f_classif, k=2)\n    selected_features = selector.fit_transform(X_scaled, y)\n    selected_indices = selector.get_support(indices=True)\n    selected_features_names = X.columns[selected_indices].tolist()\n    \n    corr = np.corrcoef(selected_features.T)\n    sns.heatmap(corr, annot=True, fmt=\".2f\", xticklabels=selected_features_names, yticklabels=selected_features_names)\n    plt.tight_layout()\n    fig = plt.gcf()\n    \n    return selected_features_names, fig.axes[0]"
  },
  {
    "output": "def task_func(string, patterns):\n    import re\n    if not isinstance(string, str):\n        raise ValueError(\"Input string must be a string.\")\n    if not isinstance(patterns, list):\n        raise ValueError(\"Input patterns must be a list.\")\n    result = {}\n    for pattern in patterns:\n        if not pattern:\n            continue\n        regex = re.compile(pattern)\n        matches = regex.findall(string)\n        result[pattern] = len(matches)\n    return result"
  },
  {
    "output": "return ax, empirical_mean, empirical_std"
  },
  {
    "output": "def task_func(data_dict):\n    if not data_dict:\n        return \"No data provided\"\n    counts = list(data_dict.values())\n    average_count = sum(counts) / len(counts)\n    is_uniform = all(count == counts[0] for count in counts)\n    import matplotlib.pyplot as plt\n    plt.hist(counts, bins=range(min(counts), max(counts)+2), align='left', rwidth=0.8)\n    plt.title('Histogram of Counts')\n    plt.xlabel('Count Value')\n    plt.ylabel('Frequency')\n    plt.grid(axis='y', alpha=0.75)\n    plt.show()\n    return f\"Average count: {average_count:.2f}, Uniform distribution: {is_uniform}\""
  },
  {
    "output": "```python\nfrom sklearn.preprocessing import MinMaxScaler\nimport pandas as pd\n\ndef task_func(l):\n    scaler = MinMaxScaler()\n    scaled_array = scaler.fit_transform(l)\n    df = pd.DataFrame(scaled_array, columns=['Scaled Values'])\n    return df\n```"
  },
  {
    "output": "import numpy as np\nimport itertools\n\ndef task_func(dimension, seed=42):\n    np.random.seed(seed)\n    matrix = np.random.randint(1, 101, size=dimension)\n    flat_list = list(itertools.chain.from_iterable(matrix))\n    return (matrix, flat_list)"
  },
  {
    "output": "def create_series_list(list_of_lists):\n    import pandas as pd\n    import numpy as np\n    result = []\n    for sublist in list_of_lists:\n        indices = sublist\n        values = np.random.permutation(range(1, len(indices) + 1))\n        series = pd.Series(values, index=indices)\n        result.append(series)\n    return result"
  },
  {
    "output": "def generate_employee_dates():\n    import pandas as pd\n    employees = ['Alice', 'Bob', 'Charlie']\n    dates = pd.date_range(start='2023-04-01', periods=10)\n    data = []\n    for employee in employees:\n        for date in dates:\n            data.append({'Employee': employee, 'Date': date})\n    return pd.DataFrame(data)"
  },
  {
    "output": "task_func(date_str, from_tz)"
  },
  {
    "output": "def task_func():\n    try:\n        result = 10 / 0\n    except ZeroDivisionError:\n        return \"Error: Division by zero\"\n    return result"
  },
  {
    "output": "def matrix_tensor_multiplication_and_heatmap(matrix, tensor):\n    import numpy as np\n    import matplotlib.pyplot as plt\n    import seaborn as sns\n    result = np.tensordot(matrix, tensor, axes=1)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(result, annot=True, fmt=\".2f\", cmap=\"viridis\")\n    plt.title(\"Matrix-Tensor Multiplication Result\")\n    plt.show()"
  },
  {
    "output": "import matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\ndef create_swarm_plot(data, x, y, intersecting_points):\n    fig, ax = plt.subplots()\n    sns.swarmplot(x=x, y=y, data=data, ax=ax)\n    for point in intersecting_points:\n        ax.scatter(point[x], point[y], color='red', s=100, edgecolor='black')\n    return ax, len(intersecting_points)"
  },
  {
    "output": "def process_data(d):\n    if not isinstance(d, list) or any(not isinstance(item, dict) for item in d):\n        raise ValueError(\"Input must be a list of dictionaries\")\n    stats = {}\n    for key in ['x', 'y', 'z']:\n        values = [item[key] for item in d]\n        mean = sum(values) / len(values)\n        sum_val = sum(values)\n        max_val = max(values)\n        min_val = min(values)\n        variance = sum((x - mean)**2 for x in values) / len(values)\n        std_dev = variance**0.5\n        stats[key] = {\n            'mean': mean,\n            'sum': sum_val,\n            'max': max_val,\n            'min': min_val,\n            'std_dev': std_dev\n        }\n    return stats"
  },
  {
    "output": "```python\nimport regex as re\nimport glob\nimport os\nfrom openpyxl import load_workbook\n\ndef task_func(directory_path='./xlsx_files/'):\n    # Find all Excel files in the specified directory\n    excel_files = glob.glob(os.path.join(directory_path, \"*.xlsx\"))\n    \n    # Initialize counter for processed files\n    processed_files = 0\n    \n    # Process each Excel file\n    for file_path in excel_files:\n        try:\n            # Load the workbook and select the active worksheet\n            workbook = load_workbook(filename=file_path)\n            worksheet = workbook.active\n            \n            # Iterate through all cells in the worksheet\n            for row in worksheet.iter_rows():\n                for cell in row:\n                    # Check if the cell contains double quotes\n                    if '\"' in str(cell.value):\n                        # Replace all double quotes with double backslashes\n                        new_value = re.sub(r'\\\"', r'\\\\\\\"', str(cell.value))\n                        # Update the cell value\n                        cell.value = new_value\n            \n            # Save the modified workbook\n            workbook"
  },
  {
    "output": "import xml.etree.ElementTree as ET\nimport csv\n\ndef task_func(xml_content, csv_file_path):\n    try:\n        root = ET.fromstring(xml_content)\n        data = []\n        for child in root:\n            row = []\n            for subchild in child:\n                row.append(subchild.text)\n            data.append(row)\n        with open(csv_file_path, 'w', newline='') as csvfile:\n            writer = csv.writer(csvfile)\n            writer.writerows(data)\n    except ET.ParseError:\n        pass\n    except IOError:\n        pass"
  },
  {
    "output": "def count_keys_with_prefixes(directory, prefixes):\n    import os\n    import json\n    stats = {}\n    for filename in os.listdir(directory):\n        file_path = os.path.join(directory, filename)\n        if os.path.isfile(file_path) and filename.endswith('.json'):\n            with open(file_path, 'r') as f:\n                data = json.load(f)\n            for key in data:\n                for prefix in prefixes:\n                    if key.startswith(prefix):\n                        stats[prefix] = stats.get(prefix, 0) + 1\n    return stats"
  },
  {
    "output": "def task_func(colors, seed=None):\n    import random\n    from itertools import cycle\n    if seed is not None:\n        random.seed(seed)\n    return [random.choice(colors) for _ in cycle(colors)]"
  },
  {
    "output": "import json\nimport random\nfrom itertools import combinations_with_replacement\n\ndef generate_combinations_and_save(letters, n, output_dir):\n    random_number = random.randint(1000, 9999)\n    filename = f\"{output_dir}/combinations_{random_number}.json\"\n    results = {}\n    for combo in combinations_with_replacement(letters, n):\n        count = {}\n        for letter in combo:\n            count[letter] = count.get(letter, 0) + 1\n        results[tuple(combo)] = count\n    with open(filename, 'w') as f:\n        json.dump(results, f)"
  },
  {
    "output": "def generate_and_plot_timestamps(num_timestamps, output_path):\n    import random\n    import datetime\n    import matplotlib.pyplot as plt\n    timestamps = [datetime.datetime.now() + datetime.timedelta(seconds=random.randint(0, 3600*24)) for _ in range(num_timestamps)]\n    formatted_timestamps = [t.strftime(\"%Y-%m-%d %H:%M:%S\") for t in timestamps]\n    plt.hist([t.timestamp() for t in timestamps], bins=20, color='blue', edgecolor='black')\n    plt.title('Timestamp Distribution')\n    plt.xlabel('Timestamp (seconds since epoch)')\n    plt.ylabel('Frequency')\n    plt.savefig(output_path)\n    plt.close()\n    return formatted_timestamps"
  },
  {
    "output": "plt.figure(figsize=(10, 8))\nsns.heatmap(df, annot=True, cmap='viridis', cbar_kws={'label': 'Sales'})\nplt.title('Sales Heatmap')\nplt.show()"
  },
  {
    "output": "def task_func(file_path, unknown_key):\n    import json\n    import hashlib\n    import base64\n    import datetime\n    with open(file_path, 'r') as f:\n        data = json.load(f)\n    value = data\n    for key in unknown_key.split('.'):\n        value = value[key]\n    hash_obj = hashlib.sha256(str(value).encode())\n    encoded_hash = base64.b64encode(hash_obj.digest()).decode()\n    timestamp = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n    new_file_path = f\"/tmp/encoded_hash_{timestamp}.txt\"\n    with open(new_file_path, 'w') as f:\n        f.write(encoded_hash)\n    return new_file_path"
  },
  {
    "output": "import numpy as np\n\ndef reverse_words_in_array(arr):\n    return np.char.rsplit(arr, ' ', maxsplit=1).str[::-1].str.join(' ')"
  },
  {
    "output": "def task_func(rows=3, columns=2, seed=0):\n    np.random.seed(seed)\n    matrix = np.random.rand(rows, columns)\n    U, s, Vh = svd(matrix)\n    return (U, s, Vh)"
  },
  {
    "output": "def max_weight_substring(x, w):\n    max_weight = 0\n    current_weight = 0\n    start = 0\n    max_start = 0\n    max_end = 0\n    for end in range(len(x)):\n        current_weight += w.get(x[end], 0)\n        if current_weight > max_weight:\n            max_weight = current_weight\n            max_start = start\n            max_end = end\n        elif current_weight == 0:\n            start = end + 1\n    return x[max_start:max_end+1]"
  },
  {
    "output": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport json\n\ndef json_to_df_and_hist(json_data, column_name):\n    try:\n        data = json.loads(json_data)\n        df = pd.DataFrame(data)\n        plt.hist(df[column_name], bins=10, edgecolor='black')\n        plt.title(f'Histogram of {column_name}')\n        plt.xlabel(column_name)\n        plt.ylabel('Frequency')\n        plt.show()\n    except json.JSONDecodeError:\n        print(\"Invalid JSON data\")\n    except KeyError:\n        print(f\"Column '{column_name}' not found in the data\")\n    except Exception as e:\n        print(f\"An error occurred: {e}\")"
  },
  {
    "output": "def reverse_csv_lines(file_path):\n    import pandas as pd\n    df = pd.read_csv(file_path)\n    df = df.iloc[::-1].reset_index(drop=True)\n    df.to_csv(file_path, index=False)\n    with open(file_path, 'r') as f:\n        lines = f.readlines()\n    with open(file_path, 'w') as f:\n        f.writelines(lines)"
  },
  {
    "output": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef task_func(df):\n    X = df[['feature']].values\n    y = df['value'].values\n    model = LinearRegression().fit(X, y)\n    coefficients = model.coef_[0]\n    intercept = model.intercept_\n    result = {\n        'coefficients': coefficients,\n        'intercept': intercept\n    }\n    return result"
  },
  {
    "output": "import pandas as pd\nimport numpy as np\n\ndef generate_random_dataframe(rows, cols, min_val, max_val, seed=None):\n    np.random.seed(seed)\n    data = np.random.uniform(min_val, max_val, size=(rows, cols))\n    return pd.DataFrame(data)"
  },
  {
    "output": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef generate_and_visualize_df(num_rows):\n    data = np.random.randint(0, 10, size=(num_rows, 5))\n    df = pd.DataFrame(data, columns=['A', 'B', 'C', 'D', 'E'])\n    non_zero_counts = df.apply(lambda col: col[col != 0].count())\n    fig, ax = plt.subplots()\n    non_zero_counts.plot(kind='bar', ax=ax)\n    return df, ax"
  },
  {
    "output": "from collections import Counter\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport itertools\n\ndef task_func(list_of_menuitems, title=\"Menu Distribution\", color=\"blue\", width=1.0):\n    flattened = list(itertools.chain.from_iterable(list_of_menuitems))\n    item_counts = Counter(flattened)\n    items = list(item_counts.keys())\n    counts = list(item_counts.values())\n    items.sort()\n    fig, ax = plt.subplots(figsize=(10, 6))\n    ax.bar(items, counts, color=color, width=width)\n    ax.set_xlabel(\"Menu Items\")\n    ax.set_ylabel(\"Frequency\")\n    ax.set_title(title)\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    return ax"
  },
  {
    "output": "import numpy as np\nimport math\nimport random\nfrom random import uniform\n\ndef task_func(radius, num_points):\n    points = []\n    for _ in range(num_points):\n        while True:\n            x = uniform(-radius, radius)\n            y = uniform(-radius, radius)\n            if x**2 + y**2 <= radius**2:\n                points.append((x, y))\n                break\n    return points"
  },
  {
    "output": "import pandas as pd\nimport numpy as np\n\ndef generate_ratings_df(weights, num_users=1000, num_items=500):\n    np.random.seed(42)\n    ratings = np.random.choice(list(weights.keys()), size=num_users * num_items, p=list(weights.values()))\n    ratings = ratings.reshape(num_users, num_items)\n    df = pd.DataFrame(ratings, columns=weights.keys())\n    df = df.melt(var_name='item', value_name='rating')\n    df = df.sort_values('rating', ascending=False)\n    return df"
  },
  {
    "output": "import random\n\nLETTERS = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n\ndef task_func(n_keys, n_values):\n    n_keys = min(n_keys, len(LETTERS))\n    selected_keys = random.sample(LETTERS, n_keys)\n    values = list(range(1, n_values + 1))\n    result_dict = {key: values for key in selected_keys}\n    return result_dict"
  },
  {
    "output": "def task_func(s_list, plot_path=None):\n    import numpy as np\n    from difflib import SequenceMatcher\n\n    if not isinstance(s_list, list) or any(not isinstance(s_str, str) for s_str in s_list):\n        raise ValueError(\"s_list must be a list of strings\")\n    if len(s_list) <= 1:\n        return np.nan\n    scores = []\n    for i, s1 in enumerate(s_list):\n        total = 0\n        count = 0\n        for j, s2 in enumerate(s_list):\n            if i != j:\n                ratio = SequenceMatcher(None, s1, s2).ratio()\n                total += ratio\n                count += 1\n        avg_score = total / count\n        scores.append(avg_score)\n    if plot_path is not None:\n        import matplotlib.pyplot as plt\n        plt.plot(scores)\n        plt.savefig(plot_path)\n    return scores"
  },
  {
    "output": "import random\nimport collections\n\ndef task_func(number_teams=5):\n    teams = {}\n    for i in range(1, number_teams + 1):\n        team_name = f\"Team {i}\"\n        points = random.randint(0, 100)\n        teams[team_name] = points\n    \n    sorted_teams = sorted(teams.items(), key=lambda x: x[1], reverse=True)\n    ordered_dict = collections.OrderedDict(sorted_teams)\n    \n    return ordered_dict"
  },
  {
    "output": "```python\nimport xmltodict\nimport json\n\ndef task_func(s, save_json, json_file_path):\n    # Input validation\n    if not s.strip():\n        raise ValueError(\"The input XML string is empty or contains only whitespace.\")\n    \n    # Parse XML string into a dictionary\n    parsed_xml = xmltodict.parse(s)\n    \n    # Convert the parsed XML to a dictionary\n    xml_dict = parsed_xml.get('school', {})\n    \n    # Save as JSON if required\n    if save_json and json_file_path:\n        with open(json_file_path, 'w') as json_file:\n            json.dump(xml_dict, json_file)\n    \n    return xml_dict\n```"
  },
  {
    "output": "```python\nimport pandas as pd\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    # Part A: Validate the input\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"The input is not a DataFrame.\")\n    \n    # Part B: Remove rows with duplicate names\n    df = df.groupby('name').filter(lambda x: len(x) == 1)\n    \n    # Part C: Perform linear regression\n    x = df['age']\n    y = df['score']\n    slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n    \n    # Part D: Plot the data\n    plt.figure"
  },
  {
    "output": "import requests\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nimport re\n\ndef task_func(url):\n    response = requests.get(url)\n    text = response.text\n    words = re.findall(r'\\b\\w+\\b', text.lower())\n    word_counts = Counter(words)\n    top_ten = word_counts.most_common(10)\n    words_list = [word for word, _ in top_ten]\n    counts_list = [count for _, count in top_ten]\n    plt.bar(words_list, counts_list)\n    plt.xlabel('Words')\n    plt.ylabel('Frequency')\n    plt.title('Top 10 Most Frequent Words')\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.show()"
  },
  {
    "output": "'residuals': residuals.tolist(),\n        'predicted_values': y_pred.tolist(),\n        'plot': plt\n    }"
  },
  {
    "output": "import pandas as pd\nimport statistics\nimport random\n\ndef task_func(students, subjects, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    grades = []\n    for student in students:\n        subject_grades = [random.randint(0, 100) for _ in subjects]\n        grades.append(subject_grades)\n    average_grades = [statistics.mean(subjects) for subjects in grades]\n    data = {\n        'Student': students,\n        **{f'Subject{i+1}': grades[i] for i in range(len(subjects))}\n    }\n    data['Average Grade'] = average_grades\n    df = pd.DataFrame(data)\n    return df"
  },
  {
    "output": "import re\nimport json\n\ndef extract_urls_from_json(json_str):\n    data = json.loads(json_str)\n    url_pattern = re.compile(r'https?://\\S+')\n    url_counts = {}\n    for value in data.values():\n        urls = url_pattern.findall(str(value))\n        for url in urls:\n            url_counts[url] = url_counts.get(url, 0) + 1\n    return url_counts"
  },
  {
    "output": "import pandas as pd\nimport regex as re\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nCOLUMN_NAMES = [\"Name\", \"Email\", \"Age\", \"Country\"]\n\ndef task_func(text):\n    pattern = r\"Name: (.*?), Email: (.*?), Age: (.*?), Country: (.*?)($|\\n)\"\n    matches = re.finditer(pattern, text)\n    data = []\n    for match in matches:\n        name = match.group(1)\n        email = match.group(2)\n        age = int(match.group(3))\n        country = match.group(4)\n        data.append([name, email, age, country])\n    df = pd.DataFrame(data, columns=COLUMN_NAMES)\n    sns.histplot(df['Age'], bins=10, kde=False)\n    plt.title('Age Distribution')\n    plt.xlabel('Age')\n    plt.ylabel('Frequency')\n    plt.show()\n    return df"
  },
  {
    "output": "```python\nimport heapq\nimport random\n\ndef task_func(obj_list, attr, top_n=5, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    if not obj_list:\n        return [], None\n    # Extract the values of the specified attribute\n    attribute_values = [getattr(obj, attr) for obj in obj_list]\n    # Find the top N values\n    top_values = heapq.nlargest(top_n, attribute_values)\n    # Randomly sample a value of all attributes\n    all_values = [getattr(obj, attr) for obj in obj_list]\n    random_value = random.choice(all_values)\n    return top_values, random_value\n```"
  },
  {
    "output": "def task_func(input_list):\n    import numpy as np\n    import statistics\n    sorted_list = sorted(input_list, key=lambda x: x)\n    mean_list = statistics.mean(sorted_list)\n    median_list = statistics.median(sorted_list)\n    mode_list = statistics.mode(sorted_list)\n    fft = np.fft.fft(sorted_list)\n    magnitudes = np.abs(fft)\n    mean_mag = statistics.mean(magnitudes)\n    median_mag = statistics.median(magnitudes)\n    mode_mag = statistics.mode(magnitudes)\n    return (round(mean_list), round(median_list), round(mode_list), round(mean_mag), round(median_mag), round(mode_mag))"
  },
  {
    "output": "def get_business_days(start_date, end_date, country_code):\n    import datetime\n    import holidays\n    if not isinstance(start_date, datetime.date) or not isinstance(end_date, datetime.date):\n        raise ValueError(\"Invalid date format\")\n    if start_date > end_date:\n        raise ValueError(\"Start date cannot be after end date\")\n    country_holidays = holidays.CountryHoliday(country_code)\n    date_range = [start_date + datetime.timedelta(days=i) for i in range((end_date - start_date).days + 1)]\n    business_days = [date for date in date_range if date.weekday() < 5 and date not in country_holidays]\n    return business_days"
  },
  {
    "output": "import os\nimport sqlite3\nimport pandas as pd\nimport re\n\ndef task_func(database_path, table_name, column_name, regex_pattern):\n    if not os.path.exists(database_path):\n        return pd.DataFrame()\n    conn = sqlite3.connect(database_path)\n    query = f\"SELECT {column_name} FROM {table_name}\"\n    df = pd.read_sql_query(query, conn)\n    conn.close()\n    matches = df[column_name].apply(lambda x: re.findall(regex_pattern, str(x)))\n    matches_df = pd.DataFrame(matches)\n    return matches_df"
  },
  {
    "output": "import random\nimport numpy as np\nimport statistics\n\ndef generate_and_analyze_data(size, min_val, max_val):\n    data = [random.uniform(min_val, max_val) for _ in range(size)]\n    truncated_data = [x for x in data if min_val <= x <= max_val]\n    mean = statistics.mean(truncated_data)\n    median = statistics.median(truncated_data)\n    std_dev = statistics.stdev(truncated_data)\n    return mean, median, std_dev"
  },
  {
    "output": "elif not in_brackets:\n            current_name += char\n        elif current_name:\n            extracted_names.append(current_name)\n            current_name = \"\"\n    if current_name:\n        extracted_names.append(current_name)\n    \n    # Format email message\n    message = \"Extracted names:\\n\" + \"\\n\".join(extracted_names)\n    \n    # Send email\n    if smtp is None:\n        smtp = smtplib.SMTP(smtp_server, smtp_port)\n        smtp.starttls()\n        smtp.login(email_address, email_password)\n    smtp.sendmail(email_address, recepient_address, message)\n    smtp.quit()\n    \n    return extracted_names"
  },
  {
    "output": "python_code_returner\n```python\nimport itertools\nfrom typing import Any\nfrom scipy import stats\n\n\ndef task_func(input_list: list, repetitions: int) -> Any:\n    flattened_list = list(itertools.chain.from_iterable(itertools.repeat(input_list, repetitions)))\n    mode_result = stats.mode(flattened_list)\n    return mode_result"
  },
  {
    "output": "```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(file_path=\"data.csv\", columns=[\"A\", \"B\", \"C\"]):\n    # Read CSV file into a DataFrame\n    df = pd.read_csv(file_path)\n    \n    # Convert numeric values to floats\n    df = df.apply(pd.to_numeric, errors='coerce')\n    \n    # Drop rows with NaN values\n    df = df.dropna()\n    \n    # Plot the data\n    fig, ax = plt.subplots()\n    df[columns].plot"
  },
  {
    "output": "task_func([\"A\", \"E\", \"I\"]) 45"
  },
  {
    "output": "import os\nimport pandas as pd\n\ndef task_func(dataset, filename, output_dir):\n    os.makedirs(output_dir, exist_ok=True)\n    filepath = os.path.join(output_dir, filename)\n    with open(filepath, 'w') as f:\n        for i, df in enumerate(dataset):\n            df.to_csv(f, index=False)\n            if i != len(dataset) - 1:\n                f.write('-' * 40 + '\\n')"
  },
  {
    "output": "# Plot the counts for each animal\n    plt.figure(figsize=(12, 6))\n    for i, animal in enumerate(animals):\n        plt.plot(counts[animal], label=f'{animal} Counts')\n    plt.title('Animal Counts Over 10 Observations')\n    plt.xlabel('Observation')\n    plt.ylabel('Count')\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\n    # Return the statistics\n    return statistics"
  },
  {
    "output": "def insert_number_into_sorted_list(original_list, number):\n    import random\n    new_list = original_list.copy()\n    new_list.append(number)\n    new_list.sort()\n    return tuple((original_list, new_list))"
  },
  {
    "output": "def task_func(source_dir: str, target_dir: str, extensions: List[str]) -> int:\n    import shutil\n    from pathlib import Path\n    source_path = Path(source_dir)\n    target_path = Path(target_dir)\n    if not source_path.exists() or not target_path.exists():\n        raise ValueError(\"source_dir or target_dir does not exist\")\n    moved_count = 0\n    for file in source_path.iterdir():\n        if file.is_file():\n            file_ext = file.suffix[1:]\n            if file_ext in extensions:\n                target_file = target_path / file.name\n                shutil.move(str(file), str(target_file))\n                moved_count += 1\n    return moved_count"
  },
  {
    "output": "def task_func(file_path):\n    import csv\n    from collections import Counter\n    with open(file_path, 'r') as file:\n        reader = csv.reader(file)\n        words = []\n        for row in reader:\n            words.extend(row)\n    word_counts = Counter(words)\n    return sorted(word_counts.items(), key=lambda x: -x[1])"
  },
  {
    "output": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef fit_and_plot_quadratic(X, Y):\n    X = np.array(X).reshape(-1, 1)\n    Y = np.array(Y)\n    A = np.c_[np.ones(X.shape[0]), X, X**2]\n    params, _ = np.linalg.lstsq(A, Y, rcond=None)\n    x_fit = np.linspace(min(X), max(X), 100)\n    y_fit = params[0] + params[1] * x_fit + params[2] * x_fit**2\n    fig, ax = plt.subplots()\n    ax.scatter(X, Y, color='blue')\n    ax.plot(x_fit, y_fit, color='red')\n    return params, ax"
  },
  {
    "output": "from django.http import FileResponse\nfrom django.core.files import File\nimport io\nimport zipfile\n\ndef generate_zip_file_response(request, files):\n    buffer = io.BytesIO()\n    with zipfile.ZipFile(buffer, 'w') as zipf:\n        for file in files:\n            zipf.writestr(file['name'], file['content'])\n    buffer.seek(0)\n    return FileResponse(buffer, as_attachment=True, filename='files.zip')"
  },
  {
    "output": "def extract_and_plot(data):\n    import numpy as np\n    import matplotlib.pyplot as plt\n    values = [item for sublist in data for item in sublist if isinstance(item, (int, float))]\n    mean = np.mean(values)\n    median = np.median(values)\n    std_dev = np.std(values)\n    plt.hist(values, bins=20, density=True, alpha=0.6, color='g')\n    pdf = np.histogram(values, bins=20, density=True)[0]\n    x = np.linspace(min(values), max(values), 100)\n    pdf_values = (1 / (std_dev * np.sqrt(2 * np.pi))) * np.exp(- (x - mean)**2 / (2 * std_dev**2))\n    plt.plot(x, pdf_values, 'k--', linewidth=2)\n    plt.title('Histogram with PDF')\n    plt.xlabel('Value')\n    plt.ylabel('Density')\n    plt.show()"
  },
  {
    "output": "```python\nimport re\nimport random\nimport pandas as pd\n\ndef task_func(data_list, seed=None):\n    if seed is not None:\n        random.seed(seed)\n    original_strings = []\n    shuffled_strings = []\n    \n    for string in data_list:\n        substrings = [s.strip() for s in string.split(',')]\n        random.shuffle(substrings)\n        original_strings.append(string)\n        shuffled_strings.append(', '.join(substrings))\n    \n    df = pd.DataFrame({\n        'Original String': original_strings,\n        'Shuffled String': shuffled_strings\n    })\n    return df\n```"
  },
  {
    "output": "def generate_and_insert(n, total):\n    import random\n    import bisect\n    while True:\n        numbers = [random.randint(1, total - (n-1)) for _ in range(n-1)]\n        remaining = total - sum(numbers)\n        if remaining > 0:\n            numbers.append(remaining)\n            random.shuffle(numbers)\n            break\n    sorted_numbers = sorted(numbers)\n    new_number = random.randint(1, total)\n    return bisect.bisect_left(sorted_numbers, new_number)"
  },
  {
    "output": "import mechanize\nfrom bs4 import BeautifulSoup\n\ndef task_func(url, form_id, data):\n    br = mechanize.Browser()\n    br.open(url)\n    br.select_form(nr=0)\n    br.form['form_id'] = form_id\n    br.form.set_all_readonly(False)\n    br.form['data'] = data\n    response = br.submit()\n    soup = BeautifulSoup(response.read(), 'html.parser')\n    title = soup.find('title')\n    return title.get_text() if title else 'No Title'"
  },
  {
    "output": "def generate_and_plot_scores(students):\n    import numpy as np\n    import matplotlib.pyplot as plt\n    scores = np.random.randint(0, 100, size=len(students))\n    sorted_scores = np.sort(scores)\n    plt.bar(students, sorted_scores)\n    plt.xlabel('Students')\n    plt.ylabel('Scores')\n    plt.title('Student Scores')\n    plt.show()\n    return sorted_scores, plt.gcf()"
  },
  {
    "output": "import time\nimport subprocess\nimport os\n\ndef task_func(script_path, output_file, timeout):\n    start_time = time.time()\n    process = subprocess.Popen(['Rscript', script_path], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    while True:\n        if os.path.exists(output_file):\n            return True, f\"Output file {output_file} generated successfully.\"\n        if time.time() - start_time > timeout:\n            return False, f\"Timeout exceeded. Output file {output_file} not generated.\"\n        time.sleep(1)"
  },
  {
    "output": "def task_func(directory, extension):\n    import os\n    import json\n    result = {}\n    for filename in os.listdir(directory):\n        if filename.endswith(extension):\n            file_path = os.path.join(directory, filename)\n            with open(file_path, 'r') as file:\n                content = json.load(file)\n            result[filename] = content\n    return result"
  },
  {
    "output": "import matplotlib.pyplot as plt\nfrom collections import Counter\n\ndef calculate_word_occurrences(sentences, target_words):\n    word_counts = Counter()\n    for sentence in sentences:\n        words = sentence.split()\n        word_counts.update(words)\n    target_counts = {word: word_counts.get(word, 0) for word in target_words}\n    plt.bar(target_counts.keys(), target_counts.values())\n    plt.xlabel('Words')\n    plt.ylabel('Occurrences')\n    plt.title('Word Occurrences')\n    plt.show()"
  },
  {
    "output": "def function_name(keys):\n    if len(set(keys)) != 10:\n        raise ValueError(\"The 'keys' parameter must contain exactly 10 unique elements.\")\n    import random\n    import json\n    import os\n    random_elements = [random.randint(1, 100) for _ in range(10)]\n    updated_dict = {k: random_elements[i] for i, k in enumerate(keys)}\n    json_file_path = \"updated_dict.json\"\n    with open(json_file_path, 'w') as f:\n        json.dump(updated_dict, f)\n    from collections import Counter\n    key_freq = Counter(updated_dict.keys())\n    text_file_path = \"key_frequency.txt\"\n    with open(text_file_path, 'w') as f:\n        for key, freq in key_freq.items():\n            f.write(f\"{key}: {freq}\\n\")\n    return (updated_dict, json_file_path, text_file_path)"
  },
  {
    "output": "def task_func():\n    import math\n    return math.sqrt(16)"
  },
  {
    "output": "def process_string_to_df(input_string):\n    processed_lines = [line.replace('\\t', ' ') for line in input_string.splitlines() if line.strip()]\n    import pandas as pd\n    return pd.DataFrame(processed_lines, columns=['Text'])"
  },
  {
    "output": "def task_func(text):\n    from textblob import TextBlob\n    from nltk.corpus import stopwords\n    from nltk.tokenize import word_tokenize\n    import re\n\n    stop_words = set(stopwords.words('english'))\n    words = word_tokenize(text.lower())\n    filtered = [word for word in words if word.isalpha() and word not in stop_words]\n    cleaned_text = ' '.join(filtered)\n    return TextBlob(cleaned_text).sentiment.polarity"
  },
  {
    "output": "def task_func(data_list):\n    if not data_list:\n        raise ValueError(\"Input data list is empty\")\n    from collections import Counter\n    import matplotlib.pyplot as plt\n    counts = Counter(data_list)\n    predefined_categories = ['A', 'B', 'C', 'D']\n    predefined_counts = {cat: counts.get(cat, 0) for cat in predefined_categories}\n    total_predefined = sum(predefined_counts.values())\n    total_all = sum(counts.values())\n    is_uniform = abs(total_all - 4 * total_predefined) < 1\n    additional_categories = [cat for cat in counts if cat not in predefined_categories]\n    plt.bar(predefined_categories, [counts.get(cat, 0) for cat in predefined_categories])\n    plt.bar(additional_categories, [counts[cat] for cat in additional_categories], bottom=[sum(predefined_counts.values()), 0])\n    plt.xlabel('Categories')\n    plt.ylabel('Frequency')\n    plt.title('Category Distribution')\n    plt.show()"
  },
  {
    "output": "def calculate_time_differences_and_plot(datetime_strings):\n    import matplotlib.pyplot as plt\n    from datetime import datetime\n    time_differences = []\n    for i in range(1, len(datetime_strings)):\n        t1 = datetime.strptime(datetime_strings[i-1], \"%Y-%m-%d %H:%M:%S\")\n        t2 = datetime.strptime(datetime_strings[i], \"%Y-%m-%d %H:%M:%S\")\n        diff = (t2 - t1).total_seconds()\n        time_differences.append(diff)\n    fig, ax = plt.subplots()\n    ax.bar(range(len(time_differences)), time_differences)\n    ax.set_xlabel('Interval')\n    ax.set_ylabel('Time Difference (seconds)')\n    ax.set_title('Time Differences Between Consecutive Datetimes')\n    return ax"
  },
  {
    "output": "import os\nimport shutil\n\ndef arrange_files_by_extension(directory):\n    for filename in os.listdir(directory):\n        file_path = os.path.join(directory, filename)\n        if os.path.isfile(file_path):\n            _, ext = os.path.splitext(filename)\n            ext = ext.lower()\n            if ext not in ['','.']:\n                ext_dir = os.path.join(directory, ext[1:])\n                os.makedirs(ext_dir, exist_ok=True)\n                shutil.move(file_path, os.path.join(ext_dir, filename))"
  },
  {
    "output": "def generate_and_visualize_normal_samples(mean, std_dev):\n    import numpy as np\n    import matplotlib.pyplot as plt\n    import scipy.stats as stats\n    samples = np.random.normal(mean, std_dev, 500)\n    plt.hist(samples, bins=30, density=True, alpha=0.6, color='g')\n    pdf = stats.norm.pdf(samples, mean, std_dev)\n    plt.plot(samples, pdf, 'k', linewidth=2)\n    plt.show()"
  },
  {
    "output": "def generate_random_dataframe(rows, columns):\n    import pandas as pd\n    import numpy as np\n    data = {}\n    for col in columns:\n        if np.random.rand() > 0.5:\n            data[col] = np.random.randint(0, 100, size=rows)\n        else:\n            data[col] = np.random.choice(['low', 'medium', 'high'], size=rows)\n    return pd.DataFrame(data)"
  },
  {
    "output": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nCOLUMNS = ['col1', 'col2', 'col3']\n\ndef task_func(data):\n    df = pd.DataFrame(data, columns=COLUMNS)\n    pivot_df = df.pivot_table(index='col1', columns='col2', values='col3', aggfunc='count').fillna(0)\n    ax = sns.heatmap(pivot_df, annot=True, fmt='d', cmap='viridis')\n    return df, ax"
  },
  {
    "output": "def task_func(text, stopwords):\n    import re\n    from collections import Counter\n    text = re.sub(r'http\\S+', '', text)\n    words = text.split()\n    word_counts = Counter(words)\n    filtered_counts = {word: count for word, count in word_counts.items() if word in stopwords}\n    return list(filtered_counts.items())"
  },
  {
    "output": "```python\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(df, features):\n    scaler = StandardScaler()\n    df[features] = scaler.fit_transform(df[features])\n    return df\n```"
  },
  {
    "output": "def task_func(directory):\n    import os\n    import json\n    count = 0\n    for filename in os.listdir(directory):\n        file_path = os.path.join(directory, filename)\n        if os.path.isfile(file_path) and filename.endswith('.json'):\n            with open(file_path, 'r') as f:\n                data = json.load(f)\n            if 'mynewkey' not in data:\n                data['mynewkey'] = 'value'\n                count += 1\n                with open(file_path, 'w') as f:\n                    json.dump(data, f)\n    return count"
  },
  {
    "output": "except FileNotFoundError as e:\n        return str(e)\n    except HTTPError as e:\n        return f\"HTTP error occurred: {e}\"\n    except Exception as e:\n        return f\"An error occurred: {e}\""
  },
  {
    "output": "def task_func(data=None):\n    if not isinstance(data, pd.DataFrame):\n        data = pd.DataFrame(data)\n    data = data.applymap(lambda x: 0 if x < 0.5 else x)\n    scaler = StandardScaler()\n    data_scaled = scaler.fit_transform(data)\n    data_preprocessed = pd.DataFrame(data_scaled, columns=data.columns)\n    return data_preprocessed"
  },
  {
    "output": "import subprocess\nimport time\nimport json\nimport platform\nimport psutil\nLOGFILE_PATH = \"logfile.log\"\n\ndef task_func(interval, duration):\n    if interval <= 0 or duration <= 0:\n        raise ValueError(\"Both 'interval' and 'duration' must be greater than zero.\")\n    log_data = []\n    start_time = time.time()\n    while (time.time() - start_time) < duration:\n        cpu_usage = psutil.cpu_percent(interval=1)\n        log_data.append({\n            \"timestamp\": time.time(),\n            \"cpu_usage\": cpu_usage\n        })\n        time.sleep(interval)\n    try:\n        with open(LOGFILE_PATH, 'w') as file:\n            json.dump(log_data, file)\n        return LOGFILE_PATH\n    except IOError:\n        return None"
  },
  {
    "output": "def task_func(df, letter):\n    filtered_words = df[df['Word'].str.startswith(letter)]['Word']\n    lengths = filtered_words.str.len()\n    import matplotlib.pyplot as plt\n    plt.hist(lengths, bins=range(1, max(lengths)+2), edgecolor='black')\n    plt.xlabel('Word Length')\n    plt.ylabel('Frequency')\n    plt.title('Histogram of Word Lengths')\n    plt.show()"
  },
  {
    "output": "def predict_price_based_on_area(area):\n    import numpy as np\n    from sklearn.linear_model import LinearRegression\n    # Example training data\n    areas = np.array([100, 150, 200, 250, 300]).reshape(-1, 1)\n    prices = np.array([100000, 150000, 200000, 250000, 300000])\n    model = LinearRegression()\n    model.fit(areas, prices)\n    return model.predict([[area]])[0]"
  },
  {
    "output": "def process_text(text):\n    import re\n    from collections import Counter\n    cleaned = re.sub(r'[^a-zA-Z0-9]', '', text)\n    words = cleaned.split()\n    return dict(Counter(words))"
  },
  {
    "output": "def task_func(json_str):\n    import json\n    data = json.loads(json_str)\n    cleaned_data = {k: v for k, v in data.items() if v is not None}\n    from collections import Counter\n    freq = Counter(cleaned_data.values())\n    return {'processed_data': cleaned_data, 'frequency': freq}"
  },
  {
    "output": "def task_func(df):\n    if not isinstance(df, pd.DataFrame) or 'Name' not in df.columns:\n        return \"Invalid input\"\n    unique_names = df['Name'].unique()\n    scores = df[df['Name'].isin(unique_names)]['Score']\n    countries = df[df['Name'].isin(unique_names)]['Country']\n    plt.figure(figsize=(12, 6))\n    plt.hist(scores, bins=10, color='blue', alpha=0.7)\n    plt.title('Histogram of Scores')\n    plt.xlabel('Score')\n    plt.ylabel('Frequency')\n    plt.show()\n    plt.figure(figsize=(12, 6))\n    countries = countries.dropna()\n    scores = scores.loc[countries.index]\n    plt.boxplot([scores[countries == country] for country in countries.unique()], labels=countries.unique())\n    plt.title('Boxplot of Scores by Country')\n    plt.xlabel('Country')\n    plt.ylabel('Score')\n    plt.show()"
  },
  {
    "output": "def generate_histograms_and_check_uniformity(df):\n    import matplotlib.pyplot as plt\n    fig, axes = plt.subplots(nrows=len(df.columns), ncols=1, figsize=(10, 5*len(df.columns)))\n    for i, col in enumerate(df.columns):\n        ax = axes[i] if len(df.columns) > 1 else axes\n        df[col].plot(kind='hist', ax=ax)\n        ax.set_title(f'Histogram of {col}')\n        # Check for uniform distribution\n        if len(df[col].unique()) == len(df[col]):\n            print(f\"The distribution of '{col}' is uniform.\")\n        else:\n            print(f\"The distribution of '{col}' is not uniform.\")\n    plt.tight_layout()\n    return axes if len(df.columns) > 1 else [axes]"
  },
  {
    "output": "import pandas as pd\nimport csv\nimport os\n\ndef read_excel_to_csv_and_sum_columns(file_path, output_csv_path):\n    try:\n        df = pd.read_excel(file_path)\n        df.to_csv(output_csv_path, index=False)\n        sums = df.sum(numeric_only=True)\n        return sums.to_dict()\n    except Exception as e:\n        return {\"error\": str(e)}"
  },
  {
    "output": "def task_func(num_samples=100, n_estimators=100, random_seed=None, cv=5):\n    import numpy as np\n    from sklearn.model_selection import cross_val_score\n    from sklearn.ensemble import RandomForestRegressor\n    if num_samples / cv < 2:\n        raise ValueError(\"num_samples / cv < 2\")\n    np.random.seed(random_seed)\n    features = np.random.randn(num_samples, 5)\n    feature_sum = np.sum(features, axis=1)\n    noise = np.random.randn(num_samples)\n    target = feature_sum + noise\n    model = RandomForestRegressor(n_estimators=n_estimators, random_state=random_seed)\n    scores = cross_val_score(model, features, target, cv=cv)\n    mean_score = np.mean(scores)\n    return mean_score, model"
  },
  {
    "output": "import os\nimport subprocess\n\ndef task_func(pattern):\n    files = [f for f in os.listdir() if os.path.isfile(f) and pattern in f]\n    archive_name = 'archive.tar'\n    subprocess.run(['tar', '-cvf', archive_name] + files)\n    for file in files:\n        os.remove(file)\n    return archive_name"
  },
  {
    "output": "import matplotlib.pyplot as plt\nimport numpy as np\n\ndef task_func(n, seed=0):\n    np.random.seed(seed)\n    x = np.random.rand(n)\n    y = np.random.rand(n)\n    points = list(zip(x, y))\n    \n    plt.figure()\n    plt.scatter(x, y)\n    plt.title(\"Scatter plot of random points\")\n    plt.xlabel(\"X\")\n    plt.ylabel(\"Y\")\n    \n    return plt.gcf(), points"
  },
  {
    "output": "def process_text(text):\n    text = re.sub(r'\\W+', ' ', text).lower()\n    words = text.split()\n    filtered_words = [word for word in words if word not in STOPWORDS]\n    return ' '.join(filtered_words)"
  },
  {
    "output": "```python\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(d):\n    if not d:\n        return pd.DataFrame()\n    df = pd.DataFrame(d)\n    scaler = MinMaxScaler()\n    scaled_data = scaler.fit_transform(df[['x', 'y', 'z']])\n    scaled_df = pd.DataFrame(scaled_data, columns=['x', 'y', 'z'])\n    return scaled_df\n```"
  },
  {
    "output": "def read_image(path, threshold):\n    from PIL import Image\n    import os\n    if not os.path.exists(path):\n        raise FileNotFoundError(f\"Invalid file path: {path}\")\n    if threshold < 0 or threshold > 255:\n        raise ValueError(\"Threshold must be between 0 and 255\")\n    img = Image.open(path)\n    img = img.convert(\"L\")\n    img = img.point(lambda p: 255 if p >= threshold else 0)\n    img.save(\"binary_image.jpg\")"
  },
  {
    "output": "import os\nimport zipfile\n\ndef zip_files_with_extensions(source_dir, target_dir, zip_name, valid_extensions):\n    if not os.path.exists(source_dir):\n        raise OSError(f\"Source directory '{source_dir}' does not exist.\")\n    files = [f for f in os.listdir(source_dir) if os.path.isfile(os.path.join(source_dir, f)) and os.path.splitext(f)[1].lower() in valid_extensions]\n    zip_path = os.path.join(target_dir, zip_name)\n    with zipfile.ZipFile(zip_path, 'w') as zipf:\n        for file in files:\n            file_path = os.path.join(source_dir, file)\n            zipf.write(file_path, os.path.basename(file_path))\n    return zip_path"
  },
  {
    "output": "import os\nimport csv\nimport subprocess\n\ndef task_func(commands_file, output_dir):\n    if not os.path.exists(commands_file):\n        raise FileNotFoundError(f\"The commands file {commands_file} does not exist.\")\n    os.makedirs(output_dir, exist_ok=True)\n    output_files = []\n    with open(commands_file, 'r') as f:\n        reader = csv.reader(f)\n        for i, row in enumerate(reader):\n            command = ' '.join(row)\n            output_file = os.path.join(output_dir, f\"output_{i}.txt\")\n            output_files.append(output_file)\n            with open(output_file, 'w') as out_f:\n                try:\n                    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n                    out_f.write(result.stdout)\n                except Exception as e:\n                    out_f.write(f\"Error: {str(e)}\")\n    return output_files"
  },
  {
    "output": "def task_func(n_rows):\n    import random\n    import matplotlib.pyplot as plt\n    from collections import Counter\n    if n_rows <= 0:\n        raise ValueError(\"n_rows must be greater than 0\")\n    data = [''.join(random.choices('ABCDEFGHIJKLMNOPQRSTUVWXYZ', k=3)) for _ in range(n_rows)]\n    counts = Counter(data)\n    top_30 = counts.most_common(30)\n    labels, values = zip(*top_30)\n    plt.bar(labels, values)\n    plt.xlabel('3-letter strings')\n    plt.ylabel('Frequency')\n    plt.title('Frequency of Top 30 Most Common 3-letter Strings')\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.show()"
  },
  {
    "output": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(df, cols):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"df is not a DataFrame\")\n    if not isinstance(cols, list):\n        raise ValueError(\"cols is not a list\")\n    for col in cols:\n        if col not in df.columns:\n            raise ValueError(f\"Column {col} does not exist in the DataFrame\")\n    scaler = StandardScaler()\n    df[cols] = scaler.fit_transform(df[cols])\n    return df"
  },
  {
    "output": "import os\nimport re\n\ndef task_func(pattern, log_dir='/var/log/'):\n    # Step 1: List all files in the directory\n    files = [f for f in os.listdir(log_dir) if os.path.isfile(os.path.join(log_dir, f))]\n    \n    # Step 2: Filter files based on the regex pattern\n    regex = re.compile(pattern)\n    matching_files = [f for f"
  },
  {
    "output": "def task_func():\n    return \"Hello, World!\""
  },
  {
    "output": ""
  },
  {
    "output": "def task_func(**kwargs):\n    import os\n    import shutil\n    target_dir = kwargs.get('target_dir', '.')\n    copied_files = []\n    for file_path, source_path in kwargs.items():\n        if os.path.exists(source_path):\n            if os.path.isfile(source_path):\n                shutil.copy2(source_path, target_dir)\n                copied_files.append(os.path.join(target_dir, os.path.basename(source_path)))\n    return copied_files"
  },
  {
    "output": "60"
  },
  {
    "output": "def task_func(source_folder):\n    import os\n    import shutil\n    try:\n        if not os.path.exists(source_folder):\n            raise ValueError\n        shutil.copytree(source_folder, f\"{source_folder}_backup\")\n        os.rmdir(source_folder)\n        return True\n    except Exception as e:\n        return False"
  },
  {
    "output": "def task_func(df, column, pattern):\n    import re\n    if pattern == '':\n        return df.copy()\n    def reverse_matching_words(row):\n        words = row[column].split()\n        def reverse_word(word):\n            return word[::-1] if re.match(pattern, word) else word\n        reversed_words = [reverse_word(word) for word in words]\n        return ' '.join(reversed_words)\n    return df.apply(reverse_matching_words, axis=1)"
  },
  {
    "output": "import random\nimport math\n\ndef generate_average_distance(n, RADIUS):\n    total_distance = 0.0\n    for _ in range(n):\n        theta = 2 * math.pi * random.random()\n        r = RADIUS * random.random() ** 0.5\n        x = r * math.cos(theta)\n        y = r * math.sin(theta)\n        distance = math.hypot(x, y)\n        total_distance += distance\n    return total_distance / n"
  },
  {
    "output": "def task_func(text):\n    import re\n    from collections import Counter\n    import matplotlib.pyplot as plt\n    import numpy as np\n    names = re.findall(r'\\b([A-Za-z]+)\\b', text)\n    name_counts = Counter(names)\n    names, counts = zip(*name_counts.items())\n    plt.bar(names, counts)\n    plt.xlabel('Names')\n    plt.ylabel('Frequency')\n    plt.title('Name Frequencies')\n    plt.show()\n    skewness = np.ma.masked_invalid(counts).skew()\n    kurtosis = np.ma.masked_invalid(counts).kurtosis()\n    return {'name_counts': dict(name_counts), 'skewness': skewness, 'kurtosis': kurtosis}"
  },
  {
    "output": "def task_func(df):\n    if len(df) < 2:\n        return float('nan')\n    scores = df['scores'].astype(float)\n    grades = df['grades'].str.replace('A', '4').str.replace('B', '3').str.replace('C', '2').str.replace('D', '1').astype(float)\n    return (scores - scores.mean()) * (grades - grades.mean()).sum() / ( (scores - scores.mean()).pow(2).sum() * (grades - grades.mean()).pow(2).sum() )**0.5"
  },
  {
    "output": "def analyze_sales_data(data):\n    if not data:\n        return \"No data provided\"\n    try:\n        for value in data:\n            if value < 0:\n                raise ValueError(\"Negative values are not allowed\")\n        sum_val = sum(data)\n        mean_val = sum_val / len(data)\n        min_val = min(data)\n        max_val = max(data)\n        import matplotlib.pyplot as plt\n        plt.bar(range(len(data)), data)\n        plt.xlabel('Index')\n        plt.ylabel('Sales')\n        plt.title('Sales Data')\n        plt.show()\n        return f\"Sum: {sum_val}, Mean: {mean_val}, Min: {min_val}, Max: {max_val}\"\n    except ValueError as e:\n        return str(e)"
  },
  {
    "output": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef calculate_row_sums_and_plot(data):\n    if data.size == 0:\n        return pd.DataFrame(columns=['row_sum'])\n    row_sums = np.sum(data, axis=1)\n    dates = pd.date_range(start='2020-01-01', periods=row_sums.shape[0])\n    df = pd.DataFrame({'row_sum': row_sums}, index=dates)\n    df.plot(kind='line')\n    plt.show()\n    return df"
  },
  {
    "output": "def task_func(elements, pattern):\n    import random\n    import re\n    formatted = []\n    for elem in elements:\n        replaced = ''.join(random.choice('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789') for _ in range(len(elem)))\n        formatted.append(f\"%{replaced}%\")\n    combined = ''.join(formatted)\n    result = re.search(pattern, combined)\n    return formatted, bool(result)"
  },
  {
    "output": "def task_func(start_ip, end_ip):\n    import subprocess\n    import re\n    active_ips = {}\n    for ip in range(int(start_ip.split('.')[-1]), int(end_ip.split('.')[-1]) + 1):\n        ip_address = f\"{start_ip.split('.')[0]}.{start_ip.split('.')[1]}.{start_ip.split('.')[2]}.{ip}\"\n        try:\n            output = subprocess.check_output([\"ping\", \"-c\", \"1\", ip_address], stderr=subprocess.STDOUT, timeout=1)\n            if b\"1 received\" in output:\n                active_ips[ip_address] = True\n            else:\n                active_ips[ip_address] = False\n        except subprocess.CalledProcessError:\n            active_ips[ip_address] = False\n        except Exception:\n            active_ips[ip_address] = False\n    return active_ips"
  },
  {
    "output": "def task_func(text):\n    import pandas as pd\n    if not isinstance(text, str):\n        raise ValueError(\"Input must be a string\")\n    import re\n    words = re.findall(r'\\b\\w+\\b', text)\n    filtered = [word for word in words if word.startswith('$')]\n    filtered = [word for word in filtered if not re.fullmatch(r'[^a-zA-Z0-9]+', word)]\n    from collections import Counter\n    counts = Counter(filtered)\n    return pd.DataFrame(list(counts.items()), columns=['word', 'frequency'])"
  },
  {
    "output": "import csv\nimport os\n\nOUTPUT_DIR = './output'\n\ndef task_func(df, filename, output_dir=OUTPUT_DIR):\n    # Ensure the output directory exists\n    os.makedirs(output_dir, exist_ok=True)\n    # Construct the full file path\n    file_path = os.path.join(output_dir, filename)\n    # Save the DataFrame to a CSV file\n    df.to_csv(file_path, index=False)\n    # Return the absolute path of the saved CSV file\n    return os.path.abspath(file_path)"
  },
  {
    "output": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(data_str, separator=\",\", bins=20):\n    try:\n        data_list = list(map(int, data_str.split(separator)))\n        if not data_list:\n            raise ValueError(\"Data is empty.\")\n        series = pd.Series(data_list, dtype=np.int64)\n        fig, ax = plt.subplots()\n        ax.hist(series, bins=bins, color='#607c8e', rwidth=0.9, grid=True)\n        return (series, ax)\n    except ValueError as e:\n        raise ValueError(\"Failed to convert data or data is empty.\") from e"
  },
  {
    "output": "def task_func():\n    return \"Hello, world!\""
  },
  {
    "output": "kurtosis, ax)"
  },
  {
    "output": "def load_data_and_plot(file_path):\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    try:\n        df = pd.read_excel(file_path)\n        if df.empty:\n            raise ValueError(\"The Excel file is empty.\")\n        mean = df.mean()\n        std_dev = df.std()\n        mean.plot(kind='bar', yerr=std_dev, capsize=5)\n        plt.title('Mean Values with Standard Deviation')\n        plt.ylabel('Value')\n        plt.xlabel('Columns')\n        plt.show()\n    except Exception as e:\n        print(f\"An error occurred: {e}\")"
  },
  {
    "output": "```python\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime, timedelta\nimport matplotlib.pyplot as plt\n\ndef task_func(start_date, end_date, seed=42):\n    np.random.seed(seed)\n    \n    # Calculate the number of days between start_date and end_date\n    start = datetime.strptime(start_date, \"%Y-%m-%d\")\n    end = datetime.strptime(end_date, \"%Y-%m-%d\")\n    delta = end - start\n    num_days = delta.days + 1\n    \n    # Generate random sales data\n    sales = np.random.randint(0, 501, size=num_days)\n    \n    # Create date range\n    dates = [start + timedelta(days=i) for i in range(num_days)]\n    \n    # Create DataFrame\n    df = pd.DataFrame({\n        'Date': dates,\n        'Sales': sales\n    })\n    \n    # Plot sales over time\n    plt.figure(figsize=(10, 5"
  },
  {
    "output": "def serialize_and_save(obj, file_path):\n    import os\n    import pickle\n    try:\n        directory = os.path.dirname(file_path)\n        if not os.path.exists(directory):\n            os.makedirs(directory)\n        with open(file_path, 'wb') as f:\n            pickle.dump(obj, f)\n        return True\n    except Exception as e:\n        return False"
  },
  {
    "output": "def process_data(file_path, sort_column, write_to_file=None, do_regression=False, regression_columns=None):\n    import pandas as pd\n    try:\n        df = pd.read_csv(file_path)\n    except FileNotFoundError:\n        raise FileNotFoundError(f\"The file {file_path} does not exist.\")\n    if sort_column not in df.columns:\n        raise ValueError(f\"Column {sort_column} not found in the CSV file.\")\n    df.sort_values(by=sort_column, inplace=True)\n    if write_to_file:\n        df.to_csv(write_to_file, index=False)\n    if do_regression:\n        if not regression_columns or len(regression_columns) < 2:\n            raise ValueError(\"Regression requires at least two columns.\")\n        if any(col not in df.columns for col in regression_columns):\n            raise ValueError(\"One or more regression columns not found in the CSV file.\")\n        X = df[regression_columns[:-1]]\n        y = df[regression_columns[-1]]\n        from sklearn.linear_model import LinearRegression\n        model = LinearRegression().fit(X, y)\n        return model.coef_, model.intercept_\n    return df"
  },
  {
    "output": "import pytz\nfrom dateutil.parser import parse\nfrom datetime import datetime\n\ndef task_func(date_str, from_tz, to_tz):\n    naive_date = parse(date_str)\n    from_tz = pytz.timezone(from_tz)\n    localized_date = from_tz.localize(naive_date)\n    to_tz = pytz.timezone(to_tz)\n    converted_date = localized_date.astimezone(to_tz)\n    current_time = datetime.now(to_tz)\n    time_difference = (current_time - converted_date).total_seconds()\n    return int(time_difference)"
  },
  {
    "output": "def calculate_and_plot_differences(list1, list2, n):\n    import numpy as np\n    import matplotlib.pyplot as plt\n    diffs = np.array(list1) - np.array(list2)\n    squared_diffs = np.square(diffs)\n    sorted_diffs = np.sort(squared_diffs)[::-1]\n    top_n = sorted_diffs[:n]\n    plt.plot(top_n)\n    plt.title(\"Top N Squared Differences\")\n    plt.xlabel(\"Index\")\n    plt.ylabel(\"Squared Difference\")\n    plt.show()"
  },
  {
    "output": "def task_func(hex_str, encoding='utf-8'):\n    import binascii\n    return binascii.unhexlify(hex_str).decode(encoding)"
  },
  {
    "output": "```python\nimport numpy as np\nimport itertools\nimport random\n\ndef task_func(T1, max_value=100):\n    # Convert string representations to integers\n    integers = []\n    for inner_tuple in T1:\n        for s in inner_tuple:\n            integers.append(int(s))\n    sum_integers = sum(integers)\n    \n    # Create a list of random integers\n    random_list = [random.randint(1, max_value) for _ in range(sum_integers)]\n    \n    # Compute percentiles\n    p25 = np.percentile(random_list, 25)\n    p50 = np.percentile(random_list, 50)\n    p75 = np.percentile(random_list, 75)\n    \n    return (p25, p50, p75)\n```"
  },
  {
    "output": "from random import choice, randint\nfrom difflib import SequenceMatcher\n\ndef task_func(s, min_length, max_length, letters):\n    length = randint(min_length, max_length)\n    generated = ''.join(choice(letters) for _ in range(length))\n    similarity = SequenceMatcher(None, generated, s).ratio()\n    return (generated, similarity >= 0.5)"
  },
  {
    "output": "def calculate_position_means(data, export_to_json=False, filename=\"position_means.json\"):\n    if not data:\n        return {}\n    max_length = max(len(row) for row in data)\n    means = {}\n    for i in range(max_length):\n        values = [row[i] for row in data if len(row) > i]\n        if all(isinstance(x, (int, float)) for x in values):\n            mean = sum(values) / len(values)\n            means[f'Position {i}'] = mean\n    if export_to_json:\n        import json\n        with open(filename, 'w') as f:\n            json.dump(means, f)\n    return means"
  },
  {
    "output": "```python\nimport numpy as np\nimport random\nfrom datetime import datetime, timedelta\n\ndef task_func(rows=3, columns=2, start_date=datetime(2021, 1, 1), end_date=datetime(2021, 12, 31), seed=0):\n    random.seed(seed)\n    \n    # Generate a list of unique dates between start_date and end_date\n    date_list = []\n    current_date = start_date\n    while current_date <= end_date:\n        date_list.append(current_date)\n        current_date += timedelta(days=1)\n    \n    # Ensure the number of dates is sufficient to fill the matrix\n    if len(date_list) < rows * columns:\n        raise ValueError(\"Not enough unique dates between start and end date to fill the matrix.\")"
  },
  {
    "output": "```python\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.cluster import KMeans\n\n# Constants for configuration\nRANGE = 100\nSIZE = 1000\nCLUSTERS = 5\n\ndef task_func():\n    # Generate random 2D points\n    np.random.seed(42)\n    data = np.random.rand(SIZE, 2) * RANGE\n\n    # Apply KMeans clustering\n    kmeans = KMeans(n_clusters=CLUSTERS, n_init=10)\n    kmeans.fit(data)\n    labels = kmeans.predict(data)\n    centroids = kmeans.cluster_centers_\n\n    # Plot the results\n    plt.scatter(data[:, 0], data[:, 1], c=labels, cmap='viridis"
  },
  {
    "output": "def extract_and_analyze(text, top_n):\n    import re\n    from collections import Counter\n    import matplotlib.pyplot as plt\n    text = re.sub(r'\\[.*?\\]', ' ', text)\n    words = re.findall(r'\\b\\w+\\b', text.lower())\n    word_counts = Counter(words)\n    top_words = dict(word_counts.most_common(top_n))\n    plt.figure(figsize=(10, 5))\n    plt.bar(top_words.keys(), top_words.values())\n    plt.xlabel('Words')\n    plt.ylabel('Frequency')\n    plt.title('Top {} Word Frequencies'.format(top_n))\n    plt.show()\n    return top_words"
  },
  {
    "output": "def generate_system_usage_table():\n    import psutil\n    from texttable import Texttable\n    t = Texttable()\n    t.header(['CPU%', 'Memory%', 'Disk%'])\n    for cpu in psutil.cpu_percent(interval=1, percpu=True):\n        mem = psutil.virtual_memory().percent\n        disk = psutil.disk_usage('/').percent\n        t.add_row([cpu, mem, disk])\n    return t.draw()"
  },
  {
    "output": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func():\n    x = np.linspace(0, 2*np.pi, 1000)\n    sin_x = np.sin(x)\n    cos_x = np.cos(x)\n    abs_diff = np.abs(sin_x - cos_x)\n    sequence = list(zip(x, sin_x, cos_x, abs_diff))\n    plt.plot(x, sin_x, label='sin(x)')\n    plt.plot(x, cos_x, label='cos(x)')\n    plt.legend()\n    fft_abs_diff = np.fft.fft(abs_diff)\n    mean_fft = np.mean(np.abs(fft_abs_diff))\n    median_fft = np.median(np.abs(fft_abs_diff))\n    return mean_fft, median_fft, sequence"
  },
  {
    "output": "def convert_csv_to_json(csv_file_path):\n    import csv\n    import json\n    import os\n    if not os.path.exists(csv_file_path):\n        raise FileNotFoundError(f\"The file {csv_file_path} does not exist.\")\n    with open(csv_file_path, 'r') as csv_file:\n        csv_reader = csv.DictReader(csv_file)\n        json_data = [row for row in csv_reader]\n    json_file_path = csv_file_path.replace('.csv', '.json')\n    with open(json_file_path, 'w') as json_file:\n        json.dump(json_data, json_file)\n    return json_file_path"
  },
  {
    "output": "def task_func(directory):\n    import os\n    import json\n    processed_files = []\n    for filename in os.listdir(directory):\n        file_path = os.path.join(directory, filename)\n        try:\n            with open(file_path, 'r') as f:\n                data = json.load(f)\n            with open(file_path, 'w') as f:\n                json.dump(data, f, ensure_ascii=False)\n            processed_files.append(filename)\n        except FileNotFoundError:\n            pass\n    return processed_files"
  },
  {
    "output": "# Calculate the number of days between start_date and end_date\n    delta = relativedelta(end_date, start_date)\n    num_days = delta.days + 1\n    \n    # Generate random dates\n    random_dates = [start_date + timedelta(days=randint(0, num_days - 1)) for _ in range(10)]\n    \n    # Create pandas Series\n    return pd.Series(random_dates, name='random_dates')"
  },
  {
    "output": "def task_func(numbers):\n    if not numbers:\n        raise ValueError(\"Input list cannot be empty\")\n    import numpy as np\n    arr = np.array(numbers)\n    mode = np.unique(arr, return_counts=True)[0][np.argmax(np.unique(arr, return_counts=True)[1])]\n    counts = np.unique(arr, return_counts=True)[1]\n    probabilities = counts / counts.sum()\n    entropy = -np.sum(probabilities * np.log2(probabilities))\n    return {'mode': mode, 'entropy': entropy}"
  },
  {
    "output": "from sklearn.preprocessing import StandardScaler\nimport numpy as np\nimport base64\n\ndef task_func(data):\n    data_array = np.array(data, dtype=np.float64)\n    scaler = StandardScaler()\n    standardized_data = scaler.fit_transform(data_array.reshape(-1, 1))\n    flattened_data = standardized_data.flatten()\n    data_bytes = flattened_data.tobytes()\n    base64_encoded = base64.b64encode(data_bytes).decode('ascii')\n    return base64_encoded"
  },
  {
    "output": "def task_func(input_list, directory):\n    import os\n    import random\n    import matplotlib.pyplot as plt\n    \n    deduplicated = list(dict.fromkeys(input_list))\n    os.makedirs(directory, exist_ok=True)\n    file_names = []\n    \n    for plot_name in deduplicated:\n        data = [random.random() for _ in range(10)]\n        plt.bar(range(10), data)\n        plt.title(plot_name)\n        file_name = os.path.join(directory, f\"{plot_name}.png\")\n        plt.savefig(file_name)\n        plt.close()\n        file_names.append(file_name)\n    \n    if not os.path.exists(directory):\n        raise FileNotFoundError(f\"The directory {directory} does not exist and could not be created.\")\n    \n    return file_names"
  },
  {
    "output": "def task_func(df, visualize=False):\n    if df.empty or df['Value'].isnull().all():\n        return None\n    df['Value'] = df['Value'].apply(lambda x: x.split(',') if isinstance(x, list) else x)\n    df = df.explode('Value').reset_index(drop=True)\n    df['Value'] = pd.to_numeric(df['Value'], errors='coerce')\n    df.dropna(inplace=True)\n    corr = df.corr()\n    if visualize:\n        plt.figure(figsize=(10, 8))\n        sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\")\n        plt.title(\"Correlation Heatmap\")\n        plt.show()\n    return corr.values.tolist()"
  },
  {
    "output": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef task_func(list_of_pairs):\n    df = pd.DataFrame(list_of_pairs, columns=['Category', 'Value'])\n    plt.figure(figsize=(10, 6))\n    sns.barplot(x='Category', y='Value', data=df)\n    plt.title('Category vs Value')\n    plt.xlabel('Category')\n    plt.ylabel('Value')\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    return df, plt.gca()"
  },
  {
    "output": "df = pd.DataFrame(match_results)\n    \n    # Plotting Goals\n    plt.figure(figsize=(10, 6))\n    sns.barplot(x='Team', y='Goals', data=df)\n    plt.title('Goals Scored by Teams')\n    plt.xlabel('Team')\n    plt.ylabel('Goals')\n    plt.tight_layout()\n    \n    # Plotting Penalty Costs\n    plt.figure(figsize=(10, 6))\n    sns.barplot(x='Team', y='Fine', data=df)\n    plt.title('Penalty Costs by Teams')\n    plt.xlabel('Team')\n    plt.ylabel('Fine (in dollars)')\n    plt.tight_layout()\n    \n    return df, [plt.gca(), plt.gca()]"
  },
  {
    "output": "def process_sentences(n_sentences, vocabulary):\n    import random\n    processed = []\n    for _ in range(n_sentences):\n        sentence = ' '.join(random.choices(vocabulary, k=5))\n        processed.append(sentence.replace(' ', '_').lower())\n    return processed"
  },
  {
    "output": "import numpy as np\n\ndef random_walk(length):\n    if length < 0:\n        raise ValueError(\"Length cannot be negative\")\n    steps = np.random.choice([-1, 1], size=length)\n    positions = np.zeros(length + 1, dtype=int)\n    for i in range(length):\n        positions[i + 1] = positions[i] + steps[i]\n    return positions"
  },
  {
    "output": "import json\nimport os\nfrom openpyxl import Workbook\n\ndef convert_json_to_excel(json_str):\n    try:\n        data = json.loads(json_str)\n    except json.JSONDecodeError:\n        raise ValueError(\"Invalid JSON string\")\n    \n    if not data or not isinstance(data, list):\n        raise ValueError(\"JSON string is empty or not a list\")\n    \n    wb = Workbook()\n    ws = wb.active\n    ws.append(['Key', 'Value'])\n    \n    for item in data:\n        if isinstance(item, dict):\n            for key, value in item.items():\n                ws.append([key, value])\n        else:\n            ws.append([str(item), ''])\n    \n    file_path = os.path.join(os.getcwd(), 'output.xlsx')\n    wb.save(file_path)\n    \n    return os.path.abspath(file_path)"
  },
  {
    "output": "def extract_domains_geolocation(input_string):\n    import re\n    import requests\n    from urllib.parse import urlparse\n    \n    urls = re.findall(r'https?://(?:www\\.)?([^\"\\']+)/?', input_string)\n    domains = list(set([urlparse(url).netloc for url in urls]))\n    \n    geolocation_data = {}\n    for domain in domains:\n        try:\n            response = requests.get(f'https://ipapi.co/{domain}/json/').json()\n            geolocation_data[domain] = response\n        except:\n            geolocation_data[domain] = {\"error\": \"Failed to retrieve geolocation data\"}\n    \n    return geolocation_data"
  },
  {
    "output": "def task_func(directory, pattern, suffix):\n    import os\n    import mimetypes\n    result = {}\n    for filename in os.listdir(directory):\n        if pattern in filename and suffix in filename:\n            filepath = os.path.join(directory, filename)\n            if os.path.isfile(filepath):\n                mime_type = mimetypes.guess_type(filepath)[0] or 'application/octet-stream'\n                result[filename] = mime_type\n    return result"
  },
  {
    "output": "def analyze_fitness_data(data):\n    import numpy as np\n    import matplotlib.pyplot as plt\n    if not data or not all(isinstance(x, (int, float)) for x in data):\n        raise ValueError(\"Invalid data format\")\n    mean = np.mean(data)\n    std_dev = np.std(data)\n    plt.plot(data)\n    plt.title(\"Fitness Data\")\n    plt.xlabel(\"Sample\")\n    plt.ylabel(\"Value\")\n    plt.show()\n    return mean, std_dev"
  },
  {
    "output": "def task_func(param1, param2):\n    return param1 + param2"
  },
  {
    "output": "def extract_archive(archive_path, extract_to):\n    import os\n    import shutil\n    import zipfile\n    import tarfile\n    try:\n        if not os.path.exists(archive_path):\n            raise FileNotFoundError(f\"The archive file '{archive_path}' does not exist.\")\n        if not os.path.exists(extract_to):\n            os.makedirs(extract_to)\n        if archive_path.endswith('.zip'):\n            with zipfile.ZipFile(archive_path, 'r') as zip_ref:\n                zip_ref.extractall(extract_to)\n        elif archive_path.endswith(('.tar', '.tar.gz', '.tgz')):\n            with tarfile.open(archive_path, 'r') as tar_ref:\n                tar_ref.extractall(extract_to)\n        else:\n            raise ValueError(f\"Unsupported archive format: {archive_path}\")\n        return os.path.abspath(extract_to)\n    except Exception as e:\n        return str(e)"
  },
  {
    "output": "quantity = quantity.strip()\n        code = code.strip()\n        price = price.strip()\n        description = description.strip()\n        \n        # Assign product name based on code\n        product_name = random.choice(product_names)\n        \n        # Append the parsed data to the list\n        data.append({\n            'ID': id_val,\n            'Quantity': quantity,\n            'Code': code,\n            'Price': price,\n            'Description': description,\n            'Product': product_name\n        })\n    \n    # Create DataFrame from the parsed data\n    df = pd.DataFrame(data)\n    \n    # Return the DataFrame\n    return df"
  },
  {
    "output": "def task_func():\n    import random\n    numbers = [random.randint(1, 100) for _ in range(10)]\n    return numbers"
  },
  {
    "output": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef generate_normal_samples_and_plot():\n    np.random.seed(42)\n    samples = np.random.normal(loc=0, scale=1, size=1000)\n    fig, ax = plt.subplots()\n    ax.hist(samples, bins=30, density=True, alpha=0.6, color='g')\n    x = np.linspace(-4, 4, 100)\n    pdf = (1 / np.sqrt(2 * np.pi)) * np.exp(-x**2 / 2)\n    ax.plot(x, pdf, 'r', lw=2)\n    return ax, samples"
  },
  {
    "output": "import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\ndef task_func(num_samples, gender_options, age_range, location_options):\n    if not isinstance(num_samples, int):\n        raise ValueError(\"num_samples must be an integer\")\n    df = pd.DataFrame()\n    df['gender'] = pd.Series([LabelEncoder().fit(gender_options).transform([gender_options[i % len(gender_options)] for i in range(num_samples)]) for _ in range(num_samples)])\n    df['age'] = pd.Series([pd.Series(range(age_range[0], age_range[1] + 1))[i % len(pd.Series(range(age_range[0], age_range[1] + 1)))] for i in range(num_samples)])\n    df['location'] = pd.Series([LabelEncoder().fit(location_options).transform([location_options[i % len(location_options)] for i in range(num_samples)]) for _ in range(num_samples)])\n    return df"
  },
  {
    "output": "import math\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport random\n\nRANGE = 10000\nSIZE = 1000\nPI = np.pi\n\ndef task_func(size=SIZE, frequency=1):\n    phase = random.uniform(0, 2 * PI)\n    amplitude = random.uniform(0.5, 2.0)\n    noise = np.random.normal(0, 0.1, size)\n    x = np.linspace(0, RANGE, size)\n    sinusoidal_values = amplitude * np.sin(frequency * x + phase) + noise\n    fig, ax = plt.subplots()\n    ax.plot(x, sinusoidal_values, label='Sinusoidal Wave')\n    ax.set_xlabel('X-axis')\n    ax.set_ylabel('Amplitude')\n    ax.set_title('Random Sinusoidal Wave')\n    ax.legend()\n    return ax"
  },
  {
    "output": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef process_and_plot_data(df):\n    numeric_cols = df.select_dtypes(include=np.number).columns\n    df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())\n    stats = df[numeric_cols].describe()\n    for col in numeric_cols:\n        plt.figure()\n        plt.hist(df[col], bins=20)\n        plt.title(f'Distribution of {col}')\n        plt.xlabel(col)\n        plt.ylabel('Frequency')\n    plt.show()"
  },
  {
    "output": "import base64\nimport hashlib\nimport hmac\n\ndef task_func(s, signature, secret_key):\n    decoded_message = base64.b64decode(s)\n    hmac_hash = hmac.new(secret_key.encode('utf-8'), decoded_message, hashlib.sha1).digest()\n    computed_signature = base64.b64encode(hmac_hash).decode('utf-8')\n    return computed_signature == signature"
  },
  {
    "output": "def task_func(df, col1, col2, N=10):\n    if col1 not in df.columns or col2 not in df.columns:\n        raise ValueError('ValueError: If specified columns are not in the provided DataFrame.')\n    scaler = StandardScaler()\n    scaled_values = scaler.fit_transform(df[[col1, col2]])\n    abs_diff = np.abs(scaled_values[:, 0] - scaled_values[:, 1])\n    top_n_indices = heapq.nlargest(N, range(len(abs_diff)), key=lambda i: abs_diff[i])\n    return top_n_indices"
  },
  {
    "output": "def generate_performance_report(data):\n    import pandas as pd\n    return pd.DataFrame(data).set_index('timestamp').resample('D').mean().reset_index()"
  },
  {
    "output": "def read_convert_csv(file_path, input_encoding, output_encoding):\n    import csv\n    with open(file_path, 'r', encoding=input_encoding) as file:\n        reader = csv.DictReader(file)\n        data = [row for row in reader]\n    converted_data = '\\n'.join([','.join(row.values()) for row in data])\n    return data, converted_data.encode(output_encoding).decode('utf-8')"
  },
  {
    "output": "def predict_stock_prices(df):\n    import pandas as pd\n    import numpy as np\n    import matplotlib.pyplot as plt\n    from sklearn.linear_model import LinearRegression\n    \n    df = df.reset_index(drop=True)\n    X = np.array(df.index).reshape(-1, 1)\n    y = df['Close'].values\n    \n    model = LinearRegression()\n    model.fit(X, y)\n    y_pred = model.predict(X)\n    \n    plt.figure(figsize=(14, 7))\n    plt.plot(df.index, y, label='Actual Prices')\n    plt.plot(df.index, y_pred, label='Fitted Line')\n    plt.title('Stock Closing Prices')\n    plt.xlabel('Days')\n    plt.ylabel('Price')\n    plt.legend()\n    \n    future_days = 7\n    future_X = np.array(range(len(df), len(df) + future_days)).reshape(-1, 1)\n    future_prices = model.predict(future_X)\n    \n    return (future_prices, plt.gca())"
  },
  {
    "output": "ax.hist(values_list, bins=20, density=True, alpha=0.6, color='blue')"
  },
  {
    "output": "import pandas as pd\n\ndef flatten_and_count_menu_items(nested_list):\n    from collections import Counter\n    flat_list = [item for sublist in nested_list for item in sublist]\n    counts = Counter(flat_list)\n    return pd.DataFrame(list(counts.items()), columns=['Item', 'Count'])"
  },
  {
    "output": "def task_func(x):\n    from itertools import combinations\n    keys = list(x.keys())\n    min_total = float('inf')\n    min_subseq = []\n    for i in range(1, len(keys)+1):\n        for combo in combinations(keys, i):\n            total = sum(x[key] for key in combo)\n            if total < min_total:\n                min_total = total\n                min_subseq = list(combo)\n    return min_subseq"
  },
  {
    "output": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(df, age, weight):\n    required_columns = ['Age', 'Weight']\n    if not all(col in df.columns for col in required_columns):\n        return pd.DataFrame()\n    filtered_df = df[(df['Age'] == age) & (df['Weight'] == weight)]\n    if filtered_df.empty:\n        return pd.DataFrame()\n    scaler = StandardScaler()\n    scaled_values = scaler.fit_transform(filtered_df)\n    return pd.DataFrame(scaled_values, columns=filtered_df.columns)"
  },
  {
    "output": "from collections import Counter\n\ndef task_func(data):\n    total = 0\n    categories = []\n    for item in data:\n        total += item[1]\n        categories.append(item[0])\n    return total, Counter(categories)"
  },
  {
    "output": "import os\nimport shutil\n\ndef find_and_move_interesting_files(directory):\n    interesting_files = []\n    for filename in os.listdir(directory):\n        if \"like\" in filename or \"what\" in filename:\n            old_path = os.path.join(directory, filename)\n            new_path = os.path.join(directory, \"Interesting Files\", filename)\n            os.makedirs(os.path.join(directory, \"Interesting Files\"), exist_ok=True)\n            shutil.move(old_path, new_path)\n            interesting_files.append(filename)\n    return interesting_files"
  },
  {
    "output": "import pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\ndef calculate_tfidf_scores(documents):\n    vectorizer = TfidfVectorizer()\n    tfidf_matrix = vectorizer.fit_transform(documents)\n    feature_names = vectorizer.get_feature_names_out()\n    df = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n    return df.transpose()"
  },
  {
    "output": "return df.tolist()"
  },
  {
    "output": "def task_func(df, column, value):\n    if column in df.columns and pd.api.types.is_numeric_dtype(df[column]):\n        avg = df[column].mean()\n        greater_than_avg = df[df[column] > avg]\n        count = len(greater_than_avg)\n        plt.hist(df[column], bins=10)\n        ax = plt.gca()\n        return (np.array(df[column]), count, ax)\n    else:\n        return (np.array([]), 0, None)"
  },
  {
    "output": "from collections import Counter\nimport pandas as pd\n\ndef task_func(myList):\n    word_counts = Counter(myList)\n    return pd.DataFrame(list(word_counts.items()), columns=['word', 'count'])"
  },
  {
    "output": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(df):\n    scaler = StandardScaler()\n    df_standardized = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n    return df_standardized"
  },
  {
    "output": "```python\nimport pandas as pd\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\ndef task_func(df, n_clusters=3, random_state=0):\n    # Check if the DataFrame is empty or lacks required columns\n    if df.empty or 'date' not in df.columns or 'value' not in df.columns:\n        raise ValueError(\"DataFrame is empty or lacks required columns.\")\n    \n    # Convert 'date' to datetime\n    df['date'] = pd.to_datetime(df['date'])\n    \n    # Convert to ordinal (number of days since 0001-01-01)\n    df['date_ordinal'] = df['date'].dt.toordinal\n    \n    # Prepare the data for clustering\n    X"
  },
  {
    "output": "def perform_kmeans_clustering(data_series1, data_series2, n_clusters=3):\n    import pandas as pd\n    import numpy as np\n    from sklearn.cluster import KMeans\n    import matplotlib.pyplot as plt\n    \n    if not isinstance(data_series1, pd.Series) or not isinstance(data_series2, pd.Series):\n        raise ValueError(\"Both inputs must be pandas Series.\")\n    \n    if data_series1.shape[0] != data_series2.shape[0]:\n        raise ValueError(\"Both Series must have the same length.\")\n    \n    data = pd.DataFrame({\n        'x': data_series1,\n        'y': data_series2\n    })\n    \n    kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(data)\n    labels = kmeans.labels_\n    centroids = kmeans.cluster_centers_\n    \n    plt.scatter(data['x'], data['y'], c=labels, s=50, cmap='viridis')\n    plt.scatter(centroids[:, 0], centroids[:, 1], c='red', s=200, marker='x', label='Centroids')\n    plt.xlabel('Feature 1')\n    plt.ylabel('Feature 2')\n    plt.title('K-Means Clustering')\n    plt.legend()\n    plt.show()"
  },
  {
    "output": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(df):\n    if df.empty or 'Word' not in df.columns:\n        return None\n    filtered = df[df['Word'].str[0].str.lower().isin(['a', 'b', 'c', 'd', 'e'])]\n    if filtered.empty:\n        return None\n    lengths = filtered['Word'].str.len()\n    plt.boxplot(lengths)\n    plt.ylabel('Length')\n    plt.title('Word Length Distribution')\n    plt.show()"
  },
  {
    "output": "data.append([f\"Average\", average_age, average_height, average_weight])\n    \n    # Write to CSV\n    filename = os.path.join(os.getcwd(), filename)\n    with open(filename, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerow(COLUMNS)\n        writer.writerows(data)\n    \n    return filename"
  },
  {
    "output": "import csv\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\n\ndef process_csv_file(file_path):\n    with open(file_path, 'r') as file:\n        reader = csv.reader(file)\n        data = [float(row[0]) for row in reader]\n    sample = np.random.choice(data, size=30, replace=False)\n    mean = np.mean(sample)\n    std_dev = np.std(sample)\n    plt.hist(sample, bins=10, density=True, alpha=0.6, color='g')\n    x = np.linspace(min(sample), max(sample), 100)\n    pdf = (1 / (std_dev * np.sqrt(2 * np.pi))) * np.exp(-((x - mean) ** 2) / (2 * std_dev ** 2))\n    plt.plot(x, pdf, 'k', linewidth=2)\n    plt.title('Histogram with Normal Distribution Curve')\n    plt.xlabel('Value')\n    plt.ylabel('Frequency')\n    plt.show()"
  },
  {
    "output": "import os\nfrom flask_mail import Mail\n\ndef task_func(app):\n    mail_config = {\n        'MAIL_SERVER': os.getenv('MAIL_SERVER', 'smtp.example.com'),\n        'MAIL_PORT': int(os.getenv('MAIL_PORT', '587')),\n        'MAIL_USE_TLS': os.getenv('MAIL_USE_TLS', 'True').lower() in ('true', '1', 't'),\n        'MAIL_USE_SSL': os.getenv('MAIL_USE_SSL', 'False').lower() in ('true', '1', 't'),\n        'MAIL_USERNAME': os.getenv('MAIL_USERNAME', ''),\n        'MAIL_PASSWORD': os.getenv('MAIL_PASSWORD', ''),\n        'MAIL_DEFAULT_SENDER': os.getenv('MAIL_DEFAULT_SENDER', ''),\n    }\n    \n    mail = Mail(app)\n    \n    return (mail, mail_config)"
  },
  {
    "output": "def task_func(df, mapping):\n    required_features = ['feature1', 'feature2', 'feature3']\n    if not all(feature in df.columns for feature in required_features):\n        raise ValueError(\"DataFrame is missing required features\")\n    for col in required_features:\n        df[col] = df[col].replace(mapping)\n    stats = {}\n    for col in required_features:\n        mean = df[col].mean()\n        median = df[col].median()\n        mode = df[col].mode().iloc[0] if not df[col].mode().empty else None\n        variance = df[col].var()\n        stats[col] = {\n            'mean': mean,\n            'median': median,\n            'mode': mode,\n            'variance': variance\n        }\n    return stats"
  },
  {
    "output": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.ndimage import gaussian_filter\nfrom matplotlib.image import imread\n\ndef task_func(image_path):\n    try:\n        image = imread(image_path)\n        if len(image.shape) == 3:\n            image = np.mean(image, axis=2)\n        filtered = gaussian_filter(image, sigma=1)\n        plt.figure(figsize=(10, 5))\n        plt.subplot(1, 2, 1)\n        plt.imshow(image, cmap='gray')\n        plt.title('Original Image')\n        plt.subplot(1, 2, 2)\n        plt.imshow(filtered, cmap='gray')\n        plt.title('Filtered Image')\n        plt.show()\n        return image, filtered\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        return None, None"
  },
  {
    "output": "def task_func(url, file_path):\n    import requests\n    import pandas as pd\n    response = requests.get(url)\n    df = pd.read_csv(response.content)\n    df.to_json(file_path, orient='records')\n    return file_path"
  },
  {
    "output": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import f_oneway\n\ndef analyze_data(file_path):\n    df = pd.read_csv(file_path)\n    numeric_cols = df.select_dtypes(include=np.number).columns\n    for col in numeric_cols:\n        df[col] = pd.to_numeric(df[col], errors='coerce')\n    df.dropna(inplace=True)\n    for col in numeric_cols:\n        mean = df[col].mean()\n        std_dev = df[col].std()\n        print(f\"Mean of {col}: {mean}, Standard Deviation: {std_dev}\")\n        plt.hist(df[col], bins=10, edgecolor='black')\n        plt.title(f'Histogram of {col}')\n        plt.xlabel(col)\n        plt.ylabel('Frequency')\n        plt.show()\n    if len(numeric_cols) >= 2:\n        group_cols = numeric_cols[:2]\n        group_data = [df[col] for col in group_cols]\n        f_stat, p_val = f_oneway(*group_data)\n        print(f\"ANOVA F-statistic: {f_stat}, p-value: {p_val}\")"
  },
  {
    "output": "def simulate_dice_rolls(num_rolls):\n    import random\n    import matplotlib.pyplot as plt\n    import numpy as np\n    results = [random.randint(1, 6) for _ in range(num_rolls)]\n    frequencies = np.bincount(results, minlength=7)[1:]\n    plt.bar(range(1, 7), frequencies)\n    plt.xlabel('Dice Roll')\n    plt.ylabel('Frequency')\n    plt.title('Dice Roll Frequencies')\n    plt.show()"
  },
  {
    "output": "import pandas as pd\nimport numpy as np\n\ndef generate_random_gdp_data(countries):\n    np.random.seed(42)\n    gdp_data = np.random.uniform(1000, 100000, size=len(countries))\n    return pd.DataFrame({\n        'Country': countries,\n        'GDP': gdp_data\n    })"
  },
  {
    "output": "def task_func(request):\n    from http.server import BaseHTTPRequestHandler\n    import os\n    import urllib.parse\n\n    parsed_path = urllib.parse.urlparse(request.path).path\n    filename = parsed_path.strip('/') or 'index.html'\n    file_path = os.path.join('static', filename)\n\n    if os.path.isfile(file_path):\n        with open(file_path, 'rb') as f:\n            content = f.read()\n        response = BaseHTTPRequestHandler.responses[200][0]\n        return response + content\n    else:\n        response = BaseHTTPRequestHandler.responses[404][0]\n        return response"
  },
  {
    "output": "def function_to_create():\n    import numpy as np\n    import matplotlib.pyplot as plt\n    \n    original = [5, 10, 15, 20, 25]\n    arr = np.array(original)\n    normalized = (arr - np.min(arr)) / (np.max(arr) - np.min(arr))\n    \n    plt.figure(figsize=(10, 5))\n    plt.plot(original, label='Original')\n    plt.plot(normalized, label='Normalized')\n    plt.legend()\n    plt.show()\n    \n    return arr, normalized"
  },
  {
    "output": "import json\nimport requests\nfrom bs4 import BeautifulSoup\n\ndef scrape_title_to_json(url, filename):\n    response = requests.get(url)\n    soup = BeautifulSoup(response.text, 'html.parser')\n    title = soup.title.string if soup.title else ''\n    data = {'title': title}\n    mode = 'a' if filename.exists() else 'w'\n    with open(filename, mode) as f:\n        json.dump(data, f)\n        f.write('\\n')\n    return str(filename)"
  },
  {
    "output": "def plot_parabola():\n    import matplotlib.pyplot as plt\n    x = [i/10 for i in range(-100, 101)]\n    y = [i**2 for i in x]\n    plt.plot(x, y)\n    plt.title('Parabola y = x^2')\n    plt.xlabel('x')\n    plt.ylabel('y')\n    plt.grid(True)\n    plt.show()"
  },
  {
    "output": "```python\nimport pandas as pd\nimport os\nimport numpy as np\nimport ast\n\ndef task_func(directory):\n    # Check if directory exists\n    if not os.path.exists(directory):\n        return pd.DataFrame(columns=['email', 'list', 'sum', 'mean', 'median']), None\n    \n    # Traverse directory for CSV files\n    csv_files = [f for f in os.listdir(directory) if f.endswith('.csv')]\n    \n    # If no CSV files, return empty DataFrame and None\n    if not csv_files:\n        return pd.DataFrame(columns=['email', 'list', 'sum', 'mean', 'median']), None\n    \n    # Find CSV file with the longest filename\n    longest_file = max(csv_files, key=lambda x: len(x))\n    file_path = os.path.join(directory, longest_file)\n    \n    #"
  },
  {
    "output": "import heapq\nimport random\n\ndef task_func(list_length: int, k: int):\n    random_list = [random.randint(1, 100) for _ in range(list_length)]\n    k_largest = heapq.nlargest(k, random_list)\n    return (random_list, k_largest)"
  },
  {
    "output": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(input_dict, target_value):\n    df = pd.DataFrame(input_dict)\n    matching_rows = df.apply(lambda row: all(cell == target_value for cell in row), axis=1)\n    counts = df.apply(lambda col: (col == target_value).sum(), axis=0)\n    fig, ax = plt.subplots()\n    counts.plot(kind='bar', ax=ax)\n    return counts, ax"
  },
  {
    "output": "def task_func(source_dir, target_dir, prefix):\n    import os\n    import hashlib\n    if not os.path.exists(source_dir):\n        raise FileNotFoundError(f\"Source directory '{source_dir}' does not exist.\")\n    os.makedirs(target_dir, exist_ok=True)\n    files = [os.path.join(source_dir, f) for f in os.listdir(source_dir) if os.path.isfile(os.path.join(source_dir, f))]\n    result = []\n    for file_path in files:\n        with open(file_path, 'rb') as f:\n            content = f.read()\n        hash_md5 = hashlib.md5(content).hexdigest()\n        modified_content = f\"{prefix}{hash_md5}{content.decode('utf-8', 'ignore')}\"\n        target_path = os.path.join(target_dir, os.path.basename(file_path))\n        with open(target_path, 'wb') as f:\n            f.write(modified_content.encode('utf-8'))\n        result.append(target_path)\n    return result"
  },
  {
    "output": "import zlib\nimport base64\nimport random\nimport string\n\ndef generate_compressed_encoded_string(length):\n    random_string = ''.join(random.choices(string.ascii_uppercase + string.digits, k=length))\n    compressed = zlib.compress(random_string.encode('utf-8'))\n    encoded = base64.b64encode(compressed).decode('utf-8')\n    return encoded"
  },
  {
    "output": "from itertools import zip_longest\nfrom scipy.spatial import distance\nimport math\n\ndef task_func(points):\n    if len(points) < 2:\n        return []\n    \n    # Normalize points\n    normalized_points = []\n    for point in points:\n        if isinstance(point, tuple):\n            if len(point) == 1:\n                normalized_points.append((point[0], point[0]))\n            else:\n                normalized_points.append(point)\n        else:\n            normalized_points.append((point, point))\n    \n    # Calculate distances between consecutive points\n    distances = []\n    for i in range(len(normalized_points) - 1):\n        p1 = normalized_points[i]\n        p2 = normalized_points[i + 1]\n        dist = math.sqrt((p2[0] - p1[0])**2 + (p2[1] - p1[1])**2)\n        distances.append(dist)\n    \n    return distances"
  },
  {
    "output": "import numpy as np\nfrom scipy import stats\ndef task_func(L):\n    flat_list = np.concatenate(L)\n    mode = stats.mode(flat_list).mode[0]\n    return mode"
  },
  {
    "output": "from matplotlib import pyplot as plt\nfrom sklearn.decomposition import PCA\ndef task_func(arr):\n    summed_data = arr.sum(axis=1).reshape(-1, 1)\n    pca = PCA(n_components=1)\n    pca.fit(summed_data)\n    explained_variance_ratio = pca.explained_variance_ratio_\n    fig, ax = plt.subplots()\n    ax.bar(range(1), explained_variance_ratio, align='center')\n    ax.set_title(\"Explained Variance Ratio\")"
  },
  {
    "output": "import numpy as np\n\ndef calculate_product_of_seconds(tuples_list):\n    second_values = [t[1] for t in tuples_list]\n    product = np.prod(second_values)\n    return np.array([product])"
  },
  {
    "output": "def find_target_in_csv(directory, target, move_to=None):\n    import os\n    import csv\n    import shutil\n    files = [f for f in os.listdir(directory) if f.endswith('.csv')]\n    results = []\n    for file in files:\n        file_path = os.path.join(directory, file)\n        with open(file_path, 'r') as f:\n            reader = csv.reader(f)\n            for idx, row in enumerate(reader):\n                if row and row[0] == target:\n                    results.append((file, idx))\n                    break\n        if move_to and os.path.exists(file_path):\n            shutil.move(file_path, os.path.join(move_to, file))\n    return results"
  },
  {
    "output": "import random\nimport math\n\ndef generate_random_float_from_hex(hex_list):\n    hex_str = random.choice(hex_list)\n    float_val = float.fromhex(hex_str)\n    rounded_val = round(float_val, 2)\n    return rounded_val"
  },
  {
    "output": "def task_func(df):\n    y = df['target']\n    X = df.drop('target', axis=1)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n    return (X_train, X_test, y_train, y_test)"
  },
  {
    "output": "def task_func(api_url):\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    import requests\n    if not isinstance(api_url, str):\n        raise ValueError(\"api_url must be a string\")\n    try:\n        response = requests.get(api_url)\n        response.raise_for_status()\n    except requests.exceptions.RequestException as e:\n        raise Exception(\"API request failed\") from e\n    try:\n        data = response.json()\n    except Exception as e:\n        raise Exception(\"Failed to parse JSON response\") from e\n    if not data:\n        raise ValueError(\"API returned empty data\")\n    df = pd.DataFrame(data)\n    if not df.empty:\n        df.plot()\n        plt.show()\n    else:\n        raise ValueError(\"DataFrame is empty after processing\")"
  },
  {
    "output": "import itertools\nimport string\nimport pandas as pd\n\ndef task_func():\n    letters = string.ascii_uppercase\n    combinations = list(itertools.product(letters, repeat=3))\n    df = pd.DataFrame(combinations, columns=['Letter1', 'Letter2', 'Letter3'])\n    return df"
  },
  {
    "output": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import gaussian_kde\n\ndef generate_and_plot_gaussian_kde(mean, std_dev, sample_size):\n    np.random.seed(42)\n    data = np.random.normal(mean, std_dev, sample_size)\n    kde = gaussian_kde(data)\n    x = np.linspace(data.min(), data.max(), 1000)\n    y = kde(x)\n    fig, ax = plt.subplots()\n    ax.plot(x, y)\n    return ax"
  },
  {
    "output": "def task_func(file_path, private_key_path):\n    import rsa\n    import hashlib\n    import base64\n    with open(file_path, 'rb') as f:\n        file_data = f.read()\n    hash_object = hashlib.sha256(file_data)\n    hash_hex = hash_object.hexdigest()\n    with open(private_key_path, 'rb') as pk:\n        private_key = rsa.PrivateKey.load_pkcs1(pk.read())\n    signature = rsa.sign_hash(hash_hex.encode('utf-8'), private_key, 'sha256')\n    return base64.b64encode(signature).decode('utf-8')"
  },
  {
    "output": "```python\nimport pandas as pd\nimport string\n\ndef task_func(word):\n    # Input validation\n    if not isinstance(word, str):\n        raise ValueError(\"Input must be a string.\")\n    if not word.islower():\n        raise ValueError"
  },
  {
    "output": "def task_func(numbers):\n    def is_prime(n):\n        if n < 2:\n            return False\n        for i in range(2, int(n**0.5) + 1):\n            if n % i == 0:\n                return False\n        return True\n    primes = [n for n in numbers if is_prime(n)]\n    degrees = [n * 9 / 5 for n in primes]\n    degrees.sort()\n    return degrees"
  },
  {
    "output": "def task_func(n, pattern, seed=None):\n    import random\n    import re\n    random.seed(seed)\n    chars = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'\n    random_str = ''.join(random.choice(chars) for _ in range(n))\n    regex = re.compile(pattern)\n    matches = regex.finditer(random_str)\n    return [match.group() for match in matches]"
  },
  {
    "output": "```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef task_func(df, letters=list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')):\n    # Check if the input is a DataFrame\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"If 'df' is not a DataFrame or lacks the 'Letters' column.\")\n    # Check if the 'Letters' column exists\n    if 'Letters' not in df.columns:\n        raise ValueError(\"If 'df' is not a DataFrame or lacks the 'Letters' column.\")\n    \n    # Count the frequency of each letter\n    letter_counts = df['Letters'].value_counts()\n    \n    # Create a bar chart\n    fig, ax = plt.subplots()\n    letter_counts.plot(kind='bar', ax=ax)\n    \n    # Set labels and title\n    ax.set_xlabel('Letters')\n    ax.set_ylabel('Frequency')\n    ax.set_title('Letter Frequency')\n    \n    #"
  },
  {
    "output": "def task_func(df, target_column, target_values=None):\n    if not isinstance(df, pd.DataFrame) or not isinstance(target_column, str):\n        raise ValueError(\"Input df must be a DataFrame and target_column must be a string\")\n    if target_values is not None and not all(isinstance(val, (int, float)) for val in target_values):\n        raise ValueError(\"All elements in target_values must be numeric\")\n    for col in df.columns:\n        if target_values is not None:\n            df[col] = df[col].apply(lambda x: x if x in target_values else 0)\n    X = df.drop(columns=[target_column])\n    y = df[target_column]\n    model = LinearRegression().fit(X, y)\n    return model.coef_, model.intercept_"
  },
  {
    "output": "def task_func(n):\n    if not isinstance(n, int) or n <= 0:\n        raise ValueError(\"Input must be a positive integer.\")\n    import random\n    import matplotlib.pyplot as plt\n    steps = [0]\n    for _ in range(n):\n        step = random.choice([-1, 1])\n        steps.append(steps[-1] + step)\n    mean = sum(steps) / len(steps)\n    variance = sum((x - mean)**2 for x in steps) / len(steps)\n    plt.plot(steps)\n    plt.title(\"Random Walk\")\n    plt.xlabel(\"Step\")\n    plt.ylabel(\"Position\")\n    plt.show()\n    return mean, variance, steps"
  },
  {
    "output": "2.6666666666666665"
  },
  {
    "output": "def task_func(input_list):\n    from math import factorial\n    if not isinstance(input_list, list) or any(not isinstance(x, int) or x < 0 for x in input_list):\n        return \"Invalid input\"\n    from itertools import permutations\n    results = []\n    for perm in permutations(input_list):\n        total = sum(factorial(num) for num in perm)\n        results.append(total)\n    return results"
  },
  {
    "output": "def normalize_and_visualize(data):\n    import numpy as np\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    \n    df = pd.DataFrame(data)\n    min_vals = df.min()\n    max_vals = df.max()\n    normalized = (df - min_vals) / (max_vals - min_vals)\n    row_averages = normalized.mean(axis=1)\n    normalized['average'] = row_averages\n    normalized.plot(kind='line')\n    plt.show()"
  },
  {
    "output": "import base64\nimport json\nimport requests\n\ndef convert_and_send(data, api_endpoint):\n    json_str = json.dumps(data)\n    base64_str = base64.b64encode(json_str.encode()).decode()\n    response = requests.post(api_endpoint, data={'payload': base64_str})\n    return response"
  },
  {
    "output": "def task_func(url):\n    import os\n    import requests\n    from zipfile import ZipFile\n    import io\n\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        zip_data = io.BytesIO(response.content)\n        with ZipFile(zip_data, 'r') as zip_ref:\n            zip_ref.extractall(path='unzipped_files')\n        filenames = os.listdir('unzipped_files')\n        return \"Success\", filenames\n    except Exception as e:\n        return \"Error: \" + str(e), []"
  },
  {
    "output": "def create_cumulative_sum_heatmap(data_dict):\n    import pandas as pd\n    import seaborn as sns\n    import matplotlib.pyplot as plt\n    df = pd.DataFrame(data_dict)\n    if df.empty or not df.select_dtypes(include=['number']).shape[1] == df.shape[1]:\n        raise ValueError(\"DataFrame is empty or contains non-numeric columns\")\n    cumulative_sums = df.cumsum()\n    ax = sns.heatmap(cumulative_sums, annot=True, cmap='viridis')\n    plt.show()\n    return ax"
  },
  {
    "output": "```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef task_func(my_list, seed=42):\n    # Part A: Validate the input\n    if not isinstance(my_list, list):\n        raise TypeError(\"my_list must be a list.\")\n    \n    # Part B: Add '12' to the list\n    my_list.append('12')\n    \n    # Part C: Simulate sales data\n    categories = ['Electronics', 'Fashion', 'Home & Kitchen', 'Automotive', 'Sports']\n    np.random.seed(seed)\n    sales_data = np.random.randint(100, 1000, size=len(categories))\n    \n    # Create DataFrame\n    sales_df = pd.DataFrame"
  },
  {
    "output": "def max_weight_subsequence(s, weight_map):\n    dp = [0] * (len(s) + 1)\n    for i in range(1, len(s) + 1):\n        dp[i] = max(dp[i-1], dp[i-1] + weight_map.get(s[i-1], 0))\n    return dp[len(s)]"
  },
  {
    "output": "def process_data(df):\n    if df.empty or df['age'].min() < 0:\n        raise ValueError(\"DataFrame is empty or contains negative ages\")\n    df['age'] = df['age'].apply(lambda x: int(x // 1))\n    name_duplicates = df[df.duplicated('name', keep=False)].groupby('name').size().reset_index(name='count')\n    duplicate_names = name_duplicates[name_duplicates['count'] > 1]['name'].tolist()\n    duplicate_ages = df[df['name'].isin(duplicate_names)].groupby('name')['age'].value_counts().unstack().fillna(0).astype(int)\n    from collections import Counter\n    import matplotlib.pyplot as plt\n    import numpy as np\n    age_distribution = Counter()\n    for name, group in df.groupby('name'):\n        if len(group) > 1:\n            age_distribution[name] = group['age'].value_counts().to_dict()\n    plt.figure(figsize=(10, 6))\n    plt.hist(df['age'], bins=range(int(df['age'].min()), int(df['age'].max()) + 2), align='left', rwidth=0.8)\n    plt.title('Age Distribution')\n    plt.xlabel('Age')\n    plt.ylabel('Frequency')\n    plt.grid(axis='y', alpha=0.75)\n    plt.show()\n    return age_distribution, plt.gcf()"
  },
  {
    "output": "def task_func(l=None):\n    if l is None:\n        l = random.sample(ELEMENTS, 10)\n    arr = np.array(l)\n    if len(arr) < 3:\n        return arr\n    return np.concatenate((arr[3:], arr[:3]))"
  },
  {
    "output": "from flask import Flask, request, render_template\nimport logging\n\napp = Flask(__name__, template_folder='templates')\n\n@app.route('/', methods=['POST'])\ndef index():\n    data = request.get_json()\n    logging.info(f\"Received data: {data}\")\n    return render_template('index.html', data=data)"
  },
  {
    "output": "def extract_and_resolve_urls(input_string):\n    import re\n    import socket\n    urls = re.findall(r'https?://(?:[a-zA-Z0-9-]+\\.)+[a-zA-Z]{2,}', input_string)\n    result = {}\n    for url in urls:\n        domain = url.split('/')[2]\n        try:\n            ip = socket.gethostbyname(domain)\n            result[domain] = ip\n        except socket.gaierror:\n            raise socket.gaierror(f\"Domain {domain} could not be resolved\")\n    return result"
  },
  {
    "output": "def task_func(df):\n    numeric_cols = df.select_dtypes(include=['number']).columns\n    for col in df.columns:\n        if col not in numeric_cols:\n            try:\n                df[col] = pd.to_numeric(df[col], errors='coerce')\n                numeric_cols = numeric_cols.union([col])\n            except:\n                pass\n    scaler = StandardScaler()\n    df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n    return df"
  },
  {
    "output": "```python\nimport pandas as pd\nimport numpy as np\n\ndef task_func(data, cols):\n    df = pd.DataFrame(data, columns=cols)\n    numeric_cols = df.select_dtypes(include=np.number).columns\n    correlation_matrix = df[numeric_cols].corr()\n    return correlation_matrix\n```"
  },
  {
    "output": "import numpy as np\nfrom scipy.stats import iqr\ndef task_func(L):\n    # Flatten the nested list\n    flat_list = np.concatenate([np.array(sublist) for sublist in L])\n    # Calculate the interquartile range\n    iqr_value = iqr(flat_list)\n    return iqr_value"
  },
  {
    "output": "class EmailHandler:\n    def handle_post(self, data):\n        try:\n            import smtplib\n            from email.mime.text import MIMEText\n            from email.mime.multipart import MIMEMultipart\n\n            sender_email = \"your_email@example.com\"\n            receiver_email = \"receiver@example.com\"\n            password = \"your_password\"\n\n            message = MIMEMultipart()\n            message[\"From\"] = sender_email\n            message[\"To\"] = receiver_email\n            message[\"Subject\"] = \"New Request\"\n\n            body = \"Data received: \" + str(data)\n            message.attach(MIMEText(body, \"plain\"))\n\n            server = smtplib.SMTP(\"smtp.example.com\", 587)\n            server.starttls()\n            server.login(sender_email, password)\n            text = message.as_string()\n            server.sendmail(sender_email, receiver_email, text)\n            server.quit()\n\n            return \"Email sent successfully\"\n        except smtplib.SMTPException as e:\n            return \"SMTP error: \" + str(e)\n        except Exception as e:\n            return \"An error occurred: \" + str(e)"
  },
  {
    "output": "import numpy as np\nfrom itertools import combinations\n\ndef task_func(matrix):\n    sorted_array = np.sort(matrix.flatten())\n    unique_pairs = list(combinations(sorted_array, 2))\n    return (sorted_array, unique_pairs)"
  },
  {
    "output": "def fetch_and_convert_to_df(url):\n    import requests\n    import pandas as pd\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        data = response.json()\n        return pd.DataFrame(data)\n    except requests.exceptions.RequestException as e:\n        return f\"Network error: {e}\"\n    except ValueError as e:\n        return f\"Invalid JSON: {e}\"\n    except Exception as e:\n        return f\"Unexpected error: {e}\""
  },
  {
    "output": "import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.datasets import load_boston\nimport numpy as np\n\ndef generate_correlation_heatmap(output_file):\n    try:\n        boston = load_boston()\n        df = pd.DataFrame(boston.data, columns=boston.feature_names)\n        df['MEDV'] = boston.target\n        corr = df.corr()\n        plt.figure(figsize=(10, 8))\n        ax = sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\")\n        plt.savefig(output_file)\n        return ax\n    except Exception as e:\n        raise ValueError(f\"An error occurred: {str(e)}\")"
  },
  {
    "output": "import re\nimport csv\nimport requests\nimport os\n\ndef task_func():\n    response = requests.get('https://api.example.com/data')\n    data = response.text\n    pattern = re.compile(r'pattern')\n    matches = pattern.findall(data)\n    with open('matched_data.csv', 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        for match in matches:\n            writer.writerow([match])\n    return os.path.abspath('matched_data.csv')"
  },
  {
    "output": "import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport ast\n\ndef task_func(csv_file):\n    df = pd.read_csv(csv_file)\n    df['list'] = df['list'].apply(ast.literal_eval)\n    df['sum'] = df['list'].apply(lambda x: sum(x))\n    df['mean'] = df['list'].apply(lambda x: np.mean(x))\n    df['std'] = df['list'].apply(lambda x: np.std(x))\n    df = df.drop(columns=['list'])\n    sns.histplot(df['mean'], kde=False)\n    return df, sns.histplot(df['mean'], kde=False)"
  },
  {
    "output": "from itertools import cycle\nfrom random import shuffle\nfrom collections import Counter\n\ndef task_func(l):\n    cycled = cycle(l)\n    shuffled = list(cycled)\n    shuffle(shuffled)\n    first_30 = shuffled[:30]\n    return Counter(first_30)"
  },
  {
    "output": "def task_func(request):\n    try:\n        auth_header = request.headers.get('Authorization')\n        if not auth_header:\n            return 'Missing authorization header', 401\n        parts = auth_header.split()\n        if parts[0].lower() != 'basic':\n            return 'Invalid authorization type', 401\n        decoded = base64.b64decode(parts[1]).decode('utf-8')\n        username, password = decoded.split(':', 1)\n        expected_hash = '5f4dcc3b5aa9661096a88d705e360000'  # Example hash for 'password'\n        if not username or not password:\n            return 'Invalid credentials', 401\n        if f\"{username}:{password}\" != base64.b64decode(expected_hash).decode('utf-8'):\n            return 'Invalid credentials', 401\n        return 'Authentication successful', 200\n    except Exception as e:\n        return f'Error: {str(e)}', 500"
  },
  {
    "output": "import csv\n\ndef find_most_common_values(csv_file_path):\n    with open(csv_file_path, 'r') as file:\n        reader = csv.reader(file)\n        headers = next(reader)\n        if not headers:\n            return {}\n        rows = list(reader)\n        if not rows:\n            return {}\n        result = {}\n        for col_index, header in enumerate(headers):\n            column_values = [row[col_index] for row in rows]\n            unique_values = {}\n            for value in column_values:\n                unique_values[value] = unique_values.get(value, 0) + 1\n            max_count = max(unique_values.values())\n            candidates = [k for k, v in unique_values.items() if v == max_count]\n            candidates.sort()\n            result[header] = candidates[0]\n        return result"
  },
  {
    "output": "def task_func(input_text, output_file):\n    import re\n    words = re.findall(r'\\b\\w+\\b', input_text)\n    filtered = [word for word in words if word.startswith('$') and not re.fullmatch(r'[^a-zA-Z0-9]+', word)]\n    with open(output_file, 'w') as f:\n        f.write('\\n'.join(filtered))\n    return f\"{output_file}\""
  },
  {
    "output": "Error generating code"
  },
  {
    "output": "import os\nfrom datetime import datetime\n\ndef task_func(filepath: str) -> dict:\n    if not os.path.exists(filepath):\n        raise FileNotFoundError(f\"The file {filepath} does not exist.\")\n    \n    file_size = os.path.getsize(filepath)\n    modification_time = os.path.getmtime(filepath)\n    modification_date = datetime.fromtimestamp(modification_time).strftime('%Y-%m-%d %H:%M:%S')\n    \n    return {\n        'size': file_size,\n        'last_modified': modification_date\n    }"
  },
  {
    "output": ""
  },
  {
    "output": "import pandas as pd\n\ndef load_and_clean_csv(file_path, column_name):\n    df = pd.read_csv(file_path)\n    df[column_name] = df[column_name].str.replace('\\n', '<br>')\n    return df"
  },
  {
    "output": "def task_func(source_dir, dest_dir, extension):\n    import os\n    import shutil\n    if not os.path.exists(source_dir) or not os.path.exists(dest_dir):\n        raise FileNotFoundError\n    result = []\n    for filename in os.listdir(source_dir):\n        if filename.endswith(extension):\n            src_path = os.path.join(source_dir, filename)\n            dest_path = os.path.join(dest_dir, filename)\n            if not os.path.exists(dest_path):\n                shutil.move(src_path, dest_path)\n                result.append(dest_path)\n    return result"
  },
  {
    "output": "plt.grid(axis='y')"
  },
  {
    "output": "```python\nimport struct\n\ndef task_func(hex_string=KEY):\n    # Convert hex string to float\n    float_value = float.fromhex(hex_string)\n    \n    # Convert float to 32-bit binary representation (little-endian)\n    binary_bytes = struct.pack('<f', float_value)\n    \n    return binary_bytes\n```"
  },
  {
    "output": "```python\nimport os\nimport re\n\ndef find_files_and_write_config(directory, pattern, target_dir):\n    # Step 1: Validate the input\n    if not os.path.exists(directory):\n        raise ValueError(f\"Directory {directory} does not exist.\")\n    \n    # Compile the regular expression pattern\n    try:\n        regex = re.compile(pattern)\n    except re.error as e:\n        raise ValueError(f\"Invalid regular expression pattern: {e}\")\n\n    # Step 2: Search for files\n    matched_files = []\n    for filename in os.listdir(directory):\n        if re.fullmatch(pattern, filename):\n            matched_files.append(os.path.join(directory, filename))\n\n    # Step 3: Write to a configuration file\n    config_file_path = os.path.join(target_dir, \"config.txt\")\n    with open(config_file_path, 'w') as config_file:\n        for file_path in matched_files:\n            config_file.write(file_path + '\\n')\n\n    # Step 4: Return the configuration file path\n    return config_file_path"
  },
  {
    "output": "```python\nimport pandas as pd\nimport numpy as np\n\ndef task_func(data_size=1000, column_names=['A', 'B', 'C', 'D', 'E'], seed=0):\n    np.random.seed(seed)\n    data = np.random.randint(1, 101, size=(data_size, len(column_names)))\n    df = pd.DataFrame(data, columns=column_names)\n    df = df.applymap(lambda x: -1 if x < 10 else x)\n    return df\n```"
  },
  {
    "output": "def task_func(data, n_clusters, random_state=None):\n    import numpy as np\n    import matplotlib.pyplot as plt\n    from sklearn.cluster import KMeans\n    \n    if not isinstance(data, np.ndarray) or data.ndim != 2:\n        raise ValueError(\"Data must be a 2D numpy array.\")\n    if not isinstance(n_clusters, int) or n_clusters <= 0:\n        raise ValueError(\"n_clusters must be a positive integer.\")\n    \n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state)\n    kmeans.fit(data)\n    labels = kmeans.labels_\n    centroids = kmeans.cluster_centers_\n    \n    plt.scatter(data[:, 0], data[:, 1], c=labels, cmap='viridis', s=50)\n    plt.scatter(centroids[:, 0], centroids[:, 1], c='red', s=200, marker='x')\n    plt.title('K-means Clustering')\n    plt.xlabel('Feature 1')\n    plt.ylabel('Feature 2')\n    plt.show()"
  },
  {
    "output": "import json\nimport pandas as pd\n\ndef task_func(result, csv_file_path=\"test.csv\", json_file_path=\"test.json\"):\n    with open(json_file_path, 'w') as json_file:\n        json.dump(result, json_file)\n    df = pd.DataFrame(result)\n    df.to_csv(csv_file_path, index=False)"
  },
  {
    "output": "def task_func(filename, num_rows, fields):\n    import csv\n    import random\n    with open(filename, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerow(fields)\n        for _ in range(num_rows):\n            row = [random.choice(field) if isinstance(field, list) else random.randint(1, 100) for field in fields]\n            writer.writerow(row)"
  },
  {
    "output": "def task_func(ax, num_points):\n    if not isinstance(ax, plt.Axes) or not isinstance(num_points, int) or num_points < 0:\n        raise ValueError\n    theta = np.random.uniform(0, 2*np.pi, num_points)\n    r = np.random.uniform(0, 1, num_points)\n    ax.scatter(theta, r)\n    ax.set_thetagrids(np.arange(0, 360, 10))\n    return ax"
  },
  {
    "output": "def process_data(data):\n    try:\n        result = {}\n        for item in data:\n            if isinstance(item, dict):\n                result.update(item)\n            elif isinstance(item, list):\n                result['lists'] = result.get('lists', []) + item\n            else:\n                result['other'] = result.get('other', []) + [item]\n        return result\n    except Exception as e:\n        import logging\n        logging.error(f\"An error occurred: {e}\")\n        return {}"
  },
  {
    "output": "import random\nimport statistics\n# Constants\nAGE_RANGE = (22, 60)\n\ndef task_func(dict1):\n    employee_ages = dict1.get(\"EMP$$\", [])\n    if not employee_ages:\n        num_employees = random.randint(5, 15)\n        employee_ages = [random.randint(AGE_RANGE[0], AGE_RANGE[1]) for _ in range(num_employees)]\n    mean = statistics.mean(employee_ages)\n    median = statistics.median(employee_ages)\n    mode = statistics.mode(employee_ages) if len(set(employee_ages)) != len(employee_ages) else []\n    return (mean, median, mode)"
  },
  {
    "output": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\ndef generate_and_plot_stacked_bar_chart(num_categories):\n    np.random.seed(42)\n    data = np.random.rand(num_categories, 3)\n    df = pd.DataFrame(data, columns=['Category', 'Value1', 'Value2'])\n    df['Category'] = df['Category'].astype(int)\n    df = df.sort_values('Category')\n    df.set_index('Category', inplace=True)\n    df.plot(kind='bar', stacked=True)\n    plt.title('Stacked Bar Chart')\n    plt.xlabel('Category')\n    plt.ylabel('Value')\n    plt.show()"
  },
  {
    "output": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.spatial import Voronoi\nimport matplotlib.patches as mpatches\n\ndef task_func(points):\n    np.random.seed(42)\n    jitter = np.random.normal(0, 0.01, points.shape)\n    points_jittered = points + jitter\n    vor = Voronoi(points_jittered)\n    fig, ax = plt.subplots()\n    voronoi_plot = voronoi_plot_2d(vor, ax=ax)\n    ax.set_title('Voronoi Diagram')\n    ax.set_aspect('equal')\n    return vor, ax"
  },
  {
    "output": "def generate_normal_distribution(length):\n    import numpy as np\n    import matplotlib.pyplot as plt\n    np.random.seed(0)\n    data = np.random.normal(0, 1, length)\n    x = np.linspace(-4, 4, 1000)\n    pdf = (1/(np.sqrt(2*np.pi))) * np.exp(-x**2/2)\n    plt.hist(data, bins=30, density=True, alpha=0.6, color='g')\n    plt.plot(x, pdf, 'k', linewidth=2)\n    plt.title('Histogram and PDF of Normal Distribution')\n    plt.xlabel('Value')\n    plt.ylabel('Density')\n    plt.grid(True)\n    return data, plt.gca()"
  },
  {
    "output": "def task_func(input_list):\n    import pandas as pd\n    import numpy as np\n    counts = np.array([t[0] for t in input_list])\n    weights = np.array([t[1] for t in input_list])\n    z_scores = (counts - np.mean(counts)) / np.std(counts)\n    min_weight = np.min(weights)\n    max_weight = np.max(weights)\n    min_max_scaled_weights = (weights - min_weight) / (max_weight - min_weight)\n    df = pd.DataFrame({\n        'z_score': z_scores,\n        'min_max_scaled_weight': min_max_scaled_weights\n    })\n    return df"
  },
  {
    "output": "import matplotlib.pyplot as plt\nimport time\nimport random\n\ndef generate_random_data(duration):\n    timestamps = []\n    values = []\n    start_time = time.time()\n    while (time.time() - start_time) < duration:\n        current_time = time.time() - start_time\n        timestamps.append(current_time)\n        values.append(random.random())\n        plt.plot(timestamps, values, 'r-')\n        plt.pause(0.01)\n    plt.show()\n    return (timestamps, values)"
  },
  {
    "output": "import json\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef process_json_and_plot(json_data):\n    data = json.loads(json_data)\n    numerical_data = [item for item in data if all(isinstance(val, (int, float)) for val in item.values())]\n    numerical_data = np.array(numerical_data)\n    min_vals = numerical_data.min(axis=0)\n    max_vals = numerical_data.max(axis=0)\n    normalized = (numerical_data - min_vals) / (max_vals - min_vals)\n    plt.plot(normalized)\n    plt.show()"
  },
  {
    "output": "def task_func(filepath, destination_dir):\n    import os\n    import shutil\n    import ctypes\n    dll_name = os.path.basename(filepath)\n    dll_path = os.path.abspath(filepath)\n    dll_dir = os.path.dirname(dll_path)\n    dll_files = [f for f in os.listdir(dll_dir) if f.endswith('.dll')]\n    for dll_file in dll_files:\n        src = os.path.join(dll_dir, dll_file)\n        dst = os.path.join(destination_dir, dll_file)\n        shutil.move(src, dst)\n    dll_handle = ctypes.windll.LoadLibrary(dll_path)\n    return dll_name"
  },
  {
    "output": "def task_func(result, colors=['b', 'g', 'r', 'c', 'm', 'y', 'k']):\n    from_users = [entry['from_user'] for entry in result]\n    selected_color = random.choice(colors)\n    sns.histplot(data=from_users, color=selected_color)\n    plt.title('Histogram of \"from_user\" Values')\n    plt.xlabel('From User')\n    plt.ylabel('Frequency')\n    plt.show()"
  },
  {
    "output": "```python\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndef task_func(records: np.ndarray, random_seed: int = 0) -> pd.DataFrame:\n    if len(records.shape) != 2:\n        raise ValueError(\"ValueError: If records is not 2D.\")\n    \n    np.random.seed(random_seed)\n    # Shuffle the features\n    shuffled_features = np.random.permutation(records.shape[1])\n    shuffled_data = records[:, shuffled_features]\n    \n    # Normalize the data\n    scaler = StandardScaler()\n    normalized_data = scaler.fit_transform(shuffled_data)\n    \n    # Create feature names\n    feature_names = [f\"f{i+1}\" for i in range(records.shape[1])]\n    np.random.shuffle(feature_names)\n    \n    # Convert to DataFrame\n    df = pd.DataFrame(normalized_data, columns=feature_names)\n    return df\n```"
  },
  {
    "output": "```python\nfrom datetime import datetime\nimport os\nfrom pathlib import Path\n# Constants\nDATE_FORMAT = '%Y-%m-%d %H:%M:%S'\n\ndef task_func(file_path):\n    path = Path(file_path)\n    if not path.exists():\n        raise FileNotFoundError(f\"The file {file_path} does not exist.\")\n    creation_time = datetime.fromtimestamp(path.stat().st_ctime)\n    formatted_time = creation_time.strftime(DATE_FORMAT)\n    return formatted_time\n```"
  },
  {
    "output": "from collections import Counter\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\nimport pandas as pd\ndef task_func(df, n_clusters=3, random_state=None, n_init=10):\n    point_tuples = list(zip(df['x'], df['y']))\n    point_counts = Counter(point_tuples)\n    unique_points = [point for point, count in point_counts.items() if count == 1]\n    unique_df = pd.DataFrame(unique_points, columns=['x', 'y'])\n    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state, n_init=n_init).fit(unique_df)\n    unique_df['cluster'] = kmeans.labels_\n    plt.scatter(unique_df['x'], unique_df['y'], c=unique_df['cluster'], cmap='viridis')\n    plt.xlabel('x')\n    plt.ylabel('y')\n    plt.title('Clustered Points')\n    plt.show()\n    return (point_counts, unique_df, plt.gcf())"
  },
  {
    "output": "return {\n        'mean': mean,\n        'median': median,\n        'std_dev': std_dev\n    }"
  },
  {
    "output": "```python\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n\ndef task_func(df):\n    # Step 1: Replace missing values with column averages\n    numeric_cols = df.select_dtypes(include=np.number).columns\n    df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())\n\n    # Step 2: Normalize numeric columns using MinMaxScaler\n    scaler = MinMaxScaler()\n    normalized_data = scaler.fit_transform(df[numeric_cols])\n\n    # Step 3: Replace original numeric columns with normalized values\n    df[numeric_cols] = normalized_data\n\n    # Step 4: Draw a box plot for each numeric column\n    fig, ax = plt.subplots()\n    df[numeric_cols].boxplot(ax=ax)\n\n    # Return the normalized"
  },
  {
    "output": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef generate_and_visualize_data(categories, num_columns):\n    if num_columns > len(categories):\n        raise ValueError(\"The number of columns cannot exceed the number of available categories.\")\n    data = {category: np.random.rand(10) for category in categories}\n    df = pd.DataFrame(data)\n    df.plot(kind='bar', stacked=True)\n    plt.title('Stacked Bar Chart')\n    plt.xlabel('Index')\n    plt.ylabel('Values')\n    plt.show()"
  },
  {
    "output": "import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\ndef transform_categorical_to_numerical(data):\n    df = pd.DataFrame(data)\n    le = LabelEncoder()\n    encoded = le.fit_transform(df.iloc[:, 0])\n    return pd.DataFrame({'Category': df.iloc[:, 0], 'Encoded': encoded})"
  },
  {
    "output": "plt.plot(history.history['val_loss'])\nplt.title('Training and Validation Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper right')\nplt.show()"
  },
  {
    "output": "color='red', label='Standard Normal PDF')\n    ax.legend()\n    return ax, normalized_data"
  },
  {
    "output": "def task_func(text):\n    import pandas as pd\n    import regex as re\n    pattern = r'Score: (\\d+), Category: ([A-Za-z]+)'\n    matches = re.findall(pattern, text)\n    data = [{'Score': int(score), 'Category': category} for score, category in matches]\n    df = pd.DataFrame(data)\n    return df"
  },
  {
    "output": "if len(indices) == 0:\n        return ('N/A', 'N/A', 'N/A', 'N/A')\n    \n    # Perform statistical analysis\n    mean = np.mean(indices)\n    variance = np.var(indices)\n    skewness = stats.skew(indices)\n    kurtosis = stats.kurtosis(indices)\n    \n    # Plot distribution\n    plt.hist(indices, bins=10, edgecolor='black')\n    plt.title('Distribution of Row Indices')\n    plt.xlabel('Index')\n    plt.ylabel('Frequency')\n    plt.show()\n    \n    return (mean, variance, skewness, kurtosis)"
  },
  {
    "output": "```python\nimport collections\nimport json\nimport os\n\ndef task_func(directory_path: str) -> dict:\n    key_counter = collections.Counter()\n    \n    for filename in os.listdir(directory_path):\n        file_path = os.path.join(directory_path, filename)\n        if os.path.isfile(file_path) and filename.endswith('.json'):\n            with open(file_path, 'r') as file:\n                data = json.load(file)\n                keys = data.keys()\n                key_counter.update(keys)\n    \n    return dict(key_counter)\n```"
  },
  {
    "output": "def task_func(df, mapping, record_histograms=None):\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(\"Input must be a DataFrame\")\n    for col in df.columns:\n        if col in mapping:\n            df[col] = df[col].replace(mapping[col])\n    if record_histograms:\n        for col in record_histograms:\n            if col in df.columns:\n                plt.hist(df[col], bins=10)\n                plt.title(f\"Histogram of {col}\")\n                plt.xlabel(col)\n                plt.ylabel(\"Frequency\")\n                plt.show()"
  },
  {
    "output": "color='purple', linestyle='--', label=f'Std Dev: {std_dev:.2f}')\n    ax.legend()\n    \n    # Save the plot as a PNG file\n    plt.savefig('random_histogram.png')\n    plt.close()"
  },
  {
    "output": "def task_func(input_dict):\n    sorted_items = sorted(input_dict.items())\n    from prettytable import PrettyTable\n    table = PrettyTable()\n    table.field_names = [\"Key\", \"Value\"]\n    table.add_rows(sorted_items)\n    return table"
  },
  {
    "output": "def task_func(input_data):\n    try:\n        result = eval(input_data)\n        return result\n    except Exception as e:\n        return f\"Error: {str(e)}\""
  },
  {
    "output": "def clean_and_hash(input_string):\n    import re\n    cleaned = re.sub(r'[^a-zA-Z0-9]', '', input_string)\n    import hashlib\n    return hashlib.sha256(cleaned.encode()).hexdigest()"
  },
  {
    "output": "def task_func(url, headers=None, timeout=10):\n    import requests\n    from bs4 import BeautifulSoup\n    try:\n        response = requests.get(url, headers=headers, timeout=timeout)\n        response.raise_for_status()\n        return BeautifulSoup(response.content, 'html.parser')\n    except Exception as e:\n        return None"
  },
  {
    "output": "True"
  },
  {
    "output": "import pandas as pd\nimport numpy as np\n\ndef generate_cdf_dataframe(start_range, end_range, length, columns):\n    data = np.random.uniform(start_range, end_range, (length, len(columns)))\n    df = pd.DataFrame(data, columns=columns)\n    cdf = df.apply(lambda col: (col - col.min()) / (col.max() - col.min()))\n    return cdf.reset_index(drop=True)"
  },
  {
    "output": "from sklearn.preprocessing import MinMaxScaler\n\ndef task_func(my_dict):\n    if 'array' not in my_dict or not isinstance(my_dict['array'], (list, tuple, np.ndarray)):\n        raise TypeError(\"The 'array' key is missing or not a valid array type.\")\n    arr = my_dict['array']\n    if isinstance(arr, (list, tuple)):\n        arr = np.array(arr)\n    scaler = MinMaxScaler()\n    normalized = scaler.fit_transform(arr.reshape(-1, 1)).flatten()\n    my_dict['normalized_array'] = normalized\n    return my_dict"
  },
  {
    "output": "def normalize_and_plot(file_path, title, x_label, y_label):\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    df = pd.read_csv(file_path)\n    df['column1'] = (df['column1'] - df['column1'].min()) / (df['column1'].max() - df['column1'].min())\n    plt.plot(df['column1'])\n    plt.title(title)\n    plt.xlabel(x_label)\n    plt.ylabel(y_label)\n    plt.show()"
  },
  {
    "output": "import base64\nimport hashlib\nimport os\n\ndef encrypt_password(password):\n    salt = os.urandom(16)\n    hashed = hashlib.sha256(salt + password.encode('utf-8')).digest()\n    return base64.b64encode(salt + hashed).decode('utf-8')"
  },
  {
    "output": "def task_func(path):\n    import sys\n    import os\n    sys.path.append(path)\n    os.makedirs(path, exist_ok=True)\n    return path"
  },
  {
    "output": "import pandas as pd\nimport random\nimport os\n\ndef select_random_data_from_csv(csv_files, num_records):\n    selected_file = random.choice(csv_files)\n    if os.path.getsize(selected_file) == 0:\n        return (selected_file, pd.DataFrame())\n    df = pd.read_csv(selected_file)\n    selected_rows = random.sample(range(len(df)), num_records)\n    return (selected_file, df.iloc[selected_rows])"
  },
  {
    "output": "def task_func(L):\n    import numpy as np\n    from collections import Counter\n    import matplotlib.pyplot as plt\n\n    mean = np.mean(L)\n    median = np.median(L)\n    counter = Counter(L)\n    mode = counter.most_common(1)[0][0]\n    std_dev = np.std(L)\n    fig, ax = plt.subplots()\n    ax.hist(L, bins=10, edgecolor='black')\n    return {\n        'mean': mean,\n        'median': median,\n        'mode': mode,\n        'std_dev': std_dev,\n        'plot': ax\n    }"
  },
  {
    "output": "from collections import Counter\nimport random\n\ndef generate_and_analyze_letter_pairs():\n    predefined_list = ['AA', 'AB', 'AC', 'AD', 'AE', 'AF', 'AG', 'AH', 'AI', 'AJ', 'AK', 'AL', 'AM', 'AN', 'AO', 'AP', 'AQ', 'AR', 'AS', 'AT', 'AU', 'AV', 'AW', 'AX', 'AY', 'AZ', 'BA', 'BB', 'BC', 'BD', 'BE', 'BF', 'BG', 'BH', 'BI', 'BJ', 'BK', 'BL', 'BM', 'BN', 'BO', 'BP', 'BQ', 'BR', 'BS', 'BT', 'BU', 'BV', 'BW', 'BX', 'BY', 'BZ']\n    sample_size = 1000\n    random_pairs = [random.choice(predefined_list) for _ in range(sample_size)]\n    frequency = Counter(random_pairs)\n    return frequency"
  },
  {
    "output": "def generate_and_plot_temperature_data(days_in_past):\n    import random\n    import matplotlib.pyplot as plt\n    if days_in_past < 1:\n        raise ValueError(\"days_in_past must be at least 1\")\n    dates = [f\"Day {i}\" for i in range(days_in_past, 0, -1)]\n    temperatures = [random.randint(15, 35) for _ in range(days_in_past)]\n    plt.plot(dates, temperatures)\n    plt.xlabel('Day')\n    plt.ylabel('Temperature (°C)')\n    plt.title('Temperature Trend')\n    plt.show()"
  },
  {
    "output": "def process_json_file(file_path):\n    import json\n    import pandas as pd\n    data = json.load(open(file_path))\n    results = {}\n    for key in data[0].keys():\n        values = [d[key] for d in data]\n        numeric_values = [v for v in values if isinstance(v, (int, float))]\n        mean = sum(numeric_values) / len(numeric_values) if numeric_values else None\n        median = sorted(numeric_values)[len(numeric_values) // 2] if numeric_values else None\n        results[key] = {'mean': mean, 'median': median}\n    df = pd.DataFrame(results).T\n    df = df.sort_index()\n    return df"
  },
  {
    "output": "import pickle\nimport os\nimport random\nimport string\n\ndef task_func(strings, filename=None):\n    if filename is None:\n        filename = f\"random_strings_{int(os.path.getmtime(''))}.pickle\"\n    if strings is None:\n        strings = [''.join(random.choices(string.ascii_letters + string.digits, k=10)) for _ in range(5)]\n    with open(filename, 'wb') as f:\n        pickle.dump(strings, f)\n    with open(filename, 'rb') as f:\n        loaded_strings = pickle.load(f)\n    return loaded_strings"
  },
  {
    "output": "import re\nimport socket\n\ndef task_func(ip_addresses: list) -> dict:\n    result = {}\n    for ip in ip_addresses:\n        if re.match(r'^(\\d{1,3}\\.){3}\\d{1,3}$', ip):\n            try:\n                hostname = socket.gethostbyaddr(ip)[0]\n                result[ip] = hostname\n            except socket.herror:\n                result[ip] = None\n    return result"
  },
  {
    "output": "from collections import Counter\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk import ngrams\n\ndef task_func(text, n=2):\n    text = re.sub(r'\\W+', ' ', text).lower()\n    stop_words = set(stopwords.words('english'))\n    words = [word for word in text.split() if word not in stop_words]\n    grams = ngrams(words, n)\n    return dict(Counter(grams))"
  },
  {
    "output": "def task_func():\n    return \"Hello, World!\""
  },
  {
    "output": "def task_func(db_path, users, salt):\n    import sqlite3\n    import hashlib\n    conn = sqlite3.connect(db_path)\n    cursor = conn.cursor()\n    updated_count = 0\n    for user in users:\n        if not isinstance(salt, str):\n            raise TypeError(\"Salt must be a string\")\n        hashed_password = hashlib.sha256(salt.encode() + user['password'].encode()).hexdigest()\n        cursor.execute(\"UPDATE user SET password = ? WHERE id = ?\", (hashed_password, user['id']))\n        updated_count += 1\n    conn.commit()\n    conn.close()\n    return updated_count"
  },
  {
    "output": "def task_func(url):\n    import requests\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        content = response.content\n        if not content:\n            return {}\n        encoding = response.apparent_encoding\n        try:\n            return response.json()\n        except Exception as e:\n            return {}\n    except requests.exceptions.RequestException as e:\n        raise Exception(f\"Request failed: {e}\") from e"
  },
  {
    "output": "import numpy as np\nimport gzip\nimport struct\n\ndef compress_numpy_array(arr):\n    data = arr.tobytes()\n    compressed = gzip.compress(data)\n    return compressed"
  },
  {
    "output": "df = pd.DataFrame(data)\n    \n    # Draw the bar chart\n    plt.figure(figsize=(12, 6))\n    plt.bar(df['Timezone'], df['Datetime'])\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.show()"
  },
  {
    "output": "def fit_quadratic(data, plot=False):\n    import numpy as np\n    from scipy.optimize import curve_fit\n    x = np.array([i for i in range(len(data))])\n    y = np.array(data)\n    def quadratic_func(x, a, b, c):\n        return a * x**2 + b * x + c\n    params, _ = curve_fit(quadratic_func, x, y)\n    fitted_values = quadratic_func(x, *params)\n    if plot:\n        import matplotlib.pyplot as plt\n        plt.scatter(x, y, label='Data')\n        plt.plot(x, fitted_values, color='red', label='Fit')\n        plt.legend()\n        plt.show()\n    return params, fitted_values"
  },
  {
    "output": "def scrape_and_save_to_csv(url, output_file):\n    import urllib.request\n    from bs4 import BeautifulSoup\n    import csv\n    response = urllib.request.urlopen(url)\n    html = response.read()\n    soup = BeautifulSoup(html, 'html.parser')\n    data = []\n    for row in soup.find_all('tr'):\n        row_data = [cell.get_text(strip=True) for cell in row.find_all(['td', 'th'])]\n        if row_data:\n            data.append(row_data)\n    with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerows(data)\n    return output_file"
  },
  {
    "output": "from collections import Counter\nimport itertools\nfrom random import randint\n\ndef task_func(T1, RANGE=100):\n    T1_int = [int(x) for x in T1]\n    num_integers = sum(T1_int)\n    random_integers = [randint(0, RANGE) for _ in range(num_integers)]\n    counter = Counter(random_integers)\n    return counter"
  },
  {
    "output": "def task_func(input_str, verify_hash=None):\n    import hashlib\n    if not isinstance(input_str, (str, type(None))) or (verify_hash is not None and not isinstance(verify_hash, (str, type(None)))):\n        raise TypeError(\"Input and verify_hash must be strings or None\")\n    hash_obj = hashlib.sha256()\n    hash_obj.update(input_str.encode('utf-8'))\n    computed_hash = hash_obj.hexdigest()\n    if verify_hash is not None:\n        if computed_hash != verify_hash:\n            raise ValueError(\"Hash mismatch\")\n    return computed_hash"
  },
  {
    "output": "import pandas as pd\nfrom datetime import datetime\nimport pytz\n\ndef convert_utc_to_timezone(utc_time_str, target_timezone):\n    utc_time = datetime.strptime(utc_time_str, \"%Y-%m-%d %H:%M:%S\")\n    utc_time = utc_time.replace(tzinfo=pytz.utc)\n    target_tz = pytz.timezone(target_timezone)\n    localized_time = utc_time.astimezone(target_tz)\n    return pd.DataFrame([localized_time.strftime(\"%Y-%m-%d %H:%M:%S\")], columns=[\"converted_time\"])"
  },
  {
    "output": "def process_and_scale_data(df, plot=False):\n    if 'Date' not in df.columns or 'Value' not in df.columns:\n        raise ValueError(\"DataFrame must contain 'Date' and 'Value' columns\")\n    df['Date'] = pd.to_datetime(df['Date'])\n    df.set_index('Date', inplace=True)\n    df = df['Value'].str.split(',', expand=True).apply(pd.to_numeric, errors='coerce')\n    scaler = StandardScaler()\n    scaled = scaler.fit_transform(df)\n    scaled_df = pd.DataFrame(scaled, index=df.index, columns=df.columns)\n    if plot:\n        scaled_df.plot(kind='bar')\n    return scaled_df, plt if plot else None"
  },
  {
    "output": "def task_func(directory, zip_filename):\n    import os\n    import zipfile\n    from Crypto.PublicKey import RSA\n    from Crypto.Cipher import PKCS1_OAEP\n    from Crypto.Random import get_random_bytes\n    import base64\n    \n    key = RSA.generate(2048)\n    public_key = key.publickey()\n    \n    encrypted_files = []\n    \n    for filename in os.listdir(directory):\n        file_path = os.path.join(directory, filename)\n        if os.path.isfile(file_path):\n            with open(file_path, 'rb') as f:\n                data = f.read()\n            cipher = PKCS1_OAEP.new(public_key)\n            encrypted_data = cipher.encrypt(data)\n            encrypted_filename = f\"encrypted_{filename}\"\n            with open(encrypted_filename, 'wb') as f:\n                f.write(encrypted_data)\n            encrypted_files.append(encrypted_filename)\n    \n    with zipfile.ZipFile(zip_filename, 'w') as zipf:\n        for file in encrypted_files:\n            zipf.write(file)\n    \n    os.makedirs('encrypted_files', exist_ok=True)\n    for file in encrypted_files:\n        os.rename(file, os.path.join('encrypted_files', file))\n    \n    return public_key, zip_filename"
  },
  {
    "output": "```python\nimport numpy as np\nfrom scipy.stats import norm\n\ndef task_func(data: np.ndarray, threshold: float = 2.0) -> list:\n    mean = np.mean(data)\n    std_dev = np.std(data)\n    var = std_dev ** 2\n    \n    if std_dev == 0:\n        return [], mean, var\n    \n    z_scores = (data - mean) / std_dev\n    outlier_indices = np.where(np.abs(z_scores) > threshold)[0].tolist()\n    \n    return outlier_indices, mean, var\n```"
  },
  {
    "output": "import sys\nimport json\nfrom datetime import datetime\n\ndef task_func(path_to_add, json_file_path):\n    sys.path.append(path_to_add)\n    current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n    with open(json_file_path, 'w') as f:\n        json.dump({\"timestamp\": current_time}, f)"
  },
  {
    "output": "def task_func(json_data, path):\n    import json\n    import matplotlib.pyplot as plt\n    import numpy as np\n    try:\n        data = json.loads(json_data)\n        current = data\n        for key in path:\n            current = current[key]\n        if isinstance(current, list):\n            plt.boxplot(current)\n            plt.show()\n        else:\n            raise ValueError(\"Path leads to a non-list value\")\n    except Exception as e:\n        return str(e)"
  },
  {
    "output": "for col1, col2 in selected_pairs) return df_filtered, selected_pairs else return pd.DataFrame(), []"
  },
  {
    "output": "def identify_duplicates_and_plot(df):\n    import pandas as pd\n    import numpy as np\n    import matplotlib.pyplot as plt\n    from scipy.stats import norm\n    \n    duplicates = df['value'].value_counts().loc[lambda x: x > 1]\n    duplicate_counts = duplicates.sort_values(ascending=False)\n    \n    plt.figure(figsize=(10, 6))\n    plt.hist(df['value'], bins=30, density=True, alpha=0.6, color='g')\n    mu, std = np.mean(df['value']), np.std(df['value'])\n    x = np.linspace(mu - 3*std, mu + 3*std, 100)\n    plt.plot(x, norm.pdf(x, mu, std), 'k', linewidth=2)\n    plt.title('Histogram with Normal Distribution Curve')\n    plt.xlabel('Value')\n    plt.ylabel('Density')\n    plt.grid(True)\n    plt.show()\n    \n    return duplicate_counts, plt.gcf()"
  },
  {
    "output": "from itertools import chain\nimport numpy as np\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\ndef task_func(L):\n    data = list(chain.from_iterable(L))\n    data_array = np.array(data).reshape(-1, 1)\n    kmeans = KMeans(n_clusters=3, random_state=0).fit(data_array)\n    labels = kmeans.labels_\n    fig, ax = plt.subplots()\n    ax.scatter(data_array, np.zeros_like(data_array), c=labels, cmap='viridis', s=10)\n    return ax"
  },
  {
    "output": "def task_func():\n    return \"Hello, world!\""
  },
  {
    "output": "import yaml\nimport math\n\ndef process_yaml_file(file_path, key):\n    with open(file_path, 'r') as file:\n        data = yaml.safe_load(file)\n    if key in data:\n        data[key] = math.cos(data[key])\n    with open(file_path, 'w') as file:\n        yaml.safe_dump(data, file)\n    return data"
  },
  {
    "output": "import sys\nimport sqlite3\n\ndef task_func(path):\n    sys.path.append(path)\n    conn = sqlite3.connect('path.db')\n    c = conn.cursor()\n    c.execute('''CREATE TABLE IF NOT EXISTS paths (path TEXT PRIMARY KEY)''')\n    c.execute(\"SELECT * FROM paths WHERE path = ?\", (path,))\n    if not c.fetchone():\n        c.execute(\"INSERT INTO paths (path) VALUES (?)\", (path,))\n        conn.commit()\n    conn.close()\n    return path"
  },
  {
    "output": "```python\nimport pytz\nimport numpy as np\nfrom dateutil.parser import parse\nimport math\n\nMOON_PHASES_YEARS = np.array([1987, 1994, 2001, 2008, 2015, 2022])\n\ndef task_func(date_str, from_tz, to_tz):\n    # Parse the input date string\n    date = parse(date_str)\n    \n    # Convert the date to the specified"
  },
  {
    "output": "from django.http import HttpResponse\nimport uuid\nimport json\n\ndef task_func(data):\n    response = HttpResponse(json.dumps(data), content_type=\"application/json\")\n    response[\"X-Request-ID\"] = str(uuid.uuid4())\n    return response"
  },
  {
    "output": "def serialize_data(data):\n    import json\n    from datetime import datetime\n    from decimal import Decimal\n    class CustomEncoder(json.JSONEncoder):\n        def default(self, obj):\n            if isinstance(obj, datetime):\n                return obj.isoformat()\n            if isinstance(obj, Decimal):\n                return str(obj)\n            return super().default(obj)\n    return json.dumps(data, cls=CustomEncoder)"
  },
  {
    "output": "import pandas as pd\nimport random\n\ndef process_strings(strings):\n    modified = []\n    for s in strings:\n        if ',' in s:\n            parts = s.split(',')\n            random_index = random.randint(0, len(parts)-1)\n            modified_str = ','.join(parts[:random_index] + parts[random_index+1:])\n            modified.append(modified_str)\n        else:\n            modified.append(s)\n    return pd.DataFrame({'Original': strings, 'Modified': modified})"
  },
  {
    "output": "```python\nimport cv2\nimport numpy as np\nimport os\nfrom sklearn.cluster import KMeans\n\ndef task_func(image_path='image.jpg', n_clusters=3, random_seed=42):\n    # Check if the image file exists\n    if not os.path.exists(image_path):\n        raise FileNotFoundError(f\"The image file '{image_path}' does not exist.\")\n    \n    # Check if n_clusters is a positive integer\n    if not isinstance(n_clusters, int) or n_clusters <= 0:\n        raise ValueError(\"n_clusters must be a positive integer.\")\n    \n    # Read the image\n    original_image = cv2.imread(image_path)\n    if original_image is None:\n        raise FileNotFoundError(f\"The image file '{image_path}' could not be read.\")\n    \n    # Reshape the image to a list of pixels\n    pixels = original_image.reshape(-1, 3"
  },
  {
    "output": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n\ndef generate_distribution(mean, std_dev):\n    samples = np.random.normal(mean, std_dev, 1000)\n    fig = plt.figure()\n    plt.hist(samples, bins=30, density=True, alpha=0.6, color='g')\n    stats.probplot(samples, dist=\"norm\", plot=plt)\n    return fig"
  },
  {
    "output": "```python\nimport pandas as pd\nfrom statistics import mean\n\ndef task_func(df: pd.DataFrame) -> dict:\n    if 'Name' not in df.columns or 'Score' not in df.columns:\n        raise ValueError(\"DataFrame must contain 'Name' and 'Score' columns"
  },
  {
    "output": "def move_files_by_extension(source_dir, dest_dir, extension):\n    import os\n    import shutil\n    count = 0\n    for filename in os.listdir(source_dir):\n        if filename.endswith(extension):\n            file_path = os.path.join(source_dir, filename)\n            dest_path = os.path.join(dest_dir, filename)\n            shutil.move(file_path, dest_path)\n            count += 1\n    return count"
  },
  {
    "output": "def task_func(lst):\n    try:\n        lst.append(12)\n        total = sum(lst)\n        import random\n        random_numbers = [random.randint(1, 100) for _ in range(total)]\n        import matplotlib.pyplot as plt\n        plt.hist(random_numbers, bins=10)\n        plt.show()\n    except Exception as e:\n        print(f\"An error occurred: {e}\")"
  },
  {
    "output": "class MyRequestHandler(http.server.BaseHTTPRequestHandler):\n    def do_POST(self):\n        content_length = int(self.headers['Content-Length'])\n        post_data = self.rfile.read(content_length)\n        self.send_response(200)\n        self.end_headers()\n        self.wfile.write(b'POST request received')"
  },
  {
    "output": "import wikipedia\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\ndef task_func(page_title):\n    try:\n        page = wikipedia.page(page_title)\n        text = page.summary\n        wordcloud = WordCloud().generate(text)\n        plt.figure(figsize=(10, 5))\n        plt.imshow(wordcloud, interpolation='bilinear')\n        plt.axis(\"off\")\n        plt.show()\n        fig, ax = plt.subplots()\n        ax.imshow(wordcloud, interpolation='bilinear')\n        ax.axis(\"off\")\n        return ax\n    except wikipedia.exceptions.PageNotFoundError:\n        return None"
  },
  {
    "output": "import pandas as pd\nimport numpy as np\n\ndef task_func():\n    np.random.seed(42)\n    articles = []\n    for _ in range(100):\n        title = f\"Article {np.random.randint(1, 1000)}\"\n        content = \" \".join(np.random.choice([\"This\", \"is\", \"a\", \"random\", \"article\"], size=np.random.randint(5, 20)))\n        author = np.random.choice([\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\"])\n        date = pd.to_datetime(\"2023-01-01\") + np.random.randint(0, 365, size=1)\n        articles.append({\n            \"title\": title,\n            \"content\": content,\n            \"author\": author,\n            \"date\": date\n        })\n    return pd.DataFrame(articles)"
  },
  {
    "output": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(list_of_pairs):\n    if not list_of_pairs:\n        raise Exception(\"Input array is empty\")\n    try:\n        df = pd.DataFrame(list_of_pairs, columns=['Category', 'Value'])\n        if not pd.api.types.is_numeric_dtype(df['Value']):\n            raise ValueError(\"Values are not numeric\")\n        scaler = MinMaxScaler()\n        df['Value'] = scaler.fit_transform(df[['Value']])\n        return df\n    except Exception as e:\n        raise e"
  },
  {
    "output": "import random\n\ndef generate_palindrome_sentence(word_pool, MIN_WORDS, MAX_WORDS):\n    length = random.randint(MIN_WORDS, MAX_WORDS)\n    if length % 2 == 0:\n        first_half = random.sample(word_pool, length // 2)\n        second_half = first_half[::-1]\n    else:\n        first_half = random.sample(word_pool, (length - 1) // 2)\n        middle = [random.choice(word_pool)]\n        second_half = first_half[::-1]\n    sentence = first_half + middle + second_half\n    return ' '.join(sentence)"
  },
  {
    "output": "import pandas as pd\nimport random\nfrom random import shuffle\n\ndef process_strings(strings):\n    def apply_operation(s, operation):\n        if operation == 'remove':\n            start = random.randint(0, len(s) - 1)\n            end = random.randint(start + 1, len(s))\n            return s[:start] + s[end:]\n        elif operation == 'replace':\n            start = random.randint(0, len(s) - 1)\n            end = random.randint(start + 1, len(s))\n            replacement = ''.join(random.choices('abcdefghijklmnopqrstuvwxyz', k=end - start))\n            return s[:start] + replacement + s[end:]\n        elif operation == 'shuffle':\n            substring = list(random.choices(s, k=random.randint(1, len(s))))\n            shuffle(substring)\n            return ''.join(substring)\n        elif operation == 'randomize':\n            return ''.join(random.choices('abcdefghijklmnopqrstuvwxyz', k=len(s)))\n        else:\n            return s\n\n    operations = ['remove', 'replace', 'shuffle', 'randomize']\n    modified = []\n    for s in strings:\n        op = random.choice(operations)\n        modified.append(apply_operation(s, op))\n    \n    df = pd.DataFrame({\n        'Original': strings,\n        'Modified': modified\n    })\n    return df"
  },
  {
    "output": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef task_func(data, columns):\n    df = data.copy()\n    scaler = MinMaxScaler()\n    df[columns] = scaler.fit_transform(df[columns])\n    return df"
  },
  {
    "output": "def task_func():\n    return \"Hello, world!\""
  },
  {
    "output": "from collections import Counter\nimport heapq\nimport string\ndef task_func(my_dict):\n    letter_counts = Counter({letter: my_dict.get(letter, 0) for letter in string.ascii_lowercase})\n    most_common_letters = heapq.nsmallest(3, letter_counts.items(), key=lambda x: x[1])\n    most_common_letters = [letter for letter, _ in most_common_letters]\n    return most_common_letters"
  },
  {
    "output": "def combine_and_plot(list1, list2, predefined_items):\n    combined = list1 + list2\n    from collections import Counter\n    counts = Counter(combined)\n    predefined_counts = {item: counts.get(item, 0) for item in predefined_items}\n    import matplotlib.pyplot as plt\n    items = predefined_counts.keys()\n    values = predefined_counts.values()\n    plt.bar(items, values)\n    plt.xlabel('Items')\n    plt.ylabel('Frequency')\n    plt.title('Frequency of Predefined Items')\n    plt.show()"
  },
  {
    "output": "def task_func(L):\n    dimensions = []\n    for sublist in L:\n        for dim in sublist:\n            dimensions.append(dim)\n    dfs = []\n    for dim in dimensions:\n        rows, cols = dim\n        df = pd.DataFrame(np.random.randint(1, 101, size=(rows, cols)))\n        dfs.append(df)\n    return dfs"
  },
  {
    "output": "import pandas as pd\nimport itertools\nimport random\n\ndef task_func(colors, states):\n    # Compute the Cartesian product of colors and states\n    combinations = list(itertools.product(colors, states))\n    \n    # Shuffle the combinations\n    random.shuffle(combinations)\n    \n    # Flatten the combinations into a list of strings in \"Color:State\" format\n    flattened = [f\"{color}:{state}\" for color, state in combinations]\n    \n    # Determine the number of columns: the smaller of the lengths of colors or states\n    num_columns = min(len(colors), len(states))\n    \n    # Determine the number of rows: ceiling of total combinations divided by num_columns\n    num_rows = (len(combinations) + num_columns - 1) // num_columns\n    \n    # Reshape the flattened list into a 2D array with num_rows rows and num_columns columns\n    reshaped = [flattened[i*num_columns:(i+1)*num_columns] for i in range(num_rows)]\n    \n    # Create a pandas DataFrame\n    df = pd.DataFrame(resh"
  },
  {
    "output": "def task_func():\n    return \"Hello, World!\""
  },
  {
    "output": "def task_func(df, feature, target, n):\n    import pandas as pd\n    from sklearn.linear_model import LinearRegression\n    import heapq\n\n    if feature not in df.columns or target not in df.columns:\n        raise ValueError(\"Feature or target column not found in DataFrame\")\n\n    X = df[[feature]]\n    y = df[target]\n    model = LinearRegression().fit(X, y)\n    residuals = y - model.predict(X)\n    indices = heapq.nlargest(n, range(len(residuals)), key=lambda i: abs(residuals[i]))\n    return indices, model"
  },
  {
    "output": "```python\nimport random\nimport re\n\n# Constants\nWORD_LIST = [\"sample\", \"text\", \"contains\", \"several\", \"words\", \"including\"]\n\ndef task_func(n_sentences):\n    sentences = []\n    for _ in range(n_sentences):\n        # Randomly select 3-5 words from the word list\n        sentence_words = random.choices(WORD_LIST, k=random.randint(3, 5))\n        # Join the words and add a period at the end\n        sentence = \" \".join(sentence_words) + \".\"\n        # Convert to lowercase and remove non-alphanumeric characters except for the period\n        cleaned_sentence = re.sub(r'[^\\w\\s.]', '', sentence).lower()\n        sentences.append(cleaned_sentence)\n    # Join all sentences into a single string\n    return \" \".join(sentences)\n```"
  },
  {
    "output": "figs.append(fig)"
  },
  {
    "output": "import matplotlib.pyplot as plt\nimport numpy as np\n\ndef plot_sales_trends_with_std_dev(sales_data):\n    fig, ax = plt.subplots()\n    products = list(sales_data.keys())\n    dates = np.arange(1, 13)\n    for i, product in enumerate(products):\n        sales = sales_data[product]\n        mean = np.mean(sales)\n        std = np.std(sales)\n        ax.plot(dates, sales, label=product)\n        ax.fill_between(dates, mean - std, mean + std, alpha=0.3)\n    ax.set_xlabel('Month')\n    ax.set_ylabel('Sales')\n    ax.set_title('Sales Trends with Standard Deviation')\n    ax.legend()\n    return ax"
  },
  {
    "output": "def task_func(filepath):\n    import hashlib\n    with open(filepath, 'rb') as f:\n        data = f.read()\n    md5_hash = hashlib.md5(data).hexdigest()\n    sha256_hash = hashlib.sha256(data).hexdigest()\n    print(f\"MD5: {md5_hash}\")\n    print(f\"SHA256: {sha256_hash}\")\n    print(f\"File name: {filepath.split('/')[-1]}\")"
  },
  {
    "output": "import os\nimport json\nimport random\n\ndef task_func(directory, n):\n    os.makedirs(directory, exist_ok=True)\n    for i in range(n):\n        file_path = os.path.join(directory, f'file_{i}.json')\n        data = {'number': random.randint(1, 100)}\n        with open(file_path, 'w') as f:\n            json.dump(data, f)\n        with open(file_path, 'r') as f:\n            content = f.read()\n        with open(file_path, 'w') as f:\n            f.write(content)"
  },
  {
    "output": "unstack the yellow block from on top of the red block"
  },
  {
    "output": ""
  },
  {
    "output": "python_code_returner(\"Generate the Python code to represent the action of lifting Crate2 from pallet2 at depot2 using Hoist2.\")"
  },
  {
    "output": "False"
  },
  {
    "output": ""
  },
  {
    "output": "Use hoist3 to drop crate1 to pallet3 at distributor0."
  },
  {
    "output": "unstack the blue block from on top of the red block"
  },
  {
    "output": ""
  },
  {
    "output": "load package_0 into truck_0 at location_0_1"
  },
  {
    "output": "load package_1 into truck_2"
  },
  {
    "output": "Use hoist0 to lift crate1 from pallet0 at depot0."
  },
  {
    "output": "False"
  },
  {
    "output": ""
  },
  {
    "output": "False"
  },
  {
    "output": "def next_action():\n    return \"Pick up the blue block.\""
  },
  {
    "output": "False"
  },
  {
    "output": "Feast(\"a\", \"b\", \"Harmony\")"
  },
  {
    "output": "Move crate2 from its current location to a position where it can be placed on pallet3."
  },
  {
    "output": "Feast object a from object"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "The plan is correct and complete. It ensures that all packages are moved to their target locations according to the given rules."
  },
  {
    "output": "False"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Use hoist1 to lift crate2 from pallet1 at depot1."
  },
  {
    "output": ""
  },
  {
    "output": "Feast object c from"
  },
  {
    "output": "def next_step():\n    return \"Pick up the orange block and place it on top of the red block.\""
  },
  {
    "output": ""
  },
  {
    "output": "Use hoist2 to unload crate2 from truck0 at depot2."
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Please provide the complete current state and the goal."
  },
  {
    "output": "Use hoist3 to lift crate0 from pallet3 at distributor0."
  },
  {
    "output": "pick up the yellow block"
  },
  {
    "output": "def next_step(): return 'unstack the blue block from on top of the yellow block'"
  },
  {
    "output": "Use hoist3 to lift crate0 from pallet3 at distributor0."
  },
  {
    "output": "pick up the red block"
  },
  {
    "output": "pick up the blue block"
  },
  {
    "output": "Use hoist1 to lift crate2 from pallet1 at depot1."
  },
  {
    "output": "Attack object c"
  },
  {
    "output": ""
  },
  {
    "output": "We cannot determine the next step in the plan without the initial conditions, available actions, and restrictions."
  },
  {
    "output": "pick up the blue block"
  },
  {
    "output": "unstack the yellow block from on top of the blue block"
  },
  {
    "output": "Feast object a from"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "False"
  },
  {
    "output": ""
  },
  {
    "output": "Feast action"
  },
  {
    "output": "Feast object d"
  },
  {
    "output": ""
  },
  {
    "output": "def next_action(): return 'unstack the orange block from on top of the blue block'"
  },
  {
    "output": "Feast object a from object c"
  },
  {
    "output": "Cannot determine the next action without additional information."
  },
  {
    "output": ""
  },
  {
    "output": "unstack the blue block from on top of the orange block"
  },
  {
    "output": "drive truck0 from depot2 to depot1"
  },
  {
    "output": ""
  },
  {
    "output": "False"
  },
  {
    "output": ""
  },
  {
    "output": "python_code_returner(\"Generate Python code to lift crate1 from pallet1\")"
  },
  {
    "output": "pick up the blue block"
  },
  {
    "output": "Complete the plan with the correct sequence of actions to achieve the goal."
  },
  {
    "output": "False"
  },
  {
    "output": "True"
  },
  {
    "output": "pick up the blue block"
  },
  {
    "output": "False"
  },
  {
    "output": "The current state of the system is incomplete and lacks clarity, making it difficult to determine the next step."
  },
  {
    "output": "move package_0 from location_0_0 to location_1_0"
  },
  {
    "output": ""
  },
  {
    "output": "Pick up the blue block."
  },
  {
    "output": "The plan is incomplete and cannot be evaluated for feasibility."
  },
  {
    "output": "wretched object_5 object_10 object_11 object_3"
  },
  {
    "output": "Use hoist1 to lift crate0 from pallet1 at depot1."
  },
  {
    "output": "Please provide the complete plan for evaluation."
  },
  {
    "output": "\"Pick up the red block\""
  },
  {
    "output": ""
  },
  {
    "output": "Analyze the initial conditions and determine which action can be taken."
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "The next action cannot be determined without the complete current state and plan details."
  },
  {
    "output": "clip object_23 object_7 object_"
  },
  {
    "output": "Use hoist1 to lift crate0 from pallet1 at depot1."
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "unstack the blue block from on top of the red block"
  },
  {
    "output": ""
  },
  {
    "output": "We cannot determine the next step in the plan without the initial conditions, available actions, and constraints."
  },
  {
    "output": "unstack the blue block from on top of the yellow block"
  },
  {
    "output": ""
  },
  {
    "output": "The plan is incomplete and requires additional steps to achieve the goal. The next step would be to continue the plan by specifying the remaining actions to move crate0 to pallet1 and crate1 to crate0."
  },
  {
    "output": "def next_action(): return \"Feast\""
  },
  {
    "output": "False"
  },
  {
    "output": "unstack the red block"
  },
  {
    "output": "pick up the yellow block"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "def next_step():\n    return \"unstack(yellow, orange)\""
  },
  {
    "output": "The current state of the world is incomplete and lacks critical information needed to determine the next step."
  },
  {
    "output": "pick up the yellow block"
  },
  {
    "output": "def next_action():\n    return \"Pick up the orange block.\""
  },
  {
    "output": "Use a hoist at depot1 to lift crate2 from pallet1."
  },
  {
    "output": "\"Pick up the yellow block\""
  },
  {
    "output": "False"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Please provide the complete and clear plan or clarify the current state of the objects."
  },
  {
    "output": ""
  },
  {
    "output": "Step 1: Unstack the yellow block from the table."
  },
  {
    "output": ""
  },
  {
    "output": "Feast object a from object"
  },
  {
    "output": ""
  },
  {
    "output": "pick up the red block"
  },
  {
    "output": "Feast object a from object c"
  },
  {
    "output": ""
  },
  {
    "output": "True"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "feast object d from object c"
  },
  {
    "output": "Please provide the complete current state and the goal."
  },
  {
    "output": "def next_step(): return 'unstack the orange block from the table'"
  },
  {
    "output": "load package"
  },
  {
    "output": "Cannot determine the next action without the current state."
  },
  {
    "output": "def next_action():\n    return \"Pick up the red block and stack it under the yellow block\""
  },
  {
    "output": "False"
  },
  {
    "output": "The information provided is incomplete and lacks clarity, making it impossible to determine the next action. Please provide a complete and clear description of the current state, the available actions, and the desired goal."
  },
  {
    "output": "Move crate0 from pallet1 to pallet2."
  },
  {
    "output": "pick up the yellow block"
  },
  {
    "output": "The plan's feasibility needs to be evaluated in detail against the initial conditions and action rules. The error suggests a problem with the CoT analysis, and further review is required."
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "unstack the red block from on top of the yellow block"
  },
  {
    "output": "def next_action(): return 'feast object d from object e'"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "unstack the blue block from on top of the red block"
  },
  {
    "output": "Error: No problem found for CoT analysis"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "True"
  },
  {
    "output": "def next_action(): return 'pick up the yellow block'"
  },
  {
    "output": "unstack the blue block from on top of the red block"
  },
  {
    "output": "False"
  },
  {
    "output": "pick up the red block"
  },
  {
    "output": "def next_step():\n    return \"Pick up the yellow block and stack it on top of the blue block\""
  },
  {
    "output": "unstack the yellow block from on top of the orange block"
  },
  {
    "output": "False"
  },
  {
    "output": "False"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "def feast_action(): return 'Feast object a from object d'"
  },
  {
    "output": "pick up the red block"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "The problem statement is incomplete, making it impossible to evaluate the feasibility of the plan. Please provide the full problem statement."
  },
  {
    "output": "unstack the yellow block from on top of the orange block"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "\"Pick up the red block\""
  },
  {
    "output": "Use hoist3 to lift crate0 from pallet3 at distributor0."
  },
  {
    "output": "Feast object a from object d"
  },
  {
    "output": "Insufficient information to determine the next action."
  },
  {
    "output": "False"
  },
  {
    "output": "unstack the orange block from on top of the blue block"
  },
  {
    "output": "def next_action(): return 'pick up the red block'"
  },
  {
    "output": "Overcome object c from object a"
  },
  {
    "output": ""
  },
  {
    "output": "True"
  },
  {
    "output": "Use hoist0 to load crate"
  },
  {
    "output": "unstack the red block from on top of the yellow block"
  },
  {
    "output": "Use hoist3 to lift crate0 from pallet3 at distributor0."
  },
  {
    "output": ""
  },
  {
    "output": "Feast action"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "False"
  },
  {
    "output": "False"
  },
  {
    "output": "Feast object from object c"
  },
  {
    "output": "def next_action(): return 'unstack the white block from on top of the orange block'"
  },
  {
    "output": "The initial conditions are not fully provided, so it is not possible to determine the next action."
  },
  {
    "output": "False"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Error in CoT analysis; problem description not recognized."
  },
  {
    "output": "Use hoist0 to lift crate0 from pallet0 at depot0."
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "pick up the white"
  },
  {
    "output": "The plan is incomplete and lacks the necessary details to determine the next action. Please provide the complete plan or additional information about the current state."
  },
  {
    "output": "drive truck0 from depot1 to depot0"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "pick up the blue block"
  },
  {
    "output": "The problem is incomplete and cannot be analyzed."
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Use hoist2 to lift crate0 from pallet2 at depot2."
  },
  {
    "output": ""
  },
  {
    "output": "overcome object b from object c"
  },
  {
    "output": "False"
  },
  {
    "output": "pick up the red block"
  },
  {
    "output": "pick up the red block"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "The next step cannot be determined without the initial conditions, available actions, and restrictions."
  },
  {
    "output": ""
  },
  {
    "output": "False"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "clip object_18 object_7 object_14"
  },
  {
    "output": "I will analyze the plan step by step to determine its feasibility based on the initial conditions and the rules of the actions."
  },
  {
    "output": ""
  },
  {
    "output": "drive truck0 from distributor0 to depot1"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "pick up the blue block"
  },
  {
    "output": "False"
  },
  {
    "output": ""
  },
  {
    "output": "Feast object a from"
  },
  {
    "output": "Insufficient information to determine the next action."
  },
  {
    "output": ""
  },
  {
    "output": "python_code_returner(\"load package_0 into airplane_0 at location_1_0\")"
  },
  {
    "output": "I will continue evaluating the rest of the plan step by step."
  },
  {
    "output": ""
  },
  {
    "output": "Use hoist1 to lift crate2 from pallet0 at depot0\nUse hoist1 to load crate2 into truck0 at depot0\nDrive truck0 from depot0 to depot1\nUse hoist1 to unload crate2 from truck0 at depot1\nUse hoist1 to drop crate2 to crate1 at depot1"
  },
  {
    "output": "unstack the yellow block from on top of the blue block"
  },
  {
    "output": "def next_action(current_state, rules):\n    if current_state['blue_block']['on_table'] and current_state['blue_block']['clear']:\n        return \"Pick up the blue block\"\n    return \"No action\""
  },
  {
    "output": "The first step is valid."
  },
  {
    "output": "Feast action"
  },
  {
    "output": "Use a hoist to lift crate0 from pallet0 and drop it on pallet1."
  },
  {
    "output": "pick up the red block"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "The plan is complete and addresses all the required steps to achieve the goal."
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Use hoist3 to lift crate2 from pallet3 at distributor0."
  },
  {
    "output": "Use a hoist to lift crate0 from pallet2 at depot2."
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Evaluate the initial conditions and determine which action can be performed first based on the conditions."
  },
  {
    "output": ""
  },
  {
    "output": "def next_action(): return 'pick up the red block'"
  },
  {
    "output": "unstack the yellow block from on top of the blue block"
  },
  {
    "output": "\"clip object_17 object_6 object_15\""
  },
  {
    "output": "False"
  },
  {
    "output": "move package_0 from location_0_1 to location_2_0"
  },
  {
    "output": "[Hard problem, difficulty=7] Step-by-step reasoning:\n### Step 1: Identify what we're asked to find  \nWe are asked to **evaluate the feasibility of a plan** based on **initial conditions** and **restrictions on actions**. However, the problem does not provide specific details about the plan, the initial conditions, or the restrictions. Therefore, we need to **assume a generic scenario** to demonstrate the process of evaluating feasibility.\n\n---\n\n### Step 2: Break down the problem into smaller parts  \nTo evaluate the feasibility of a plan, we can break the process into the following logical steps:\n\n1. **Understand the Plan**: What is the goal of the plan? What actions are proposed?\n2. **Identify Initial Conditions**: What is the current state of the system or environment?\n3. **Identify Restrictions on Actions**: Are there any constraints, limitations, or rules that must be followed?\n4. **Assess Compatibility**: Do the proposed actions align with the initial conditions and restrictions?\n5. **Determine Feasibility**: Based on the above, is the plan achievable under the given constraints?\n\n---\n\n### Step 3: Solve each part carefully  \nLet’s assume a hypothetical scenario to illustrate the process:\n\n#### **Scenario:**\n- **Plan**: Build a new bridge across a river to improve transportation.\n- **Initial Conditions**:\n  - The river is 100 meters wide.\n  - The river has a current of 2 meters per second.\n  - The river is 5 meters deep.\n  - There are no existing bridges.\n  - The area is a rural region with limited infrastructure.\n- **Restrictions on Actions**:\n  - No heavy machinery is available.\n  - No permits for construction are available.\n  - No funding is available.\n  - No skilled labor is available.\n\n#### **Step 1: Understand the Plan**\n- The goal is to build a new bridge to improve transportation.\n- The proposed action is to construct a bridge across a river.\n\n#### **Step 2: Identify Initial Conditions**\n- The river is 100 meters wide.\n- The river has a current of 2 meters per second.\n- The river is 5 meters deep.\n- No existing bridges.\n- Rural area with limited infrastructure.\n\n#### **Step 3: Identify Restrictions on Actions**\n- No heavy machinery.\n- No permits.\n- No funding.\n- No skilled labor.\n\n#### **Step 4: Assess Compatibility**\n- **Building a bridge** requires heavy machinery, skilled labor, and funding.\n- The **lack of"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Use hoist2 to lift crate1 from crate0 at depot2"
  },
  {
    "output": "when done."
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Attack object c"
  },
  {
    "output": "pick up the red block"
  },
  {
    "output": "unstack the blue block from on top of the red block"
  },
  {
    "output": "def next_step(): return 'unstack the red block from on top of the blue block'"
  },
  {
    "output": ""
  },
  {
    "output": "Determine the current location of Crate0."
  },
  {
    "output": "Use hoist1 to lift crate0 from pallet1 at depot1."
  },
  {
    "output": "unstack the blue block from on top of the orange block"
  },
  {
    "output": "def unstack_block(block, from_block): print(f'Unstacking {block} from on top of {from_block}')"
  },
  {
    "output": ""
  },
  {
    "output": "True"
  },
  {
    "output": "pick up the blue block"
  },
  {
    "output": "pick up the blue block"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "unstack the yellow block from on top of the red block"
  },
  {
    "output": "Use hoist1 to lift crate1 from crate0 at depot1."
  },
  {
    "output": "feast object d from object a"
  },
  {
    "output": ""
  },
  {
    "output": "False"
  },
  {
    "output": "Evaluate the current state to ensure that the conditions for the"
  },
  {
    "output": "Insufficient information to determine the next action."
  },
  {
    "output": ""
  },
  {
    "output": "False"
  },
  {
    "output": "\"Pick up the red block\""
  },
  {
    "output": "False"
  },
  {
    "output": ""
  },
  {
    "output": "Use hoist1 to lift crate0 from pallet1 at depot1."
  },
  {
    "output": "Use hoist3 to lift crate2 from crate1 at distributor0."
  },
  {
    "output": ""
  },
  {
    "output": "I will wait for the plan to be provided before proceeding."
  },
  {
    "output": ""
  },
  {
    "output": "def next_action():\n    return \"Pick up the red block\""
  },
  {
    "output": "The next action cannot be determined without the initial conditions and the plan. Please provide the initial conditions and the plan to proceed."
  },
  {
    "output": "\"Pick up the yellow block\""
  },
  {
    "output": "False"
  },
  {
    "output": "Feast object c from object a"
  },
  {
    "output": "unstack the orange block from on top of the red block"
  },
  {
    "output": ""
  },
  {
    "output": "def next_action(): return 'pick up the red block'"
  },
  {
    "output": "The initial conditions and the goal are not fully specified, so I cannot determine the next action."
  },
  {
    "output": "unstack the white block from on top of the red block"
  },
  {
    "output": ""
  },
  {
    "output": "Use hoist2 to lift crate1 from crate0 at depot2."
  },
  {
    "output": ""
  },
  {
    "output": "False"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "The plan's feasibility cannot be determined without further information or clarification."
  },
  {
    "output": "Please provide the complete list of initial conditions."
  },
  {
    "output": "We cannot determine the next step in the plan without the initial conditions, available actions, and constraints."
  },
  {
    "output": "overcome object d from object c"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "def next_action():\n    return \"Pick up the blue block.\""
  },
  {
    "output": "pick up the blue block, put down the blue block, pick up the orange block, put down the orange block, pick up the red block, stack the red block on top of the orange block, put down the red block"
  },
  {
    "output": "pick up the red block"
  },
  {
    "output": "False"
  },
  {
    "output": ""
  },
  {
    "output": "The next step in the plan is to perform the Feast action."
  },
  {
    "output": "True"
  },
  {
    "output": ""
  },
  {
    "output": "The next action cannot be \"feast object a from object e\" because the condition \""
  },
  {
    "output": ""
  },
  {
    "output": "Use hoist2 to lift crate2 from depot2."
  },
  {
    "output": "Overcome object c from object a."
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "unstack the red block from on top of the blue block"
  },
  {
    "output": "False"
  },
  {
    "output": "False"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Use hoist1 to lift crate1 from pallet0 at depot0 and drop it on pallet2 at depot0."
  },
  {
    "output": ""
  },
  {
    "output": "def perform_action():\n    # Perform the Feast action on object c from object d\n    # This action will change the relationship of object c\n    # from craving object d to craving object a\n    # based on the problem's logic\n    pass"
  },
  {
    "output": ""
  },
  {
    "output": "Use hoist1 to lift crate2 from pallet1 at depot1."
  },
  {
    "output": "FEAST object b from object a"
  },
  {
    "output": ""
  },
  {
    "output": "unstack the yellow block from on top of the red block"
  },
  {
    "output": "The plan is incomplete and repetitive, and the initial conditions are not fully understood. A detailed analysis of the initial conditions and the plan is required to determine the next action."
  },
  {
    "output": ""
  },
  {
    "output": "The plan is incomplete and lacks the necessary details to determine the next action."
  },
  {
    "output": "def execute_action():\n    return \"Feast object a from object c\""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "Attack object a"
  },
  {
    "output": "def next_action(): return 'unstack the orange block from on top of the red block'"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "def next_action():\n    return \"Pick up the blue block.\""
  },
  {
    "output": "def next_action(): return 'unstack the yellow block from the orange block'"
  },
  {
    "output": "Please provide a clear question or task to proceed."
  },
  {
    "output": "Feast object a from object"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "pick up the blue block"
  },
  {
    "output": "unstack the blue block from on top of the red block"
  },
  {
    "output": "The plan is valid."
  },
  {
    "output": "def next_action(): return 'overcome object b from object d'"
  },
  {
    "output": ""
  },
  {
    "output": "False"
  },
  {
    "output": "True"
  },
  {
    "output": "Use hoist1 to lift crate0 from pallet1 at depot1."
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "def execute_plan_step():\n    return \"Feast object a from object b\""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "load package_0 into airplane_0 at location_0_0"
  },
  {
    "output": ""
  },
  {
    "output": "True"
  },
  {
    "output": ""
  },
  {
    "output": "unstack the yellow block from on top of the red block"
  },
  {
    "output": "pick up the red block"
  },
  {
    "output": "I will analyze the initial conditions and the plan step by step to determine the next step."
  },
  {
    "output": "feast object a from object d"
  },
  {
    "output": "Drive truck1 from depot2 to distributor0."
  },
  {
    "output": ""
  },
  {
    "output": "True"
  },
  {
    "output": "unstack the red block from on top of the blue block"
  },
  {
    "output": ""
  },
  {
    "output": "clip object_17 object_7 object_15"
  },
  {
    "output": "pick up the red block"
  },
  {
    "output": "True"
  },
  {
    "output": "feast object d from object a"
  },
  {
    "output": "True"
  },
  {
    "output": "Use hoist1 to lift crate1 from pallet1 at depot1\nUse hoist1 to drop crate1 to pallet2 at depot1"
  },
  {
    "output": "unstack the blue block from on top of the red block"
  },
  {
    "output": "unstack the blue block from on top of the yellow block"
  },
  {
    "output": "True"
  },
  {
    "output": "unstack the blue block from on top of the red block"
  },
  {
    "output": "python_code_returner(\"Generate a corrected plan based on the initial conditions and the restrictions on the actions.\")"
  },
  {
    "output": ""
  },
  {
    "output": "True"
  },
  {
    "output": ""
  },
  {
    "output": "pick up the blue block"
  },
  {
    "output": "unstack the blue block from on top of the red block"
  },
  {
    "output": "Use hoist2 to lift crate2 from pallet2 at depot2."
  },
  {
    "output": "attack object"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "unstack the blue block from the red block"
  },
  {
    "output": "def next_action(): return 'feast object c from object d'"
  },
  {
    "output": ""
  },
  {
    "output": "Attack object b"
  },
  {
    "output": "Re-express the problem in a clear and structured manner to enable a proper Chain-of-Thought (CoT) analysis."
  },
  {
    "output": ""
  },
  {
    "output": "print('clip object_14 object_3 object_5')"
  },
  {
    "output": "unstack the yellow block from on top of the orange block"
  },
  {
    "output": "Please provide the complete list of initial conditions."
  },
  {
    "output": ""
  },
  {
    "output": "Feast object a from object d"
  },
  {
    "output": ""
  },
  {
    "output": "Insufficient information to determine the next action."
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "unstack the yellow block from on top of the orange block"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "def next_action():\n    return \"Pick up the red block\""
  },
  {
    "output": "def next_step(): return 'pick up the blue block'"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "unstack the yellow block from on top of the blue block"
  },
  {
    "output": "pick up the red block"
  },
  {
    "output": "True"
  },
  {
    "output": ""
  },
  {
    "output": "Feast object a from object c"
  },
  {
    "output": "def check_conditions(current_state):\n    return (current_state['sneeze'] == object_0 and \n            current_state['texture'] == object_1 and \n            current_state['texture'] == object_2 and \n            current_state['stupendous'] == object_3 and \n            current_state['next'] == (object_0, object_1) and \n            current_state['collect'] == (object_1, object_3) and \n            current_state['collect'] == (object_2, object_3))"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "unstack the blue block from the table"
  },
  {
    "output": "Feasibility cannot be determined with the current information."
  },
  {
    "output": "def next_action(current_state, goal):\n    if current_state['yellow_block']['clear'] and current_state['yellow_block']['on_table']:\n        return \"Pick up yellow block and stack on orange block\"\n    return \"No valid action\""
  },
  {
    "output": "def plan(): unstack('orange', 'blue')"
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "def next_action(): return 'unstack the yellow block from on top of the white block'"
  },
  {
    "output": "def simulate_creation():\n    objects = {\n        'a': {'craves': 'c'},\n        'b': {'craves': 'c'},\n        'c': {'craves': 'a'}\n    }\n    return objects"
  },
  {
    "output": "Use a hoist to lift crate2 from pallet2 at depot2."
  },
  {
    "output": ""
  },
  {
    "output": ""
  },
  {
    "output": "False"
  },
  {
    "output": ""
  },
  {
    "output": "\"drive truck0 from depot1 to depot2\""
  },
  {
    "output": ""
  },
  {
    "output": "False"
  },
  {
    "output": ""
  },
  {
    "output": "True"
  },
  {
    "output": "Feast object c from object b."
  },
  {
    "output": "pick up the orange block"
  },
  {
    "output": ""
  },
  {
    "output": "Feast object d"
  },
  {
    "output": ""
  },
  {
    "output": "Analyze the current state and the plan step by step to determine the next action."
  },
  {
    "output": "The plan is feasible. The steps to achieve the goal are: pick up the orange block and stack it on top of the red block."
  },
  {
    "output": "Feast object a from object d"
  },
  {
    "output": "Evaluate the plan and determine the next action to achieve the goal."
  },
  {
    "output": "pick up the red block"
  },
  {
    "output": "unstack the yellow block from on top of the orange block"
  },
  {
    "output": ""
  },
  {
    "output": "pick up the red block"
  },
  {
    "output": ""
  },
  {
    "output": "feast object d from object b"
  },
  {
    "output": "The next step cannot be determined without the initial conditions and available actions."
  },
  {
    "output": ""
  },
  {
    "output": "pick up the yellow block"
  },
  {
    "output": "Error: No code found"
  },
  {
    "output": "unstack the blue block from on top of the red block"
  },
  {
    "output": "The plan is incomplete and cannot be evaluated for feasibility."
  },
  {
    "output": ""
  },
  {
    "output": "Use hoist2 to lift crate2 from pallet2 at depot2."
  },
  {
    "output": ""
  },
  {
    "output": "unstack the red block from the orange block"
  },
  {
    "output": "unstack the yellow block from on top of the blue block"
  },
  {
    "output": ""
  },
  {
    "output": "def next_step(): return 'pick up the yellow block'"
  }
]